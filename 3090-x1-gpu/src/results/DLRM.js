export const model =
[{"name": "DLRM Training Iteration", "type": "root", "ops": [{"name": "Load Data", "type": "training loop", "instances": 12, "resources": {"cpu2": {"time": {"ts": 1677888387793675000, "dur": 979000, "relative_dur": 0.0009492201172611655, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "979 us"}}, "gpu3": {"time": {"ts": 1677888387842787000, "dur": 3101000, "relative_dur": 0.0030066716890979304, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 359, in train_once\n    with hotline.annotate('Load Data'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/submission_runner.py", "source_file_num": 359, "ops": [{"name": "aten::empty_strided(86%) and 1 other\u2026", "type": "generated", "instances": 2, "id": "3X3gYiJfknsxPfNv", "resources": {"cpu2": {"time": {"ts": 1677888387793675000, "dur": 82000, "relative_dur": 0.026443082876491456, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "82 us"}, "res_name": "aten::empty_strided(86%) and 1 other\u2026"}}, "pretty_name": "aten::empty_strided(86%) and 1 other\u2026", "trace_file": "/results/DLRM/DLRM.3.pt.trace.json", "trace_disk_size": "217 Bytes", "runtime": 82000, "runtime_str": "82 us", "start_timestamp": "00:06:27.793.793675", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "cudaMemcpyAsync", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888387793786000, "dur": 1000, "relative_dur": 0.0003224766204450177, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "cudaMemcpyAsync"}, "gpu3": {"time": {"ts": 1677888387842787000, "dur": 2842000, "relative_dur": 0.9164785553047404, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "3 ms"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "hw8SQD09lSdFKvIm", "pretty_name": "cudaMemcpyAsync", "trace_file": "/results/DLRM/DLRM.4.pt.trace.json", "trace_disk_size": "237 Bytes", "runtime": 2842000, "runtime_str": "3 ms", "start_timestamp": "00:06:27.793.793786", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 2}, {"name": "aten::to(72%) and 5 others\u2026", "type": "generated", "instances": 17, "id": "RmAyrbmYfrVop0Ch", "resources": {"cpu2": {"time": {"ts": 1677888387845619000, "dur": 1001000, "relative_dur": 0.3227990970654628, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 ms"}, "res_name": "aten::to(72%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1677888387845857000, "dur": 31000, "relative_dur": 0.00999677523379555, "relative_gap_to_previous": 0.07352466946146405, "parent_is_longest": true, "runtime_str": "31 us"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "pretty_name": "aten::to(72%) and 5 others\u2026", "trace_file": "/results/DLRM/DLRM.5.pt.trace.json", "trace_disk_size": "1.9 kB", "runtime": 1001000, "runtime_str": "1 ms", "start_timestamp": "00:06:27.845.845619", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 18}], "idx": 1, "id": "lwfMOyVnzVM2AbnF", "pretty_name": "Load Data", "trace_file": "/results/DLRM/DLRM.2.pt.trace.json", "trace_disk_size": "2.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/submission_runner.py", "runtime": 3101000, "runtime_str": "3 ms", "start_timestamp": "00:06:27.793.793675", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 25}, {"name": "Forward", "type": "training loop", "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888387846629000, "dur": 263496000, "relative_dur": 0.25548080083539126, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "263 ms"}}, "gpu3": {"time": {"ts": 1677888387847261000, "dur": 431800000, "relative_dur": 0.41866521617300434, "relative_gap_to_previous": 0.0013312351593458428, "parent_is_longest": true, "runtime_str": "432 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 93, in update_params\n    with hotline.annotate('Forward'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py", "source_file_num": 93, "ops": [{"idx": 3, "name": "Bottom MLP", "type": "Bottom MLP", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 117, in forward\n    with hotline.annotate('Bottom MLP'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 117, "ops": [{"idx": 4, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 123, in forward\n    bot_mlp_output = hotline.annotate_module_list(self.bot_mlp, bot_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1677888387846630000, "dur": 3144000, "relative_dur": 0.30914454277286135, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 ms"}}, "gpu3": {"time": {"ts": 1677888387847261000, "dur": 4373000, "relative_dur": 0.42999016715830873, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4 ms"}}}, "id": "r6ZzTNlCO7E7Y2Yj", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.8.pt.trace.json", "trace_disk_size": "4.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 4373000, "runtime_str": "4 ms", "start_timestamp": "00:06:27.846.846630", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 33}, {"idx": 5, "name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 123, in forward\n    bot_mlp_output = hotline.annotate_module_list(self.bot_mlp, bot_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1677888387849905000, "dur": 73000, "relative_dur": 0.007177974434611603, "relative_gap_to_previous": 0.01288102261553589, "parent_is_longest": true, "runtime_str": "73 us"}}, "gpu3": {"time": {"ts": 1677888387851635000, "dur": 954000, "relative_dur": 0.09380530973451327, "relative_gap_to_previous": 9.832841691248771e-05, "parent_is_longest": true, "runtime_str": "954 us"}}}, "id": "dmS4FVn2mWBnkLas", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.9.pt.trace.json", "trace_disk_size": "1.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 954000, "runtime_str": "954 us", "start_timestamp": "00:06:27.849.849905", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 8}, {"idx": 6, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 123, in forward\n    bot_mlp_output = hotline.annotate_module_list(self.bot_mlp, bot_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1677888387850094000, "dur": 86000, "relative_dur": 0.008456243854473943, "relative_gap_to_previous": 0.011406096361848575, "parent_is_longest": true, "runtime_str": "86 us"}}, "gpu3": {"time": {"ts": 1677888387852589000, "dur": 2990000, "relative_dur": 0.29400196656833827, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "3 ms"}}}, "id": "FbY5Wlpw4FPTH9SS", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.10.pt.trace.json", "trace_disk_size": "1.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 2990000, "runtime_str": "3 ms", "start_timestamp": "00:06:27.850.850094", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 13}, {"idx": 7, "name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 123, in forward\n    bot_mlp_output = hotline.annotate_module_list(self.bot_mlp, bot_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1677888387850300000, "dur": 48000, "relative_dur": 0.00471976401179941, "relative_gap_to_previous": 0.011799410029498525, "parent_is_longest": true, "runtime_str": "48 us"}}, "gpu3": {"time": {"ts": 1677888387855580000, "dur": 478000, "relative_dur": 0.04700098328416912, "relative_gap_to_previous": 9.832841691248771e-05, "parent_is_longest": true, "runtime_str": "478 us"}}}, "id": "UxlvGCF55leq8EOs", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.11.pt.trace.json", "trace_disk_size": "1.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 478000, "runtime_str": "478 us", "start_timestamp": "00:06:27.850.850300", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 8}, {"idx": 8, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 123, in forward\n    bot_mlp_output = hotline.annotate_module_list(self.bot_mlp, bot_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1677888387850459000, "dur": 87000, "relative_dur": 0.00855457227138643, "relative_gap_to_previous": 0.010914454277286136, "parent_is_longest": true, "runtime_str": "87 us"}}, "gpu3": {"time": {"ts": 1677888387856060000, "dur": 1129000, "relative_dur": 0.11101278269419862, "relative_gap_to_previous": 0.00019665683382497542, "parent_is_longest": true, "runtime_str": "1 ms"}}}, "id": "POdolH6xTI205aY7", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.12.pt.trace.json", "trace_disk_size": "1.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 1129000, "runtime_str": "1 ms", "start_timestamp": "00:06:27.850.850459", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 14}, {"idx": 9, "name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 123, in forward\n    bot_mlp_output = hotline.annotate_module_list(self.bot_mlp, bot_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1677888387850663000, "dur": 48000, "relative_dur": 0.00471976401179941, "relative_gap_to_previous": 0.011504424778761062, "parent_is_longest": true, "runtime_str": "48 us"}}, "gpu3": {"time": {"ts": 1677888387857190000, "dur": 241000, "relative_dur": 0.02369714847590954, "relative_gap_to_previous": 9.832841691248771e-05, "parent_is_longest": true, "runtime_str": "241 us"}}}, "id": "eki7vGNiWZwNMM5g", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.13.pt.trace.json", "trace_disk_size": "1.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 241000, "runtime_str": "241 us", "start_timestamp": "00:06:27.850.850663", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 8}], "resources": {"cpu2": {"time": {"ts": 1677888387846630000, "dur": 4081000, "relative_dur": 0.009451134784622511, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4 ms"}}, "gpu3": {"time": {"ts": 1677888387847261000, "dur": 10170000, "relative_dur": 0.023552570634553033, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "10 ms"}}}, "id": "ZYUU2j7sZGT60Ejy", "pretty_name": "Bottom MLP", "trace_file": "/results/DLRM/DLRM.7.pt.trace.json", "trace_disk_size": "11.3 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 10170000, "runtime_str": "10 ms", "start_timestamp": "00:06:27.846.846630", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 84}, {"idx": 10, "name": "ID Lookup", "type": "ID Lookup", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 125, in forward\n    with hotline.annotate('ID Lookup'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 125, "ops": [{"idx": 11, "name": "aten::remainder", "type": "aten::remainder", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 129, in forward\n    with hotline.annotate('aten::remainder'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 129, "resources": {"cpu2": {"time": {"ts": 1677888387850816000, "dur": 197000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "197 us"}}, "gpu3": {"time": {"ts": 1677888387857433000, "dur": 50000, "relative_dur": 0.25380710659898476, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "50 us"}}}, "id": "PdxclCQukrIfh8gx", "pretty_name": "aten::remainder", "trace_file": "/results/DLRM/DLRM.15.pt.trace.json", "trace_disk_size": "2.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 197000, "runtime_str": "197 us", "start_timestamp": "00:06:27.850.850816", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 15}], "resources": {"cpu2": {"time": {"ts": 1677888387850816000, "dur": 197000, "relative_dur": 0.00045622973598888377, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "197 us"}}, "gpu3": {"time": {"ts": 1677888387857433000, "dur": 50000, "relative_dur": 0.0001157943492357573, "relative_gap_to_previous": 4.631773969430292e-06, "parent_is_longest": true, "runtime_str": "50 us"}}}, "id": "NOeIVHCdXYZkB8LZ", "pretty_name": "ID Lookup", "trace_file": "/results/DLRM/DLRM.14.pt.trace.json", "trace_disk_size": "2.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 197000, "runtime_str": "197 us", "start_timestamp": "00:06:27.850.850816", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 15}, {"idx": 12, "name": "Embedding", "type": "Embedding", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 132, in forward\n    with hotline.annotate('Embedding'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 132, "resources": {"cpu2": {"time": {"ts": 1677888387851117000, "dur": 83000, "relative_dur": 0.0001922186197313571, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "83 us"}}, "gpu3": {"time": {"ts": 1677888387857484000, "dur": 6210000, "relative_dur": 0.014381658175081056, "relative_gap_to_previous": 2.315886984715146e-06, "parent_is_longest": true, "runtime_str": "6 ms"}}}, "id": "pNIJfb0tYEaTfMYu", "pretty_name": "Embedding", "trace_file": "/results/DLRM/DLRM.16.pt.trace.json", "trace_disk_size": "1.3 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 6210000, "runtime_str": "6 ms", "start_timestamp": "00:06:27.851.851117", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 10}, {"idx": 13, "name": "Reshape Data", "type": "Reshape Data", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 135, in forward\n    with hotline.annotate('Reshape Data'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 135, "ops": [{"idx": 14, "name": "aten::reshape", "type": "aten::reshape", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 136, in forward\n    with hotline.annotate('aten::reshape'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 136, "resources": {"cpu2": {"time": {"ts": 1677888387851299000, "dur": 121000, "relative_dur": 0.017126680820948335, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "121 us"}}}, "id": "8tRBnifjqQtIScN4", "pretty_name": "aten::reshape", "trace_file": "/results/DLRM/DLRM.18.pt.trace.json", "trace_disk_size": "1.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 121000, "runtime_str": "121 us", "start_timestamp": "00:06:27.851.851299", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 10}, {"idx": 15, "name": "aten::cat", "type": "aten::cat", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 139, in forward\n    with hotline.annotate('aten::cat'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 139, "resources": {"cpu2": {"time": {"ts": 1677888387851510000, "dur": 59000, "relative_dur": 0.00835102618542109, "relative_gap_to_previous": 0.012738853503184714, "parent_is_longest": true, "runtime_str": "59 us"}}, "gpu3": {"time": {"ts": 1677888387863696000, "dur": 7065000, "relative_dur": 1.0, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "7 ms"}}}, "id": "9l54T8rLfIA7giRN", "pretty_name": "aten::cat", "trace_file": "/results/DLRM/DLRM.19.pt.trace.json", "trace_disk_size": "983 Bytes", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 7065000, "runtime_str": "7 ms", "start_timestamp": "00:06:27.851.851510", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 7}], "resources": {"cpu2": {"time": {"ts": 1677888387851299000, "dur": 270000, "relative_dur": 0.0006252894858730894, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "270 us"}}, "gpu3": {"time": {"ts": 1677888387863696000, "dur": 7065000, "relative_dur": 0.016361741547012507, "relative_gap_to_previous": 4.631773969430292e-06, "parent_is_longest": true, "runtime_str": "7 ms"}}}, "id": "RU1VBrnX1dZt52Vm", "pretty_name": "Reshape Data", "trace_file": "/results/DLRM/DLRM.17.pt.trace.json", "trace_disk_size": "2.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 7065000, "runtime_str": "7 ms", "start_timestamp": "00:06:27.851.851299", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 17}, {"idx": 16, "name": "Feature Interaction", "type": "Feature Interaction", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 141, in forward\n    with hotline.annotate('Feature Interaction'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 141, "ops": [{"idx": 17, "name": "BatchMatMul", "type": "BatchMatMul", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 142, in forward\n    dot_interact_output = dot_interact(concat_features=feature_stack)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 21, in dot_interact\n    with hotline.annotate('BatchMatMul'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 21, "resources": {"cpu2": {"time": {"ts": 1677888387851670000, "dur": 232000, "relative_dur": 0.0006399805798996444, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "232 us"}}, "gpu3": {"time": {"ts": 1677888387870762000, "dur": 35945000, "relative_dur": 0.09915561182971, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "36 ms"}}}, "id": "j5nJrKUWkx0bJnHt", "pretty_name": "BatchMatMul", "trace_file": "/results/DLRM/DLRM.21.pt.trace.json", "trace_disk_size": "5.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 35945000, "runtime_str": "36 ms", "start_timestamp": "00:06:27.851.851670", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 43}, {"idx": 18, "name": "Tile", "type": "Tile", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 142, in forward\n    dot_interact_output = dot_interact(concat_features=feature_stack)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 27, in dot_interact\n    with hotline.annotate('Tile'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 27, "resources": {"cpu2": {"time": {"ts": 1677888387852008000, "dur": 61924000, "relative_dur": 0.17081964409355854, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "62 ms"}}}, "id": "a63bpWpHgypH1wXN", "pretty_name": "Tile", "trace_file": "/results/DLRM/DLRM.22.pt.trace.json", "trace_disk_size": "2.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 61924000, "runtime_str": "62 ms", "start_timestamp": "00:06:27.852.852008", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 19}, {"idx": 19, "name": "Concatenate", "type": "Concatenate", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 142, in forward\n    dot_interact_output = dot_interact(concat_features=feature_stack)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 33, in dot_interact\n    with hotline.annotate('Concatenate'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 33, "resources": {"cpu2": {"time": {"ts": 1677888387914288000, "dur": 189649000, "relative_dur": 0.5231537801611538, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "190 ms"}}}, "id": "pRdfQP3FwXaieJhA", "pretty_name": "Concatenate", "trace_file": "/results/DLRM/DLRM.23.pt.trace.json", "trace_disk_size": "3.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 189649000, "runtime_str": "190 ms", "start_timestamp": "00:06:27.914.914288", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 33}, {"idx": 20, "name": "Index", "type": "Index", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 142, in forward\n    dot_interact_output = dot_interact(concat_features=feature_stack)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 39, in dot_interact\n    with hotline.annotate('Index'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 39, "resources": {"cpu2": {"time": {"ts": 1677888388103994000, "dur": 2742000, "relative_dur": 0.007563908405538039, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 ms"}}, "gpu3": {"time": {"ts": 1677888388106624000, "dur": 125570000, "relative_dur": 0.34638948887068255, "relative_gap_to_previous": 0.5514784378956776, "parent_is_longest": true, "runtime_str": "126 ms"}}}, "id": "ktPNUgl3N8EkuCZH", "pretty_name": "Index", "trace_file": "/results/DLRM/DLRM.24.pt.trace.json", "trace_disk_size": "5.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 125570000, "runtime_str": "126 ms", "start_timestamp": "00:06:28.103.103994", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 42}, {"idx": 21, "name": "Concatenate", "type": "Concatenate", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 143, in forward\n    with hotline.annotate('Concatenate'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 143, "resources": {"cpu2": {"time": {"ts": 1677888388229362000, "dur": 1439000, "relative_dur": 0.003969534717567191, "relative_gap_to_previous": 8.551464645210766e-05, "parent_is_longest": true, "runtime_str": "1 ms"}}, "gpu3": {"time": {"ts": 1677888388232195000, "dur": 1078000, "relative_dur": 0.0029737028669474855, "relative_gap_to_previous": 2.7585369823260535e-06, "parent_is_longest": true, "runtime_str": "1 ms"}}}, "id": "9aG3jSbOjK1kYEDD", "pretty_name": "Concatenate", "trace_file": "/results/DLRM/DLRM.25.pt.trace.json", "trace_disk_size": "1.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 1439000, "runtime_str": "1 ms", "start_timestamp": "00:06:28.229.229362", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 9}], "resources": {"cpu2": {"time": {"ts": 1677888387851670000, "dur": 256536000, "relative_dur": 0.5941083835108847, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "257 ms"}}, "gpu3": {"time": {"ts": 1677888387870762000, "dur": 362511000, "relative_dur": 0.8395345067160722, "relative_gap_to_previous": 2.315886984715146e-06, "parent_is_longest": true, "runtime_str": "363 ms"}}}, "id": "BTObgBm6LmovPYcf", "pretty_name": "Feature Interaction", "trace_file": "/results/DLRM/DLRM.20.pt.trace.json", "trace_disk_size": "17.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 362511000, "runtime_str": "363 ms", "start_timestamp": "00:06:27.851.851670", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 146}, {"idx": 22, "name": "Top MLP", "type": "Top MLP", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 146, in forward\n    with hotline.annotate('Top MLP'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 146, "ops": [{"idx": 23, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1677888388230909000, "dur": 289000, "relative_dur": 0.006311835237076026, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "289 us"}}, "gpu3": {"time": {"ts": 1677888388233274000, "dur": 9498000, "relative_dur": 0.20743879267040863, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9 ms"}}}, "id": "tDxL534EnrYGdYww", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.27.pt.trace.json", "trace_disk_size": "1.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 9498000, "runtime_str": "9 ms", "start_timestamp": "00:06:28.230.230909", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 17}, {"idx": 24, "name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1677888388231319000, "dur": 73000, "relative_dur": 0.001594339004520934, "relative_gap_to_previous": 0.002642671500644288, "parent_is_longest": true, "runtime_str": "73 us"}}, "gpu3": {"time": {"ts": 1677888388242773000, "dur": 1906000, "relative_dur": 0.041627536200231505, "relative_gap_to_previous": 2.1840260335903203e-05, "parent_is_longest": true, "runtime_str": "2 ms"}}}, "id": "zjL2dcblt2XLxLU9", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.28.pt.trace.json", "trace_disk_size": "1.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 1906000, "runtime_str": "2 ms", "start_timestamp": "00:06:28.231.231319", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 8}, {"idx": 25, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1677888388231507000, "dur": 87000, "relative_dur": 0.0019001026492235788, "relative_gap_to_previous": 0.0025116299386288687, "parent_is_longest": true, "runtime_str": "87 us"}}, "gpu3": {"time": {"ts": 1677888388244680000, "dur": 18044000, "relative_dur": 0.3940856575010374, "relative_gap_to_previous": 2.1840260335903203e-05, "parent_is_longest": true, "runtime_str": "18 ms"}}}, "id": "rkgGEiAdBYCXPPlq", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.29.pt.trace.json", "trace_disk_size": "1.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 18044000, "runtime_str": "18 ms", "start_timestamp": "00:06:28.231.231507", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 14}, {"idx": 26, "name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1677888388231711000, "dur": 48000, "relative_dur": 0.001048332496123354, "relative_gap_to_previous": 0.002555310459300675, "parent_is_longest": true, "runtime_str": "48 us"}}, "gpu3": {"time": {"ts": 1677888388262726000, "dur": 1907000, "relative_dur": 0.04164937646056741, "relative_gap_to_previous": 4.3680520671806406e-05, "parent_is_longest": true, "runtime_str": "2 ms"}}}, "id": "XS7Kih6sgCYlCV1K", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.30.pt.trace.json", "trace_disk_size": "1.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 1907000, "runtime_str": "2 ms", "start_timestamp": "00:06:28.231.231711", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 8}, {"idx": 27, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1677888388231871000, "dur": 83000, "relative_dur": 0.0018127416078799659, "relative_gap_to_previous": 0.002446109157621159, "parent_is_longest": true, "runtime_str": "83 us"}}, "gpu3": {"time": {"ts": 1677888388264634000, "dur": 10001000, "relative_dur": 0.21842444361936794, "relative_gap_to_previous": 2.1840260335903203e-05, "parent_is_longest": true, "runtime_str": "10 ms"}}}, "id": "XHBAV7Vqs1l2goW0", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.31.pt.trace.json", "trace_disk_size": "1.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 10001000, "runtime_str": "10 ms", "start_timestamp": "00:06:28.231.231871", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 14}, {"idx": 28, "name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1677888388232070000, "dur": 47000, "relative_dur": 0.0010264922357874505, "relative_gap_to_previous": 0.0025334701989647716, "parent_is_longest": true, "runtime_str": "47 us"}}, "gpu3": {"time": {"ts": 1677888388274637000, "dur": 956000, "relative_dur": 0.02087928888112346, "relative_gap_to_previous": 4.3680520671806406e-05, "parent_is_longest": true, "runtime_str": "956 us"}}}, "id": "7HaMlIfEMvMbdQMm", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.32.pt.trace.json", "trace_disk_size": "1.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 956000, "runtime_str": "956 us", "start_timestamp": "00:06:28.232.232070", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 8}, {"idx": 29, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1677888388232230000, "dur": 80000, "relative_dur": 0.0017472208268722563, "relative_gap_to_previous": 0.002467949417957062, "parent_is_longest": true, "runtime_str": "80 us"}}, "gpu3": {"time": {"ts": 1677888388275594000, "dur": 2742000, "relative_dur": 0.059885993841046585, "relative_gap_to_previous": 2.1840260335903203e-05, "parent_is_longest": true, "runtime_str": "3 ms"}}}, "id": "Peqqv9731suvJxhm", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.33.pt.trace.json", "trace_disk_size": "1.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 2742000, "runtime_str": "3 ms", "start_timestamp": "00:06:28.232.232230", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 13}, {"idx": 30, "name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1677888388232425000, "dur": 47000, "relative_dur": 0.0010264922357874505, "relative_gap_to_previous": 0.0025116299386288687, "parent_is_longest": true, "runtime_str": "47 us"}}, "gpu3": {"time": {"ts": 1677888388278337000, "dur": 478000, "relative_dur": 0.01043964444056173, "relative_gap_to_previous": 2.1840260335903203e-05, "parent_is_longest": true, "runtime_str": "478 us"}}}, "id": "qI8i0GjJgeonzK8a", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.34.pt.trace.json", "trace_disk_size": "1.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 478000, "runtime_str": "478 us", "start_timestamp": "00:06:28.232.232425", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 8}, {"idx": 31, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1677888388232583000, "dur": 113000, "relative_dur": 0.002467949417957062, "relative_gap_to_previous": 0.0024242688972852555, "parent_is_longest": true, "runtime_str": "113 us"}}, "gpu3": {"time": {"ts": 1677888388278817000, "dur": 244000, "relative_dur": 0.005329023521960382, "relative_gap_to_previous": 4.3680520671806406e-05, "parent_is_longest": true, "runtime_str": "244 us"}}}, "id": "K3C1VoZnnrXCIjHt", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.35.pt.trace.json", "trace_disk_size": "2.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 244000, "runtime_str": "244 us", "start_timestamp": "00:06:28.232.232583", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 16}], "resources": {"cpu2": {"time": {"ts": 1677888388230909000, "dur": 1787000, "relative_dur": 0.004138490041685965, "relative_gap_to_previous": 0.0002501157943492358, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu3": {"time": {"ts": 1677888388233274000, "dur": 45787000, "relative_dur": 0.10603751736915239, "relative_gap_to_previous": 2.315886984715146e-06, "parent_is_longest": true, "runtime_str": "46 ms"}}}, "id": "1YLFa892eNi7JZVl", "pretty_name": "Top MLP", "trace_file": "/results/DLRM/DLRM.26.pt.trace.json", "trace_disk_size": "14.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 45787000, "runtime_str": "46 ms", "start_timestamp": "00:06:28.230.230909", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 106}], "is_model_pass": "Forward", "idx": 2, "id": "qcLW94waWTupeDT4", "pretty_name": "Forward", "trace_file": "/results/DLRM/DLRM.6.pt.trace.json", "trace_disk_size": "49.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py", "runtime": 431800000, "runtime_str": "432 ms", "start_timestamp": "00:06:27.846.846629", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 379}, {"name": "Calc Loss", "type": "training loop", "instances": 21, "resources": {"cpu2": {"time": {"ts": 1677888388232800000, "dur": 573000, "relative_dur": 0.0005555700992754319, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "573 us"}}, "gpu3": {"time": {"ts": 1677888388279063000, "dur": 56000, "relative_dur": 5.429655420492877e-05, "relative_gap_to_previous": 1.9391626501760277e-06, "parent_is_longest": true, "runtime_str": "56 us"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 102, in update_params\n    with hotline.annotate('Calc Loss'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py", "source_file_num": 102, "ops": [{"name": "aten::reshape(71%) and 3 others\u2026", "type": "generated", "generated_depth": 1, "instances": 5, "resources": {"cpu2": {"time": {"ts": 1677888388232800000, "dur": 38000, "relative_dur": 0.06631762652705062, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "38 us"}}}, "ops": [{"name": "aten::zeros", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888388232800000, "dur": 4000, "relative_dur": 0.10526315789473684, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4 us"}, "res_name": "aten::zeros"}}, "id": "DaA9F26U5crSaQhU", "pretty_name": "aten::zeros", "trace_file": "/results/DLRM/DLRM.38.pt.trace.json", "trace_disk_size": "203 Bytes", "runtime": 4000, "runtime_str": "4 us", "start_timestamp": "00:06:28.232.232800", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::empty", "type": "generated", "generated_depth": 2, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1677888388232804000, "dur": 8000, "relative_dur": 0.21052631578947367, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "8 us"}}}, "ops": [{"name": "aten::zero_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888388232804000, "dur": 0, "relative_dur": 0.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "0 us"}, "res_name": "aten::zero_"}}, "id": "yY1UlpI7gl3OcapO", "pretty_name": "aten::zero_", "trace_file": "/results/DLRM/DLRM.40.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 0, "runtime_str": "0 us", "start_timestamp": "00:06:28.232.232804", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "n6SLwb7LVKuN7RpU", "pretty_name": "aten::empty", "trace_file": "/results/DLRM/DLRM.39.pt.trace.json", "trace_disk_size": "203 Bytes", "runtime": 8000, "runtime_str": "8 us", "start_timestamp": "00:06:28.232.232804", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::reshape", "type": "generated", "generated_depth": 2, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1677888388232823000, "dur": 15000, "relative_dur": 0.39473684210526316, "relative_gap_to_previous": 0.2894736842105263, "parent_is_longest": true, "runtime_str": "15 us"}, "res_name": "aten::reshape"}}, "id": "bE9BteKxlAUnlaij", "pretty_name": "aten::reshape", "trace_file": "/results/DLRM/DLRM.41.pt.trace.json", "trace_disk_size": "427 Bytes", "runtime": 15000, "runtime_str": "15 us", "start_timestamp": "00:06:28.232.232823", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 4}], "id": "taB1fJyU5XIalnFU", "pretty_name": "aten::reshape(71%) and 3 others\u2026", "trace_file": "/results/DLRM/DLRM.37.pt.trace.json", "trace_disk_size": "831 Bytes", "runtime": 38000, "runtime_str": "38 us", "start_timestamp": "00:06:28.232.232800", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 8}, {"name": "aten::log_sigmoid", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888388232859000, "dur": 47000, "relative_dur": 0.08202443280977312, "relative_gap_to_previous": 0.03664921465968586, "parent_is_longest": true, "runtime_str": "47 us"}}, "gpu3": {"time": {"ts": 1677888388279063000, "dur": 4000, "relative_dur": 0.006980802792321117, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "4 us"}}}, "ops": [{"name": "aten::empty_like", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888388232869000, "dur": 10000, "relative_dur": 0.2127659574468085, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "10 us"}, "res_name": "aten::empty_like"}}, "id": "NcEvYawkkJTu1tlu", "pretty_name": "aten::empty_like", "trace_file": "/results/DLRM/DLRM.43.pt.trace.json", "trace_disk_size": "217 Bytes", "runtime": 10000, "runtime_str": "10 us", "start_timestamp": "00:06:28.232.232869", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::empty", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888388232880000, "dur": 3000, "relative_dur": 0.06382978723404255, "relative_gap_to_previous": 0.02127659574468085, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "aten::empty"}}, "id": "gDvOJ0tVvboyOc3Y", "pretty_name": "aten::empty", "trace_file": "/results/DLRM/DLRM.44.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 3000, "runtime_str": "3 us", "start_timestamp": "00:06:28.232.232880", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "cudaLaunchKernel", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888388232891000, "dur": 11000, "relative_dur": 0.23404255319148937, "relative_gap_to_previous": 0.1702127659574468, "parent_is_longest": true, "runtime_str": "11 us"}, "res_name": "cudaLaunchKernel"}, "gpu3": {"time": {"ts": 1677888388279063000, "dur": 4000, "relative_dur": 0.0851063829787234, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "4 us"}, "res_name": "vectorized_elementwise_kernel<4 launch_log_sigmoid_forward_kernelTensorIteratorBase&::{lambda#1}::operator const::{lambda#4}::operator const::{lambda#1} Array<char 2> launch_log_sigmoid_forward_kernelTensorIteratorBase&::{lambda#1}::operator const::{lambda#4}::operator const::{lambda#1} Array<char 2>"}}, "id": "I1UWbv3A3FKIg1St", "pretty_name": "cudaLaunchKernel", "trace_file": "/results/DLRM/DLRM.45.pt.trace.json", "trace_disk_size": "627 Bytes", "runtime": 11000, "runtime_str": "11 us", "start_timestamp": "00:06:28.232.232891", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}], "id": "lIM9ccMAzaX5VzqV", "pretty_name": "aten::log_sigmoid", "trace_file": "/results/DLRM/DLRM.42.pt.trace.json", "trace_disk_size": "1.2 kB", "runtime": 47000, "runtime_str": "47 us", "start_timestamp": "00:06:28.232.232859", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 7}, {"name": "aten::log_sigmoid(34%) and 2 others\u2026", "type": "generated", "generated_depth": 1, "instances": 3, "resources": {"cpu2": {"time": {"ts": 1677888388232911000, "dur": 80000, "relative_dur": 0.13961605584642234, "relative_gap_to_previous": 0.008726003490401396, "parent_is_longest": true, "runtime_str": "80 us"}}, "gpu3": {"time": {"ts": 1677888388279068000, "dur": 11000, "relative_dur": 0.019197207678883072, "relative_gap_to_previous": 0.0017452006980802793, "parent_is_longest": true, "runtime_str": "11 us"}}}, "ops": [{"name": "aten::neg", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888388232911000, "dur": 23000, "relative_dur": 0.2875, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "23 us"}, "res_name": "aten::neg"}, "gpu3": {"time": {"ts": 1677888388279068000, "dur": 3000, "relative_dur": 0.0375, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "vectorized_elementwise_kernel<4 neg_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda#1} Array<char 2> neg_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda#1} Array<char 2>"}}, "id": "HQXGlPll4sgtxtR5", "pretty_name": "aten::neg", "trace_file": "/results/DLRM/DLRM.47.pt.trace.json", "trace_disk_size": "692 Bytes", "runtime": 23000, "runtime_str": "23 us", "start_timestamp": "00:06:28.232.232911", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::log_sigmoid", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888388232938000, "dur": 24000, "relative_dur": 0.3, "relative_gap_to_previous": 0.05, "parent_is_longest": true, "runtime_str": "24 us"}}, "gpu3": {"time": {"ts": 1677888388279072000, "dur": 3000, "relative_dur": 0.0375, "relative_gap_to_previous": 0.0125, "parent_is_longest": true, "runtime_str": "3 us"}}}, "ops": [{"name": "aten::empty_like", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888388232942000, "dur": 5000, "relative_dur": 0.20833333333333334, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5 us"}, "res_name": "aten::empty_like"}}, "id": "RjpzfLNJHDH9HZza", "pretty_name": "aten::empty_like", "trace_file": "/results/DLRM/DLRM.49.pt.trace.json", "trace_disk_size": "216 Bytes", "runtime": 5000, "runtime_str": "5 us", "start_timestamp": "00:06:28.232.232942", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::empty", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888388232948000, "dur": 3000, "relative_dur": 0.125, "relative_gap_to_previous": 0.041666666666666664, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "aten::empty"}}, "id": "ek88AJMXTinXIynE", "pretty_name": "aten::empty", "trace_file": "/results/DLRM/DLRM.50.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 3000, "runtime_str": "3 us", "start_timestamp": "00:06:28.232.232948", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "cudaLaunchKernel", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888388232954000, "dur": 5000, "relative_dur": 0.20833333333333334, "relative_gap_to_previous": 0.125, "parent_is_longest": true, "runtime_str": "5 us"}, "res_name": "cudaLaunchKernel"}, "gpu3": {"time": {"ts": 1677888388279072000, "dur": 3000, "relative_dur": 0.125, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "vectorized_elementwise_kernel<4 launch_log_sigmoid_forward_kernelTensorIteratorBase&::{lambda#1}::operator const::{lambda#4}::operator const::{lambda#1} Array<char 2> launch_log_sigmoid_forward_kernelTensorIteratorBase&::{lambda#1}::operator const::{lambda#4}::operator const::{lambda#1} Array<char 2>"}}, "id": "r0yB2jz4RRIHTo4o", "pretty_name": "cudaLaunchKernel", "trace_file": "/results/DLRM/DLRM.51.pt.trace.json", "trace_disk_size": "626 Bytes", "runtime": 5000, "runtime_str": "5 us", "start_timestamp": "00:06:28.232.232954", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}], "id": "jv2gM0Ua9wDsRLw9", "pretty_name": "aten::log_sigmoid", "trace_file": "/results/DLRM/DLRM.48.pt.trace.json", "trace_disk_size": "1.2 kB", "runtime": 24000, "runtime_str": "24 us", "start_timestamp": "00:06:28.232.232938", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 7}, {"name": "aten::mul", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888388232967000, "dur": 24000, "relative_dur": 0.3, "relative_gap_to_previous": 0.0625, "parent_is_longest": true, "runtime_str": "24 us"}, "res_name": "aten::mul"}, "gpu3": {"time": {"ts": 1677888388279076000, "dur": 3000, "relative_dur": 0.0375, "relative_gap_to_previous": 0.0125, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "vectorized_elementwise_kernel<4 BinaryFunctor  binary_ernal::MulFunctor Array<char 3> BinaryFunctor  binary_ernal::MulFunctor Array<char 3>"}}, "id": "cY7ScwL8Lv5R4oVI", "pretty_name": "aten::mul", "trace_file": "/results/DLRM/DLRM.52.pt.trace.json", "trace_disk_size": "602 Bytes", "runtime": 24000, "runtime_str": "24 us", "start_timestamp": "00:06:28.232.232967", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}], "id": "VvL0BTaJg5yHnMG5", "pretty_name": "aten::log_sigmoid(34%) and 2 others\u2026", "trace_file": "/results/DLRM/DLRM.46.pt.trace.json", "trace_disk_size": "2.5 kB", "runtime": 80000, "runtime_str": "80 us", "start_timestamp": "00:06:28.232.232911", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 13}, {"name": "aten::rsub", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888388233012000, "dur": 30000, "relative_dur": 0.05235602094240838, "relative_gap_to_previous": 0.03664921465968586, "parent_is_longest": true, "runtime_str": "30 us"}, "res_name": "aten::rsub"}, "gpu3": {"time": {"ts": 1677888388279081000, "dur": 2000, "relative_dur": 0.0034904013961605585, "relative_gap_to_previous": 0.0034904013961605585, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctorOnOther_add Array<char 2> CUDAFunctorOnOther_add Array<char 2>"}}, "id": "LUe25q2mbmXGTXFZ", "pretty_name": "aten::rsub", "trace_file": "/results/DLRM/DLRM.53.pt.trace.json", "trace_disk_size": "595 Bytes", "runtime": 30000, "runtime_str": "30 us", "start_timestamp": "00:06:28.233.233012", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 4}, {"name": "aten::add(39%) and 2 others\u2026", "type": "generated", "generated_depth": 1, "instances": 4, "resources": {"cpu2": {"time": {"ts": 1677888388233045000, "dur": 93000, "relative_dur": 0.16230366492146597, "relative_gap_to_previous": 0.005235602094240838, "parent_is_longest": true, "runtime_str": "93 us"}}, "gpu3": {"time": {"ts": 1677888388279085000, "dur": 11000, "relative_dur": 0.019197207678883072, "relative_gap_to_previous": 0.0034904013961605585, "parent_is_longest": true, "runtime_str": "11 us"}}}, "ops": [{"name": "aten::mul", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888388233045000, "dur": 16000, "relative_dur": 0.17204301075268819, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "16 us"}, "res_name": "aten::mul"}, "gpu3": {"time": {"ts": 1677888388279085000, "dur": 3000, "relative_dur": 0.03225806451612903, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "vectorized_elementwise_kernel<4 BinaryFunctor  binary_ernal::MulFunctor Array<char 3> BinaryFunctor  binary_ernal::MulFunctor Array<char 3>"}}, "id": "GVbTpc0eGplnhz14", "pretty_name": "aten::mul", "trace_file": "/results/DLRM/DLRM.55.pt.trace.json", "trace_disk_size": "602 Bytes", "runtime": 16000, "runtime_str": "16 us", "start_timestamp": "00:06:28.233.233045", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::add", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888388233065000, "dur": 27000, "relative_dur": 0.2903225806451613, "relative_gap_to_previous": 0.043010752688172046, "parent_is_longest": true, "runtime_str": "27 us"}, "res_name": "aten::add"}, "gpu3": {"time": {"ts": 1677888388279089000, "dur": 3000, "relative_dur": 0.03225806451612903, "relative_gap_to_previous": 0.010752688172043012, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>"}}, "id": "uP6Z6mvEnJnf6F5P", "pretty_name": "aten::add", "trace_file": "/results/DLRM/DLRM.56.pt.trace.json", "trace_disk_size": "480 Bytes", "runtime": 27000, "runtime_str": "27 us", "start_timestamp": "00:06:28.233.233065", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::mul", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888388233100000, "dur": 19000, "relative_dur": 0.20430107526881722, "relative_gap_to_previous": 0.08602150537634409, "parent_is_longest": true, "runtime_str": "19 us"}, "res_name": "aten::mul"}, "gpu3": {"time": {"ts": 1677888388279093000, "dur": 3000, "relative_dur": 0.03225806451612903, "relative_gap_to_previous": 0.010752688172043012, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "vectorized_elementwise_kernel<4 AUnaryFunctor  binary_ernal::MulFunctor Array<char 2> AUnaryFunctor  binary_ernal::MulFunctor Array<char 2>"}}, "id": "g2tXjsVS4lhW83IJ", "pretty_name": "aten::mul", "trace_file": "/results/DLRM/DLRM.57.pt.trace.json", "trace_disk_size": "602 Bytes", "runtime": 19000, "runtime_str": "19 us", "start_timestamp": "00:06:28.233.233100", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::reshape", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888388233131000, "dur": 7000, "relative_dur": 0.07526881720430108, "relative_gap_to_previous": 0.12903225806451613, "parent_is_longest": true, "runtime_str": "7 us"}, "res_name": "aten::reshape"}}, "id": "e9ifcJua7pSFGPhm", "pretty_name": "aten::reshape", "trace_file": "/results/DLRM/DLRM.58.pt.trace.json", "trace_disk_size": "214 Bytes", "runtime": 7000, "runtime_str": "7 us", "start_timestamp": "00:06:28.233.233131", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}], "id": "ADYz0xp7bKIiQFxz", "pretty_name": "aten::add(39%) and 2 others\u2026", "trace_file": "/results/DLRM/DLRM.54.pt.trace.json", "trace_disk_size": "1.9 kB", "runtime": 93000, "runtime_str": "93 us", "start_timestamp": "00:06:28.233.233045", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 11}, {"name": "aten::sum", "type": "generated", "generated_depth": 1, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1677888388233142000, "dur": 88000, "relative_dur": 0.15357766143106458, "relative_gap_to_previous": 0.006980802792321117, "parent_is_longest": true, "runtime_str": "88 us"}, "res_name": "aten::sum"}, "gpu3": {"time": {"ts": 1677888388279098000, "dur": 18000, "relative_dur": 0.031413612565445025, "relative_gap_to_previous": 0.0034904013961605585, "parent_is_longest": true, "runtime_str": "18 us"}, "res_name": "reduce_kernel<128 4 ReduceOpfunc_wrapper_tsum_functor::operatorTensorIterator&::{lambda #1}>    4>ReduceOpfunc_wrapper_tsum_functor::operatorTensorIterator&::{lambda #1}>    4>(47%) and 2 others\u2026"}}, "id": "exg9R658Z42Ty20A", "pretty_name": "aten::sum", "trace_file": "/results/DLRM/DLRM.59.pt.trace.json", "trace_disk_size": "2.0 kB", "runtime": 88000, "runtime_str": "88 us", "start_timestamp": "00:06:28.233.233142", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 11}, {"name": "aten::div(75%) and 3 others\u2026", "type": "generated", "generated_depth": 1, "instances": 5, "resources": {"cpu2": {"time": {"ts": 1677888388233237000, "dur": 136000, "relative_dur": 0.23734729493891799, "relative_gap_to_previous": 0.012216404886561954, "parent_is_longest": true, "runtime_str": "136 us"}}, "gpu3": {"time": {"ts": 1677888388279117000, "dur": 2000, "relative_dur": 0.0034904013961605585, "relative_gap_to_previous": 0.0017452006980802793, "parent_is_longest": true, "runtime_str": "2 us"}}}, "ops": [{"name": "aten::div", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888388233237000, "dur": 24000, "relative_dur": 0.17647058823529413, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "24 us"}, "res_name": "aten::div"}, "gpu3": {"time": {"ts": 1677888388279117000, "dur": 2000, "relative_dur": 0.014705882352941176, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "vectorized_elementwise_kernel<4 BUnaryFunctor  binary_ernal::MulFunctor Array<char 2> BUnaryFunctor  binary_ernal::MulFunctor Array<char 2>"}}, "id": "yXk7Kuyym0phs2Qv", "pretty_name": "aten::div", "trace_file": "/results/DLRM/DLRM.61.pt.trace.json", "trace_disk_size": "602 Bytes", "runtime": 24000, "runtime_str": "24 us", "start_timestamp": "00:06:28.233.233237", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::zeros(88%) and 2 others\u2026", "type": "generated", "generated_depth": 2, "instances": 4, "resources": {"cpu2": {"time": {"ts": 1677888388233348000, "dur": 25000, "relative_dur": 0.18382352941176472, "relative_gap_to_previous": 0.6397058823529411, "parent_is_longest": true, "runtime_str": "25 us"}}}, "ops": [{"name": "aten::zeros", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888388233348000, "dur": 5000, "relative_dur": 0.2, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5 us"}, "res_name": "aten::zeros"}}, "id": "E8lljngUgzvgq4kN", "pretty_name": "aten::zeros", "trace_file": "/results/DLRM/DLRM.63.pt.trace.json", "trace_disk_size": "304 Bytes", "runtime": 5000, "runtime_str": "5 us", "start_timestamp": "00:06:28.233.233348", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::empty", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888388233360000, "dur": 1000, "relative_dur": 0.04, "relative_gap_to_previous": 0.28, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::empty"}}, "id": "JEPvBlrsDg4njUGd", "pretty_name": "aten::empty", "trace_file": "/results/DLRM/DLRM.64.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "00:06:28.233.233360", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::zeros", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888388233371000, "dur": 2000, "relative_dur": 0.08, "relative_gap_to_previous": 0.4, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "aten::zeros"}}, "id": "aFSFb5Lz5OqMTlD6", "pretty_name": "aten::zeros", "trace_file": "/results/DLRM/DLRM.65.pt.trace.json", "trace_disk_size": "203 Bytes", "runtime": 2000, "runtime_str": "2 us", "start_timestamp": "00:06:28.233.233371", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::zero_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888388233373000, "dur": 0, "relative_dur": 0.0, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "0 us"}, "res_name": "aten::zero_"}}, "id": "B3U91HwFHsoheANg", "pretty_name": "aten::zero_", "trace_file": "/results/DLRM/DLRM.66.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 0, "runtime_str": "0 us", "start_timestamp": "00:06:28.233.233373", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "D6L4CjKYld5wKm2d", "pretty_name": "aten::zeros(88%) and 2 others\u2026", "trace_file": "/results/DLRM/DLRM.62.pt.trace.json", "trace_disk_size": "708 Bytes", "runtime": 25000, "runtime_str": "25 us", "start_timestamp": "00:06:28.233.233348", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 7}], "id": "pW1jN50Aro6BHVE7", "pretty_name": "aten::div(75%) and 3 others\u2026", "trace_file": "/results/DLRM/DLRM.60.pt.trace.json", "trace_disk_size": "1.3 kB", "runtime": 136000, "runtime_str": "136 us", "start_timestamp": "00:06:28.233.233237", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 10}], "idx": 32, "id": "N6ZzXKl6MsnbN8up", "pretty_name": "Calc Loss", "trace_file": "/results/DLRM/DLRM.36.pt.trace.json", "trace_disk_size": "10.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py", "runtime": 573000, "runtime_str": "573 us", "start_timestamp": "00:06:28.232.232800", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 64}, {"name": "Zero Grad", "type": "training loop", "instances": 4, "resources": {"cpu2": {"time": {"ts": 1677888388233377000, "dur": 386000, "relative_dur": 0.0003742583914839733, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "386 us"}}, "gpu3": {"time": {"ts": 1677888388279120000, "dur": 2470000, "relative_dur": 0.002394865872967394, "relative_gap_to_previous": 9.695813250880138e-07, "parent_is_longest": true, "runtime_str": "2 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 106, in update_params\n    with hotline.annotate('Zero Grad'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py", "source_file_num": 106, "ops": [{"name": "aten::empty", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888388233378000, "dur": 0, "relative_dur": 0.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "0 us"}, "res_name": "aten::empty"}}, "id": "MbzfXPk4Xaeszjw1", "pretty_name": "aten::empty", "trace_file": "/results/DLRM/DLRM.68.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 0, "runtime_str": "0 us", "start_timestamp": "00:06:28.233.233378", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::zero_", "type": "generated", "generated_depth": 2, "instances": 17, "resources": {"cpu2": {"time": {"ts": 1677888388233388000, "dur": 240000, "relative_dur": 0.09716599190283401, "relative_gap_to_previous": 0.004048582995951417, "parent_is_longest": true, "runtime_str": "240 us"}, "res_name": "aten::zero_"}, "gpu3": {"time": {"ts": 1677888388279120000, "dur": 2467000, "relative_dur": 0.9987854251012146, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "2 ms"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>"}}, "id": "Kxy2wn63g0jttGk6", "pretty_name": "aten::zero_", "trace_file": "/results/DLRM/DLRM.69.pt.trace.json", "trace_disk_size": "9.8 kB", "runtime": 2467000, "runtime_str": "2 ms", "start_timestamp": "00:06:28.233.233388", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 68}, {"name": "aten::ones_like(80%) and 2 others\u2026", "type": "generated", "instances": 9, "id": "49EmaSUiYI3RcVo1", "resources": {"cpu2": {"time": {"ts": 1677888388233706000, "dur": 57000, "relative_dur": 0.023076923076923078, "relative_gap_to_previous": 0.031578947368421054, "parent_is_longest": true, "runtime_str": "57 us"}, "res_name": "aten::ones_like(80%) and 2 others\u2026"}, "gpu3": {"time": {"ts": 1677888388281588000, "dur": 2000, "relative_dur": 0.0008097165991902834, "relative_gap_to_previous": 0.0004048582995951417, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>"}}, "pretty_name": "aten::ones_like(80%) and 2 others\u2026", "trace_file": "/results/DLRM/DLRM.70.pt.trace.json", "trace_disk_size": "1.2 kB", "runtime": 57000, "runtime_str": "57 us", "start_timestamp": "00:06:28.233.233706", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 10}], "idx": 33, "id": "zQwhgapqjtzPqNae", "pretty_name": "Zero Grad", "trace_file": "/results/DLRM/DLRM.67.pt.trace.json", "trace_disk_size": "11.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py", "runtime": 2470000, "runtime_str": "2 ms", "start_timestamp": "00:06:28.233.233377", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 80}, {"name": "Backward", "type": "training loop", "instances": 65, "resources": {"cpu2": {"time": {"ts": 1677888388791915000, "dur": 103000, "relative_dur": 0.32496778566047396, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "103 us"}}, "cpu4": {"time": {"ts": 1677888388233888000, "dur": 335163000, "relative_dur": 0.32496778566047396, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "335 ms"}}, "gpu3": {"time": {"ts": 1677888388281591000, "dur": 536539000, "relative_dur": 0.5202181945813978, "relative_gap_to_previous": 9.695813250880138e-07, "parent_is_longest": true, "runtime_str": "537 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 109, in update_params\n    with hotline.annotate('Backward'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py", "source_file_num": 109, "ops": [{"name": "Top MLP", "type": "Top MLP", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 146, in forward\n    with hotline.annotate('Top MLP'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 146, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1677888388233888000, "dur": 736000, "relative_dur": 0.008904159307024123, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "736 us"}}, "gpu3": {"time": {"ts": 1677888388281591000, "dur": 525000, "relative_dur": 0.0063514723317767184, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "525 us"}}}, "is_backward_op": true, "id": "FgxgQNfUsEc9KVOK", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.73.pt.trace.json", "trace_disk_size": "14.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 736000, "runtime_str": "736 us", "start_timestamp": "00:06:28.233.233888", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu4", "trace_event_count": 94}, {"name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1677888388234635000, "dur": 100000, "relative_dur": 0.001209804253671756, "relative_gap_to_previous": 0.00013307846790389314, "parent_is_longest": true, "runtime_str": "100 us"}}, "gpu3": {"time": {"ts": 1677888388282117000, "dur": 713000, "relative_dur": 0.00862590432867962, "relative_gap_to_previous": 1.209804253671756e-05, "parent_is_longest": true, "runtime_str": "713 us"}}}, "is_backward_op": true, "id": "OUjMH4lgrW2T2B5m", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.74.pt.trace.json", "trace_disk_size": "3.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 713000, "runtime_str": "713 us", "start_timestamp": "00:06:28.234.234635", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 20}, {"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1677888388234739000, "dur": 139000, "relative_dur": 0.0016816279126037406, "relative_gap_to_previous": 4.839217014687024e-05, "parent_is_longest": true, "runtime_str": "139 us"}}, "gpu3": {"time": {"ts": 1677888388282832000, "dur": 5091000, "relative_dur": 0.06159113455442909, "relative_gap_to_previous": 2.419608507343512e-05, "parent_is_longest": true, "runtime_str": "5 ms"}}}, "is_backward_op": true, "id": "EfrzpGW6sAFtjJHl", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.75.pt.trace.json", "trace_disk_size": "4.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 5091000, "runtime_str": "5 ms", "start_timestamp": "00:06:28.234.234739", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 32}, {"name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1677888388234885000, "dur": 81000, "relative_dur": 0.0009799414454741222, "relative_gap_to_previous": 8.468629775702292e-05, "parent_is_longest": true, "runtime_str": "81 us"}}, "gpu3": {"time": {"ts": 1677888388287924000, "dur": 1424000, "relative_dur": 0.017227612572285805, "relative_gap_to_previous": 1.209804253671756e-05, "parent_is_longest": true, "runtime_str": "1 ms"}}}, "is_backward_op": true, "id": "LBlRA58gsmDstUHL", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.76.pt.trace.json", "trace_disk_size": "3.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 1424000, "runtime_str": "1 ms", "start_timestamp": "00:06:28.234.234885", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 20}, {"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1677888388234970000, "dur": 125000, "relative_dur": 0.0015122553170896949, "relative_gap_to_previous": 4.839217014687024e-05, "parent_is_longest": true, "runtime_str": "125 us"}}, "gpu3": {"time": {"ts": 1677888388289350000, "dur": 18600000, "relative_dur": 0.2250235911829466, "relative_gap_to_previous": 2.419608507343512e-05, "parent_is_longest": true, "runtime_str": "19 ms"}}}, "is_backward_op": true, "id": "TQ6AA4UqKTxglILr", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.77.pt.trace.json", "trace_disk_size": "4.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 18600000, "runtime_str": "19 ms", "start_timestamp": "00:06:28.234.234970", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 34}, {"name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1677888388235103000, "dur": 80000, "relative_dur": 0.0009678434029374047, "relative_gap_to_previous": 9.678434029374048e-05, "parent_is_longest": true, "runtime_str": "80 us"}}, "gpu3": {"time": {"ts": 1677888388307952000, "dur": 2846000, "relative_dur": 0.03443102905949817, "relative_gap_to_previous": 2.419608507343512e-05, "parent_is_longest": true, "runtime_str": "3 ms"}}}, "is_backward_op": true, "id": "dggZdCyVYJn4YPUg", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.78.pt.trace.json", "trace_disk_size": "3.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 2846000, "runtime_str": "3 ms", "start_timestamp": "00:06:28.235.235103", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 20}, {"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1677888388235187000, "dur": 117000, "relative_dur": 0.0014154709767959545, "relative_gap_to_previous": 4.839217014687024e-05, "parent_is_longest": true, "runtime_str": "117 us"}}, "gpu3": {"time": {"ts": 1677888388310800000, "dur": 33650000, "relative_dur": 0.4070991313605459, "relative_gap_to_previous": 2.419608507343512e-05, "parent_is_longest": true, "runtime_str": "34 ms"}}}, "is_backward_op": true, "id": "mHfAaEnuphfqgnJh", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.79.pt.trace.json", "trace_disk_size": "4.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 33650000, "runtime_str": "34 ms", "start_timestamp": "00:06:28.235.235187", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 34}, {"name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1677888388235311000, "dur": 79000, "relative_dur": 0.0009557453604006872, "relative_gap_to_previous": 8.468629775702292e-05, "parent_is_longest": true, "runtime_str": "79 us"}}, "gpu3": {"time": {"ts": 1677888388344451000, "dur": 2850000, "relative_dur": 0.03447942122964504, "relative_gap_to_previous": 1.209804253671756e-05, "parent_is_longest": true, "runtime_str": "3 ms"}}}, "is_backward_op": true, "id": "SoMlsBFHYJNeVEG8", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.80.pt.trace.json", "trace_disk_size": "3.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 2850000, "runtime_str": "3 ms", "start_timestamp": "00:06:28.235.235311", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 20}, {"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1677888388235394000, "dur": 117000, "relative_dur": 0.0014154709767959545, "relative_gap_to_previous": 4.839217014687024e-05, "parent_is_longest": true, "runtime_str": "117 us"}}, "gpu3": {"time": {"ts": 1677888388347302000, "dur": 16947000, "relative_dur": 0.20502552686975248, "relative_gap_to_previous": 1.209804253671756e-05, "parent_is_longest": true, "runtime_str": "17 ms"}}}, "is_backward_op": true, "id": "Ql1HA9omZ8pk0dqd", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.81.pt.trace.json", "trace_disk_size": "4.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 16947000, "runtime_str": "17 ms", "start_timestamp": "00:06:28.235.235394", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 34}], "resources": {"cpu4": {"time": {"ts": 1677888388233888000, "dur": 1623000, "relative_dur": 0.0030249432007738485, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu3": {"time": {"ts": 1677888388281591000, "dur": 82658000, "relative_dur": 0.1540577665370085, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "83 ms"}}}, "is_backward_op": true, "id": "a8wcQBnQNunqm0TT", "pretty_name": "Top MLP", "trace_file": "/results/DLRM/DLRM.72.pt.trace.json", "trace_disk_size": "44.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 82658000, "runtime_str": "83 ms", "start_timestamp": "00:06:28.233.233888", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 308}, {"name": "Feature Interaction", "type": "Feature Interaction", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 141, in forward\n    with hotline.annotate('Feature Interaction'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 141, "ops": [{"name": "Concatenate", "type": "Concatenate", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 143, in forward\n    with hotline.annotate('Concatenate'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 143, "resources": {"cpu4": {"time": {"ts": 1677888388235519000, "dur": 76000, "relative_dur": 0.00017041161130905267, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "76 us"}}, "gpu3": {"time": {"ts": 1677888388364251000, "dur": 10000, "relative_dur": 2.2422580435401667e-05, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "10 us"}}}, "is_backward_op": true, "id": "0d3Ou2xJ3T0Jeu4J", "pretty_name": "Concatenate", "trace_file": "/results/DLRM/DLRM.83.pt.trace.json", "trace_disk_size": "2.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 76000, "runtime_str": "76 us", "start_timestamp": "00:06:28.235.235519", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu4", "trace_event_count": 23}, {"name": "Index", "type": "Index", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 142, in forward\n    dot_interact_output = dot_interact(concat_features=feature_stack)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 39, in dot_interact\n    with hotline.annotate('Index'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 39, "resources": {"cpu4": {"time": {"ts": 1677888388235599000, "dur": 331689000, "relative_dur": 0.7437323282037943, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "332 ms"}}, "gpu3": {"time": {"ts": 1677888388364263000, "dur": 353577000, "relative_dur": 0.7928108722608015, "relative_gap_to_previous": 4.484516087080333e-06, "parent_is_longest": true, "runtime_str": "354 ms"}}}, "is_backward_op": true, "id": "oaZchhon5mRI69j3", "pretty_name": "Index", "trace_file": "/results/DLRM/DLRM.84.pt.trace.json", "trace_disk_size": "16.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 353577000, "runtime_str": "354 ms", "start_timestamp": "00:06:28.235.235599", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 110}, {"name": "Concatenate", "type": "Concatenate", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 142, in forward\n    dot_interact_output = dot_interact(concat_features=feature_stack)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 33, in dot_interact\n    with hotline.annotate('Concatenate'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 33, "resources": {"cpu4": {"time": {"ts": 1677888388746397000, "dur": 425000, "relative_dur": 0.0009529596685045709, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "425 us"}}, "gpu3": {"time": {"ts": 1677888388746564000, "dur": 34684000, "relative_dur": 0.07777047798214715, "relative_gap_to_previous": 0.06440662004264774, "parent_is_longest": true, "runtime_str": "35 ms"}}}, "is_backward_op": true, "id": "EF1Bv960KEFXbwPs", "pretty_name": "Concatenate", "trace_file": "/results/DLRM/DLRM.85.pt.trace.json", "trace_disk_size": "12.3 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 34684000, "runtime_str": "35 ms", "start_timestamp": "00:06:28.746.746397", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 89}, {"name": "Tile", "type": "Tile", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 142, in forward\n    dot_interact_output = dot_interact(concat_features=feature_stack)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 27, in dot_interact\n    with hotline.annotate('Tile'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 27, "resources": {"cpu4": {"time": {"ts": 1677888388746827000, "dur": 72000, "relative_dur": 0.000161442579134892, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "72 us"}}, "gpu3": {"time": {"ts": 1677888388781250000, "dur": 6143000, "relative_dur": 0.013774191161467244, "relative_gap_to_previous": 4.484516087080333e-06, "parent_is_longest": true, "runtime_str": "6 ms"}}}, "is_backward_op": true, "id": "rcLFn715yalL3AmC", "pretty_name": "Tile", "trace_file": "/results/DLRM/DLRM.86.pt.trace.json", "trace_disk_size": "2.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 6143000, "runtime_str": "6 ms", "start_timestamp": "00:06:28.746.746827", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 12}, {"name": "BatchMatMul", "type": "BatchMatMul", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 142, in forward\n    dot_interact_output = dot_interact(concat_features=feature_stack)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 21, in dot_interact\n    with hotline.annotate('BatchMatMul'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 21, "resources": {"cpu4": {"time": {"ts": 1677888388746904000, "dur": 740000, "relative_dur": 0.0016592709522197234, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "740 us"}}, "gpu3": {"time": {"ts": 1677888388787394000, "dur": 22836000, "relative_dur": 0.05120420468228325, "relative_gap_to_previous": 2.2422580435401665e-06, "parent_is_longest": true, "runtime_str": "23 ms"}}}, "is_backward_op": true, "id": "wIACCj83LKGCzDvu", "pretty_name": "BatchMatMul", "trace_file": "/results/DLRM/DLRM.87.pt.trace.json", "trace_disk_size": "23.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 22836000, "runtime_str": "23 ms", "start_timestamp": "00:06:28.746.746904", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 150}], "resources": {"cpu4": {"time": {"ts": 1677888388235519000, "dur": 333059000, "relative_dur": 0.6207545024685996, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "333 ms"}}, "gpu3": {"time": {"ts": 1677888388364251000, "dur": 445979000, "relative_dur": 0.8312145063080223, "relative_gap_to_previous": 3.7275948253528636e-06, "parent_is_longest": true, "runtime_str": "446 ms"}}}, "is_backward_op": true, "id": "TWloMfVjRT4n0Afa", "pretty_name": "Feature Interaction", "trace_file": "/results/DLRM/DLRM.82.pt.trace.json", "trace_disk_size": "57.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 445979000, "runtime_str": "446 ms", "start_timestamp": "00:06:28.235.235519", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 384}, {"name": "Bottom MLP", "type": "Bottom MLP", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 117, in forward\n    with hotline.annotate('Bottom MLP'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 117, "ops": [{"name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 123, in forward\n    bot_mlp_output = hotline.annotate_module_list(self.bot_mlp, bot_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1677888388790967000, "dur": 82000, "relative_dur": 0.010390268626457172, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "82 us"}}, "gpu3": {"time": {"ts": 1677888388810231000, "dur": 715000, "relative_dur": 0.09059807399898631, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "715 us"}}}, "is_backward_op": true, "id": "cS05LanUPHPiJclC", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.89.pt.trace.json", "trace_disk_size": "3.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 715000, "runtime_str": "715 us", "start_timestamp": "00:06:28.790.790967", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 20}, {"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 123, in forward\n    bot_mlp_output = hotline.annotate_module_list(self.bot_mlp, bot_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1677888388791053000, "dur": 120000, "relative_dur": 0.015205271160669031, "relative_gap_to_previous": 0.0005068423720223011, "parent_is_longest": true, "runtime_str": "120 us"}}, "gpu3": {"time": {"ts": 1677888388810948000, "dur": 4730000, "relative_dur": 0.599341104916371, "relative_gap_to_previous": 0.00025342118601115053, "parent_is_longest": true, "runtime_str": "5 ms"}}}, "is_backward_op": true, "id": "xCb8pJukOvGuJ2Do", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.90.pt.trace.json", "trace_disk_size": "4.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 4730000, "runtime_str": "5 ms", "start_timestamp": "00:06:28.791.791053", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 32}, {"name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 123, in forward\n    bot_mlp_output = hotline.annotate_module_list(self.bot_mlp, bot_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1677888388791180000, "dur": 80000, "relative_dur": 0.01013684744044602, "relative_gap_to_previous": 0.0008869741510390269, "parent_is_longest": true, "runtime_str": "80 us"}}, "gpu3": {"time": {"ts": 1677888388815679000, "dur": 1425000, "relative_dur": 0.18056259503294475, "relative_gap_to_previous": 0.00012671059300557527, "parent_is_longest": true, "runtime_str": "1 ms"}}}, "is_backward_op": true, "id": "2DwEHmi279zhACuj", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.91.pt.trace.json", "trace_disk_size": "3.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 1425000, "runtime_str": "1 ms", "start_timestamp": "00:06:28.791.791180", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 20}, {"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 123, in forward\n    bot_mlp_output = hotline.annotate_module_list(self.bot_mlp, bot_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1677888388791264000, "dur": 97000, "relative_dur": 0.0122909275215408, "relative_gap_to_previous": 0.0005068423720223011, "parent_is_longest": true, "runtime_str": "97 us"}}, "gpu3": {"time": {"ts": 1677888388817105000, "dur": 1018000, "relative_dur": 0.1289913836796756, "relative_gap_to_previous": 0.00012671059300557527, "parent_is_longest": true, "runtime_str": "1 ms"}}}, "is_backward_op": true, "id": "AwfKO3XvjPWCFPk8", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.92.pt.trace.json", "trace_disk_size": "3.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 1018000, "runtime_str": "1 ms", "start_timestamp": "00:06:28.791.791264", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 26}], "resources": {"cpu4": {"time": {"ts": 1677888388790967000, "dur": 394000, "relative_dur": 0.0007343361805945141, "relative_gap_to_previous": 1.4910379301411454e-05, "parent_is_longest": true, "runtime_str": "394 us"}}, "gpu3": {"time": {"ts": 1677888388810231000, "dur": 7892000, "relative_dur": 0.0147090891808424, "relative_gap_to_previous": 1.8637974126764318e-06, "parent_is_longest": true, "runtime_str": "8 ms"}}}, "is_backward_op": true, "id": "OTqjZ8cBvHYrHCnO", "pretty_name": "Bottom MLP", "trace_file": "/results/DLRM/DLRM.88.pt.trace.json", "trace_disk_size": "13.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 7892000, "runtime_str": "8 ms", "start_timestamp": "00:06:28.790.790967", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 98}], "is_model_pass": "Backward", "idx": 34, "id": "MqpSrFH6Frc9Y71q", "pretty_name": "Backward", "trace_file": "/results/DLRM/DLRM.71.pt.trace.json", "trace_disk_size": "118.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py", "runtime": 536539000, "runtime_str": "537 ms", "start_timestamp": "00:06:28.233.233888", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 812}, {"name": "Optimizer", "type": "training loop", "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677888388792028000, "dur": 3147000, "relative_dur": 0.003051272430051979, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 ms"}}, "gpu3": {"time": {"ts": 1677888388818131000, "dur": 56029000, "relative_dur": 0.054324672063356325, "relative_gap_to_previous": 9.695813250880138e-07, "parent_is_longest": true, "runtime_str": "56 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 112, in update_params\n    with hotline.annotate('Optimizer'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py", "source_file_num": 112, "ops": [{"name": "aten::sqrt(12%) and 9 others\u2026", "type": "generated", "generated_depth": 1, "instances": 194, "resources": {"cpu2": {"time": {"ts": 1677888388792030000, "dur": 3130000, "relative_dur": 0.055863927608916814, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 ms"}, "res_name": "aten::sqrt(12%) and 9 others\u2026"}, "gpu3": {"time": {"ts": 1677888388818131000, "dur": 56029000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "56 ms"}, "res_name": "vectorized_elementwise_kernel<4 addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4> addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4>(18%) and 6 others\u2026"}}, "id": "XR460wHay1gefP8t", "pretty_name": "aten::sqrt(12%) and 9 others\u2026", "trace_file": "/results/DLRM/DLRM.94.pt.trace.json", "trace_disk_size": "108.1 kB", "runtime": 56029000, "runtime_str": "56 ms", "start_timestamp": "00:06:28.792.792030", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 580}], "idx": 35, "id": "xlJMfBxFLOmVXHZS", "pretty_name": "Optimizer", "trace_file": "/results/DLRM/DLRM.93.pt.trace.json", "trace_disk_size": "108.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py", "runtime": 56029000, "runtime_str": "56 ms", "start_timestamp": "00:06:28.792.792028", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 581}], "resources": {"cpu2": {"time": {"ts": 1677888387793675000, "dur": 826939000, "parent_is_longest": true, "runtime_str": "827 ms"}}, "cpu4": {"time": {"ts": 1677888388233888000, "dur": 335163000, "parent_is_longest": false, "runtime_str": "335 ms"}}, "gpu3": {"time": {"ts": 1677888387842787000, "dur": 1031373000, "parent_is_longest": true, "runtime_str": "1 s, 31 ms"}}}, "source_file_name": "/home/ubuntu/algorithmic-efficiency/submission_runner.py", "source_file_num": 334, "id": "R29C3Nuq7JdnColm", "pretty_name": "DLRM Training Iteration", "total_accuracy_str": "97.06%", "trace_file": "/results/DLRM/DLRM.1.pt.trace.json", "trace_disk_size": "783.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/submission_runner.py", "config": {"trace_filepath": "/home/ubuntu/cpath/results/DLRM.worker0.pt.trace.json", "output_dir": "/home/ubuntu/cpath/results", "ui_traces_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/DLRM", "ui_model_path": "/home/ubuntu/cpath/results/ui/src/results/DLRM.js", "results_summary_csv_filepath": "/home/ubuntu/cpath/results/results_summary.csv", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM", "run_name": "DLRM", "model_name": "DLRM", "backend": "torch", "test": false, "is_test_accuracy": true, "view_manual_annotations": false, "source_file_name": "/home/ubuntu/algorithmic-efficiency/submission_runner.py", "source_file_num": 334, "num_gpus": 1, "slice_idx": 0, "drop_flow_view": "", "last_found_was_fused": false, "count_sum_greater_than_1": 0, "count_sum_less_than_1": 0, "tiny_op_threshold": 0.05, "max_generated_depth": 2, "remove_slice_args": true, "write_model_ops_to_file": true, "op_idx": 1}, "metadata": {}, "metadata.model": "DLRM", "metadata.dataset": "Criteo1TB", "metadata.batch_size": 196608, "metadata.optimizer": "AdamW", "trace_event_count": 1941, "gpu_model": "NVIDIA GeForce RTX 3090", "gpu_cuda_version": "11.6", "hotline_traces_trace_disk_size": "1.3 MB", "hotline_annotation_count": "94", "processed_datetime": "04/03/2023 00:06:33", "runtime_without_profiling": "1 s, 228 ms \u00b17%", "runtime_with_profiling": "1 s, 473 ms \u00b110%", "runtime_profiling_overhead_factor": "0.20\u00d7 slower", "hotline_analysis_time": "2 s, 299 ms", "runtime": 1031373000, "runtime_str": "1 s, 31 ms", "start_timestamp": "00:06:27.793.793675", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3"}]