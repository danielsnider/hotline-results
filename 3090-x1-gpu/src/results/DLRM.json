export const model =
[{"name": "DLRM Training Iteration", "type": "root", "ops": [{"name": "Load Data", "type": "training loop", "instances": 13, "resources": {"cpu2": {"time": {"ts": 1678056304774040000, "dur": 763000, "relative_dur": 0.0008402398923435756, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "763 us"}}, "gpu3": {"time": {"ts": 1678056304774301000, "dur": 2708000, "relative_dur": 0.002982135817125036, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.71 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 359, in train_once\n    with hotline.annotate('Load Data'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/submission_runner.py", "source_file_num": 359, "ops": [{"name": "aten::empty_strided(88%) and 1 other\u2026", "type": "generated", "instances": 2, "id": "lV5Wakq7BLW6mIOh", "resources": {"cpu2": {"time": {"ts": 1678056304774040000, "dur": 96000, "relative_dur": 0.03545051698670606, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "96 us"}, "res_name": "aten::empty_strided(88%) and 1 other\u2026"}}, "pretty_name": "aten::empty_strided(88%) and 1 other\u2026", "trace_file": "/results/DLRM/DLRM.3.pt.trace.json", "trace_disk_size": "217 Bytes", "runtime": 96000, "runtime_str": "96 us", "start_timestamp": "22:45:04.774.774040", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "cudaMemcpyAsync", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056304774168000, "dur": 1000, "relative_dur": 0.00036927621861152144, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "cudaMemcpyAsync"}, "gpu3": {"time": {"ts": 1678056304774301000, "dur": 2475000, "relative_dur": 0.9139586410635155, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "2.48 ms"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "EQSaUIElSSocCGJP", "pretty_name": "cudaMemcpyAsync", "trace_file": "/results/DLRM/DLRM.4.pt.trace.json", "trace_disk_size": "236 Bytes", "runtime": 2475000, "runtime_str": "2.48 ms", "start_timestamp": "22:45:04.774.774168", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 2}, {"name": "cudaStreamSynchronize", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056304776763000, "dur": 1000, "relative_dur": 0.00036927621861152144, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "cudaStreamSynchronize"}}, "id": "COFfTQlOhh7x08v8", "pretty_name": "cudaStreamSynchronize", "trace_file": "/results/DLRM/DLRM.5.pt.trace.json", "trace_disk_size": "119 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "22:45:04.776.776763", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::to(82%) and 5 others\u2026", "type": "generated", "generated_depth": 1, "instances": 8, "resources": {"cpu2": {"time": {"ts": 1678056304776854000, "dur": 560000, "relative_dur": 0.206794682422452, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "560 us"}}, "gpu3": {"time": {"ts": 1678056304776978000, "dur": 31000, "relative_dur": 0.011447562776957163, "relative_gap_to_previous": 0.07459379615952733, "parent_is_longest": true, "runtime_str": "31 us"}}}, "ops": [{"name": "aten::lift_fresh", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056304776854000, "dur": 3000, "relative_dur": 0.005357142857142857, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "aten::lift_fresh"}}, "id": "xTwEFuo2mu0jMrdh", "pretty_name": "aten::lift_fresh", "trace_file": "/results/DLRM/DLRM.7.pt.trace.json", "trace_disk_size": "107 Bytes", "runtime": 3000, "runtime_str": "3 us", "start_timestamp": "22:45:04.776.776854", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::to", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056304776862000, "dur": 48000, "relative_dur": 0.08571428571428572, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "48 us"}}, "gpu3": {"time": {"ts": 1678056304776978000, "dur": 31000, "relative_dur": 0.055357142857142855, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "31 us"}}}, "ops": [{"name": "aten::empty_strided", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056304776870000, "dur": 18000, "relative_dur": 0.375, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "18 us"}, "res_name": "aten::empty_strided"}}, "id": "ZZLcnE76M2VlbJtu", "pretty_name": "aten::empty_strided", "trace_file": "/results/DLRM/DLRM.9.pt.trace.json", "trace_disk_size": "111 Bytes", "runtime": 18000, "runtime_str": "18 us", "start_timestamp": "22:45:04.776.776870", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::copy_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056304776890000, "dur": 19000, "relative_dur": 0.3958333333333333, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "19 us"}, "res_name": "aten::copy_"}, "gpu3": {"time": {"ts": 1678056304776978000, "dur": 31000, "relative_dur": 0.6458333333333334, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "31 us"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "PEVPiw0BubGGz4Tx", "pretty_name": "aten::copy_", "trace_file": "/results/DLRM/DLRM.10.pt.trace.json", "trace_disk_size": "453 Bytes", "runtime": 31000, "runtime_str": "31 us", "start_timestamp": "22:45:04.776.776890", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 4}], "id": "UDTXVCTIdzZxBEEN", "pretty_name": "aten::to", "trace_file": "/results/DLRM/DLRM.8.pt.trace.json", "trace_disk_size": "769 Bytes", "runtime": 48000, "runtime_str": "48 us", "start_timestamp": "22:45:04.776.776862", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 7}, {"name": "aten::zeros(60%) and 3 others\u2026", "type": "generated", "generated_depth": 2, "instances": 6, "resources": {"cpu2": {"time": {"ts": 1678056304777038000, "dur": 481000, "relative_dur": 0.8589285714285714, "relative_gap_to_previous": 0.04107142857142857, "parent_is_longest": true, "runtime_str": "481 us"}, "res_name": "aten::zeros(60%) and 3 others\u2026"}}, "id": "FFboSImksAfHuQXQ", "pretty_name": "aten::zeros(60%) and 3 others\u2026", "trace_file": "/results/DLRM/DLRM.11.pt.trace.json", "trace_disk_size": "910 Bytes", "runtime": 481000, "runtime_str": "481 us", "start_timestamp": "22:45:04.777.777038", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 9}], "id": "vRMjhe1D9NY3571P", "pretty_name": "aten::to(82%) and 5 others\u2026", "trace_file": "/results/DLRM/DLRM.6.pt.trace.json", "trace_disk_size": "1.8 kB", "runtime": 560000, "runtime_str": "560 us", "start_timestamp": "22:45:04.776.776854", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 17}], "idx": 1, "id": "M2KcPEi9juEEXBU0", "pretty_name": "Load Data", "trace_file": "/results/DLRM/DLRM.2.pt.trace.json", "trace_disk_size": "2.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/submission_runner.py", "runtime": 2708000, "runtime_str": "2.71 ms", "start_timestamp": "22:45:04.774.774040", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 25}, {"name": "Forward", "type": "training loop", "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056304777525000, "dur": 178782000, "relative_dur": 0.19688043044950082, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "179 ms"}}, "gpu3": {"time": {"ts": 1678056304777960000, "dur": 343976000, "relative_dur": 0.3787973226851556, "relative_gap_to_previous": 0.0010472714778751511, "parent_is_longest": true, "runtime_str": "344 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 93, in update_params\n    with hotline.annotate('Forward'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py", "source_file_num": 93, "ops": [{"idx": 3, "name": "Bottom MLP", "type": "Bottom MLP", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 117, in forward\n    with hotline.annotate('Bottom MLP'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 117, "ops": [{"idx": 4, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 123, in forward\n    bot_mlp_output = hotline.annotate_module_list(self.bot_mlp, bot_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1678056304777526000, "dur": 731000, "relative_dur": 0.09388646288209607, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "731 us"}}, "gpu3": {"time": {"ts": 1678056304777960000, "dur": 2043000, "relative_dur": 0.26239404058566657, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.04 ms"}}}, "id": "ldbh2nbs8S0pKFER", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.14.pt.trace.json", "trace_disk_size": "4.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 2043000, "runtime_str": "2.04 ms", "start_timestamp": "22:45:04.777.777526", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 33}, {"idx": 5, "name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 123, in forward\n    bot_mlp_output = hotline.annotate_module_list(self.bot_mlp, bot_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1678056304778399000, "dur": 76000, "relative_dur": 0.009761109684048292, "relative_gap_to_previous": 0.018237862830721808, "parent_is_longest": true, "runtime_str": "76 us"}}, "gpu3": {"time": {"ts": 1678056304780004000, "dur": 953000, "relative_dur": 0.12239917801181607, "relative_gap_to_previous": 0.00012843565373747752, "parent_is_longest": true, "runtime_str": "953 us"}}}, "id": "bUxrFtyMHhR0tUmh", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.15.pt.trace.json", "trace_disk_size": "1.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 953000, "runtime_str": "953 us", "start_timestamp": "22:45:04.778.778399", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 8}, {"idx": 6, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 123, in forward\n    bot_mlp_output = hotline.annotate_module_list(self.bot_mlp, bot_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1678056304778592000, "dur": 89000, "relative_dur": 0.0114307731826355, "relative_gap_to_previous": 0.01502697148728487, "parent_is_longest": true, "runtime_str": "89 us"}}, "gpu3": {"time": {"ts": 1678056304780959000, "dur": 2988000, "relative_dur": 0.38376573336758285, "relative_gap_to_previous": 0.00025687130747495504, "parent_is_longest": true, "runtime_str": "2.99 ms"}}}, "id": "XcgLTstgtUxxhwsF", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.16.pt.trace.json", "trace_disk_size": "1.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 2988000, "runtime_str": "2.99 ms", "start_timestamp": "22:45:04.778.778592", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 13}, {"idx": 7, "name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 123, in forward\n    bot_mlp_output = hotline.annotate_module_list(self.bot_mlp, bot_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1678056304778801000, "dur": 49000, "relative_dur": 0.0062933470331363985, "relative_gap_to_previous": 0.015412278448497303, "parent_is_longest": true, "runtime_str": "49 us"}}, "gpu3": {"time": {"ts": 1678056304783948000, "dur": 479000, "relative_dur": 0.061520678140251736, "relative_gap_to_previous": 0.00012843565373747752, "parent_is_longest": true, "runtime_str": "479 us"}}}, "id": "GXD81VxU4HkPRMYr", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.17.pt.trace.json", "trace_disk_size": "1.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 479000, "runtime_str": "479 us", "start_timestamp": "22:45:04.778.778801", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 8}, {"idx": 8, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 123, in forward\n    bot_mlp_output = hotline.annotate_module_list(self.bot_mlp, bot_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1678056304778964000, "dur": 87000, "relative_dur": 0.011173901875160545, "relative_gap_to_previous": 0.014641664526072438, "parent_is_longest": true, "runtime_str": "87 us"}}, "gpu3": {"time": {"ts": 1678056304784429000, "dur": 1076000, "relative_dur": 0.13819676342152581, "relative_gap_to_previous": 0.00025687130747495504, "parent_is_longest": true, "runtime_str": "1.08 ms"}}}, "id": "aHSszuNlkPDrYFmT", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.18.pt.trace.json", "trace_disk_size": "1.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 1076000, "runtime_str": "1.08 ms", "start_timestamp": "22:45:04.778.778964", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 14}, {"idx": 9, "name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 123, in forward\n    bot_mlp_output = hotline.annotate_module_list(self.bot_mlp, bot_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1678056304779169000, "dur": 48000, "relative_dur": 0.0061649113793989215, "relative_gap_to_previous": 0.015155407141022348, "parent_is_longest": true, "runtime_str": "48 us"}}, "gpu3": {"time": {"ts": 1678056304785506000, "dur": 240000, "relative_dur": 0.030824556896994607, "relative_gap_to_previous": 0.00012843565373747752, "parent_is_longest": true, "runtime_str": "240 us"}}}, "id": "iPvslmF0YpmCPZwn", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.19.pt.trace.json", "trace_disk_size": "1.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 240000, "runtime_str": "240 us", "start_timestamp": "22:45:04.779.779169", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 8}], "resources": {"cpu2": {"time": {"ts": 1678056304777526000, "dur": 1691000, "relative_dur": 0.004916040653999116, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.69 ms"}}, "gpu3": {"time": {"ts": 1678056304777960000, "dur": 7786000, "relative_dur": 0.022635300137218876, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "7.79 ms"}}}, "id": "zlVp2rleCa0PypWx", "pretty_name": "Bottom MLP", "trace_file": "/results/DLRM/DLRM.13.pt.trace.json", "trace_disk_size": "11.3 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 7786000, "runtime_str": "7.79 ms", "start_timestamp": "22:45:04.777.777526", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 84}, {"idx": 10, "name": "ID Lookup", "type": "ID Lookup", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 125, in forward\n    with hotline.annotate('ID Lookup'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 125, "ops": [{"idx": 11, "name": "aten::remainder", "type": "aten::remainder", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 129, in forward\n    with hotline.annotate('aten::remainder'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 129, "resources": {"cpu2": {"time": {"ts": 1678056304779324000, "dur": 200000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "200 us"}}, "gpu3": {"time": {"ts": 1678056304785747000, "dur": 50000, "relative_dur": 0.25, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "50 us"}}}, "id": "K2bpitP9yOOITv24", "pretty_name": "aten::remainder", "trace_file": "/results/DLRM/DLRM.21.pt.trace.json", "trace_disk_size": "2.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 200000, "runtime_str": "200 us", "start_timestamp": "22:45:04.779.779324", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 15}], "resources": {"cpu2": {"time": {"ts": 1678056304779324000, "dur": 200000, "relative_dur": 0.0005814359141335442, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "200 us"}}, "gpu3": {"time": {"ts": 1678056304785747000, "dur": 50000, "relative_dur": 0.00014535897853338605, "relative_gap_to_previous": 2.907179570667721e-06, "parent_is_longest": true, "runtime_str": "50 us"}}}, "id": "hgGzMU6HgDtyGOdw", "pretty_name": "ID Lookup", "trace_file": "/results/DLRM/DLRM.20.pt.trace.json", "trace_disk_size": "2.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 200000, "runtime_str": "200 us", "start_timestamp": "22:45:04.779.779324", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 15}, {"idx": 12, "name": "Embedding", "type": "Embedding", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 132, in forward\n    with hotline.annotate('Embedding'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 132, "resources": {"cpu2": {"time": {"ts": 1678056304779639000, "dur": 84000, "relative_dur": 0.00024420308393608857, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "84 us"}}, "gpu3": {"time": {"ts": 1678056304785799000, "dur": 6226000, "relative_dur": 0.018100100006977232, "relative_gap_to_previous": 5.814359141335442e-06, "parent_is_longest": true, "runtime_str": "6.23 ms"}}}, "id": "9nzCugOI3ME0pyZ0", "pretty_name": "Embedding", "trace_file": "/results/DLRM/DLRM.22.pt.trace.json", "trace_disk_size": "1.3 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 6226000, "runtime_str": "6.23 ms", "start_timestamp": "22:45:04.779.779639", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 10}, {"idx": 13, "name": "Reshape Data", "type": "Reshape Data", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 135, in forward\n    with hotline.annotate('Reshape Data'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 135, "ops": [{"idx": 14, "name": "aten::reshape", "type": "aten::reshape", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 136, in forward\n    with hotline.annotate('aten::reshape'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 136, "resources": {"cpu2": {"time": {"ts": 1678056304779827000, "dur": 124000, "relative_dur": 0.01739862494738319, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "124 us"}}}, "id": "RMsKNoHUq41OjLhh", "pretty_name": "aten::reshape", "trace_file": "/results/DLRM/DLRM.24.pt.trace.json", "trace_disk_size": "1.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 124000, "runtime_str": "124 us", "start_timestamp": "22:45:04.779.779827", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 10}, {"idx": 15, "name": "aten::cat", "type": "aten::cat", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 139, in forward\n    with hotline.annotate('aten::cat'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 139, "resources": {"cpu2": {"time": {"ts": 1678056304780045000, "dur": 58000, "relative_dur": 0.008138066507646976, "relative_gap_to_previous": 0.013189280202048547, "parent_is_longest": true, "runtime_str": "58 us"}}, "gpu3": {"time": {"ts": 1678056304792026000, "dur": 7127000, "relative_dur": 1.0, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "7.13 ms"}}}, "id": "oI5aKxxThq0y6X5H", "pretty_name": "aten::cat", "trace_file": "/results/DLRM/DLRM.25.pt.trace.json", "trace_disk_size": "983 Bytes", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 7127000, "runtime_str": "7.13 ms", "start_timestamp": "22:45:04.780.780045", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 7}], "resources": {"cpu2": {"time": {"ts": 1678056304779827000, "dur": 276000, "relative_dur": 0.000802381561504291, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "276 us"}}, "gpu3": {"time": {"ts": 1678056304792026000, "dur": 7127000, "relative_dur": 0.020719468800148848, "relative_gap_to_previous": 2.907179570667721e-06, "parent_is_longest": true, "runtime_str": "7.13 ms"}}}, "id": "TyUQsxFCQ0aCKebG", "pretty_name": "Reshape Data", "trace_file": "/results/DLRM/DLRM.23.pt.trace.json", "trace_disk_size": "2.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 7127000, "runtime_str": "7.13 ms", "start_timestamp": "22:45:04.779.779827", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 17}, {"idx": 16, "name": "Feature Interaction", "type": "Feature Interaction", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 141, in forward\n    with hotline.annotate('Feature Interaction'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 141, "ops": [{"idx": 17, "name": "BatchMatMul", "type": "BatchMatMul", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 142, in forward\n    dot_interact_output = dot_interact(concat_features=feature_stack)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 21, in dot_interact\n    with hotline.annotate('BatchMatMul'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 21, "resources": {"cpu2": {"time": {"ts": 1678056304780208000, "dur": 236000, "relative_dur": 0.0008503769043398049, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "236 us"}}, "gpu3": {"time": {"ts": 1678056304799155000, "dur": 34956000, "relative_dur": 0.12595667401738228, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "35 ms"}}}, "id": "vTFO0AD8XQ1KHDfF", "pretty_name": "BatchMatMul", "trace_file": "/results/DLRM/DLRM.27.pt.trace.json", "trace_disk_size": "5.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 34956000, "runtime_str": "35 ms", "start_timestamp": "22:45:04.780.780208", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 43}, {"idx": 18, "name": "Tile", "type": "Tile", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 142, in forward\n    dot_interact_output = dot_interact(concat_features=feature_stack)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 27, in dot_interact\n    with hotline.annotate('Tile'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 27, "resources": {"cpu2": {"time": {"ts": 1678056304780555000, "dur": 53621000, "relative_dur": 0.19321211859154525, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "53.6 ms"}}}, "id": "mHbf8Yl7YOBb31X3", "pretty_name": "Tile", "trace_file": "/results/DLRM/DLRM.28.pt.trace.json", "trace_disk_size": "2.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 53621000, "runtime_str": "53.6 ms", "start_timestamp": "22:45:04.780.780555", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 19}, {"idx": 19, "name": "Concatenate", "type": "Concatenate", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 142, in forward\n    dot_interact_output = dot_interact(concat_features=feature_stack)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 33, in dot_interact\n    with hotline.annotate('Concatenate'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 33, "resources": {"cpu2": {"time": {"ts": 1678056304834660000, "dur": 114857000, "relative_dur": 0.4138633055159193, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "115 ms"}}}, "id": "7EqIHnP5499kLjZ3", "pretty_name": "Concatenate", "trace_file": "/results/DLRM/DLRM.29.pt.trace.json", "trace_disk_size": "3.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 114857000, "runtime_str": "115 ms", "start_timestamp": "22:45:04.834.834660", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 33}, {"idx": 20, "name": "Index", "type": "Index", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 142, in forward\n    dot_interact_output = dot_interact(concat_features=feature_stack)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 39, in dot_interact\n    with hotline.annotate('Index'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 39, "resources": {"cpu2": {"time": {"ts": 1678056304949570000, "dur": 3306000, "relative_dur": 0.011912483244692351, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3.31 ms"}}, "gpu3": {"time": {"ts": 1678056304952754000, "dur": 122829000, "relative_dur": 0.4425887490811605, "relative_gap_to_previous": 0.42750536890503166, "parent_is_longest": true, "runtime_str": "123 ms"}}}, "id": "44zqyaALIwZAMujS", "pretty_name": "Index", "trace_file": "/results/DLRM/DLRM.30.pt.trace.json", "trace_disk_size": "5.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 122829000, "runtime_str": "123 ms", "start_timestamp": "22:45:04.949.949570", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 42}, {"idx": 21, "name": "Concatenate", "type": "Concatenate", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 143, in forward\n    with hotline.annotate('Concatenate'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 143, "resources": {"cpu2": {"time": {"ts": 1678056305072686000, "dur": 1407000, "relative_dur": 0.0050698317983309555, "relative_gap_to_previous": 0.00011170205099378792, "parent_is_longest": true, "runtime_str": "1.41 ms"}}, "gpu3": {"time": {"ts": 1678056305075585000, "dur": 1094000, "relative_dur": 0.003942001412490451, "relative_gap_to_previous": 7.206583935083092e-06, "parent_is_longest": true, "runtime_str": "1.09 ms"}}}, "id": "bvnyfZNUvIclM8Mc", "pretty_name": "Concatenate", "trace_file": "/results/DLRM/DLRM.31.pt.trace.json", "trace_disk_size": "1.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 1407000, "runtime_str": "1.41 ms", "start_timestamp": "22:45:05.072.72686", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 9}], "resources": {"cpu2": {"time": {"ts": 1678056304780208000, "dur": 174106000, "relative_dur": 0.5061574063306742, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "174 ms"}}, "gpu3": {"time": {"ts": 1678056304799155000, "dur": 277524000, "relative_dur": 0.8068121031699886, "relative_gap_to_previous": 5.814359141335442e-06, "parent_is_longest": true, "runtime_str": "278 ms"}}}, "id": "9ch1scK22y937w1c", "pretty_name": "Feature Interaction", "trace_file": "/results/DLRM/DLRM.26.pt.trace.json", "trace_disk_size": "17.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 277524000, "runtime_str": "278 ms", "start_timestamp": "22:45:04.780.780208", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 146}, {"idx": 22, "name": "Top MLP", "type": "Top MLP", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 146, in forward\n    with hotline.annotate('Top MLP'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 146, "ops": [{"idx": 23, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1678056305074200000, "dur": 296000, "relative_dur": 0.006540569206293088, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "296 us"}}, "gpu3": {"time": {"ts": 1678056305076680000, "dur": 9525000, "relative_dur": 0.2104693300335867, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9.53 ms"}}}, "id": "7bp0jOCTL308U0CG", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.33.pt.trace.json", "trace_disk_size": "1.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 9525000, "runtime_str": "9.53 ms", "start_timestamp": "22:45:05.074.74200", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 17}, {"idx": 24, "name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1678056305074643000, "dur": 77000, "relative_dur": 0.001701431854339756, "relative_gap_to_previous": 0.0032481880855577162, "parent_is_longest": true, "runtime_str": "77 us"}}, "gpu3": {"time": {"ts": 1678056305086207000, "dur": 1904000, "relative_dur": 0.04207176948912851, "relative_gap_to_previous": 4.4193035177656004e-05, "parent_is_longest": true, "runtime_str": "1.90 ms"}}}, "id": "AcqvwxSfoxIc59gg", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.34.pt.trace.json", "trace_disk_size": "1.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 1904000, "runtime_str": "1.90 ms", "start_timestamp": "22:45:05.074.74643", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 8}, {"idx": 25, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1678056305074833000, "dur": 89000, "relative_dur": 0.001966590065405692, "relative_gap_to_previous": 0.0024969064875375643, "parent_is_longest": true, "runtime_str": "89 us"}}, "gpu3": {"time": {"ts": 1678056305088112000, "dur": 18026000, "relative_dur": 0.3983118260562135, "relative_gap_to_previous": 2.2096517588828002e-05, "parent_is_longest": true, "runtime_str": "18 ms"}}}, "id": "i29d9T9dgobPHCNZ", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.35.pt.trace.json", "trace_disk_size": "1.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 18026000, "runtime_str": "18 ms", "start_timestamp": "22:45:05.074.74833", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 14}, {"idx": 26, "name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1678056305075039000, "dur": 47000, "relative_dur": 0.0010385363266749161, "relative_gap_to_previous": 0.002585292557892876, "parent_is_longest": true, "runtime_str": "47 us"}}, "gpu3": {"time": {"ts": 1678056305106139000, "dur": 1905000, "relative_dur": 0.04209386600671734, "relative_gap_to_previous": 2.2096517588828002e-05, "parent_is_longest": true, "runtime_str": "1.91 ms"}}}, "id": "WfHdNdoQx09Py9P7", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.36.pt.trace.json", "trace_disk_size": "1.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 1905000, "runtime_str": "1.91 ms", "start_timestamp": "22:45:05.075.75039", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 8}, {"idx": 27, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1678056305075197000, "dur": 83000, "relative_dur": 0.0018340109598727241, "relative_gap_to_previous": 0.0024527134523599082, "parent_is_longest": true, "runtime_str": "83 us"}}, "gpu3": {"time": {"ts": 1678056305108045000, "dur": 9494000, "relative_dur": 0.20978433798833304, "relative_gap_to_previous": 2.2096517588828002e-05, "parent_is_longest": true, "runtime_str": "9.49 ms"}}}, "id": "ArM9BI0yQUBoM2Zu", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.37.pt.trace.json", "trace_disk_size": "1.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 9494000, "runtime_str": "9.49 ms", "start_timestamp": "22:45:05.075.75197", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 14}, {"idx": 28, "name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1678056305075395000, "dur": 49000, "relative_dur": 0.001082729361852572, "relative_gap_to_previous": 0.0025410995227152203, "parent_is_longest": true, "runtime_str": "49 us"}}, "gpu3": {"time": {"ts": 1678056305117540000, "dur": 955000, "relative_dur": 0.02110217429733074, "relative_gap_to_previous": 2.2096517588828002e-05, "parent_is_longest": true, "runtime_str": "955 us"}}}, "id": "ryKgYrKAn3Axw47S", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.38.pt.trace.json", "trace_disk_size": "1.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 955000, "runtime_str": "955 us", "start_timestamp": "22:45:05.075.75395", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 8}, {"idx": 29, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1678056305075580000, "dur": 96000, "relative_dur": 0.0021212656885274883, "relative_gap_to_previous": 0.003005126392080608, "parent_is_longest": true, "runtime_str": "96 us"}}, "gpu3": {"time": {"ts": 1678056305118497000, "dur": 2712000, "relative_dur": 0.059925755700901535, "relative_gap_to_previous": 4.4193035177656004e-05, "parent_is_longest": true, "runtime_str": "2.71 ms"}}}, "id": "K4Rbm7CTEdmI3yBp", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.39.pt.trace.json", "trace_disk_size": "1.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 2712000, "runtime_str": "2.71 ms", "start_timestamp": "22:45:05.075.75580", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 13}, {"idx": 30, "name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1678056305075790000, "dur": 47000, "relative_dur": 0.0010385363266749161, "relative_gap_to_previous": 0.002519003005126392, "parent_is_longest": true, "runtime_str": "47 us"}}, "gpu3": {"time": {"ts": 1678056305121210000, "dur": 480000, "relative_dur": 0.01060632844263744, "relative_gap_to_previous": 2.2096517588828002e-05, "parent_is_longest": true, "runtime_str": "480 us"}}}, "id": "Or3gtyT5VNBDTgyI", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.40.pt.trace.json", "trace_disk_size": "1.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 480000, "runtime_str": "480 us", "start_timestamp": "22:45:05.075.75790", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 8}, {"idx": 31, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1678056305075947000, "dur": 114000, "relative_dur": 0.002519003005126392, "relative_gap_to_previous": 0.00243061693477108, "parent_is_longest": true, "runtime_str": "114 us"}}, "gpu3": {"time": {"ts": 1678056305121691000, "dur": 245000, "relative_dur": 0.00541364680926286, "relative_gap_to_previous": 2.2096517588828002e-05, "parent_is_longest": true, "runtime_str": "245 us"}}}, "id": "GhjQoBzhazlubYlZ", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.41.pt.trace.json", "trace_disk_size": "2.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 245000, "runtime_str": "245 us", "start_timestamp": "22:45:05.075.75947", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 16}], "resources": {"cpu2": {"time": {"ts": 1678056305074200000, "dur": 1861000, "relative_dur": 0.005410261181012629, "relative_gap_to_previous": 0.00031106821406144615, "parent_is_longest": true, "runtime_str": "1.86 ms"}}, "gpu3": {"time": {"ts": 1678056305076680000, "dur": 45256000, "relative_dur": 0.13156731865013838, "relative_gap_to_previous": 2.907179570667721e-06, "parent_is_longest": true, "runtime_str": "45.3 ms"}}}, "id": "tlZ5jZds9y5Hy4UN", "pretty_name": "Top MLP", "trace_file": "/results/DLRM/DLRM.32.pt.trace.json", "trace_disk_size": "14.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 45256000, "runtime_str": "45.3 ms", "start_timestamp": "22:45:05.074.74200", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 106}], "is_model_pass": "Forward", "idx": 2, "id": "2KjAHumnCCmHfak1", "pretty_name": "Forward", "trace_file": "/results/DLRM/DLRM.12.pt.trace.json", "trace_disk_size": "49.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py", "runtime": 343976000, "runtime_str": "344 ms", "start_timestamp": "22:45:04.777.777525", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 379}, {"name": "Calc Loss", "type": "training loop", "instances": 20, "resources": {"cpu2": {"time": {"ts": 1678056305076167000, "dur": 581000, "relative_dur": 0.0006398156978396033, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "581 us"}}, "gpu3": {"time": {"ts": 1678056305121937000, "dur": 56000, "relative_dur": 6.166898292429912e-05, "relative_gap_to_previous": 1.1012318379339128e-06, "parent_is_longest": true, "runtime_str": "56 us"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 102, in update_params\n    with hotline.annotate('Calc Loss'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py", "source_file_num": 102, "ops": [{"name": "aten::reshape(72%) and 3 others\u2026", "type": "generated", "generated_depth": 1, "instances": 5, "resources": {"cpu2": {"time": {"ts": 1678056305076167000, "dur": 37000, "relative_dur": 0.06368330464716007, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "37 us"}}}, "ops": [{"name": "aten::zeros", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056305076167000, "dur": 4000, "relative_dur": 0.10810810810810811, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4 us"}, "res_name": "aten::zeros"}}, "id": "Af7vxUSl7R4J4oUI", "pretty_name": "aten::zeros", "trace_file": "/results/DLRM/DLRM.44.pt.trace.json", "trace_disk_size": "203 Bytes", "runtime": 4000, "runtime_str": "4 us", "start_timestamp": "22:45:05.076.76167", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::empty", "type": "generated", "generated_depth": 2, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1678056305076171000, "dur": 8000, "relative_dur": 0.21621621621621623, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "8 us"}}}, "ops": [{"name": "aten::zero_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056305076171000, "dur": 0, "relative_dur": 0.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "0 us"}, "res_name": "aten::zero_"}}, "id": "MZtKeA4PLKb4YnIs", "pretty_name": "aten::zero_", "trace_file": "/results/DLRM/DLRM.46.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 0, "runtime_str": "0 us", "start_timestamp": "22:45:05.076.76171", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "4citb8Xob3XdunPf", "pretty_name": "aten::empty", "trace_file": "/results/DLRM/DLRM.45.pt.trace.json", "trace_disk_size": "203 Bytes", "runtime": 8000, "runtime_str": "8 us", "start_timestamp": "22:45:05.076.76171", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::reshape", "type": "generated", "generated_depth": 2, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1678056305076189000, "dur": 15000, "relative_dur": 0.40540540540540543, "relative_gap_to_previous": 0.2702702702702703, "parent_is_longest": true, "runtime_str": "15 us"}, "res_name": "aten::reshape"}}, "id": "XpKdkcX1xPnCQsnt", "pretty_name": "aten::reshape", "trace_file": "/results/DLRM/DLRM.47.pt.trace.json", "trace_disk_size": "427 Bytes", "runtime": 15000, "runtime_str": "15 us", "start_timestamp": "22:45:05.076.76189", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 4}], "id": "da6STBwrKRL2d7sJ", "pretty_name": "aten::reshape(72%) and 3 others\u2026", "trace_file": "/results/DLRM/DLRM.43.pt.trace.json", "trace_disk_size": "831 Bytes", "runtime": 37000, "runtime_str": "37 us", "start_timestamp": "22:45:05.076.76167", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 8}, {"name": "aten::log_sigmoid", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056305076223000, "dur": 52000, "relative_dur": 0.08950086058519793, "relative_gap_to_previous": 0.03270223752151463, "parent_is_longest": true, "runtime_str": "52 us"}}, "gpu3": {"time": {"ts": 1678056305121937000, "dur": 4000, "relative_dur": 0.0068846815834767644, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "4 us"}}}, "ops": [{"name": "aten::empty_like", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056305076233000, "dur": 12000, "relative_dur": 0.23076923076923078, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12 us"}, "res_name": "aten::empty_like"}}, "id": "exkBpeYL77gLUY5u", "pretty_name": "aten::empty_like", "trace_file": "/results/DLRM/DLRM.49.pt.trace.json", "trace_disk_size": "217 Bytes", "runtime": 12000, "runtime_str": "12 us", "start_timestamp": "22:45:05.076.76233", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::empty", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056305076246000, "dur": 3000, "relative_dur": 0.057692307692307696, "relative_gap_to_previous": 0.019230769230769232, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "aten::empty"}}, "id": "kvrMjk7KzQPPnvTN", "pretty_name": "aten::empty", "trace_file": "/results/DLRM/DLRM.50.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 3000, "runtime_str": "3 us", "start_timestamp": "22:45:05.076.76246", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "cudaLaunchKernel", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056305076258000, "dur": 13000, "relative_dur": 0.25, "relative_gap_to_previous": 0.17307692307692307, "parent_is_longest": true, "runtime_str": "13 us"}, "res_name": "cudaLaunchKernel"}, "gpu3": {"time": {"ts": 1678056305121937000, "dur": 4000, "relative_dur": 0.07692307692307693, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "4 us"}, "res_name": "vectorized_elementwise_kernel<4 launch_log_sigmoid_forward_kernelTensorIteratorBase&::{lambda#1}::operator const::{lambda#4}::operator const::{lambda#1} Array<char 2> launch_log_sigmoid_forward_kernelTensorIteratorBase&::{lambda#1}::operator const::{lambda#4}::operator const::{lambda#1} Array<char 2>"}}, "id": "NMDJDbL59Vnb4Oa0", "pretty_name": "cudaLaunchKernel", "trace_file": "/results/DLRM/DLRM.51.pt.trace.json", "trace_disk_size": "627 Bytes", "runtime": 13000, "runtime_str": "13 us", "start_timestamp": "22:45:05.076.76258", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}], "id": "OtKUd6Cs5fHQnzgZ", "pretty_name": "aten::log_sigmoid", "trace_file": "/results/DLRM/DLRM.48.pt.trace.json", "trace_disk_size": "1.2 kB", "runtime": 52000, "runtime_str": "52 us", "start_timestamp": "22:45:05.076.76223", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 7}, {"name": "aten::neg(34%) and 2 others\u2026", "type": "generated", "generated_depth": 1, "instances": 3, "resources": {"cpu2": {"time": {"ts": 1678056305076286000, "dur": 84000, "relative_dur": 0.14457831325301204, "relative_gap_to_previous": 0.0189328743545611, "parent_is_longest": true, "runtime_str": "84 us"}}, "gpu3": {"time": {"ts": 1678056305121943000, "dur": 11000, "relative_dur": 0.0189328743545611, "relative_gap_to_previous": 0.0034423407917383822, "parent_is_longest": true, "runtime_str": "11 us"}}}, "ops": [{"name": "aten::neg", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056305076286000, "dur": 25000, "relative_dur": 0.2976190476190476, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "25 us"}, "res_name": "aten::neg"}, "gpu3": {"time": {"ts": 1678056305121943000, "dur": 3000, "relative_dur": 0.03571428571428571, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "vectorized_elementwise_kernel<4 neg_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda#1} Array<char 2> neg_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda#1} Array<char 2>"}}, "id": "RaNogh8sHDo21Yvr", "pretty_name": "aten::neg", "trace_file": "/results/DLRM/DLRM.53.pt.trace.json", "trace_disk_size": "692 Bytes", "runtime": 25000, "runtime_str": "25 us", "start_timestamp": "22:45:05.076.76286", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::log_sigmoid", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056305076316000, "dur": 25000, "relative_dur": 0.2976190476190476, "relative_gap_to_previous": 0.05952380952380952, "parent_is_longest": true, "runtime_str": "25 us"}}, "gpu3": {"time": {"ts": 1678056305121947000, "dur": 3000, "relative_dur": 0.03571428571428571, "relative_gap_to_previous": 0.011904761904761904, "parent_is_longest": true, "runtime_str": "3 us"}}}, "ops": [{"name": "aten::empty_like", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056305076320000, "dur": 5000, "relative_dur": 0.2, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5 us"}, "res_name": "aten::empty_like"}}, "id": "axq7GKy1hdEuXh37", "pretty_name": "aten::empty_like", "trace_file": "/results/DLRM/DLRM.55.pt.trace.json", "trace_disk_size": "216 Bytes", "runtime": 5000, "runtime_str": "5 us", "start_timestamp": "22:45:05.076.76320", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::empty", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056305076326000, "dur": 3000, "relative_dur": 0.12, "relative_gap_to_previous": 0.04, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "aten::empty"}}, "id": "M4QKeE5iBRYbBl7H", "pretty_name": "aten::empty", "trace_file": "/results/DLRM/DLRM.56.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 3000, "runtime_str": "3 us", "start_timestamp": "22:45:05.076.76326", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "cudaLaunchKernel", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056305076332000, "dur": 5000, "relative_dur": 0.2, "relative_gap_to_previous": 0.12, "parent_is_longest": true, "runtime_str": "5 us"}, "res_name": "cudaLaunchKernel"}, "gpu3": {"time": {"ts": 1678056305121947000, "dur": 3000, "relative_dur": 0.12, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "vectorized_elementwise_kernel<4 launch_log_sigmoid_forward_kernelTensorIteratorBase&::{lambda#1}::operator const::{lambda#4}::operator const::{lambda#1} Array<char 2> launch_log_sigmoid_forward_kernelTensorIteratorBase&::{lambda#1}::operator const::{lambda#4}::operator const::{lambda#1} Array<char 2>"}}, "id": "7VfiP0Cqt92NGchI", "pretty_name": "cudaLaunchKernel", "trace_file": "/results/DLRM/DLRM.57.pt.trace.json", "trace_disk_size": "626 Bytes", "runtime": 5000, "runtime_str": "5 us", "start_timestamp": "22:45:05.076.76332", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}], "id": "K9pgHlpeOj8RSHKZ", "pretty_name": "aten::log_sigmoid", "trace_file": "/results/DLRM/DLRM.54.pt.trace.json", "trace_disk_size": "1.2 kB", "runtime": 25000, "runtime_str": "25 us", "start_timestamp": "22:45:05.076.76316", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 7}, {"name": "aten::mul", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056305076346000, "dur": 24000, "relative_dur": 0.2857142857142857, "relative_gap_to_previous": 0.05952380952380952, "parent_is_longest": true, "runtime_str": "24 us"}, "res_name": "aten::mul"}, "gpu3": {"time": {"ts": 1678056305121951000, "dur": 3000, "relative_dur": 0.03571428571428571, "relative_gap_to_previous": 0.011904761904761904, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "vectorized_elementwise_kernel<4 BinaryFunctor  binary_ernal::MulFunctor Array<char 3> BinaryFunctor  binary_ernal::MulFunctor Array<char 3>"}}, "id": "mH4KKQyURadS49QW", "pretty_name": "aten::mul", "trace_file": "/results/DLRM/DLRM.58.pt.trace.json", "trace_disk_size": "602 Bytes", "runtime": 24000, "runtime_str": "24 us", "start_timestamp": "22:45:05.076.76346", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}], "id": "RuQ2vIDCEW5KZchc", "pretty_name": "aten::neg(34%) and 2 others\u2026", "trace_file": "/results/DLRM/DLRM.52.pt.trace.json", "trace_disk_size": "2.5 kB", "runtime": 84000, "runtime_str": "84 us", "start_timestamp": "22:45:05.076.76286", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 13}, {"name": "aten::rsub", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056305076389000, "dur": 31000, "relative_dur": 0.05335628227194492, "relative_gap_to_previous": 0.03270223752151463, "parent_is_longest": true, "runtime_str": "31 us"}, "res_name": "aten::rsub"}, "gpu3": {"time": {"ts": 1678056305121955000, "dur": 3000, "relative_dur": 0.0051635111876075735, "relative_gap_to_previous": 0.0017211703958691911, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctorOnOther_add Array<char 2> CUDAFunctorOnOther_add Array<char 2>"}}, "id": "iJyqUOl3SAY7YiDY", "pretty_name": "aten::rsub", "trace_file": "/results/DLRM/DLRM.59.pt.trace.json", "trace_disk_size": "595 Bytes", "runtime": 31000, "runtime_str": "31 us", "start_timestamp": "22:45:05.076.76389", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 4}, {"name": "aten::add(33%) and 2 others\u2026", "type": "generated", "generated_depth": 1, "instances": 4, "resources": {"cpu2": {"time": {"ts": 1678056305076423000, "dur": 85000, "relative_dur": 0.14629948364888123, "relative_gap_to_previous": 0.0051635111876075735, "parent_is_longest": true, "runtime_str": "85 us"}}, "gpu3": {"time": {"ts": 1678056305121959000, "dur": 12000, "relative_dur": 0.020654044750430294, "relative_gap_to_previous": 0.0017211703958691911, "parent_is_longest": true, "runtime_str": "12 us"}}}, "ops": [{"name": "aten::mul", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056305076423000, "dur": 17000, "relative_dur": 0.2, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "17 us"}, "res_name": "aten::mul"}, "gpu3": {"time": {"ts": 1678056305121959000, "dur": 3000, "relative_dur": 0.03529411764705882, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "vectorized_elementwise_kernel<4 BinaryFunctor  binary_ernal::MulFunctor Array<char 3> BinaryFunctor  binary_ernal::MulFunctor Array<char 3>"}}, "id": "EQmGs3kohDe0jIfR", "pretty_name": "aten::mul", "trace_file": "/results/DLRM/DLRM.61.pt.trace.json", "trace_disk_size": "602 Bytes", "runtime": 17000, "runtime_str": "17 us", "start_timestamp": "22:45:05.076.76423", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::add", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056305076444000, "dur": 20000, "relative_dur": 0.23529411764705882, "relative_gap_to_previous": 0.047058823529411764, "parent_is_longest": true, "runtime_str": "20 us"}, "res_name": "aten::add"}, "gpu3": {"time": {"ts": 1678056305121963000, "dur": 3000, "relative_dur": 0.03529411764705882, "relative_gap_to_previous": 0.011764705882352941, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>"}}, "id": "QATV1bmCYy3StB2K", "pretty_name": "aten::add", "trace_file": "/results/DLRM/DLRM.62.pt.trace.json", "trace_disk_size": "480 Bytes", "runtime": 20000, "runtime_str": "20 us", "start_timestamp": "22:45:05.076.76444", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::mul", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056305076471000, "dur": 18000, "relative_dur": 0.21176470588235294, "relative_gap_to_previous": 0.08235294117647059, "parent_is_longest": true, "runtime_str": "18 us"}, "res_name": "aten::mul"}, "gpu3": {"time": {"ts": 1678056305121968000, "dur": 3000, "relative_dur": 0.03529411764705882, "relative_gap_to_previous": 0.023529411764705882, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "vectorized_elementwise_kernel<4 AUnaryFunctor  binary_ernal::MulFunctor Array<char 2> AUnaryFunctor  binary_ernal::MulFunctor Array<char 2>"}}, "id": "pd51MFRdkE2L3kAM", "pretty_name": "aten::mul", "trace_file": "/results/DLRM/DLRM.63.pt.trace.json", "trace_disk_size": "602 Bytes", "runtime": 18000, "runtime_str": "18 us", "start_timestamp": "22:45:05.076.76471", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::reshape", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056305076502000, "dur": 6000, "relative_dur": 0.07058823529411765, "relative_gap_to_previous": 0.15294117647058825, "parent_is_longest": true, "runtime_str": "6 us"}, "res_name": "aten::reshape"}}, "id": "uxPu1fry4V8daSR9", "pretty_name": "aten::reshape", "trace_file": "/results/DLRM/DLRM.64.pt.trace.json", "trace_disk_size": "214 Bytes", "runtime": 6000, "runtime_str": "6 us", "start_timestamp": "22:45:05.076.76502", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}], "id": "QHK5eLKX86WVFlBF", "pretty_name": "aten::add(33%) and 2 others\u2026", "trace_file": "/results/DLRM/DLRM.60.pt.trace.json", "trace_disk_size": "1.9 kB", "runtime": 85000, "runtime_str": "85 us", "start_timestamp": "22:45:05.076.76423", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 11}, {"name": "aten::sum", "type": "generated", "generated_depth": 1, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1678056305076512000, "dur": 92000, "relative_dur": 0.15834767641996558, "relative_gap_to_previous": 0.0068846815834767644, "parent_is_longest": true, "runtime_str": "92 us"}, "res_name": "aten::sum"}, "gpu3": {"time": {"ts": 1678056305121972000, "dur": 17000, "relative_dur": 0.029259896729776247, "relative_gap_to_previous": 0.0017211703958691911, "parent_is_longest": true, "runtime_str": "17 us"}, "res_name": "reduce_kernel<128 4 ReduceOpfunc_wrapper_tsum_functor::operatorTensorIterator&::{lambda #1}>    4>ReduceOpfunc_wrapper_tsum_functor::operatorTensorIterator&::{lambda #1}>    4>(54%) and 2 others\u2026"}}, "id": "iDLhE3V13GYb7lI8", "pretty_name": "aten::sum", "trace_file": "/results/DLRM/DLRM.65.pt.trace.json", "trace_disk_size": "2.0 kB", "runtime": 92000, "runtime_str": "92 us", "start_timestamp": "22:45:05.076.76512", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 11}, {"name": "aten::div(73%) and 2 others\u2026", "type": "generated", "generated_depth": 1, "instances": 4, "resources": {"cpu2": {"time": {"ts": 1678056305076611000, "dur": 137000, "relative_dur": 0.23580034423407917, "relative_gap_to_previous": 0.012048192771084338, "parent_is_longest": true, "runtime_str": "137 us"}}, "gpu3": {"time": {"ts": 1678056305121991000, "dur": 2000, "relative_dur": 0.0034423407917383822, "relative_gap_to_previous": 0.0034423407917383822, "parent_is_longest": true, "runtime_str": "2 us"}}}, "ops": [{"name": "aten::div", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056305076611000, "dur": 24000, "relative_dur": 0.17518248175182483, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "24 us"}, "res_name": "aten::div"}, "gpu3": {"time": {"ts": 1678056305121991000, "dur": 2000, "relative_dur": 0.014598540145985401, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "vectorized_elementwise_kernel<4 BUnaryFunctor  binary_ernal::MulFunctor Array<char 2> BUnaryFunctor  binary_ernal::MulFunctor Array<char 2>"}}, "id": "8KBIaseKF7Qeh897", "pretty_name": "aten::div", "trace_file": "/results/DLRM/DLRM.67.pt.trace.json", "trace_disk_size": "602 Bytes", "runtime": 24000, "runtime_str": "24 us", "start_timestamp": "22:45:05.076.76611", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::zeros(89%) and 1 other\u2026", "type": "generated", "generated_depth": 2, "instances": 3, "resources": {"cpu2": {"time": {"ts": 1678056305076722000, "dur": 26000, "relative_dur": 0.1897810218978102, "relative_gap_to_previous": 0.635036496350365, "parent_is_longest": true, "runtime_str": "26 us"}}}, "ops": [{"name": "aten::zeros", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056305076722000, "dur": 5000, "relative_dur": 0.19230769230769232, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5 us"}, "res_name": "aten::zeros"}}, "id": "1a01vYz8YLb7gp5f", "pretty_name": "aten::zeros", "trace_file": "/results/DLRM/DLRM.69.pt.trace.json", "trace_disk_size": "304 Bytes", "runtime": 5000, "runtime_str": "5 us", "start_timestamp": "22:45:05.076.76722", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::empty", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056305076734000, "dur": 1000, "relative_dur": 0.038461538461538464, "relative_gap_to_previous": 0.2692307692307692, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::empty"}}, "id": "NEugP097NMrylKfd", "pretty_name": "aten::empty", "trace_file": "/results/DLRM/DLRM.70.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "22:45:05.076.76734", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::zeros", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056305076745000, "dur": 3000, "relative_dur": 0.11538461538461539, "relative_gap_to_previous": 0.38461538461538464, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "aten::zeros"}}, "id": "86owPzqfGIyBYXsX", "pretty_name": "aten::zeros", "trace_file": "/results/DLRM/DLRM.71.pt.trace.json", "trace_disk_size": "304 Bytes", "runtime": 3000, "runtime_str": "3 us", "start_timestamp": "22:45:05.076.76745", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}], "id": "vd5OB31t6xueyZgZ", "pretty_name": "aten::zeros(89%) and 1 other\u2026", "trace_file": "/results/DLRM/DLRM.68.pt.trace.json", "trace_disk_size": "708 Bytes", "runtime": 26000, "runtime_str": "26 us", "start_timestamp": "22:45:05.076.76722", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 7}], "id": "hlTxo8iLYWsdHjgo", "pretty_name": "aten::div(73%) and 2 others\u2026", "trace_file": "/results/DLRM/DLRM.66.pt.trace.json", "trace_disk_size": "1.3 kB", "runtime": 137000, "runtime_str": "137 us", "start_timestamp": "22:45:05.076.76611", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 10}], "idx": 32, "id": "WgeGnF8Rf3KxhbVe", "pretty_name": "Calc Loss", "trace_file": "/results/DLRM/DLRM.42.pt.trace.json", "trace_disk_size": "10.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py", "runtime": 581000, "runtime_str": "581 us", "start_timestamp": "22:45:05.076.76167", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 64}, {"name": "Zero Grad", "type": "training loop", "instances": 4, "resources": {"cpu2": {"time": {"ts": 1678056305076751000, "dur": 389000, "relative_dur": 0.0004283791849562921, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "389 us"}}, "gpu3": {"time": {"ts": 1678056305121994000, "dur": 2470000, "relative_dur": 0.002720042639696765, "relative_gap_to_previous": 1.1012318379339128e-06, "parent_is_longest": true, "runtime_str": "2.47 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 106, in update_params\n    with hotline.annotate('Zero Grad'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py", "source_file_num": 106, "ops": [{"name": "aten::empty", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056305076752000, "dur": 1000, "relative_dur": 0.0004048582995951417, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::empty"}}, "id": "tnF4njKlcZYC6qH3", "pretty_name": "aten::empty", "trace_file": "/results/DLRM/DLRM.73.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "22:45:05.076.76752", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::zero_", "type": "generated", "generated_depth": 2, "instances": 17, "resources": {"cpu2": {"time": {"ts": 1678056305076763000, "dur": 240000, "relative_dur": 0.09716599190283401, "relative_gap_to_previous": 0.004048582995951417, "parent_is_longest": true, "runtime_str": "240 us"}, "res_name": "aten::zero_"}, "gpu3": {"time": {"ts": 1678056305121994000, "dur": 2467000, "relative_dur": 0.9987854251012146, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "2.47 ms"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>"}}, "id": "9HgDrw9CR7mfm1mc", "pretty_name": "aten::zero_", "trace_file": "/results/DLRM/DLRM.74.pt.trace.json", "trace_disk_size": "9.8 kB", "runtime": 2467000, "runtime_str": "2.47 ms", "start_timestamp": "22:45:05.076.76763", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 68}, {"name": "aten::ones_like(81%) and 2 others\u2026", "type": "generated", "instances": 9, "id": "kjTaNNQrjGcT0804", "resources": {"cpu2": {"time": {"ts": 1678056305077083000, "dur": 57000, "relative_dur": 0.023076923076923078, "relative_gap_to_previous": 0.032388663967611336, "parent_is_longest": true, "runtime_str": "57 us"}, "res_name": "aten::ones_like(81%) and 2 others\u2026"}, "gpu3": {"time": {"ts": 1678056305124462000, "dur": 2000, "relative_dur": 0.0008097165991902834, "relative_gap_to_previous": 0.0004048582995951417, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>"}}, "pretty_name": "aten::ones_like(81%) and 2 others\u2026", "trace_file": "/results/DLRM/DLRM.75.pt.trace.json", "trace_disk_size": "1.2 kB", "runtime": 57000, "runtime_str": "57 us", "start_timestamp": "22:45:05.077.77083", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 10}], "idx": 33, "id": "AIVlDERy17f7e09U", "pretty_name": "Zero Grad", "trace_file": "/results/DLRM/DLRM.72.pt.trace.json", "trace_disk_size": "11.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py", "runtime": 2470000, "runtime_str": "2.47 ms", "start_timestamp": "22:45:05.076.76751", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 80}, {"name": "Backward", "type": "training loop", "instances": 64, "resources": {"cpu2": {"time": {"ts": 1678056305600077000, "dur": 93000, "relative_dur": 0.3179014045110861, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "93 us"}}, "cpu4": {"time": {"ts": 1678056305077268000, "dur": 288678000, "relative_dur": 0.3179014045110861, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "289 ms"}}, "gpu3": {"time": {"ts": 1678056305124465000, "dur": 501891000, "relative_dur": 0.5526983483724894, "relative_gap_to_previous": 1.1012318379339128e-06, "parent_is_longest": true, "runtime_str": "502 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 109, in update_params\n    with hotline.annotate('Backward'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py", "source_file_num": 109, "ops": [{"name": "Top MLP", "type": "Top MLP", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 146, in forward\n    with hotline.annotate('Top MLP'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 146, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1678056305077268000, "dur": 748000, "relative_dur": 0.009101196052903745, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "748 us"}}, "gpu3": {"time": {"ts": 1678056305124465000, "dur": 522000, "relative_dur": 0.006351369437988977, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "522 us"}}}, "is_backward_op": true, "id": "z6xlbUZvpzG4Wq51", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.78.pt.trace.json", "trace_disk_size": "14.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 748000, "runtime_str": "748 us", "start_timestamp": "22:45:05.077.77268", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu4", "trace_event_count": 94}, {"name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1678056305078028000, "dur": 101000, "relative_dur": 0.001228904814630051, "relative_gap_to_previous": 0.00014600849282733278, "parent_is_longest": true, "runtime_str": "101 us"}}, "gpu3": {"time": {"ts": 1678056305124988000, "dur": 716000, "relative_dur": 0.008711840072030857, "relative_gap_to_previous": 1.2167374402277733e-05, "parent_is_longest": true, "runtime_str": "716 us"}}}, "is_backward_op": true, "id": "qqh25886tNZX9Ekp", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.79.pt.trace.json", "trace_disk_size": "3.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 716000, "runtime_str": "716 us", "start_timestamp": "22:45:05.078.78028", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 20}, {"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1678056305078133000, "dur": 141000, "relative_dur": 0.0017155997907211604, "relative_gap_to_previous": 4.866949760911093e-05, "parent_is_longest": true, "runtime_str": "141 us"}}, "gpu3": {"time": {"ts": 1678056305125706000, "dur": 5042000, "relative_dur": 0.06134790173628433, "relative_gap_to_previous": 2.4334748804555465e-05, "parent_is_longest": true, "runtime_str": "5.04 ms"}}}, "is_backward_op": true, "id": "ElYKUTVRJpfrWsh6", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.80.pt.trace.json", "trace_disk_size": "4.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 5042000, "runtime_str": "5.04 ms", "start_timestamp": "22:45:05.078.78133", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 32}, {"name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1678056305078282000, "dur": 79000, "relative_dur": 0.0009612225777799408, "relative_gap_to_previous": 9.733899521822186e-05, "parent_is_longest": true, "runtime_str": "79 us"}}, "gpu3": {"time": {"ts": 1678056305130749000, "dur": 1427000, "relative_dur": 0.017362843272050323, "relative_gap_to_previous": 1.2167374402277733e-05, "parent_is_longest": true, "runtime_str": "1.43 ms"}}}, "is_backward_op": true, "id": "8dicQCh22qRGL85w", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.81.pt.trace.json", "trace_disk_size": "3.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 1427000, "runtime_str": "1.43 ms", "start_timestamp": "22:45:05.078.78282", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 20}, {"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1678056305078365000, "dur": 127000, "relative_dur": 0.001545256549089272, "relative_gap_to_previous": 4.866949760911093e-05, "parent_is_longest": true, "runtime_str": "127 us"}}, "gpu3": {"time": {"ts": 1678056305132177000, "dur": 18471000, "relative_dur": 0.224743572584472, "relative_gap_to_previous": 1.2167374402277733e-05, "parent_is_longest": true, "runtime_str": "18.5 ms"}}}, "is_backward_op": true, "id": "4Jz4LifjubpAWllK", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.82.pt.trace.json", "trace_disk_size": "4.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 18471000, "runtime_str": "18.5 ms", "start_timestamp": "22:45:05.078.78365", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 34}, {"name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1678056305078500000, "dur": 78000, "relative_dur": 0.0009490552033776631, "relative_gap_to_previous": 9.733899521822186e-05, "parent_is_longest": true, "runtime_str": "78 us"}}, "gpu3": {"time": {"ts": 1678056305150649000, "dur": 2850000, "relative_dur": 0.03467701704649154, "relative_gap_to_previous": 1.2167374402277733e-05, "parent_is_longest": true, "runtime_str": "2.85 ms"}}}, "is_backward_op": true, "id": "6IWrntqbUje0eg9V", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.83.pt.trace.json", "trace_disk_size": "3.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 2850000, "runtime_str": "2.85 ms", "start_timestamp": "22:45:05.078.78500", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 20}, {"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1678056305078582000, "dur": 118000, "relative_dur": 0.0014357501794687725, "relative_gap_to_previous": 4.866949760911093e-05, "parent_is_longest": true, "runtime_str": "118 us"}}, "gpu3": {"time": {"ts": 1678056305153501000, "dur": 33548000, "relative_dur": 0.4081910764476134, "relative_gap_to_previous": 2.4334748804555465e-05, "parent_is_longest": true, "runtime_str": "33.5 ms"}}}, "is_backward_op": true, "id": "iUC4HB4kyGvhH1N3", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.84.pt.trace.json", "trace_disk_size": "4.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 33548000, "runtime_str": "33.5 ms", "start_timestamp": "22:45:05.078.78582", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 34}, {"name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1678056305078707000, "dur": 80000, "relative_dur": 0.0009733899521822186, "relative_gap_to_previous": 8.517162081594413e-05, "parent_is_longest": true, "runtime_str": "80 us"}}, "gpu3": {"time": {"ts": 1678056305187050000, "dur": 2856000, "relative_dur": 0.034750021292905206, "relative_gap_to_previous": 1.2167374402277733e-05, "parent_is_longest": true, "runtime_str": "2.86 ms"}}}, "is_backward_op": true, "id": "SfBRMkixMMCnegV6", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.85.pt.trace.json", "trace_disk_size": "3.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 2856000, "runtime_str": "2.86 ms", "start_timestamp": "22:45:05.078.78707", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 20}, {"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 148, in forward\n    logits = hotline.annotate_module_list(self.top_mlp, top_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1678056305078791000, "dur": 119000, "relative_dur": 0.00144791755387105, "relative_gap_to_previous": 4.866949760911093e-05, "parent_is_longest": true, "runtime_str": "119 us"}}, "gpu3": {"time": {"ts": 1678056305189907000, "dur": 16745000, "relative_dur": 0.20374268436614063, "relative_gap_to_previous": 1.2167374402277733e-05, "parent_is_longest": true, "runtime_str": "16.8 ms"}}}, "is_backward_op": true, "id": "505DdDRxzD69oPdx", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.86.pt.trace.json", "trace_disk_size": "4.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 16745000, "runtime_str": "16.8 ms", "start_timestamp": "22:45:05.078.78791", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 34}], "resources": {"cpu4": {"time": {"ts": 1678056305077268000, "dur": 1642000, "relative_dur": 0.003271626707791134, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.64 ms"}}, "gpu3": {"time": {"ts": 1678056305124465000, "dur": 82187000, "relative_dur": 0.16375467980099265, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "82.2 ms"}}}, "is_backward_op": true, "id": "M91uWuvZyfr0pN5h", "pretty_name": "Top MLP", "trace_file": "/results/DLRM/DLRM.77.pt.trace.json", "trace_disk_size": "44.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 82187000, "runtime_str": "82.2 ms", "start_timestamp": "22:45:05.077.77268", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 308}, {"name": "Feature Interaction", "type": "Feature Interaction", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 141, in forward\n    with hotline.annotate('Feature Interaction'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 141, "ops": [{"name": "Concatenate", "type": "Concatenate", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 143, in forward\n    with hotline.annotate('Concatenate'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 143, "resources": {"cpu4": {"time": {"ts": 1678056305078918000, "dur": 77000, "relative_dur": 0.00018693540046661018, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "77 us"}}, "gpu3": {"time": {"ts": 1678056305206653000, "dur": 11000, "relative_dur": 2.670505720951574e-05, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "11 us"}}}, "is_backward_op": true, "id": "haB3UiwlBgv9jTGY", "pretty_name": "Concatenate", "trace_file": "/results/DLRM/DLRM.88.pt.trace.json", "trace_disk_size": "2.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 77000, "runtime_str": "77 us", "start_timestamp": "22:45:05.078.78918", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu4", "trace_event_count": 23}, {"name": "Index", "type": "Index", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 142, in forward\n    dot_interact_output = dot_interact(concat_features=feature_stack)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 39, in dot_interact\n    with hotline.annotate('Index'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 39, "resources": {"cpu4": {"time": {"ts": 1678056305078998000, "dur": 285227000, "relative_dur": 0.6924548502453224, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "285 ms"}}, "gpu3": {"time": {"ts": 1678056305206665000, "dur": 347479000, "relative_dur": 0.8435860521913927, "relative_gap_to_previous": 2.42773247359234e-06, "parent_is_longest": true, "runtime_str": "347 ms"}}}, "is_backward_op": true, "id": "xiF9gzxXMiW7wN07", "pretty_name": "Index", "trace_file": "/results/DLRM/DLRM.89.pt.trace.json", "trace_disk_size": "16.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 347479000, "runtime_str": "347 ms", "start_timestamp": "22:45:05.078.78998", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 110}, {"name": "Concatenate", "type": "Concatenate", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 142, in forward\n    dot_interact_output = dot_interact(concat_features=feature_stack)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 33, in dot_interact\n    with hotline.annotate('Concatenate'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 33, "resources": {"cpu4": {"time": {"ts": 1678056305509067000, "dur": 369000, "relative_dur": 0.0008958332827555735, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "369 us"}}, "gpu3": {"time": {"ts": 1678056305554146000, "dur": 35327000, "relative_dur": 0.0857645050945966, "relative_gap_to_previous": 4.85546494718468e-06, "parent_is_longest": true, "runtime_str": "35.3 ms"}}}, "is_backward_op": true, "id": "erQdYoVSjHOnRm3D", "pretty_name": "Concatenate", "trace_file": "/results/DLRM/DLRM.90.pt.trace.json", "trace_disk_size": "12.3 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 35327000, "runtime_str": "35.3 ms", "start_timestamp": "22:45:05.509.509067", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 89}, {"name": "Tile", "type": "Tile", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 142, in forward\n    dot_interact_output = dot_interact(concat_features=feature_stack)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 27, in dot_interact\n    with hotline.annotate('Tile'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 27, "resources": {"cpu4": {"time": {"ts": 1678056305509440000, "dur": 68000, "relative_dur": 0.00016508580820427912, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "68 us"}}, "gpu3": {"time": {"ts": 1678056305589475000, "dur": 6126000, "relative_dur": 0.014872289133226675, "relative_gap_to_previous": 4.85546494718468e-06, "parent_is_longest": true, "runtime_str": "6.13 ms"}}}, "is_backward_op": true, "id": "E9V8Sd5ld1iy7GcJ", "pretty_name": "Tile", "trace_file": "/results/DLRM/DLRM.91.pt.trace.json", "trace_disk_size": "2.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 6126000, "runtime_str": "6.13 ms", "start_timestamp": "22:45:05.509.509440", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 12}, {"name": "BatchMatMul", "type": "BatchMatMul", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 142, in forward\n    dot_interact_output = dot_interact(concat_features=feature_stack)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 21, in dot_interact\n    with hotline.annotate('BatchMatMul'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 21, "resources": {"cpu4": {"time": {"ts": 1678056305509513000, "dur": 745000, "relative_dur": 0.0018086606928262932, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "745 us"}}, "gpu3": {"time": {"ts": 1678056305595602000, "dur": 22958000, "relative_dur": 0.05573588212873294, "relative_gap_to_previous": 2.42773247359234e-06, "parent_is_longest": true, "runtime_str": "23 ms"}}}, "is_backward_op": true, "id": "b1AjqUkzJEyanC5v", "pretty_name": "BatchMatMul", "trace_file": "/results/DLRM/DLRM.92.pt.trace.json", "trace_disk_size": "23.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 22958000, "runtime_str": "23 ms", "start_timestamp": "22:45:05.509.509513", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 150}], "resources": {"cpu4": {"time": {"ts": 1678056305078918000, "dur": 286537000, "relative_dur": 0.570914800225547, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "287 ms"}}, "gpu3": {"time": {"ts": 1678056305206653000, "dur": 411907000, "relative_dur": 0.8207100744982476, "relative_gap_to_previous": 1.9924644992637843e-06, "parent_is_longest": true, "runtime_str": "412 ms"}}}, "is_backward_op": true, "id": "uSJ0oBD1nixSSCM9", "pretty_name": "Feature Interaction", "trace_file": "/results/DLRM/DLRM.87.pt.trace.json", "trace_disk_size": "57.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 411907000, "runtime_str": "412 ms", "start_timestamp": "22:45:05.078.78918", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 384}, {"name": "Bottom MLP", "type": "Bottom MLP", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 117, in forward\n    with hotline.annotate('Bottom MLP'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "source_file_num": 117, "ops": [{"name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 123, in forward\n    bot_mlp_output = hotline.annotate_module_list(self.bot_mlp, bot_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1678056305599159000, "dur": 81000, "relative_dur": 0.010400616332819723, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "81 us"}}, "gpu3": {"time": {"ts": 1678056305618561000, "dur": 716000, "relative_dur": 0.09193631227529532, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "716 us"}}}, "is_backward_op": true, "id": "gnZVI3EcheqjZ37W", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.94.pt.trace.json", "trace_disk_size": "3.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 716000, "runtime_str": "716 us", "start_timestamp": "22:45:05.599.599159", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 20}, {"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 123, in forward\n    bot_mlp_output = hotline.annotate_module_list(self.bot_mlp, bot_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1678056305599244000, "dur": 122000, "relative_dur": 0.01566512583461736, "relative_gap_to_previous": 0.0005136106831022085, "parent_is_longest": true, "runtime_str": "122 us"}}, "gpu3": {"time": {"ts": 1678056305619279000, "dur": 4624000, "relative_dur": 0.593733949666153, "relative_gap_to_previous": 0.00025680534155110427, "parent_is_longest": true, "runtime_str": "4.62 ms"}}}, "is_backward_op": true, "id": "6Sp5FHfcmSzbPfN9", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.95.pt.trace.json", "trace_disk_size": "4.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 4624000, "runtime_str": "4.62 ms", "start_timestamp": "22:45:05.599.599244", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 32}, {"name": "ReLU", "type": "ReLU", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 123, in forward\n    bot_mlp_output = hotline.annotate_module_list(self.bot_mlp, bot_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1678056305599374000, "dur": 99000, "relative_dur": 0.012711864406779662, "relative_gap_to_previous": 0.001027221366204417, "parent_is_longest": true, "runtime_str": "99 us"}}, "gpu3": {"time": {"ts": 1678056305623905000, "dur": 1424000, "relative_dur": 0.18284540318438625, "relative_gap_to_previous": 0.00025680534155110427, "parent_is_longest": true, "runtime_str": "1.42 ms"}}}, "is_backward_op": true, "id": "JYcR7E776fYODPgt", "pretty_name": "ReLU", "trace_file": "/results/DLRM/DLRM.96.pt.trace.json", "trace_disk_size": "3.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 1424000, "runtime_str": "1.42 ms", "start_timestamp": "22:45:05.599.599374", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 20}, {"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 94, in update_params\n    logits_batch, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/workload.py\", line 116, in model_fn\n    logits_batch = model(inputs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py\", line 123, in forward\n    bot_mlp_output = hotline.annotate_module_list(self.bot_mlp, bot_mlp_input)\n  File \"/home/ubuntu/cpath/hotline/annotate.py\", line 108, in annotate_module_list\n    with self.make_wrapper()(module_name):\n", "source_file_name": "/home/ubuntu/cpath/hotline/annotate.py", "source_file_num": 108, "resources": {"cpu4": {"time": {"ts": 1678056305599477000, "dur": 98000, "relative_dur": 0.012583461736004109, "relative_gap_to_previous": 0.0005136106831022085, "parent_is_longest": true, "runtime_str": "98 us"}}, "gpu3": {"time": {"ts": 1678056305625330000, "dur": 1019000, "relative_dur": 0.13084232152028763, "relative_gap_to_previous": 0.00012840267077555214, "parent_is_longest": true, "runtime_str": "1.02 ms"}}}, "is_backward_op": true, "id": "51Hbqjg4hFKCHXW4", "pretty_name": "Linear", "trace_file": "/results/DLRM/DLRM.97.pt.trace.json", "trace_disk_size": "3.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/cpath/hotline/annotate.py", "runtime": 1019000, "runtime_str": "1.02 ms", "start_timestamp": "22:45:05.599.599477", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 26}], "resources": {"cpu4": {"time": {"ts": 1678056305599159000, "dur": 416000, "relative_dur": 0.0008288652316937343, "relative_gap_to_previous": 1.5939715994110275e-05, "parent_is_longest": true, "runtime_str": "416 us"}}, "gpu3": {"time": {"ts": 1678056305618561000, "dur": 7788000, "relative_dur": 0.015517313520266352, "relative_gap_to_previous": 1.9924644992637843e-06, "parent_is_longest": true, "runtime_str": "7.79 ms"}}}, "is_backward_op": true, "id": "LhkRCNoS1zuAOasn", "pretty_name": "Bottom MLP", "trace_file": "/results/DLRM/DLRM.93.pt.trace.json", "trace_disk_size": "13.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/criteo1tb/criteo1tb_pytorch/models.py", "runtime": 7788000, "runtime_str": "7.79 ms", "start_timestamp": "22:45:05.599.599159", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 98}], "is_model_pass": "Backward", "idx": 34, "id": "gLLBuytZB4kYkor3", "pretty_name": "Backward", "trace_file": "/results/DLRM/DLRM.76.pt.trace.json", "trace_disk_size": "118.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py", "runtime": 501891000, "runtime_str": "502 ms", "start_timestamp": "22:45:05.077.77268", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 812}, {"name": "Optimizer", "type": "training loop", "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056305600179000, "dur": 4741000, "relative_dur": 0.005220940143644681, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4.74 ms"}}, "gpu3": {"time": {"ts": 1678056305626357000, "dur": 56018000, "relative_dur": 0.06168880509738193, "relative_gap_to_previous": 1.1012318379339128e-06, "parent_is_longest": true, "runtime_str": "56 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 667, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 640, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 575, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 370, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py\", line 112, in update_params\n    with hotline.annotate('Optimizer'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py", "source_file_num": 112, "ops": [{"name": "aten::sqrt(12%) and 9 others\u2026", "type": "generated", "generated_depth": 1, "instances": 191, "resources": {"cpu2": {"time": {"ts": 1678056305600181000, "dur": 4723000, "relative_dur": 0.08431218536898855, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4.72 ms"}, "res_name": "aten::sqrt(12%) and 9 others\u2026"}, "gpu3": {"time": {"ts": 1678056305626357000, "dur": 56018000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "56 ms"}, "res_name": "vectorized_elementwise_kernel<4 addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4> addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4>(18%) and 6 others\u2026"}}, "id": "775622LJsMJlaIqb", "pretty_name": "aten::sqrt(12%) and 9 others\u2026", "trace_file": "/results/DLRM/DLRM.99.pt.trace.json", "trace_disk_size": "108.2 kB", "runtime": 56018000, "runtime_str": "56 ms", "start_timestamp": "22:45:05.600.600181", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 580}], "idx": 35, "id": "Arne9j5ewj7CvULY", "pretty_name": "Optimizer", "trace_file": "/results/DLRM/DLRM.98.pt.trace.json", "trace_disk_size": "108.3 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/criteo1tb/criteo1tb_pytorch/submission.py", "runtime": 56018000, "runtime_str": "56 ms", "start_timestamp": "22:45:05.600.600179", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 581}], "resources": {"cpu2": {"time": {"ts": 1678056304774040000, "dur": 708385000, "parent_is_longest": true, "runtime_str": "708 ms"}}, "cpu4": {"time": {"ts": 1678056305077268000, "dur": 288678000, "parent_is_longest": false, "runtime_str": "289 ms"}}, "gpu3": {"time": {"ts": 1678056304774301000, "dur": 908074000, "parent_is_longest": true, "runtime_str": "908 ms"}}}, "source_file_name": "/home/ubuntu/algorithmic-efficiency/submission_runner.py", "source_file_num": 334, "id": "Dy6E8HGhDkgtYCe6", "pretty_name": "DLRM Training Iteration", "total_accuracy_str": "97.06%", "trace_file": "/results/DLRM/DLRM.1.pt.trace.json", "trace_disk_size": "783.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM/home/ubuntu/algorithmic-efficiency/submission_runner.py", "config": {"trace_filepath": "/home/ubuntu/cpath/results/DLRM.worker0.pt.trace.json", "output_dir": "/home/ubuntu/cpath/results", "ui_traces_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/DLRM", "ui_model_path": "/home/ubuntu/cpath/results/ui/src/results/DLRM.js", "results_summary_csv_filepath": "/home/ubuntu/cpath/results/results_summary.csv", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/DLRM", "run_name": "DLRM", "model_name": "DLRM", "backend": "torch", "test": false, "is_test_accuracy": true, "view_manual_annotations": false, "source_file_name": "/home/ubuntu/algorithmic-efficiency/submission_runner.py", "source_file_num": 334, "num_gpus": 1, "slice_idx": 0, "drop_flow_view": "", "last_found_was_fused": false, "count_sum_greater_than_1": 0, "count_sum_less_than_1": 0, "tiny_op_threshold": 0.05, "max_generated_depth": 2, "remove_slice_args": true, "write_model_ops_to_file": true, "op_idx": 1}, "metadata": {}, "metadata.model": "DLRM", "metadata.dataset": "Criteo1TB", "metadata.batch_size": 196608, "metadata.optimizer": "AdamW", "trace_event_count": 1941, "pytorch_version": "1.13.1+cu116", "gpu_model": "NVIDIA GeForce RTX 3090", "gpu_cuda_version": "11.6", "hotline_traces_trace_disk_size": "1.3 MB", "hotline_annotation_count": "99", "processed_datetime": "05/03/2023 22:45:10", "runtime_without_profiling": "1.42 s \u00b18%", "runtime_with_profiling": "1.35 s \u00b110%", "runtime_profiling_overhead_factor": "0.05\u00d7 faster", "hotline_analysis_time": "2.18 s", "runtime": 908074000, "runtime_str": "908 ms", "start_timestamp": "22:45:04.774.774040", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3"}]