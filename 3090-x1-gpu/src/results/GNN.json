export const model =
[{"name": "GNN Training Iteration", "type": "root", "ops": [{"name": "Load Data", "type": "training loop", "instances": 29, "resources": {"cpu2": {"time": {"ts": 1678056532179261000, "dur": 1403000, "relative_dur": 0.0036278259160712947, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.40 ms"}}, "gpu3": {"time": {"ts": 1678056532179486000, "dur": 2499000, "relative_dur": 0.006461822497692206, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.50 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 379, in train_once\n    with hotline.annotate('Load Data'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/submission_runner.py", "source_file_num": 379, "ops": [{"name": "aten::lift_fresh", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532179261000, "dur": 6000, "relative_dur": 0.0024009603841536613, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "6 us"}, "res_name": "aten::lift_fresh"}}, "id": "oNTXLopqWafhTv6U", "pretty_name": "aten::lift_fresh", "trace_file": "/results/GNN/GNN.3.pt.trace.json", "trace_disk_size": "99 Bytes", "runtime": 6000, "runtime_str": "6 us", "start_timestamp": "22:48:52.179.179261", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::to", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532179293000, "dur": 84000, "relative_dur": 0.03361344537815126, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "84 us"}}, "gpu3": {"time": {"ts": 1678056532179486000, "dur": 390000, "relative_dur": 0.15606242496998798, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "390 us"}}}, "ops": [{"name": "aten::empty_strided", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532179306000, "dur": 38000, "relative_dur": 0.09743589743589744, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "38 us"}, "res_name": "aten::empty_strided"}}, "id": "X0BShDqc1SA12IML", "pretty_name": "aten::empty_strided", "trace_file": "/results/GNN/GNN.5.pt.trace.json", "trace_disk_size": "103 Bytes", "runtime": 38000, "runtime_str": "38 us", "start_timestamp": "22:48:52.179.179306", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "cudaMemcpyAsync", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532179369000, "dur": 1000, "relative_dur": 0.002564102564102564, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "cudaMemcpyAsync"}, "gpu3": {"time": {"ts": 1678056532179486000, "dur": 390000, "relative_dur": 1.0, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "390 us"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "iEeeDyJdfegPsRI2", "pretty_name": "cudaMemcpyAsync", "trace_file": "/results/GNN/GNN.6.pt.trace.json", "trace_disk_size": "226 Bytes", "runtime": 390000, "runtime_str": "390 us", "start_timestamp": "22:48:52.179.179369", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 2}, {"name": "cudaStreamSynchronize", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532179832000, "dur": 1000, "relative_dur": 0.002564102564102564, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "cudaStreamSynchronize"}}, "id": "5Dke0Y1RGiJkMaEK", "pretty_name": "cudaStreamSynchronize", "trace_file": "/results/GNN/GNN.7.pt.trace.json", "trace_disk_size": "111 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "22:48:52.179.179832", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "rdg0fY1jX5akZIlR", "pretty_name": "aten::to", "trace_file": "/results/GNN/GNN.4.pt.trace.json", "trace_disk_size": "723 Bytes", "runtime": 390000, "runtime_str": "390 us", "start_timestamp": "22:48:52.179.179293", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 7}, {"name": "aten::view(90%) and 1 other\u2026", "type": "generated", "generated_depth": 1, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1678056532179911000, "dur": 28000, "relative_dur": 0.011204481792717087, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "28 us"}}}, "ops": [{"name": "aten::view", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532179911000, "dur": 9000, "relative_dur": 0.32142857142857145, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9 us"}, "res_name": "aten::view"}}, "id": "vAgOKLavFjOWHqSv", "pretty_name": "aten::view", "trace_file": "/results/GNN/GNN.9.pt.trace.json", "trace_disk_size": "93 Bytes", "runtime": 9000, "runtime_str": "9 us", "start_timestamp": "22:48:52.179.179911", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::lift_fresh", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532179938000, "dur": 1000, "relative_dur": 0.03571428571428571, "relative_gap_to_previous": 0.6428571428571429, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::lift_fresh"}}, "id": "VuQTPUwVrcgsT0Nk", "pretty_name": "aten::lift_fresh", "trace_file": "/results/GNN/GNN.10.pt.trace.json", "trace_disk_size": "99 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "22:48:52.179.179938", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "1GBLW05lv4vSuwSt", "pretty_name": "aten::view(90%) and 1 other\u2026", "trace_file": "/results/GNN/GNN.8.pt.trace.json", "trace_disk_size": "191 Bytes", "runtime": 28000, "runtime_str": "28 us", "start_timestamp": "22:48:52.179.179911", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::to", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532179941000, "dur": 20000, "relative_dur": 0.008003201280512205, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "20 us"}}, "gpu3": {"time": {"ts": 1678056532180034000, "dur": 268000, "relative_dur": 0.10724289715886355, "relative_gap_to_previous": 0.06322529011604641, "parent_is_longest": true, "runtime_str": "268 us"}}}, "ops": [{"name": "aten::empty_strided", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532179944000, "dur": 7000, "relative_dur": 0.026119402985074626, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "7 us"}, "res_name": "aten::empty_strided"}}, "id": "lC3NLedUzHgR3gcH", "pretty_name": "aten::empty_strided", "trace_file": "/results/GNN/GNN.12.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 7000, "runtime_str": "7 us", "start_timestamp": "22:48:52.179.179944", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "cudaMemcpyAsync", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532179955000, "dur": 1000, "relative_dur": 0.0037313432835820895, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "cudaMemcpyAsync"}, "gpu3": {"time": {"ts": 1678056532180034000, "dur": 268000, "relative_dur": 1.0, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "268 us"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "h4LcIADeKnULENNI", "pretty_name": "cudaMemcpyAsync", "trace_file": "/results/GNN/GNN.13.pt.trace.json", "trace_disk_size": "226 Bytes", "runtime": 268000, "runtime_str": "268 us", "start_timestamp": "22:48:52.179.179955", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 2}, {"name": "cudaStreamSynchronize", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532180250000, "dur": 1000, "relative_dur": 0.0037313432835820895, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "cudaStreamSynchronize"}}, "id": "ZrIyaz2yvyZdGZSe", "pretty_name": "cudaStreamSynchronize", "trace_file": "/results/GNN/GNN.14.pt.trace.json", "trace_disk_size": "111 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "22:48:52.180.180250", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "rvy92QcdDBDvQsg2", "pretty_name": "aten::to", "trace_file": "/results/GNN/GNN.11.pt.trace.json", "trace_disk_size": "722 Bytes", "runtime": 268000, "runtime_str": "268 us", "start_timestamp": "22:48:52.179.179941", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 7}, {"name": "aten::view", "type": "generated", "generated_depth": 1, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1678056532180314000, "dur": 15000, "relative_dur": 0.006002400960384154, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "15 us"}}}, "ops": [{"name": "aten::lift_fresh", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532180329000, "dur": 0, "relative_dur": 0.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "0 us"}, "res_name": "aten::lift_fresh"}}, "id": "X04pMqGVuBaN5Cm8", "pretty_name": "aten::lift_fresh", "trace_file": "/results/GNN/GNN.16.pt.trace.json", "trace_disk_size": "99 Bytes", "runtime": 0, "runtime_str": "0 us", "start_timestamp": "22:48:52.180.180329", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "TTN5LaBS1GLnN0t1", "pretty_name": "aten::view", "trace_file": "/results/GNN/GNN.15.pt.trace.json", "trace_disk_size": "191 Bytes", "runtime": 15000, "runtime_str": "15 us", "start_timestamp": "22:48:52.180.180314", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::to", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532180330000, "dur": 17000, "relative_dur": 0.006802721088435374, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "17 us"}}, "gpu3": {"time": {"ts": 1678056532180420000, "dur": 169000, "relative_dur": 0.06762705082032813, "relative_gap_to_previous": 0.04721888755502201, "parent_is_longest": true, "runtime_str": "169 us"}}}, "ops": [{"name": "aten::empty_strided", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532180332000, "dur": 6000, "relative_dur": 0.03550295857988166, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "6 us"}, "res_name": "aten::empty_strided"}}, "id": "Lw8dYwtBplMxtcfY", "pretty_name": "aten::empty_strided", "trace_file": "/results/GNN/GNN.18.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 6000, "runtime_str": "6 us", "start_timestamp": "22:48:52.180.180332", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "cudaMemcpyAsync", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532180342000, "dur": 1000, "relative_dur": 0.005917159763313609, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "cudaMemcpyAsync"}, "gpu3": {"time": {"ts": 1678056532180420000, "dur": 169000, "relative_dur": 1.0, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "169 us"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "L1j9M5byP2lj5QRv", "pretty_name": "cudaMemcpyAsync", "trace_file": "/results/GNN/GNN.19.pt.trace.json", "trace_disk_size": "226 Bytes", "runtime": 169000, "runtime_str": "169 us", "start_timestamp": "22:48:52.180.180342", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 2}, {"name": "cudaStreamSynchronize", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532180549000, "dur": 1000, "relative_dur": 0.005917159763313609, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "cudaStreamSynchronize"}}, "id": "zCeLEVupfOCFVKx0", "pretty_name": "cudaStreamSynchronize", "trace_file": "/results/GNN/GNN.20.pt.trace.json", "trace_disk_size": "111 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "22:48:52.180.180549", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "r6STUCzvyq06FLKx", "pretty_name": "aten::to", "trace_file": "/results/GNN/GNN.17.pt.trace.json", "trace_disk_size": "722 Bytes", "runtime": 169000, "runtime_str": "169 us", "start_timestamp": "22:48:52.180.180330", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 7}, {"name": "aten::view(67%) and 1 other\u2026", "type": "generated", "generated_depth": 1, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1678056532180599000, "dur": 15000, "relative_dur": 0.006002400960384154, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "15 us"}}}, "ops": [{"name": "aten::view", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532180599000, "dur": 2000, "relative_dur": 0.13333333333333333, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "aten::view"}}, "id": "LHFgZH0uF0hSA9Kt", "pretty_name": "aten::view", "trace_file": "/results/GNN/GNN.22.pt.trace.json", "trace_disk_size": "93 Bytes", "runtime": 2000, "runtime_str": "2 us", "start_timestamp": "22:48:52.180.180599", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::lift_fresh", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532180613000, "dur": 1000, "relative_dur": 0.06666666666666667, "relative_gap_to_previous": 0.8, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::lift_fresh"}}, "id": "AKX08z91XJuj0GKu", "pretty_name": "aten::lift_fresh", "trace_file": "/results/GNN/GNN.23.pt.trace.json", "trace_disk_size": "99 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "22:48:52.180.180613", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "9HbtQhamdanJDkBm", "pretty_name": "aten::view(67%) and 1 other\u2026", "trace_file": "/results/GNN/GNN.21.pt.trace.json", "trace_disk_size": "191 Bytes", "runtime": 15000, "runtime_str": "15 us", "start_timestamp": "22:48:52.180.180599", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::to", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532180615000, "dur": 18000, "relative_dur": 0.007202881152460984, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "18 us"}}, "gpu3": {"time": {"ts": 1678056532180709000, "dur": 169000, "relative_dur": 0.06762705082032813, "relative_gap_to_previous": 0.04801920768307323, "parent_is_longest": true, "runtime_str": "169 us"}}}, "ops": [{"name": "aten::empty_strided", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532180617000, "dur": 7000, "relative_dur": 0.04142011834319527, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "7 us"}, "res_name": "aten::empty_strided"}}, "id": "M0zlQeHlzHIXTOEJ", "pretty_name": "aten::empty_strided", "trace_file": "/results/GNN/GNN.25.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 7000, "runtime_str": "7 us", "start_timestamp": "22:48:52.180.180617", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "cudaMemcpyAsync", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532180628000, "dur": 1000, "relative_dur": 0.005917159763313609, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "cudaMemcpyAsync"}, "gpu3": {"time": {"ts": 1678056532180709000, "dur": 169000, "relative_dur": 1.0, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "169 us"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "vgI7XAZhz2tLIiqy", "pretty_name": "cudaMemcpyAsync", "trace_file": "/results/GNN/GNN.26.pt.trace.json", "trace_disk_size": "226 Bytes", "runtime": 169000, "runtime_str": "169 us", "start_timestamp": "22:48:52.180.180628", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 2}, {"name": "cudaStreamSynchronize", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532180835000, "dur": 1000, "relative_dur": 0.005917159763313609, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "cudaStreamSynchronize"}}, "id": "g8YDJRbshezqJNeC", "pretty_name": "cudaStreamSynchronize", "trace_file": "/results/GNN/GNN.27.pt.trace.json", "trace_disk_size": "111 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "22:48:52.180.180835", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "l1mSmAKhoF1asH7F", "pretty_name": "aten::to", "trace_file": "/results/GNN/GNN.24.pt.trace.json", "trace_disk_size": "722 Bytes", "runtime": 169000, "runtime_str": "169 us", "start_timestamp": "22:48:52.180.180615", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 7}, {"name": "aten::to(95%) and 2 others\u2026", "type": "generated", "generated_depth": 1, "instances": 8, "resources": {"cpu2": {"time": {"ts": 1678056532180887000, "dur": 95000, "relative_dur": 0.03801520608243297, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "95 us"}}, "gpu3": {"time": {"ts": 1678056532181013000, "dur": 56000, "relative_dur": 0.022408963585434174, "relative_gap_to_previous": 0.05402160864345738, "parent_is_longest": true, "runtime_str": "56 us"}}}, "ops": [{"name": "aten::view", "type": "generated", "generated_depth": 2, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1678056532180887000, "dur": 19000, "relative_dur": 0.2, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "19 us"}}}, "ops": [{"name": "aten::lift_fresh", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532180906000, "dur": 0, "relative_dur": 0.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "0 us"}, "res_name": "aten::lift_fresh"}}, "id": "vS0KAYm8egd521DN", "pretty_name": "aten::lift_fresh", "trace_file": "/results/GNN/GNN.30.pt.trace.json", "trace_disk_size": "99 Bytes", "runtime": 0, "runtime_str": "0 us", "start_timestamp": "22:48:52.180.180906", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "RsEGaeKImV1Wbi0O", "pretty_name": "aten::view", "trace_file": "/results/GNN/GNN.29.pt.trace.json", "trace_disk_size": "191 Bytes", "runtime": 19000, "runtime_str": "19 us", "start_timestamp": "22:48:52.180.180887", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::to", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532180908000, "dur": 19000, "relative_dur": 0.2, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "19 us"}}, "gpu3": {"time": {"ts": 1678056532181013000, "dur": 4000, "relative_dur": 0.042105263157894736, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "4 us"}}}, "ops": [{"name": "aten::empty_strided", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532180910000, "dur": 8000, "relative_dur": 0.42105263157894735, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "8 us"}, "res_name": "aten::empty_strided"}}, "id": "5Z8qqB1t4oAht4SY", "pretty_name": "aten::empty_strided", "trace_file": "/results/GNN/GNN.32.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 8000, "runtime_str": "8 us", "start_timestamp": "22:48:52.180.180910", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::copy_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532180918000, "dur": 9000, "relative_dur": 0.47368421052631576, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9 us"}, "res_name": "aten::copy_"}, "gpu3": {"time": {"ts": 1678056532181013000, "dur": 4000, "relative_dur": 0.21052631578947367, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "4 us"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "eteoRghLESgEzoQ7", "pretty_name": "aten::copy_", "trace_file": "/results/GNN/GNN.33.pt.trace.json", "trace_disk_size": "428 Bytes", "runtime": 9000, "runtime_str": "9 us", "start_timestamp": "22:48:52.180.180918", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 4}], "id": "UrPyahTdAbe3YTOF", "pretty_name": "aten::to", "trace_file": "/results/GNN/GNN.31.pt.trace.json", "trace_disk_size": "719 Bytes", "runtime": 19000, "runtime_str": "19 us", "start_timestamp": "22:48:52.180.180908", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 7}, {"name": "aten::view", "type": "generated", "generated_depth": 2, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1678056532181025000, "dur": 13000, "relative_dur": 0.1368421052631579, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "13 us"}}}, "ops": [{"name": "aten::lift_fresh", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532181038000, "dur": 0, "relative_dur": 0.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "0 us"}, "res_name": "aten::lift_fresh"}}, "id": "acTI23UkwfJAPbUZ", "pretty_name": "aten::lift_fresh", "trace_file": "/results/GNN/GNN.35.pt.trace.json", "trace_disk_size": "99 Bytes", "runtime": 0, "runtime_str": "0 us", "start_timestamp": "22:48:52.181.181038", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "ui6EW0lkWrQeWHxQ", "pretty_name": "aten::view", "trace_file": "/results/GNN/GNN.34.pt.trace.json", "trace_disk_size": "191 Bytes", "runtime": 13000, "runtime_str": "13 us", "start_timestamp": "22:48:52.181.181025", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::to", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532181039000, "dur": 17000, "relative_dur": 0.17894736842105263, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "17 us"}}, "gpu3": {"time": {"ts": 1678056532181065000, "dur": 4000, "relative_dur": 0.042105263157894736, "relative_gap_to_previous": 0.5052631578947369, "parent_is_longest": true, "runtime_str": "4 us"}}}, "ops": [{"name": "aten::empty_strided", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532181041000, "dur": 7000, "relative_dur": 0.4117647058823529, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "7 us"}, "res_name": "aten::empty_strided"}}, "id": "Q3wBTKPwNjF6DRlE", "pretty_name": "aten::empty_strided", "trace_file": "/results/GNN/GNN.37.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 7000, "runtime_str": "7 us", "start_timestamp": "22:48:52.181.181041", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::copy_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532181048000, "dur": 7000, "relative_dur": 0.4117647058823529, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "7 us"}, "res_name": "aten::copy_"}, "gpu3": {"time": {"ts": 1678056532181065000, "dur": 4000, "relative_dur": 0.23529411764705882, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "4 us"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "d225nULzjFyujBlX", "pretty_name": "aten::copy_", "trace_file": "/results/GNN/GNN.38.pt.trace.json", "trace_disk_size": "426 Bytes", "runtime": 7000, "runtime_str": "7 us", "start_timestamp": "22:48:52.181.181048", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 4}], "id": "04GpMR7AhxdGVlI0", "pretty_name": "aten::to", "trace_file": "/results/GNN/GNN.36.pt.trace.json", "trace_disk_size": "715 Bytes", "runtime": 17000, "runtime_str": "17 us", "start_timestamp": "22:48:52.181.181039", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 7}, {"name": "aten::view(67%) and 1 other\u2026", "type": "generated", "generated_depth": 2, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1678056532181076000, "dur": 17000, "relative_dur": 0.17894736842105263, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "17 us"}}}, "ops": [{"name": "aten::view", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532181076000, "dur": 2000, "relative_dur": 0.11764705882352941, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "aten::view"}}, "id": "NvIczPKKPLqd0oxL", "pretty_name": "aten::view", "trace_file": "/results/GNN/GNN.40.pt.trace.json", "trace_disk_size": "93 Bytes", "runtime": 2000, "runtime_str": "2 us", "start_timestamp": "22:48:52.181.181076", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::lift_fresh", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532181092000, "dur": 1000, "relative_dur": 0.058823529411764705, "relative_gap_to_previous": 0.8235294117647058, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::lift_fresh"}}, "id": "f4TNPhA4aFAzlnIU", "pretty_name": "aten::lift_fresh", "trace_file": "/results/GNN/GNN.41.pt.trace.json", "trace_disk_size": "99 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "22:48:52.181.181092", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "9RkARm8C58X7pa4D", "pretty_name": "aten::view(67%) and 1 other\u2026", "trace_file": "/results/GNN/GNN.39.pt.trace.json", "trace_disk_size": "191 Bytes", "runtime": 17000, "runtime_str": "17 us", "start_timestamp": "22:48:52.181.181076", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}], "id": "CWGp8dFsSfFyVFBi", "pretty_name": "aten::to(95%) and 2 others\u2026", "trace_file": "/results/GNN/GNN.28.pt.trace.json", "trace_disk_size": "2.0 kB", "runtime": 95000, "runtime_str": "95 us", "start_timestamp": "22:48:52.180.180887", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 20}, {"name": "aten::to", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532181094000, "dur": 17000, "relative_dur": 0.006802721088435374, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "17 us"}}, "gpu3": {"time": {"ts": 1678056532181182000, "dur": 319000, "relative_dur": 0.12765106042416965, "relative_gap_to_previous": 0.045218087234893956, "parent_is_longest": true, "runtime_str": "319 us"}}}, "ops": [{"name": "aten::empty_strided", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532181096000, "dur": 6000, "relative_dur": 0.018808777429467086, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "6 us"}, "res_name": "aten::empty_strided"}}, "id": "oCalKSvl8L8S9tZb", "pretty_name": "aten::empty_strided", "trace_file": "/results/GNN/GNN.43.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 6000, "runtime_str": "6 us", "start_timestamp": "22:48:52.181.181096", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "cudaMemcpyAsync", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532181106000, "dur": 1000, "relative_dur": 0.003134796238244514, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "cudaMemcpyAsync"}, "gpu3": {"time": {"ts": 1678056532181182000, "dur": 319000, "relative_dur": 1.0, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "319 us"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "xq0zgvaHu1N3luDo", "pretty_name": "cudaMemcpyAsync", "trace_file": "/results/GNN/GNN.44.pt.trace.json", "trace_disk_size": "226 Bytes", "runtime": 319000, "runtime_str": "319 us", "start_timestamp": "22:48:52.181.181106", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 2}, {"name": "cudaStreamSynchronize", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532181461000, "dur": 1000, "relative_dur": 0.003134796238244514, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "cudaStreamSynchronize"}}, "id": "o6IbXwXHIc1lQiJe", "pretty_name": "cudaStreamSynchronize", "trace_file": "/results/GNN/GNN.45.pt.trace.json", "trace_disk_size": "111 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "22:48:52.181.181461", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "y15K39y2c83xOpA1", "pretty_name": "aten::to", "trace_file": "/results/GNN/GNN.42.pt.trace.json", "trace_disk_size": "722 Bytes", "runtime": 319000, "runtime_str": "319 us", "start_timestamp": "22:48:52.181.181094", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 7}, {"name": "aten::lift_fresh", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532181513000, "dur": 0, "relative_dur": 0.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "0 us"}, "res_name": "aten::lift_fresh"}}, "id": "BxVQt9SGfFk1rWNJ", "pretty_name": "aten::lift_fresh", "trace_file": "/results/GNN/GNN.46.pt.trace.json", "trace_disk_size": "99 Bytes", "runtime": 0, "runtime_str": "0 us", "start_timestamp": "22:48:52.181.181513", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::to", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532181514000, "dur": 371000, "relative_dur": 0.1484593837535014, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "371 us"}}, "gpu3": {"time": {"ts": 1678056532181954000, "dur": 31000, "relative_dur": 0.012404961984793917, "relative_gap_to_previous": 0.18127250900360145, "parent_is_longest": true, "runtime_str": "31 us"}}}, "ops": [{"name": "aten::empty_strided", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532181516000, "dur": 9000, "relative_dur": 0.02425876010781671, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9 us"}, "res_name": "aten::empty_strided"}}, "id": "oQaWstFLPDgW2i3v", "pretty_name": "aten::empty_strided", "trace_file": "/results/GNN/GNN.48.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 9000, "runtime_str": "9 us", "start_timestamp": "22:48:52.181.181516", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::to", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532181529000, "dur": 324000, "relative_dur": 0.8733153638814016, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "324 us"}, "res_name": "aten::to"}}, "id": "6ni6007s0GT78jEh", "pretty_name": "aten::to", "trace_file": "/results/GNN/GNN.49.pt.trace.json", "trace_disk_size": "387 Bytes", "runtime": 324000, "runtime_str": "324 us", "start_timestamp": "22:48:52.181.181529", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 4}, {"name": "aten::expand_as", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532181855000, "dur": 17000, "relative_dur": 0.04582210242587601, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "17 us"}, "res_name": "aten::expand_as"}}, "id": "SiI1peFO7h4wgbUy", "pretty_name": "aten::expand_as", "trace_file": "/results/GNN/GNN.50.pt.trace.json", "trace_disk_size": "291 Bytes", "runtime": 17000, "runtime_str": "17 us", "start_timestamp": "22:48:52.181.181855", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}], "id": "u2ZEyH8OqGLPhrrh", "pretty_name": "aten::to", "trace_file": "/results/GNN/GNN.47.pt.trace.json", "trace_disk_size": "1.5 kB", "runtime": 371000, "runtime_str": "371 us", "start_timestamp": "22:48:52.181.181514", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 15}, {"name": "aten::zeros(84%) and 1 other\u2026", "type": "generated", "generated_depth": 1, "instances": 3, "resources": {"cpu2": {"time": {"ts": 1678056532181999000, "dur": 633000, "relative_dur": 0.2533013205282113, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "633 us"}, "res_name": "aten::zeros(84%) and 1 other\u2026"}}, "id": "rfnyeDIf9vHd8efi", "pretty_name": "aten::zeros(84%) and 1 other\u2026", "trace_file": "/results/GNN/GNN.51.pt.trace.json", "trace_disk_size": "465 Bytes", "runtime": 633000, "runtime_str": "633 us", "start_timestamp": "22:48:52.181.181999", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 5}], "idx": 1, "id": "LkhoFkqZK5nAgnqV", "pretty_name": "Load Data", "trace_file": "/results/GNN/GNN.2.pt.trace.json", "trace_disk_size": "8.3 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/submission_runner.py", "runtime": 2499000, "runtime_str": "2.50 ms", "start_timestamp": "22:48:52.179.179261", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 83}, {"name": "Forward", "type": "training loop", "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532182645000, "dur": 15450000, "relative_dur": 0.03995004305295902, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "15.4 ms"}}, "gpu3": {"time": {"ts": 1678056532183623000, "dur": 145500000, "relative_dur": 0.3762285607900024, "relative_gap_to_previous": 0.004235480292604976, "parent_is_longest": true, "runtime_str": "146 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 78, in forward\n    with hotline.annotate(\"Forward\"):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 78, "ops": [{"idx": 3, "name": "Node Embedder", "type": "Node Embedder", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 79, in forward\n    with hotline.annotate('Node Embedder'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 79, "ops": [{"idx": 4, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 80, in forward\n    with hotline.annotate('Linear'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 80, "resources": {"cpu2": {"time": {"ts": 1678056532182646000, "dur": 1120000, "relative_dur": 0.6965174129353234, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.12 ms"}}, "gpu3": {"time": {"ts": 1678056532183623000, "dur": 1608000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.61 ms"}}}, "id": "SmtBFmH6wfcoUFHr", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.54.pt.trace.json", "trace_disk_size": "6.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 1608000, "runtime_str": "1.61 ms", "start_timestamp": "22:48:52.182.182646", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 64}], "resources": {"cpu2": {"time": {"ts": 1678056532182646000, "dur": 1120000, "relative_dur": 0.007697594501718213, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.12 ms"}}, "gpu3": {"time": {"ts": 1678056532183623000, "dur": 1608000, "relative_dur": 0.011051546391752577, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.61 ms"}}}, "id": "UNGCD3V8zTFn7ZqX", "pretty_name": "Node Embedder", "trace_file": "/results/GNN/GNN.53.pt.trace.json", "trace_disk_size": "6.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 1608000, "runtime_str": "1.61 ms", "start_timestamp": "22:48:52.182.182646", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 64}, {"idx": 5, "name": "Edge Embedder", "type": "Edge Embedder", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 86, in forward\n    with hotline.annotate('Edge Embedder'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 86, "ops": [{"idx": 6, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 87, in forward\n    with hotline.annotate('Linear'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 87, "resources": {"cpu2": {"time": {"ts": 1678056532183880000, "dur": 192000, "relative_dur": 0.42761692650334077, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "192 us"}}, "gpu3": {"time": {"ts": 1678056532185232000, "dur": 449000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "449 us"}}}, "id": "liEHFM2Qr2lIFJvv", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.56.pt.trace.json", "trace_disk_size": "1.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 449000, "runtime_str": "449 us", "start_timestamp": "22:48:52.183.183880", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 18}], "resources": {"cpu2": {"time": {"ts": 1678056532183880000, "dur": 192000, "relative_dur": 0.0013195876288659794, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "192 us"}}, "gpu3": {"time": {"ts": 1678056532185232000, "dur": 449000, "relative_dur": 0.0030859106529209624, "relative_gap_to_previous": 6.8728522336769755e-06, "parent_is_longest": true, "runtime_str": "449 us"}}}, "id": "6sFuew11Z3bpghx9", "pretty_name": "Edge Embedder", "trace_file": "/results/GNN/GNN.55.pt.trace.json", "trace_disk_size": "1.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 449000, "runtime_str": "449 us", "start_timestamp": "22:48:52.183.183880", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 18}, {"idx": 7, "name": "Graph Network", "type": "Graph Network", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 91, in forward\n    with hotline.annotate('Graph Network'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 91, "ops": [{"idx": 8, "name": "Layer1", "type": "Layer1", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 93, in forward\n    with hotline.annotate(f'Layer{idx+1}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 93, "ops": [{"idx": 9, "name": "Edge", "type": "Edge", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 156, in forward\n    with hotline.annotate('Edge'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 156, "ops": [{"idx": 10, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 157, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS1\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 157, "resources": {"cpu2": {"time": {"ts": 1678056532184183000, "dur": 840000, "relative_dur": 0.06659795449139777, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "840 us"}}, "gpu3": {"time": {"ts": 1678056532185682000, "dur": 12613000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12.6 ms"}}}, "id": "1CKYyxbr0TEbGf2E", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.60.pt.trace.json", "trace_disk_size": "12.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 12613000, "runtime_str": "12.6 ms", "start_timestamp": "22:48:52.184.184183", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 82}], "resources": {"cpu2": {"time": {"ts": 1678056532184183000, "dur": 840000, "relative_dur": 0.032779208616249125, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "840 us"}}, "gpu3": {"time": {"ts": 1678056532185682000, "dur": 12613000, "relative_dur": 0.4921954265199407, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12.6 ms"}}}, "id": "nbO0QqmVyCW8wpgz", "pretty_name": "Edge", "trace_file": "/results/GNN/GNN.59.pt.trace.json", "trace_disk_size": "12.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 12613000, "runtime_str": "12.6 ms", "start_timestamp": "22:48:52.184.184183", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 82}, {"idx": 11, "name": "Node", "type": "Node", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 182, in forward\n    with hotline.annotate('Node'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 182, "ops": [{"idx": 12, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 183, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS2\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 183, "resources": {"cpu2": {"time": {"ts": 1678056532187318000, "dur": 892000, "relative_dur": 0.08642573394050965, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "892 us"}}, "gpu3": {"time": {"ts": 1678056532198296000, "dur": 10321000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "10.3 ms"}}}, "id": "oDO6rFr9WdjmE2jU", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.62.pt.trace.json", "trace_disk_size": "15.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 10321000, "runtime_str": "10.3 ms", "start_timestamp": "22:48:52.187.187318", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 114}], "resources": {"cpu2": {"time": {"ts": 1678056532187318000, "dur": 892000, "relative_dur": 0.034808397721064546, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "892 us"}}, "gpu3": {"time": {"ts": 1678056532198296000, "dur": 10321000, "relative_dur": 0.40275501443846096, "relative_gap_to_previous": 3.9022867400296575e-05, "parent_is_longest": true, "runtime_str": "10.3 ms"}}}, "id": "1E8AS61PDx2AMOLJ", "pretty_name": "Node", "trace_file": "/results/GNN/GNN.61.pt.trace.json", "trace_disk_size": "15.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 10321000, "runtime_str": "10.3 ms", "start_timestamp": "22:48:52.187.187318", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 114}, {"idx": 13, "name": "Global", "type": "Global", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 201, in forward\n    with hotline.annotate('Global'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 201, "ops": [{"idx": 14, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 202, in forward\n    with hotline.annotate('Linear'): # Should be replaced with THIS3\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 202, "resources": {"cpu2": {"time": {"ts": 1678056532203439000, "dur": 986000, "relative_dur": 0.36654275092936806, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "986 us"}}, "gpu3": {"time": {"ts": 1678056532208618000, "dur": 2690000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.69 ms"}}}, "id": "tbTrnjAW0BRWO7xO", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.64.pt.trace.json", "trace_disk_size": "22.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 2690000, "runtime_str": "2.69 ms", "start_timestamp": "22:48:52.203.203439", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 163}], "resources": {"cpu2": {"time": {"ts": 1678056532203439000, "dur": 986000, "relative_dur": 0.038476547256692424, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "986 us"}}, "gpu3": {"time": {"ts": 1678056532208618000, "dur": 2690000, "relative_dur": 0.10497151330679778, "relative_gap_to_previous": 3.9022867400296575e-05, "parent_is_longest": true, "runtime_str": "2.69 ms"}}}, "id": "PWgYne40FkF2E8iD", "pretty_name": "Global", "trace_file": "/results/GNN/GNN.63.pt.trace.json", "trace_disk_size": "22.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 2690000, "runtime_str": "2.69 ms", "start_timestamp": "22:48:52.203.203439", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 163}], "resources": {"cpu2": {"time": {"ts": 1678056532184183000, "dur": 2749000, "relative_dur": 0.019181924751590935, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.75 ms"}}, "gpu3": {"time": {"ts": 1678056532185682000, "dur": 25626000, "relative_dur": 0.17881266048900302, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "25.6 ms"}}}, "id": "mI5Caxa1ZMpYs47q", "pretty_name": "Layer1", "trace_file": "/results/GNN/GNN.58.pt.trace.json", "trace_disk_size": "50.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 25626000, "runtime_str": "25.6 ms", "start_timestamp": "22:48:52.184.184183", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 359}, {"idx": 15, "name": "Layer2", "type": "Layer2", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 93, in forward\n    with hotline.annotate(f'Layer{idx+1}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 93, "ops": [{"idx": 16, "name": "Edge", "type": "Edge", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 156, in forward\n    with hotline.annotate('Edge'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 156, "ops": [{"idx": 17, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 157, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS1\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 157, "resources": {"cpu2": {"time": {"ts": 1678056532210574000, "dur": 865000, "relative_dur": 0.057524772228503024, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "865 us"}}, "gpu3": {"time": {"ts": 1678056532211309000, "dur": 15037000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "15 ms"}}}, "id": "5J1gbGSgN9sQqeOU", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.67.pt.trace.json", "trace_disk_size": "14.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 15037000, "runtime_str": "15 ms", "start_timestamp": "22:48:52.210.210574", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 100}], "resources": {"cpu2": {"time": {"ts": 1678056532210574000, "dur": 865000, "relative_dur": 0.02931607130753067, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "865 us"}}, "gpu3": {"time": {"ts": 1678056532211309000, "dur": 15037000, "relative_dur": 0.5096251609842066, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "15 ms"}}}, "id": "SPFFeDsFQqKK6SAP", "pretty_name": "Edge", "trace_file": "/results/GNN/GNN.66.pt.trace.json", "trace_disk_size": "14.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 15037000, "runtime_str": "15 ms", "start_timestamp": "22:48:52.210.210574", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 100}, {"idx": 18, "name": "Node", "type": "Node", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 182, in forward\n    with hotline.annotate('Node'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 182, "ops": [{"idx": 19, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 183, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS2\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 183, "resources": {"cpu2": {"time": {"ts": 1678056532212944000, "dur": 808000, "relative_dur": 0.06932052161976665, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "808 us"}}, "gpu3": {"time": {"ts": 1678056532226347000, "dur": 11656000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "11.7 ms"}}}, "id": "4gSHygWKj1reOBdW", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.69.pt.trace.json", "trace_disk_size": "15.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11656000, "runtime_str": "11.7 ms", "start_timestamp": "22:48:52.212.212944", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 114}], "resources": {"cpu2": {"time": {"ts": 1678056532212944000, "dur": 808000, "relative_dur": 0.02738426082830611, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "808 us"}}, "gpu3": {"time": {"ts": 1678056532226347000, "dur": 11656000, "relative_dur": 0.3950382972954653, "relative_gap_to_previous": 3.389141191622043e-05, "parent_is_longest": true, "runtime_str": "11.7 ms"}}}, "id": "9uZF0z7zx3iFZFmt", "pretty_name": "Node", "trace_file": "/results/GNN/GNN.68.pt.trace.json", "trace_disk_size": "15.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11656000, "runtime_str": "11.7 ms", "start_timestamp": "22:48:52.212.212944", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 114}, {"idx": 20, "name": "Global", "type": "Global", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 201, in forward\n    with hotline.annotate('Global'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 201, "ops": [{"idx": 21, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 202, in forward\n    with hotline.annotate('Linear'): # Should be replaced with THIS3\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 202, "resources": {"cpu2": {"time": {"ts": 1678056532231599000, "dur": 980000, "relative_dur": 0.3487544483985765, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "980 us"}}, "gpu3": {"time": {"ts": 1678056532238005000, "dur": 2810000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.81 ms"}}}, "id": "HA0BxwczVML2QbVR", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.71.pt.trace.json", "trace_disk_size": "22.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 2810000, "runtime_str": "2.81 ms", "start_timestamp": "22:48:52.231.231599", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 163}], "resources": {"cpu2": {"time": {"ts": 1678056532231599000, "dur": 980000, "relative_dur": 0.03321358367789602, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "980 us"}}, "gpu3": {"time": {"ts": 1678056532238005000, "dur": 2810000, "relative_dur": 0.0952348674845794, "relative_gap_to_previous": 6.778282383244086e-05, "parent_is_longest": true, "runtime_str": "2.81 ms"}}}, "id": "tKA5p2GSMBiPxyFl", "pretty_name": "Global", "trace_file": "/results/GNN/GNN.70.pt.trace.json", "trace_disk_size": "22.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 2810000, "runtime_str": "2.81 ms", "start_timestamp": "22:48:52.231.231599", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 163}], "resources": {"cpu2": {"time": {"ts": 1678056532210574000, "dur": 2679000, "relative_dur": 0.01869347995980797, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.68 ms"}}, "gpu3": {"time": {"ts": 1678056532211309000, "dur": 29506000, "relative_dur": 0.2058864575192587, "relative_gap_to_previous": 6.977782739756615e-06, "parent_is_longest": true, "runtime_str": "29.5 ms"}}}, "id": "YRR2EwShWO9aFYBC", "pretty_name": "Layer2", "trace_file": "/results/GNN/GNN.65.pt.trace.json", "trace_disk_size": "52.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 29506000, "runtime_str": "29.5 ms", "start_timestamp": "22:48:52.210.210574", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 377}, {"idx": 22, "name": "Layer3", "type": "Layer3", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 93, in forward\n    with hotline.annotate(f'Layer{idx+1}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 93, "ops": [{"idx": 23, "name": "Edge", "type": "Edge", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 156, in forward\n    with hotline.annotate('Edge'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 156, "ops": [{"idx": 24, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 157, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS1\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 157, "resources": {"cpu2": {"time": {"ts": 1678056532239999000, "dur": 866000, "relative_dur": 0.05714285714285714, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "866 us"}}, "gpu3": {"time": {"ts": 1678056532240817000, "dur": 15155000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "15.2 ms"}}}, "id": "Ukn4YgeStRlwtrr8", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.74.pt.trace.json", "trace_disk_size": "14.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 15155000, "runtime_str": "15.2 ms", "start_timestamp": "22:48:52.239.239999", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 100}], "resources": {"cpu2": {"time": {"ts": 1678056532239999000, "dur": 866000, "relative_dur": 0.029376844533396656, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "866 us"}}, "gpu3": {"time": {"ts": 1678056532240817000, "dur": 15155000, "relative_dur": 0.5140947793344415, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "15.2 ms"}}}, "id": "Ls0GySsgMQirCv1q", "pretty_name": "Edge", "trace_file": "/results/GNN/GNN.73.pt.trace.json", "trace_disk_size": "14.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 15155000, "runtime_str": "15.2 ms", "start_timestamp": "22:48:52.239.239999", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 100}, {"idx": 25, "name": "Node", "type": "Node", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 182, in forward\n    with hotline.annotate('Node'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 182, "ops": [{"idx": 26, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 183, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS2\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 183, "resources": {"cpu2": {"time": {"ts": 1678056532242490000, "dur": 837000, "relative_dur": 0.07244244417517742, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "837 us"}}, "gpu3": {"time": {"ts": 1678056532255973000, "dur": 11554000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "11.6 ms"}}}, "id": "pAjuf1htOclXEEQq", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.76.pt.trace.json", "trace_disk_size": "15.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11554000, "runtime_str": "11.6 ms", "start_timestamp": "22:48:52.242.242490", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 114}], "resources": {"cpu2": {"time": {"ts": 1678056532242490000, "dur": 837000, "relative_dur": 0.028393093388513858, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "837 us"}}, "gpu3": {"time": {"ts": 1678056532255973000, "dur": 11554000, "relative_dur": 0.39194002510261544, "relative_gap_to_previous": 3.3922453271820615e-05, "parent_is_longest": true, "runtime_str": "11.6 ms"}}}, "id": "e8yUNf5TupaaScu3", "pretty_name": "Node", "trace_file": "/results/GNN/GNN.75.pt.trace.json", "trace_disk_size": "15.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11554000, "runtime_str": "11.6 ms", "start_timestamp": "22:48:52.242.242490", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 114}, {"idx": 27, "name": "Global", "type": "Global", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 201, in forward\n    with hotline.annotate('Global'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 201, "ops": [{"idx": 28, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 202, in forward\n    with hotline.annotate('Linear'): # Should be replaced with THIS3\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 202, "resources": {"cpu2": {"time": {"ts": 1678056532261196000, "dur": 965000, "relative_dur": 0.3486271676300578, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "965 us"}}, "gpu3": {"time": {"ts": 1678056532267528000, "dur": 2768000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.77 ms"}}}, "id": "T8lQZ1gVxT12yLtN", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.78.pt.trace.json", "trace_disk_size": "22.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 2768000, "runtime_str": "2.77 ms", "start_timestamp": "22:48:52.261.261196", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 163}], "resources": {"cpu2": {"time": {"ts": 1678056532261196000, "dur": 965000, "relative_dur": 0.0327351674073069, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "965 us"}}, "gpu3": {"time": {"ts": 1678056532267528000, "dur": 2768000, "relative_dur": 0.09389735065639947, "relative_gap_to_previous": 3.3922453271820615e-05, "parent_is_longest": true, "runtime_str": "2.77 ms"}}}, "id": "85K02ahROX1VnMwW", "pretty_name": "Global", "trace_file": "/results/GNN/GNN.77.pt.trace.json", "trace_disk_size": "22.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 2768000, "runtime_str": "2.77 ms", "start_timestamp": "22:48:52.261.261196", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 163}], "resources": {"cpu2": {"time": {"ts": 1678056532239999000, "dur": 2692000, "relative_dur": 0.01878419113542481, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.69 ms"}}, "gpu3": {"time": {"ts": 1678056532240817000, "dur": 29479000, "relative_dur": 0.20569805738528527, "relative_gap_to_previous": 1.395556547951323e-05, "parent_is_longest": true, "runtime_str": "29.5 ms"}}}, "id": "2mqdhQdnQmEq6eyx", "pretty_name": "Layer3", "trace_file": "/results/GNN/GNN.72.pt.trace.json", "trace_disk_size": "52.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 29479000, "runtime_str": "29.5 ms", "start_timestamp": "22:48:52.239.239999", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 377}, {"idx": 29, "name": "Layer4", "type": "Layer4", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 93, in forward\n    with hotline.annotate(f'Layer{idx+1}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 93, "ops": [{"idx": 30, "name": "Edge", "type": "Edge", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 156, in forward\n    with hotline.annotate('Edge'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 156, "ops": [{"idx": 31, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 157, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS1\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 157, "resources": {"cpu2": {"time": {"ts": 1678056532269501000, "dur": 864000, "relative_dur": 0.058923821864557045, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "864 us"}}, "gpu3": {"time": {"ts": 1678056532270297000, "dur": 14663000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "14.7 ms"}}}, "id": "BmAUrucKoV5CVHN5", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.81.pt.trace.json", "trace_disk_size": "14.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 14663000, "runtime_str": "14.7 ms", "start_timestamp": "22:48:52.269.269501", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 100}], "resources": {"cpu2": {"time": {"ts": 1678056532269501000, "dur": 864000, "relative_dur": 0.029746944396625924, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "864 us"}}, "gpu3": {"time": {"ts": 1678056532270297000, "dur": 14663000, "relative_dur": 0.504837321397831, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "14.7 ms"}}}, "id": "Qwl7nOSAn6z2WwLi", "pretty_name": "Edge", "trace_file": "/results/GNN/GNN.80.pt.trace.json", "trace_disk_size": "14.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 14663000, "runtime_str": "14.7 ms", "start_timestamp": "22:48:52.269.269501", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 100}, {"idx": 32, "name": "Node", "type": "Node", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 182, in forward\n    with hotline.annotate('Node'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 182, "ops": [{"idx": 33, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 183, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS2\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 183, "resources": {"cpu2": {"time": {"ts": 1678056532271953000, "dur": 795000, "relative_dur": 0.06854039141305285, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "795 us"}}, "gpu3": {"time": {"ts": 1678056532284961000, "dur": 11599000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "11.6 ms"}}}, "id": "LZ8hbMigMbU8Wlqi", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.83.pt.trace.json", "trace_disk_size": "15.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11599000, "runtime_str": "11.6 ms", "start_timestamp": "22:48:52.271.271953", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 114}], "resources": {"cpu2": {"time": {"ts": 1678056532271953000, "dur": 795000, "relative_dur": 0.02737132036495094, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "795 us"}}, "gpu3": {"time": {"ts": 1678056532284961000, "dur": 11599000, "relative_dur": 0.3993458426579446, "relative_gap_to_previous": 3.442933379239112e-05, "parent_is_longest": true, "runtime_str": "11.6 ms"}}}, "id": "tzJQfC2oVLaifPs3", "pretty_name": "Node", "trace_file": "/results/GNN/GNN.82.pt.trace.json", "trace_disk_size": "15.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11599000, "runtime_str": "11.6 ms", "start_timestamp": "22:48:52.271.271953", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 114}, {"idx": 34, "name": "Global", "type": "Global", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 201, in forward\n    with hotline.annotate('Global'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 201, "ops": [{"idx": 35, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 202, in forward\n    with hotline.annotate('Linear'): # Should be replaced with THIS3\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 202, "resources": {"cpu2": {"time": {"ts": 1678056532290197000, "dur": 956000, "relative_dur": 0.34376123696512045, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "956 us"}}, "gpu3": {"time": {"ts": 1678056532296561000, "dur": 2781000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.78 ms"}}}, "id": "l5aGBiPzb0Ck2Qxf", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.85.pt.trace.json", "trace_disk_size": "22.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 2781000, "runtime_str": "2.78 ms", "start_timestamp": "22:48:52.290.290197", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 163}], "resources": {"cpu2": {"time": {"ts": 1678056532290197000, "dur": 956000, "relative_dur": 0.03291444310552591, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "956 us"}}, "gpu3": {"time": {"ts": 1678056532296561000, "dur": 2781000, "relative_dur": 0.0957479772766397, "relative_gap_to_previous": 3.442933379239112e-05, "parent_is_longest": true, "runtime_str": "2.78 ms"}}}, "id": "qB8FytBMWNdAUcNO", "pretty_name": "Global", "trace_file": "/results/GNN/GNN.84.pt.trace.json", "trace_disk_size": "22.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 2781000, "runtime_str": "2.78 ms", "start_timestamp": "22:48:52.290.290197", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 163}], "resources": {"cpu2": {"time": {"ts": 1678056532269501000, "dur": 2639000, "relative_dur": 0.018414368650217706, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.64 ms"}}, "gpu3": {"time": {"ts": 1678056532270297000, "dur": 29045000, "relative_dur": 0.20266969967623089, "relative_gap_to_previous": 6.977782739756615e-06, "parent_is_longest": true, "runtime_str": "29.1 ms"}}}, "id": "0V2GU1kLTeJdZNYm", "pretty_name": "Layer4", "trace_file": "/results/GNN/GNN.79.pt.trace.json", "trace_disk_size": "52.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 29045000, "runtime_str": "29.1 ms", "start_timestamp": "22:48:52.269.269501", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 377}, {"idx": 36, "name": "Layer5", "type": "Layer5", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 93, in forward\n    with hotline.annotate(f'Layer{idx+1}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 93, "ops": [{"idx": 37, "name": "Edge", "type": "Edge", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 156, in forward\n    with hotline.annotate('Edge'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 156, "ops": [{"idx": 38, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 157, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS1\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 157, "resources": {"cpu2": {"time": {"ts": 1678056532298546000, "dur": 847000, "relative_dur": 0.05571268828520687, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "847 us"}}, "gpu3": {"time": {"ts": 1678056532299343000, "dur": 15203000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "15.2 ms"}}}, "id": "xGS8IMJIWXGZEqwu", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.88.pt.trace.json", "trace_disk_size": "14.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 15203000, "runtime_str": "15.2 ms", "start_timestamp": "22:48:52.298.298546", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 100}], "resources": {"cpu2": {"time": {"ts": 1678056532298546000, "dur": 847000, "relative_dur": 0.02856564702708172, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "847 us"}}, "gpu3": {"time": {"ts": 1678056532299343000, "dur": 15203000, "relative_dur": 0.512731442447135, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "15.2 ms"}}}, "id": "7vi2BqVfFHU0NeKz", "pretty_name": "Edge", "trace_file": "/results/GNN/GNN.87.pt.trace.json", "trace_disk_size": "14.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 15203000, "runtime_str": "15.2 ms", "start_timestamp": "22:48:52.298.298546", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 100}, {"idx": 39, "name": "Node", "type": "Node", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 182, in forward\n    with hotline.annotate('Node'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 182, "ops": [{"idx": 40, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 183, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS2\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 183, "resources": {"cpu2": {"time": {"ts": 1678056532301002000, "dur": 807000, "relative_dur": 0.06916945230136282, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "807 us"}}, "gpu3": {"time": {"ts": 1678056532314547000, "dur": 11667000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "11.7 ms"}}}, "id": "alRcyzfHGfSQdP4Q", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.90.pt.trace.json", "trace_disk_size": "15.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11667000, "runtime_str": "11.7 ms", "start_timestamp": "22:48:52.301.301002", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 114}], "resources": {"cpu2": {"time": {"ts": 1678056532301002000, "dur": 807000, "relative_dur": 0.027216620012815756, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "807 us"}}, "gpu3": {"time": {"ts": 1678056532314547000, "dur": 11667000, "relative_dur": 0.3934774543860241, "relative_gap_to_previous": 3.3725675356649016e-05, "parent_is_longest": true, "runtime_str": "11.7 ms"}}}, "id": "RDoLv4Y5O9mFyvEU", "pretty_name": "Node", "trace_file": "/results/GNN/GNN.89.pt.trace.json", "trace_disk_size": "15.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11667000, "runtime_str": "11.7 ms", "start_timestamp": "22:48:52.301.301002", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 114}, {"idx": 41, "name": "Global", "type": "Global", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 201, in forward\n    with hotline.annotate('Global'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 201, "ops": [{"idx": 42, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 202, in forward\n    with hotline.annotate('Linear'): # Should be replaced with THIS3\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 202, "resources": {"cpu2": {"time": {"ts": 1678056532319784000, "dur": 952000, "relative_dur": 0.3425692695214106, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "952 us"}}, "gpu3": {"time": {"ts": 1678056532326215000, "dur": 2779000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.78 ms"}}}, "id": "ScXnTCCEEhj3fGZC", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.92.pt.trace.json", "trace_disk_size": "22.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 2779000, "runtime_str": "2.78 ms", "start_timestamp": "22:48:52.319.319784", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 163}], "resources": {"cpu2": {"time": {"ts": 1678056532319784000, "dur": 952000, "relative_dur": 0.03210684293952987, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "952 us"}}, "gpu3": {"time": {"ts": 1678056532326215000, "dur": 2779000, "relative_dur": 0.09372365181612761, "relative_gap_to_previous": 3.3725675356649016e-05, "parent_is_longest": true, "runtime_str": "2.78 ms"}}}, "id": "LR5VQw0wCHX2eqWL", "pretty_name": "Global", "trace_file": "/results/GNN/GNN.91.pt.trace.json", "trace_disk_size": "22.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 2779000, "runtime_str": "2.78 ms", "start_timestamp": "22:48:52.319.319784", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 163}], "resources": {"cpu2": {"time": {"ts": 1678056532298546000, "dur": 2630000, "relative_dur": 0.018351568605559896, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.63 ms"}}, "gpu3": {"time": {"ts": 1678056532299343000, "dur": 29651000, "relative_dur": 0.20689823601652338, "relative_gap_to_previous": 6.977782739756615e-06, "parent_is_longest": true, "runtime_str": "29.6 ms"}}}, "id": "EvCnO6Y4vx9Pu1GY", "pretty_name": "Layer5", "trace_file": "/results/GNN/GNN.86.pt.trace.json", "trace_disk_size": "52.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 29651000, "runtime_str": "29.6 ms", "start_timestamp": "22:48:52.298.298546", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 377}], "resources": {"cpu2": {"time": {"ts": 1678056532184183000, "dur": 13438000, "relative_dur": 0.0923573883161512, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "13.4 ms"}}, "gpu3": {"time": {"ts": 1678056532185682000, "dur": 143312000, "relative_dur": 0.9849621993127148, "relative_gap_to_previous": 6.8728522336769755e-06, "parent_is_longest": true, "runtime_str": "143 ms"}}}, "id": "oluAQh7A8ZMvUxxU", "pretty_name": "Graph Network", "trace_file": "/results/GNN/GNN.57.pt.trace.json", "trace_disk_size": "260.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 143312000, "runtime_str": "143 ms", "start_timestamp": "22:48:52.184.184183", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1867}, {"idx": 43, "name": "Decoder", "type": "Decoder", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 97, in forward\n    with hotline.annotate('Decoder'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 97, "ops": [{"idx": 44, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('Linear'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 98, "resources": {"cpu2": {"time": {"ts": 1678056532328194000, "dur": 437000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "437 us"}}, "gpu3": {"time": {"ts": 1678056532328995000, "dur": 128000, "relative_dur": 0.2929061784897025, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "128 us"}}}, "id": "tHJVmAdIjW5rVqJU", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.94.pt.trace.json", "trace_disk_size": "5.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 437000, "runtime_str": "437 us", "start_timestamp": "22:48:52.328.328194", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 40}], "resources": {"cpu2": {"time": {"ts": 1678056532328194000, "dur": 437000, "relative_dur": 0.0030034364261168384, "relative_gap_to_previous": 8.934707903780069e-05, "parent_is_longest": true, "runtime_str": "437 us"}}, "gpu3": {"time": {"ts": 1678056532328995000, "dur": 128000, "relative_dur": 0.0008797250859106529, "relative_gap_to_previous": 6.8728522336769755e-06, "parent_is_longest": true, "runtime_str": "128 us"}}}, "id": "eTkAn28O0M7eFl2S", "pretty_name": "Decoder", "trace_file": "/results/GNN/GNN.93.pt.trace.json", "trace_disk_size": "5.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 437000, "runtime_str": "437 us", "start_timestamp": "22:48:52.328.328194", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 40}], "is_model_pass": "Forward", "idx": 2, "id": "bGlHwkQKYXgOxarF", "pretty_name": "Forward", "trace_file": "/results/GNN/GNN.52.pt.trace.json", "trace_disk_size": "274.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 145500000, "runtime_str": "146 ms", "start_timestamp": "22:48:52.182.182645", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1990}, {"name": "Calc Loss", "type": "training loop", "instances": 23, "resources": {"cpu2": {"time": {"ts": 1678056532328731000, "dur": 758000, "relative_dur": 0.0019600085847341704, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "758 us"}}, "gpu3": {"time": {"ts": 1678056532329123000, "dur": 254000, "relative_dur": 0.000656783879317255, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "254 us"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 76, in update_params\n    with hotline.annotate('Calc Loss'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py", "source_file_num": 76, "ops": [{"name": "aten::zeros(86%) and 1 other\u2026", "type": "generated", "generated_depth": 1, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1678056532328731000, "dur": 13000, "relative_dur": 0.017150395778364115, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "13 us"}}}, "ops": [{"name": "aten::zeros", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532328731000, "dur": 6000, "relative_dur": 0.46153846153846156, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "6 us"}}}, "ops": [{"name": "aten::empty", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532328732000, "dur": 3000, "relative_dur": 0.5, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "aten::empty"}}, "id": "WWQWe4sjsHrO3KsQ", "pretty_name": "aten::empty", "trace_file": "/results/GNN/GNN.98.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 3000, "runtime_str": "3 us", "start_timestamp": "22:48:52.328.328732", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::zero_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532328736000, "dur": 1000, "relative_dur": 0.16666666666666666, "relative_gap_to_previous": 0.16666666666666666, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::zero_"}}, "id": "1P6K9ipJYInOr8vE", "pretty_name": "aten::zero_", "trace_file": "/results/GNN/GNN.99.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "22:48:52.328.328736", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "yeckGKGLZirwKxV4", "pretty_name": "aten::zeros", "trace_file": "/results/GNN/GNN.97.pt.trace.json", "trace_disk_size": "280 Bytes", "runtime": 6000, "runtime_str": "6 us", "start_timestamp": "22:48:52.328.328731", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::empty", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532328743000, "dur": 1000, "relative_dur": 0.07692307692307693, "relative_gap_to_previous": 0.46153846153846156, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::empty"}}, "id": "gWXVanNaybeTFRRu", "pretty_name": "aten::empty", "trace_file": "/results/GNN/GNN.100.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "22:48:52.328.328743", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "0NWFRun9gtb0SQ1u", "pretty_name": "aten::zeros(86%) and 1 other\u2026", "trace_file": "/results/GNN/GNN.96.pt.trace.json", "trace_disk_size": "373 Bytes", "runtime": 13000, "runtime_str": "13 us", "start_timestamp": "22:48:52.328.328731", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 4}, {"name": "aten::where", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532328758000, "dur": 71000, "relative_dur": 0.09366754617414248, "relative_gap_to_previous": 0.018469656992084433, "parent_is_longest": true, "runtime_str": "71 us"}}, "gpu3": {"time": {"ts": 1678056532329123000, "dur": 16000, "relative_dur": 0.021108179419525065, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "16 us"}}}, "ops": [{"name": "aten::scalar_tensor", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532328761000, "dur": 30000, "relative_dur": 0.4225352112676056, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "30 us"}}, "gpu3": {"time": {"ts": 1678056532329123000, "dur": 2000, "relative_dur": 0.028169014084507043, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 us"}}}, "ops": [{"name": "aten::empty", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532328763000, "dur": 7000, "relative_dur": 0.23333333333333334, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "7 us"}, "res_name": "aten::empty"}}, "id": "0F9U8RCUDEJcSdeM", "pretty_name": "aten::empty", "trace_file": "/results/GNN/GNN.103.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 7000, "runtime_str": "7 us", "start_timestamp": "22:48:52.328.328763", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::fill_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532328771000, "dur": 19000, "relative_dur": 0.6333333333333333, "relative_gap_to_previous": 0.03333333333333333, "parent_is_longest": true, "runtime_str": "19 us"}, "res_name": "aten::fill_"}, "gpu3": {"time": {"ts": 1678056532329123000, "dur": 2000, "relative_dur": 0.06666666666666667, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>"}}, "id": "NXrnhPzrgu5JqEmi", "pretty_name": "aten::fill_", "trace_file": "/results/GNN/GNN.104.pt.trace.json", "trace_disk_size": "459 Bytes", "runtime": 19000, "runtime_str": "19 us", "start_timestamp": "22:48:52.328.328771", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}], "id": "JCNLPzO6qJd6HstC", "pretty_name": "aten::scalar_tensor", "trace_file": "/results/GNN/GNN.102.pt.trace.json", "trace_disk_size": "654 Bytes", "runtime": 30000, "runtime_str": "30 us", "start_timestamp": "22:48:52.328.328761", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 5}, {"name": "aten::to", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532328792000, "dur": 0, "relative_dur": 0.0, "relative_gap_to_previous": 0.014084507042253521, "parent_is_longest": true, "runtime_str": "0 us"}, "res_name": "aten::to"}}, "id": "JOhgxxu4ivFoteTU", "pretty_name": "aten::to", "trace_file": "/results/GNN/GNN.105.pt.trace.json", "trace_disk_size": "91 Bytes", "runtime": 0, "runtime_str": "0 us", "start_timestamp": "22:48:52.328.328792", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "TlNpIa1QacEiSz0S", "pretty_name": "aten::where", "trace_file": "/results/GNN/GNN.101.pt.trace.json", "trace_disk_size": "2.2 kB", "runtime": 71000, "runtime_str": "71 us", "start_timestamp": "22:48:52.328.328758", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 12}, {"name": "aten::mul(35%) and 2 others\u2026", "type": "generated", "generated_depth": 1, "instances": 3, "resources": {"cpu2": {"time": {"ts": 1678056532328840000, "dur": 83000, "relative_dur": 0.10949868073878628, "relative_gap_to_previous": 0.014511873350923483, "parent_is_longest": true, "runtime_str": "83 us"}}, "gpu3": {"time": {"ts": 1678056532329140000, "dur": 22000, "relative_dur": 0.029023746701846966, "relative_gap_to_previous": 0.0013192612137203166, "parent_is_longest": true, "runtime_str": "22 us"}}}, "ops": [{"name": "aten::mul", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532328840000, "dur": 24000, "relative_dur": 0.2891566265060241, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "24 us"}, "res_name": "aten::mul"}, "gpu3": {"time": {"ts": 1678056532329140000, "dur": 5000, "relative_dur": 0.060240963855421686, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5 us"}, "res_name": "vectorized_elementwise_kernel<4 AUnaryFunctor  binary_ernal::MulFunctor Array<char 2> AUnaryFunctor  binary_ernal::MulFunctor Array<char 2>"}}, "id": "bPSwmzC0I9649f7u", "pretty_name": "aten::mul", "trace_file": "/results/GNN/GNN.107.pt.trace.json", "trace_disk_size": "586 Bytes", "runtime": 24000, "runtime_str": "24 us", "start_timestamp": "22:48:52.328.328840", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::add", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532328871000, "dur": 23000, "relative_dur": 0.27710843373493976, "relative_gap_to_previous": 0.08433734939759036, "parent_is_longest": true, "runtime_str": "23 us"}, "res_name": "aten::add"}, "gpu3": {"time": {"ts": 1678056532329147000, "dur": 6000, "relative_dur": 0.07228915662650602, "relative_gap_to_previous": 0.024096385542168676, "parent_is_longest": true, "runtime_str": "6 us"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctorOnSelf_add Array<char 2> CUDAFunctorOnSelf_add Array<char 2>"}}, "id": "YfPsraGESn7OWyGq", "pretty_name": "aten::add", "trace_file": "/results/GNN/GNN.108.pt.trace.json", "trace_disk_size": "476 Bytes", "runtime": 23000, "runtime_str": "23 us", "start_timestamp": "22:48:52.328.328871", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::ge", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532328901000, "dur": 22000, "relative_dur": 0.26506024096385544, "relative_gap_to_previous": 0.08433734939759036, "parent_is_longest": true, "runtime_str": "22 us"}, "res_name": "aten::ge"}, "gpu3": {"time": {"ts": 1678056532329154000, "dur": 8000, "relative_dur": 0.0963855421686747, "relative_gap_to_previous": 0.012048192771084338, "parent_is_longest": true, "runtime_str": "8 us"}, "res_name": "vectorized_elementwise_kernel<4 compare_scalar_kernelTensorIteratorBase& OpType ::{lambda#1} Array<char 2> compare_scalar_kernelTensorIteratorBase& OpType ::{lambda#1} Array<char 2>"}}, "id": "XYQaqKew5FsVXr8d", "pretty_name": "aten::ge", "trace_file": "/results/GNN/GNN.109.pt.trace.json", "trace_disk_size": "663 Bytes", "runtime": 22000, "runtime_str": "22 us", "start_timestamp": "22:48:52.328.328901", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}], "id": "vz5qhKGt0olUFZ2B", "pretty_name": "aten::mul(35%) and 2 others\u2026", "trace_file": "/results/GNN/GNN.106.pt.trace.json", "trace_disk_size": "1.7 kB", "runtime": 83000, "runtime_str": "83 us", "start_timestamp": "22:48:52.328.328840", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 9}, {"name": "aten::where", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532328926000, "dur": 47000, "relative_dur": 0.06200527704485488, "relative_gap_to_previous": 0.00395778364116095, "parent_is_longest": true, "runtime_str": "47 us"}}, "gpu3": {"time": {"ts": 1678056532329163000, "dur": 9000, "relative_dur": 0.011873350923482849, "relative_gap_to_previous": 0.0013192612137203166, "parent_is_longest": true, "runtime_str": "9 us"}}}, "ops": [{"name": "aten::scalar_tensor", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532328928000, "dur": 17000, "relative_dur": 0.3617021276595745, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "17 us"}}, "gpu3": {"time": {"ts": 1678056532329163000, "dur": 2000, "relative_dur": 0.0425531914893617, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 us"}}}, "ops": [{"name": "aten::empty", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532328929000, "dur": 4000, "relative_dur": 0.23529411764705882, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4 us"}, "res_name": "aten::empty"}}, "id": "M7WsnFP2IJG62GLP", "pretty_name": "aten::empty", "trace_file": "/results/GNN/GNN.112.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 4000, "runtime_str": "4 us", "start_timestamp": "22:48:52.328.328929", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::fill_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532328934000, "dur": 10000, "relative_dur": 0.5882352941176471, "relative_gap_to_previous": 0.058823529411764705, "parent_is_longest": true, "runtime_str": "10 us"}, "res_name": "aten::fill_"}, "gpu3": {"time": {"ts": 1678056532329163000, "dur": 2000, "relative_dur": 0.11764705882352941, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>"}}, "id": "62Y956s5lL2cQgt5", "pretty_name": "aten::fill_", "trace_file": "/results/GNN/GNN.113.pt.trace.json", "trace_disk_size": "458 Bytes", "runtime": 10000, "runtime_str": "10 us", "start_timestamp": "22:48:52.328.328934", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}], "id": "AVFYYYLTf4QmTTZc", "pretty_name": "aten::scalar_tensor", "trace_file": "/results/GNN/GNN.111.pt.trace.json", "trace_disk_size": "653 Bytes", "runtime": 17000, "runtime_str": "17 us", "start_timestamp": "22:48:52.328.328928", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 5}, {"name": "aten::to", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532328946000, "dur": 0, "relative_dur": 0.0, "relative_gap_to_previous": 0.02127659574468085, "parent_is_longest": true, "runtime_str": "0 us"}, "res_name": "aten::to"}}, "id": "KvIKS1NXOP74z25y", "pretty_name": "aten::to", "trace_file": "/results/GNN/GNN.114.pt.trace.json", "trace_disk_size": "91 Bytes", "runtime": 0, "runtime_str": "0 us", "start_timestamp": "22:48:52.328.328946", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "45hc9fCzuNr1YFAP", "pretty_name": "aten::where", "trace_file": "/results/GNN/GNN.110.pt.trace.json", "trace_disk_size": "2.2 kB", "runtime": 47000, "runtime_str": "47 us", "start_timestamp": "22:48:52.328.328926", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 12}, {"name": "aten::where(14%) and 6 others\u2026", "type": "generated", "generated_depth": 1, "instances": 9, "resources": {"cpu2": {"time": {"ts": 1678056532328978000, "dur": 205000, "relative_dur": 0.2704485488126649, "relative_gap_to_previous": 0.006596306068601583, "parent_is_longest": true, "runtime_str": "205 us"}}, "gpu3": {"time": {"ts": 1678056532329173000, "dur": 86000, "relative_dur": 0.11345646437994723, "relative_gap_to_previous": 0.0013192612137203166, "parent_is_longest": true, "runtime_str": "86 us"}}}, "ops": [{"name": "aten::neg", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532328978000, "dur": 21000, "relative_dur": 0.1024390243902439, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "21 us"}, "res_name": "aten::neg"}, "gpu3": {"time": {"ts": 1678056532329173000, "dur": 9000, "relative_dur": 0.04390243902439024, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9 us"}, "res_name": "vectorized_elementwise_kernel<4 neg_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda#1} Array<char 2> neg_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda#1} Array<char 2>"}}, "id": "oWVIbVjori19DVGs", "pretty_name": "aten::neg", "trace_file": "/results/GNN/GNN.116.pt.trace.json", "trace_disk_size": "676 Bytes", "runtime": 21000, "runtime_str": "21 us", "start_timestamp": "22:48:52.328.328978", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::where", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532329002000, "dur": 25000, "relative_dur": 0.12195121951219512, "relative_gap_to_previous": 0.014634146341463415, "parent_is_longest": true, "runtime_str": "25 us"}}, "gpu3": {"time": {"ts": 1678056532329183000, "dur": 11000, "relative_dur": 0.05365853658536585, "relative_gap_to_previous": 0.004878048780487805, "parent_is_longest": true, "runtime_str": "11 us"}}}, "ops": [{"name": "aten::empty", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532329005000, "dur": 3000, "relative_dur": 0.12, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "aten::empty"}}, "id": "gY64yBO2wPU02PSK", "pretty_name": "aten::empty", "trace_file": "/results/GNN/GNN.118.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 3000, "runtime_str": "3 us", "start_timestamp": "22:48:52.329.329005", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::resize_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532329010000, "dur": 4000, "relative_dur": 0.16, "relative_gap_to_previous": 0.08, "parent_is_longest": true, "runtime_str": "4 us"}, "res_name": "aten::resize_"}}, "id": "0MPFZwdZ1dRt3g5w", "pretty_name": "aten::resize_", "trace_file": "/results/GNN/GNN.119.pt.trace.json", "trace_disk_size": "96 Bytes", "runtime": 4000, "runtime_str": "4 us", "start_timestamp": "22:48:52.329.329010", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "cudaLaunchKernel", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532329018000, "dur": 7000, "relative_dur": 0.28, "relative_gap_to_previous": 0.16, "parent_is_longest": true, "runtime_str": "7 us"}, "res_name": "cudaLaunchKernel"}, "gpu3": {"time": {"ts": 1678056532329183000, "dur": 11000, "relative_dur": 0.44, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "11 us"}, "res_name": "vectorized_elementwise_kernel<4 where_kernel_implTensorIterator&::{lambda#1}::operator const::{lambda#14}::operator const::{lambdabool  #1} Array<char 4> where_kernel_implTensorIterator&::{lambda#1}::operator const::{lambda#14}::operator const::{lambdabool  #1} Array<char 4>"}}, "id": "EDuiZDeksOrCN5Qc", "pretty_name": "cudaLaunchKernel", "trace_file": "/results/GNN/GNN.120.pt.trace.json", "trace_disk_size": "653 Bytes", "runtime": 11000, "runtime_str": "11 us", "start_timestamp": "22:48:52.329.329018", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 2}], "id": "qsavNLd6up7YyZUG", "pretty_name": "aten::where", "trace_file": "/results/GNN/GNN.117.pt.trace.json", "trace_disk_size": "935 Bytes", "runtime": 25000, "runtime_str": "25 us", "start_timestamp": "22:48:52.329.329002", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 5}, {"name": "aten::mul", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532329031000, "dur": 19000, "relative_dur": 0.09268292682926829, "relative_gap_to_previous": 0.01951219512195122, "parent_is_longest": true, "runtime_str": "19 us"}, "res_name": "aten::mul"}, "gpu3": {"time": {"ts": 1678056532329195000, "dur": 13000, "relative_dur": 0.06341463414634146, "relative_gap_to_previous": 0.004878048780487805, "parent_is_longest": true, "runtime_str": "13 us"}, "res_name": "vectorized_elementwise_kernel<4 BinaryFunctor  binary_ernal::MulFunctor Array<char 3> BinaryFunctor  binary_ernal::MulFunctor Array<char 3>"}}, "id": "lrjjWiHELRBdlObT", "pretty_name": "aten::mul", "trace_file": "/results/GNN/GNN.121.pt.trace.json", "trace_disk_size": "587 Bytes", "runtime": 19000, "runtime_str": "19 us", "start_timestamp": "22:48:52.329.329031", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::sub", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532329055000, "dur": 20000, "relative_dur": 0.0975609756097561, "relative_gap_to_previous": 0.024390243902439025, "parent_is_longest": true, "runtime_str": "20 us"}, "res_name": "aten::sub"}, "gpu3": {"time": {"ts": 1678056532329210000, "dur": 9000, "relative_dur": 0.04390243902439024, "relative_gap_to_previous": 0.00975609756097561, "parent_is_longest": true, "runtime_str": "9 us"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>"}}, "id": "IF3Itzjow8A2E8vK", "pretty_name": "aten::sub", "trace_file": "/results/GNN/GNN.122.pt.trace.json", "trace_disk_size": "464 Bytes", "runtime": 20000, "runtime_str": "20 us", "start_timestamp": "22:48:52.329.329055", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::neg", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532329079000, "dur": 14000, "relative_dur": 0.06829268292682927, "relative_gap_to_previous": 0.01951219512195122, "parent_is_longest": true, "runtime_str": "14 us"}, "res_name": "aten::neg"}, "gpu3": {"time": {"ts": 1678056532329220000, "dur": 9000, "relative_dur": 0.04390243902439024, "relative_gap_to_previous": 0.004878048780487805, "parent_is_longest": true, "runtime_str": "9 us"}, "res_name": "vectorized_elementwise_kernel<4 neg_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda#1} Array<char 2> neg_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda#1} Array<char 2>"}}, "id": "YaThAHaPS4gw9uJz", "pretty_name": "aten::neg", "trace_file": "/results/GNN/GNN.123.pt.trace.json", "trace_disk_size": "676 Bytes", "runtime": 14000, "runtime_str": "14 us", "start_timestamp": "22:48:52.329.329079", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::exp", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532329096000, "dur": 23000, "relative_dur": 0.11219512195121951, "relative_gap_to_previous": 0.014634146341463415, "parent_is_longest": true, "runtime_str": "23 us"}, "res_name": "aten::exp"}, "gpu3": {"time": {"ts": 1678056532329231000, "dur": 5000, "relative_dur": 0.024390243902439025, "relative_gap_to_previous": 0.00975609756097561, "parent_is_longest": true, "runtime_str": "5 us"}, "res_name": "vectorized_elementwise_kernel<4 exp_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#4}::operator const::{lambda#1} Array<char 2> exp_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#4}::operator const::{lambda#1} Array<char 2>"}}, "id": "EvZwZIuDDBtTsg45", "pretty_name": "aten::exp", "trace_file": "/results/GNN/GNN.124.pt.trace.json", "trace_disk_size": "674 Bytes", "runtime": 23000, "runtime_str": "23 us", "start_timestamp": "22:48:52.329.329096", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::add", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532329125000, "dur": 17000, "relative_dur": 0.08292682926829269, "relative_gap_to_previous": 0.02926829268292683, "parent_is_longest": true, "runtime_str": "17 us"}, "res_name": "aten::add"}, "gpu3": {"time": {"ts": 1678056532329237000, "dur": 5000, "relative_dur": 0.024390243902439025, "relative_gap_to_previous": 0.004878048780487805, "parent_is_longest": true, "runtime_str": "5 us"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctorOnSelf_add Array<char 2> CUDAFunctorOnSelf_add Array<char 2>"}}, "id": "Klv8r1Vg5XjvhpmK", "pretty_name": "aten::add", "trace_file": "/results/GNN/GNN.125.pt.trace.json", "trace_disk_size": "476 Bytes", "runtime": 17000, "runtime_str": "17 us", "start_timestamp": "22:48:52.329.329125", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::log", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532329146000, "dur": 20000, "relative_dur": 0.0975609756097561, "relative_gap_to_previous": 0.01951219512195122, "parent_is_longest": true, "runtime_str": "20 us"}, "res_name": "aten::log"}, "gpu3": {"time": {"ts": 1678056532329243000, "dur": 5000, "relative_dur": 0.024390243902439025, "relative_gap_to_previous": 0.004878048780487805, "parent_is_longest": true, "runtime_str": "5 us"}, "res_name": "vectorized_elementwise_kernel<4 log_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#4}::operator const::{lambda#1} Array<char 2> log_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#4}::operator const::{lambda#1} Array<char 2>"}}, "id": "F1XmXi7c0yXEl4Ju", "pretty_name": "aten::log", "trace_file": "/results/GNN/GNN.126.pt.trace.json", "trace_disk_size": "674 Bytes", "runtime": 20000, "runtime_str": "20 us", "start_timestamp": "22:48:52.329.329146", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::add", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532329168000, "dur": 15000, "relative_dur": 0.07317073170731707, "relative_gap_to_previous": 0.00975609756097561, "parent_is_longest": true, "runtime_str": "15 us"}, "res_name": "aten::add"}, "gpu3": {"time": {"ts": 1678056532329249000, "dur": 10000, "relative_dur": 0.04878048780487805, "relative_gap_to_previous": 0.004878048780487805, "parent_is_longest": true, "runtime_str": "10 us"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>"}}, "id": "xNu81UT7XAYBn4uv", "pretty_name": "aten::add", "trace_file": "/results/GNN/GNN.127.pt.trace.json", "trace_disk_size": "465 Bytes", "runtime": 15000, "runtime_str": "15 us", "start_timestamp": "22:48:52.329.329168", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}], "id": "sq23ghcweP1fOYhI", "pretty_name": "aten::where(14%) and 6 others\u2026", "trace_file": "/results/GNN/GNN.115.pt.trace.json", "trace_disk_size": "5.6 kB", "runtime": 205000, "runtime_str": "205 us", "start_timestamp": "22:48:52.328.328978", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 29}, {"name": "aten::where", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532329189000, "dur": 47000, "relative_dur": 0.06200527704485488, "relative_gap_to_previous": 0.0079155672823219, "parent_is_longest": true, "runtime_str": "47 us"}}, "gpu3": {"time": {"ts": 1678056532329261000, "dur": 13000, "relative_dur": 0.017150395778364115, "relative_gap_to_previous": 0.002638522427440633, "parent_is_longest": true, "runtime_str": "13 us"}}}, "ops": [{"name": "aten::scalar_tensor", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532329190000, "dur": 18000, "relative_dur": 0.3829787234042553, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "18 us"}}, "gpu3": {"time": {"ts": 1678056532329261000, "dur": 2000, "relative_dur": 0.0425531914893617, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 us"}}}, "ops": [{"name": "aten::empty", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532329191000, "dur": 5000, "relative_dur": 0.2777777777777778, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5 us"}, "res_name": "aten::empty"}}, "id": "PXW1zR3bJn2DEsoW", "pretty_name": "aten::empty", "trace_file": "/results/GNN/GNN.130.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 5000, "runtime_str": "5 us", "start_timestamp": "22:48:52.329.329191", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::fill_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532329197000, "dur": 11000, "relative_dur": 0.6111111111111112, "relative_gap_to_previous": 0.05555555555555555, "parent_is_longest": true, "runtime_str": "11 us"}, "res_name": "aten::fill_"}, "gpu3": {"time": {"ts": 1678056532329261000, "dur": 2000, "relative_dur": 0.1111111111111111, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>"}}, "id": "aBryBicPvbtP8PNz", "pretty_name": "aten::fill_", "trace_file": "/results/GNN/GNN.131.pt.trace.json", "trace_disk_size": "458 Bytes", "runtime": 11000, "runtime_str": "11 us", "start_timestamp": "22:48:52.329.329197", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}], "id": "ueYBfBc22A4AjoxR", "pretty_name": "aten::scalar_tensor", "trace_file": "/results/GNN/GNN.129.pt.trace.json", "trace_disk_size": "653 Bytes", "runtime": 18000, "runtime_str": "18 us", "start_timestamp": "22:48:52.329.329190", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 5}, {"name": "aten::to", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532329209000, "dur": 1000, "relative_dur": 0.02127659574468085, "relative_gap_to_previous": 0.02127659574468085, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::to"}}, "id": "5MNigFRwEinnWEvL", "pretty_name": "aten::to", "trace_file": "/results/GNN/GNN.132.pt.trace.json", "trace_disk_size": "91 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "22:48:52.329.329209", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "GgeaA0gRqjAqRVIl", "pretty_name": "aten::where", "trace_file": "/results/GNN/GNN.128.pt.trace.json", "trace_disk_size": "2.2 kB", "runtime": 47000, "runtime_str": "47 us", "start_timestamp": "22:48:52.329.329189", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 12}, {"name": "aten::sum(77%) and 3 others\u2026", "type": "generated", "generated_depth": 1, "instances": 6, "resources": {"cpu2": {"time": {"ts": 1678056532329245000, "dur": 244000, "relative_dur": 0.32189973614775724, "relative_gap_to_previous": 0.011873350923482849, "parent_is_longest": true, "runtime_str": "244 us"}}, "gpu3": {"time": {"ts": 1678056532329282000, "dur": 95000, "relative_dur": 0.12532981530343007, "relative_gap_to_previous": 0.010554089709762533, "parent_is_longest": true, "runtime_str": "95 us"}}}, "ops": [{"name": "aten::sum", "type": "generated", "generated_depth": 2, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1678056532329245000, "dur": 104000, "relative_dur": 0.4262295081967213, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "104 us"}, "res_name": "aten::sum"}, "gpu3": {"time": {"ts": 1678056532329282000, "dur": 74000, "relative_dur": 0.30327868852459017, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "74 us"}, "res_name": "unrolled_elementwise_kernel<direct_copy_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#8}::operator const::{lambdalong#1} Array<char 2> TrivialOffsetCalculator<1  char memory::LoadWithCast<1> Array<char 2>::StoreWithCast<1> direct_copy_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#8}::operator const::{lambdalong#1} Array<char 2> TrivialOffsetCalculator<1  char memory::LoadWithCast<1> Array<char 2>::StoreWithCast<1>(35%) and 3 others\u2026"}}, "id": "dQlYzFSkT01GuImG", "pretty_name": "aten::sum", "trace_file": "/results/GNN/GNN.134.pt.trace.json", "trace_disk_size": "3.4 kB", "runtime": 104000, "runtime_str": "104 us", "start_timestamp": "22:48:52.329.329245", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 20}, {"name": "aten::div", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532329353000, "dur": 22000, "relative_dur": 0.09016393442622951, "relative_gap_to_previous": 0.01639344262295082, "parent_is_longest": true, "runtime_str": "22 us"}, "res_name": "aten::div"}, "gpu3": {"time": {"ts": 1678056532329374000, "dur": 3000, "relative_dur": 0.012295081967213115, "relative_gap_to_previous": 0.07377049180327869, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "unrolled_elementwise_kernel<BinaryFunctor  binary_ernal::DivFunctor Array<char 3> TrivialOffsetCalculator<2  TrivialOffsetCalculator<1  memory::LoadWithCast<2> memory::StoreWithCast<1> BinaryFunctor  binary_ernal::DivFunctor Array<char 3> TrivialOffsetCalculator<2  TrivialOffsetCalculator<1  memory::LoadWithCast<2> memory::StoreWithCast<1>"}}, "id": "wKGrFOxB9ACnNZpx", "pretty_name": "aten::div", "trace_file": "/results/GNN/GNN.135.pt.trace.json", "trace_disk_size": "899 Bytes", "runtime": 22000, "runtime_str": "22 us", "start_timestamp": "22:48:52.329.329353", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::zeros(88%) and 1 other\u2026", "type": "generated", "generated_depth": 2, "instances": 3, "resources": {"cpu2": {"time": {"ts": 1678056532329464000, "dur": 25000, "relative_dur": 0.10245901639344263, "relative_gap_to_previous": 0.36475409836065575, "parent_is_longest": true, "runtime_str": "25 us"}}}, "ops": [{"name": "aten::zeros", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532329464000, "dur": 5000, "relative_dur": 0.2, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5 us"}, "res_name": "aten::zeros"}}, "id": "YQCWSHc7rnh3Eybr", "pretty_name": "aten::zeros", "trace_file": "/results/GNN/GNN.137.pt.trace.json", "trace_disk_size": "280 Bytes", "runtime": 5000, "runtime_str": "5 us", "start_timestamp": "22:48:52.329.329464", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::empty", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532329475000, "dur": 1000, "relative_dur": 0.04, "relative_gap_to_previous": 0.24, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::empty"}}, "id": "qcaFaJjo51QOHzeT", "pretty_name": "aten::empty", "trace_file": "/results/GNN/GNN.138.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "22:48:52.329.329475", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::zeros", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532329487000, "dur": 2000, "relative_dur": 0.08, "relative_gap_to_previous": 0.44, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "aten::zeros"}}, "id": "P5A0gbobRXUpNwAd", "pretty_name": "aten::zeros", "trace_file": "/results/GNN/GNN.139.pt.trace.json", "trace_disk_size": "280 Bytes", "runtime": 2000, "runtime_str": "2 us", "start_timestamp": "22:48:52.329.329487", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}], "id": "iPF8CiXrLb7bnc9Q", "pretty_name": "aten::zeros(88%) and 1 other\u2026", "trace_file": "/results/GNN/GNN.136.pt.trace.json", "trace_disk_size": "652 Bytes", "runtime": 25000, "runtime_str": "25 us", "start_timestamp": "22:48:52.329.329464", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 7}], "id": "riA4ZIkrrFDw53HT", "pretty_name": "aten::sum(77%) and 3 others\u2026", "trace_file": "/results/GNN/GNN.133.pt.trace.json", "trace_disk_size": "5.0 kB", "runtime": 244000, "runtime_str": "244 us", "start_timestamp": "22:48:52.329.329245", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 30}], "idx": 45, "id": "01IZ0fhwsiixi03Q", "pretty_name": "Calc Loss", "trace_file": "/results/GNN/GNN.95.pt.trace.json", "trace_disk_size": "19.3 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py", "runtime": 758000, "runtime_str": "758 us", "start_timestamp": "22:48:52.328.328731", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 108}, {"name": "Zero Grad", "type": "training loop", "instances": 4, "resources": {"cpu2": {"time": {"ts": 1678056532329492000, "dur": 1071000, "relative_dur": 0.0027693524990109455, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.07 ms"}}, "gpu3": {"time": {"ts": 1678056532329522000, "dur": 1043000, "relative_dur": 0.0026969511264877837, "relative_gap_to_previous": 0.0003749356791378031, "parent_is_longest": true, "runtime_str": "1.04 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 80, in update_params\n    with hotline.annotate('Zero Grad'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py", "source_file_num": 80, "ops": [{"name": "aten::zero_", "type": "generated", "generated_depth": 2, "instances": 67, "resources": {"cpu2": {"time": {"ts": 1678056532329493000, "dur": 933000, "relative_dur": 0.8711484593837535, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "933 us"}, "res_name": "aten::zero_"}, "gpu3": {"time": {"ts": 1678056532329522000, "dur": 905000, "relative_dur": 0.8450046685340803, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "905 us"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>"}}, "id": "xitZcLQX3xRDSyQN", "pretty_name": "aten::zero_", "trace_file": "/results/GNN/GNN.141.pt.trace.json", "trace_disk_size": "36.4 kB", "runtime": 933000, "runtime_str": "933 us", "start_timestamp": "22:48:52.329.329493", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 265}, {"name": "aten::ones_like(81%) and 2 others\u2026", "type": "generated", "generated_depth": 1, "instances": 3, "resources": {"cpu2": {"time": {"ts": 1678056532330506000, "dur": 57000, "relative_dur": 0.05322128851540616, "relative_gap_to_previous": 0.07469654528478058, "parent_is_longest": true, "runtime_str": "57 us"}}, "gpu3": {"time": {"ts": 1678056532330563000, "dur": 2000, "relative_dur": 0.0018674136321195146, "relative_gap_to_previous": 0.12698412698412698, "parent_is_longest": true, "runtime_str": "2 us"}}}, "ops": [{"name": "aten::zeros", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532330506000, "dur": 5000, "relative_dur": 0.08771929824561403, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5 us"}}}, "ops": [{"name": "aten::empty", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532330507000, "dur": 2000, "relative_dur": 0.4, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "aten::empty"}}, "id": "RIGeu3KC93EAkh79", "pretty_name": "aten::empty", "trace_file": "/results/GNN/GNN.144.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 2000, "runtime_str": "2 us", "start_timestamp": "22:48:52.330.330507", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::zero_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532330510000, "dur": 1000, "relative_dur": 0.2, "relative_gap_to_previous": 0.2, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::zero_"}}, "id": "0NHKVGoGCRNfxq23", "pretty_name": "aten::zero_", "trace_file": "/results/GNN/GNN.145.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "22:48:52.330.330510", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "tRQAY8nHanuTx0hu", "pretty_name": "aten::zeros", "trace_file": "/results/GNN/GNN.143.pt.trace.json", "trace_disk_size": "280 Bytes", "runtime": 5000, "runtime_str": "5 us", "start_timestamp": "22:48:52.330.330506", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::empty", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532330517000, "dur": 1000, "relative_dur": 0.017543859649122806, "relative_gap_to_previous": 0.10526315789473684, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::empty"}}, "id": "D8Rp40z3qeeYIMDI", "pretty_name": "aten::empty", "trace_file": "/results/GNN/GNN.146.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "22:48:52.330.330517", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::ones_like", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532330537000, "dur": 26000, "relative_dur": 0.45614035087719296, "relative_gap_to_previous": 0.3333333333333333, "parent_is_longest": true, "runtime_str": "26 us"}}, "gpu3": {"time": {"ts": 1678056532330563000, "dur": 2000, "relative_dur": 0.03508771929824561, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "2 us"}}}, "ops": [{"name": "aten::empty_like", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532330538000, "dur": 9000, "relative_dur": 0.34615384615384615, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9 us"}, "res_name": "aten::empty_like"}}, "id": "oGczCP0EZ4FbqscS", "pretty_name": "aten::empty_like", "trace_file": "/results/GNN/GNN.148.pt.trace.json", "trace_disk_size": "200 Bytes", "runtime": 9000, "runtime_str": "9 us", "start_timestamp": "22:48:52.330.330538", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::fill_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532330548000, "dur": 15000, "relative_dur": 0.5769230769230769, "relative_gap_to_previous": 0.038461538461538464, "parent_is_longest": true, "runtime_str": "15 us"}, "res_name": "aten::fill_"}, "gpu3": {"time": {"ts": 1678056532330563000, "dur": 2000, "relative_dur": 0.07692307692307693, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>"}}, "id": "RptlF5e9XD9A55VB", "pretty_name": "aten::fill_", "trace_file": "/results/GNN/GNN.149.pt.trace.json", "trace_disk_size": "458 Bytes", "runtime": 15000, "runtime_str": "15 us", "start_timestamp": "22:48:52.330.330548", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}], "id": "9q1NlqumuUcAwPLv", "pretty_name": "aten::ones_like", "trace_file": "/results/GNN/GNN.147.pt.trace.json", "trace_disk_size": "755 Bytes", "runtime": 26000, "runtime_str": "26 us", "start_timestamp": "22:48:52.330.330537", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 6}], "id": "5NWh5spe1VdmU4aF", "pretty_name": "aten::ones_like(81%) and 2 others\u2026", "trace_file": "/results/GNN/GNN.142.pt.trace.json", "trace_disk_size": "1.1 kB", "runtime": 57000, "runtime_str": "57 us", "start_timestamp": "22:48:52.330.330506", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 10}], "idx": 46, "id": "nn18Pts383W6mrMh", "pretty_name": "Zero Grad", "trace_file": "/results/GNN/GNN.140.pt.trace.json", "trace_disk_size": "37.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py", "runtime": 1071000, "runtime_str": "1.07 ms", "start_timestamp": "22:48:52.329.329492", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 276}, {"name": "Backward", "type": "training loop", "instances": 218, "resources": {"cpu2": {"time": {"ts": 1678056532353771000, "dur": 60000, "relative_dur": 0.05900711860637701, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "60 us"}}, "cpu4": {"time": {"ts": 1678056532330807000, "dur": 22820000, "relative_dur": 0.05900711860637701, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "22.8 ms"}}, "gpu3": {"time": {"ts": 1678056532330991000, "dur": 233345000, "relative_dur": 0.6033749382649011, "relative_gap_to_previous": 0.0011015351676738215, "parent_is_longest": true, "runtime_str": "233 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 83, in update_params\n    with hotline.annotate('Backward'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py", "source_file_num": 83, "is_model_pass": "Backward", "ops": [{"name": "Decoder", "type": "Decoder", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 97, in forward\n    with hotline.annotate('Decoder'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 97, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('Linear'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 98, "resources": {"cpu4": {"time": {"ts": 1678056532330807000, "dur": 1663000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.66 ms"}}, "gpu3": {"time": {"ts": 1678056532330991000, "dur": 1456000, "relative_dur": 0.8755261575466026, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.46 ms"}}}, "is_backward_op": true, "id": "kXhL54ii6kdCJdBh", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.152.pt.trace.json", "trace_disk_size": "22.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 1663000, "runtime_str": "1.66 ms", "start_timestamp": "22:48:52.330.330807", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu4", "trace_event_count": 140}], "resources": {"cpu4": {"time": {"ts": 1678056532330807000, "dur": 1663000, "relative_dur": 0.007126786517816966, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.66 ms"}}, "gpu3": {"time": {"ts": 1678056532330991000, "dur": 1456000, "relative_dur": 0.00623968801559922, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.46 ms"}}}, "is_backward_op": true, "id": "isx4rZlnn6xnXlWE", "pretty_name": "Decoder", "trace_file": "/results/GNN/GNN.151.pt.trace.json", "trace_disk_size": "22.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 1663000, "runtime_str": "1.66 ms", "start_timestamp": "22:48:52.330.330807", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu4", "trace_event_count": 140}, {"name": "Graph Network", "type": "Graph Network", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 91, in forward\n    with hotline.annotate('Graph Network'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 91, "ops": [{"name": "Layer5", "type": "Layer5", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 93, in forward\n    with hotline.annotate(f'Layer{idx+1}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 93, "ops": [{"name": "Global", "type": "Global", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 201, in forward\n    with hotline.annotate('Global'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 201, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 202, in forward\n    with hotline.annotate('Linear'): # Should be replaced with THIS3\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 202, "resources": {"cpu4": {"time": {"ts": 1678056532332491000, "dur": 820000, "relative_dur": 0.9403669724770642, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "820 us"}}, "gpu3": {"time": {"ts": 1678056532332531000, "dur": 872000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "872 us"}}}, "is_backward_op": true, "id": "5lYe3YVrxzYnWCc7", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.156.pt.trace.json", "trace_disk_size": "11.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 872000, "runtime_str": "872 us", "start_timestamp": "22:48:52.332.332491", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 81}], "resources": {"cpu4": {"time": {"ts": 1678056532332491000, "dur": 820000, "relative_dur": 0.021631888569393517, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "820 us"}}, "gpu3": {"time": {"ts": 1678056532332531000, "dur": 872000, "relative_dur": 0.023003666868916032, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "872 us"}}}, "is_backward_op": true, "id": "H9IvmZ2WpZ6Cz2Vl", "pretty_name": "Global", "trace_file": "/results/GNN/GNN.155.pt.trace.json", "trace_disk_size": "11.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 872000, "runtime_str": "872 us", "start_timestamp": "22:48:52.332.332491", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 81}, {"name": "Node", "type": "Node", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 182, in forward\n    with hotline.annotate('Node'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 182, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 183, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS2\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 183, "resources": {"cpu4": {"time": {"ts": 1678056532333328000, "dur": 931000, "relative_dur": 0.08403285495080784, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "931 us"}}, "gpu3": {"time": {"ts": 1678056532333405000, "dur": 11079000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "11.1 ms"}}}, "is_backward_op": true, "id": "DgOEg9egmYgGjSjC", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.158.pt.trace.json", "trace_disk_size": "14.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11079000, "runtime_str": "11.1 ms", "start_timestamp": "22:48:52.333.333328", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 103}], "resources": {"cpu4": {"time": {"ts": 1678056532333328000, "dur": 931000, "relative_dur": 0.024560107631835807, "relative_gap_to_previous": 0.000448465982536207, "parent_is_longest": true, "runtime_str": "931 us"}}, "gpu3": {"time": {"ts": 1678056532333405000, "dur": 11079000, "relative_dur": 0.2922679188540375, "relative_gap_to_previous": 5.276070382778906e-05, "parent_is_longest": true, "runtime_str": "11.1 ms"}}}, "is_backward_op": true, "id": "EnP5okfdy03CTMRy", "pretty_name": "Node", "trace_file": "/results/GNN/GNN.157.pt.trace.json", "trace_disk_size": "14.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11079000, "runtime_str": "11.1 ms", "start_timestamp": "22:48:52.333.333328", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 103}, {"name": "Edge", "type": "Edge", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 156, in forward\n    with hotline.annotate('Edge'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 156, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 157, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS1\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 157, "resources": {"cpu4": {"time": {"ts": 1678056532334275000, "dur": 1108000, "relative_dur": 0.042692559627018074, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.11 ms"}}, "gpu3": {"time": {"ts": 1678056532344485000, "dur": 25953000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "25.9 ms"}}}, "is_backward_op": true, "id": "Lp3jtTuWktnIHoUB", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.160.pt.trace.json", "trace_disk_size": "18.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 25953000, "runtime_str": "25.9 ms", "start_timestamp": "22:48:52.334.334275", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 128}], "resources": {"cpu4": {"time": {"ts": 1678056532334275000, "dur": 1108000, "relative_dur": 0.02922942992059514, "relative_gap_to_previous": 0.0004220856306223125, "parent_is_longest": true, "runtime_str": "1.11 ms"}}, "gpu3": {"time": {"ts": 1678056532344485000, "dur": 25953000, "relative_dur": 0.6846492732213048, "relative_gap_to_previous": 2.638035191389453e-05, "parent_is_longest": true, "runtime_str": "25.9 ms"}}}, "is_backward_op": true, "id": "zkCnezBbgxKIGuEB", "pretty_name": "Edge", "trace_file": "/results/GNN/GNN.159.pt.trace.json", "trace_disk_size": "18.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 25953000, "runtime_str": "25.9 ms", "start_timestamp": "22:48:52.334.334275", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 128}], "resources": {"cpu4": {"time": {"ts": 1678056532332491000, "dur": 2892000, "relative_dur": 0.01297710608739354, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.89 ms"}}, "gpu3": {"time": {"ts": 1678056532332531000, "dur": 37907000, "relative_dur": 0.1700979116372154, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "37.9 ms"}}}, "is_backward_op": true, "id": "IWcr0lwqdfTJtCnr", "pretty_name": "Layer5", "trace_file": "/results/GNN/GNN.154.pt.trace.json", "trace_disk_size": "43.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 37907000, "runtime_str": "37.9 ms", "start_timestamp": "22:48:52.332.332491", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 312}, {"name": "Layer4", "type": "Layer4", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 93, in forward\n    with hotline.annotate(f'Layer{idx+1}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 93, "ops": [{"name": "Global", "type": "Global", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 201, in forward\n    with hotline.annotate('Global'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 201, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 202, in forward\n    with hotline.annotate('Linear'): # Should be replaced with THIS3\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 202, "resources": {"cpu4": {"time": {"ts": 1678056532335399000, "dur": 2033000, "relative_dur": 0.25789673981986555, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.03 ms"}}, "gpu3": {"time": {"ts": 1678056532370438000, "dur": 7883000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "7.88 ms"}}}, "is_backward_op": true, "id": "ARz88uSN0YZPQ70e", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.163.pt.trace.json", "trace_disk_size": "39.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 7883000, "runtime_str": "7.88 ms", "start_timestamp": "22:48:52.335.335399", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 261}], "resources": {"cpu4": {"time": {"ts": 1678056532335399000, "dur": 2033000, "relative_dur": 0.04349128249010589, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.03 ms"}}, "gpu3": {"time": {"ts": 1678056532370438000, "dur": 7883000, "relative_dur": 0.16863835704353405, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "7.88 ms"}}}, "is_backward_op": true, "id": "ab0tnjY6yAfE1GD3", "pretty_name": "Global", "trace_file": "/results/GNN/GNN.162.pt.trace.json", "trace_disk_size": "39.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 7883000, "runtime_str": "7.88 ms", "start_timestamp": "22:48:52.335.335399", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 261}, {"name": "Node", "type": "Node", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 182, in forward\n    with hotline.annotate('Node'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 182, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 183, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS2\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 183, "resources": {"cpu4": {"time": {"ts": 1678056532337448000, "dur": 934000, "relative_dur": 0.07713271120654058, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "934 us"}}, "gpu3": {"time": {"ts": 1678056532378322000, "dur": 12109000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12.1 ms"}}}, "is_backward_op": true, "id": "O5Rr4Rwd6inH22dS", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.165.pt.trace.json", "trace_disk_size": "14.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 12109000, "runtime_str": "12.1 ms", "start_timestamp": "22:48:52.337.337448", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 106}], "resources": {"cpu4": {"time": {"ts": 1678056532337448000, "dur": 934000, "relative_dur": 0.019980746603914856, "relative_gap_to_previous": 0.0003422825970692053, "parent_is_longest": true, "runtime_str": "934 us"}}, "gpu3": {"time": {"ts": 1678056532378322000, "dur": 12109000, "relative_dur": 0.2590437479944379, "relative_gap_to_previous": 2.139266231682533e-05, "parent_is_longest": true, "runtime_str": "12.1 ms"}}}, "is_backward_op": true, "id": "0uEgMeSX8XTG2qRq", "pretty_name": "Node", "trace_file": "/results/GNN/GNN.164.pt.trace.json", "trace_disk_size": "14.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 12109000, "runtime_str": "12.1 ms", "start_timestamp": "22:48:52.337.337448", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 106}, {"name": "Edge", "type": "Edge", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 156, in forward\n    with hotline.annotate('Edge'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 156, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 157, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS1\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 157, "resources": {"cpu4": {"time": {"ts": 1678056532338398000, "dur": 1117000, "relative_dur": 0.04175544839445254, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.12 ms"}}, "gpu3": {"time": {"ts": 1678056532390432000, "dur": 26751000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "26.8 ms"}}}, "is_backward_op": true, "id": "1CvdUlopHAr3UjM7", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.167.pt.trace.json", "trace_disk_size": "18.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 26751000, "runtime_str": "26.8 ms", "start_timestamp": "22:48:52.338.338398", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 128}], "resources": {"cpu4": {"time": {"ts": 1678056532338398000, "dur": 1117000, "relative_dur": 0.023895603807893892, "relative_gap_to_previous": 0.0003422825970692053, "parent_is_longest": true, "runtime_str": "1.12 ms"}}, "gpu3": {"time": {"ts": 1678056532390432000, "dur": 26751000, "relative_dur": 0.5722751096373944, "relative_gap_to_previous": 2.139266231682533e-05, "parent_is_longest": true, "runtime_str": "26.8 ms"}}}, "is_backward_op": true, "id": "NqbAsWBSHljgSIle", "pretty_name": "Edge", "trace_file": "/results/GNN/GNN.166.pt.trace.json", "trace_disk_size": "18.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 26751000, "runtime_str": "26.8 ms", "start_timestamp": "22:48:52.338.338398", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 128}], "resources": {"cpu4": {"time": {"ts": 1678056532335399000, "dur": 4116000, "relative_dur": 0.01846949123641487, "relative_gap_to_previous": 7.179588430093245e-05, "parent_is_longest": true, "runtime_str": "4.12 ms"}}, "gpu3": {"time": {"ts": 1678056532370438000, "dur": 46745000, "relative_dur": 0.20975616322794297, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "46.7 ms"}}}, "is_backward_op": true, "id": "9semxHenIsQoxzRx", "pretty_name": "Layer4", "trace_file": "/results/GNN/GNN.161.pt.trace.json", "trace_disk_size": "72.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 46745000, "runtime_str": "46.7 ms", "start_timestamp": "22:48:52.335.335399", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 495}, {"name": "Layer3", "type": "Layer3", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 93, in forward\n    with hotline.annotate(f'Layer{idx+1}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 93, "ops": [{"name": "Global", "type": "Global", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 201, in forward\n    with hotline.annotate('Global'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 201, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 202, in forward\n    with hotline.annotate('Linear'): # Should be replaced with THIS3\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 202, "resources": {"cpu4": {"time": {"ts": 1678056532339531000, "dur": 1943000, "relative_dur": 0.2133055220111977, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.94 ms"}}, "gpu3": {"time": {"ts": 1678056532417185000, "dur": 9109000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9.11 ms"}}}, "is_backward_op": true, "id": "BTlOiu8O697IqDOe", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.170.pt.trace.json", "trace_disk_size": "40.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 9109000, "runtime_str": "9.11 ms", "start_timestamp": "22:48:52.339.339531", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 264}], "resources": {"cpu4": {"time": {"ts": 1678056532339531000, "dur": 1943000, "relative_dur": 0.04125002653758784, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.94 ms"}}, "gpu3": {"time": {"ts": 1678056532417185000, "dur": 9109000, "relative_dur": 0.19338471010339045, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9.11 ms"}}}, "is_backward_op": true, "id": "ie2PvuXMDShV007m", "pretty_name": "Global", "trace_file": "/results/GNN/GNN.169.pt.trace.json", "trace_disk_size": "40.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 9109000, "runtime_str": "9.11 ms", "start_timestamp": "22:48:52.339.339531", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 264}, {"name": "Node", "type": "Node", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 182, in forward\n    with hotline.annotate('Node'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 182, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 183, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS2\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 183, "resources": {"cpu4": {"time": {"ts": 1678056532341490000, "dur": 907000, "relative_dur": 0.07726382144986796, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "907 us"}}, "gpu3": {"time": {"ts": 1678056532426296000, "dur": 11739000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "11.7 ms"}}}, "is_backward_op": true, "id": "TjppJVZ7YYmLsgLq", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.172.pt.trace.json", "trace_disk_size": "14.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11739000, "runtime_str": "11.7 ms", "start_timestamp": "22:48:52.341.341490", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 106}], "resources": {"cpu4": {"time": {"ts": 1678056532341490000, "dur": 907000, "relative_dur": 0.019255673736280066, "relative_gap_to_previous": 0.0003396811243445216, "parent_is_longest": true, "runtime_str": "907 us"}}, "gpu3": {"time": {"ts": 1678056532426296000, "dur": 11739000, "relative_dur": 0.24921979491752116, "relative_gap_to_previous": 4.24601405430652e-05, "parent_is_longest": true, "runtime_str": "11.7 ms"}}}, "is_backward_op": true, "id": "w6E3J7VC63h761w3", "pretty_name": "Node", "trace_file": "/results/GNN/GNN.171.pt.trace.json", "trace_disk_size": "14.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11739000, "runtime_str": "11.7 ms", "start_timestamp": "22:48:52.341.341490", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 106}, {"name": "Edge", "type": "Edge", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 156, in forward\n    with hotline.annotate('Edge'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 156, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 157, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS1\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 157, "resources": {"cpu4": {"time": {"ts": 1678056532342414000, "dur": 1088000, "relative_dur": 0.0414460401508514, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.09 ms"}}, "gpu3": {"time": {"ts": 1678056532438037000, "dur": 26251000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "26.2 ms"}}}, "is_backward_op": true, "id": "20er1SXfrka670ra", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.174.pt.trace.json", "trace_disk_size": "18.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 26251000, "runtime_str": "26.2 ms", "start_timestamp": "22:48:52.342.342414", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 128}], "resources": {"cpu4": {"time": {"ts": 1678056532342414000, "dur": 1088000, "relative_dur": 0.023098316455427467, "relative_gap_to_previous": 0.0003609111946160542, "parent_is_longest": true, "runtime_str": "1.09 ms"}}, "gpu3": {"time": {"ts": 1678056532438037000, "dur": 26251000, "relative_dur": 0.5573105746980023, "relative_gap_to_previous": 4.24601405430652e-05, "parent_is_longest": true, "runtime_str": "26.2 ms"}}}, "is_backward_op": true, "id": "EJLWchRHBYZSDVoa", "pretty_name": "Edge", "trace_file": "/results/GNN/GNN.173.pt.trace.json", "trace_disk_size": "18.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 26251000, "runtime_str": "26.2 ms", "start_timestamp": "22:48:52.342.342414", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 128}], "resources": {"cpu4": {"time": {"ts": 1678056532339531000, "dur": 3971000, "relative_dur": 0.017818841034937673, "relative_gap_to_previous": 7.179588430093245e-05, "parent_is_longest": true, "runtime_str": "3.97 ms"}}, "gpu3": {"time": {"ts": 1678056532417185000, "dur": 47103000, "relative_dur": 0.21136259613917632, "relative_gap_to_previous": 8.974485537616556e-06, "parent_is_longest": true, "runtime_str": "47.1 ms"}}}, "is_backward_op": true, "id": "QZGMg5LKVf7QgAhc", "pretty_name": "Layer3", "trace_file": "/results/GNN/GNN.168.pt.trace.json", "trace_disk_size": "73.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 47103000, "runtime_str": "47.1 ms", "start_timestamp": "22:48:52.339.339531", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 498}, {"name": "Layer2", "type": "Layer2", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 93, in forward\n    with hotline.annotate(f'Layer{idx+1}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 93, "ops": [{"name": "Global", "type": "Global", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 201, in forward\n    with hotline.annotate('Global'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 201, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 202, in forward\n    with hotline.annotate('Linear'): # Should be replaced with THIS3\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 202, "resources": {"cpu4": {"time": {"ts": 1678056532343519000, "dur": 1949000, "relative_dur": 0.214647577092511, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.95 ms"}}, "gpu3": {"time": {"ts": 1678056532464289000, "dur": 9080000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9.08 ms"}}}, "is_backward_op": true, "id": "d9zIQ5TeyxxMxTOM", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.177.pt.trace.json", "trace_disk_size": "40.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 9080000, "runtime_str": "9.08 ms", "start_timestamp": "22:48:52.343.343519", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 264}], "resources": {"cpu4": {"time": {"ts": 1678056532343519000, "dur": 1949000, "relative_dur": 0.04100568062276457, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.95 ms"}}, "gpu3": {"time": {"ts": 1678056532464289000, "dur": 9080000, "relative_dur": 0.1910372396381233, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9.08 ms"}}}, "is_backward_op": true, "id": "3xGxB0hRrONykUGV", "pretty_name": "Global", "trace_file": "/results/GNN/GNN.176.pt.trace.json", "trace_disk_size": "40.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 9080000, "runtime_str": "9.08 ms", "start_timestamp": "22:48:52.343.343519", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 264}, {"name": "Node", "type": "Node", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 182, in forward\n    with hotline.annotate('Node'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 182, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 183, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS2\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 183, "resources": {"cpu4": {"time": {"ts": 1678056532345485000, "dur": 990000, "relative_dur": 0.0837421756048046, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "990 us"}}, "gpu3": {"time": {"ts": 1678056532473371000, "dur": 11822000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "11.8 ms"}}}, "is_backward_op": true, "id": "uEjqeIVqEZY2Bt1U", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.179.pt.trace.json", "trace_disk_size": "14.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11822000, "runtime_str": "11.8 ms", "start_timestamp": "22:48:52.345.345485", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 106}], "resources": {"cpu4": {"time": {"ts": 1678056532345485000, "dur": 990000, "relative_dur": 0.020828950136755734, "relative_gap_to_previous": 0.00035766884073216916, "parent_is_longest": true, "runtime_str": "990 us"}}, "gpu3": {"time": {"ts": 1678056532473371000, "dur": 11822000, "relative_dur": 0.24872711971386494, "relative_gap_to_previous": 4.2078687144961075e-05, "parent_is_longest": true, "runtime_str": "11.8 ms"}}}, "is_backward_op": true, "id": "q5TsVX5tj52ag1qb", "pretty_name": "Node", "trace_file": "/results/GNN/GNN.178.pt.trace.json", "trace_disk_size": "14.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11822000, "runtime_str": "11.8 ms", "start_timestamp": "22:48:52.345.345485", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 106}, {"name": "Edge", "type": "Edge", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 156, in forward\n    with hotline.annotate('Edge'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 156, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 157, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS1\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 157, "resources": {"cpu4": {"time": {"ts": 1678056532346493000, "dur": 1099000, "relative_dur": 0.04127699530516432, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.10 ms"}}, "gpu3": {"time": {"ts": 1678056532485194000, "dur": 26625000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "26.6 ms"}}}, "is_backward_op": true, "id": "QJHSHfdLleKf24Ns", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.181.pt.trace.json", "trace_disk_size": "18.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 26625000, "runtime_str": "26.6 ms", "start_timestamp": "22:48:52.346.346493", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 128}], "resources": {"cpu4": {"time": {"ts": 1678056532346493000, "dur": 1099000, "relative_dur": 0.023122238586156113, "relative_gap_to_previous": 0.0003787081843046497, "parent_is_longest": true, "runtime_str": "1.10 ms"}}, "gpu3": {"time": {"ts": 1678056532485194000, "dur": 26625000, "relative_dur": 0.5601725226172943, "relative_gap_to_previous": 2.1039343572480537e-05, "parent_is_longest": true, "runtime_str": "26.6 ms"}}}, "is_backward_op": true, "id": "DLq2iFNjusFJc22X", "pretty_name": "Edge", "trace_file": "/results/GNN/GNN.180.pt.trace.json", "trace_disk_size": "18.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 26625000, "runtime_str": "26.6 ms", "start_timestamp": "22:48:52.346.346493", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 128}], "resources": {"cpu4": {"time": {"ts": 1678056532343519000, "dur": 4073000, "relative_dur": 0.018276539797356117, "relative_gap_to_previous": 7.628312706974073e-05, "parent_is_longest": true, "runtime_str": "4.07 ms"}}, "gpu3": {"time": {"ts": 1678056532464289000, "dur": 47530000, "relative_dur": 0.21327864880145744, "relative_gap_to_previous": 4.487242768808278e-06, "parent_is_longest": true, "runtime_str": "47.5 ms"}}}, "is_backward_op": true, "id": "UlXwOp7mE1LcDUsT", "pretty_name": "Layer2", "trace_file": "/results/GNN/GNN.175.pt.trace.json", "trace_disk_size": "73.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 47530000, "runtime_str": "47.5 ms", "start_timestamp": "22:48:52.343.343519", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 498}, {"name": "Layer1", "type": "Layer1", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 93, in forward\n    with hotline.annotate(f'Layer{idx+1}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 93, "ops": [{"name": "Global", "type": "Global", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 201, in forward\n    with hotline.annotate('Global'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 201, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 202, in forward\n    with hotline.annotate('Linear'): # Should be replaced with THIS3\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 202, "resources": {"cpu4": {"time": {"ts": 1678056532347608000, "dur": 1978000, "relative_dur": 0.2153980180768812, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.98 ms"}}, "gpu3": {"time": {"ts": 1678056532511820000, "dur": 9183000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9.18 ms"}}}, "is_backward_op": true, "id": "9ioHk3jReFhK3XSc", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.184.pt.trace.json", "trace_disk_size": "40.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 9183000, "runtime_str": "9.18 ms", "start_timestamp": "22:48:52.347.347608", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 263}], "resources": {"cpu4": {"time": {"ts": 1678056532347608000, "dur": 1978000, "relative_dur": 0.04540342017674739, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.98 ms"}}, "gpu3": {"time": {"ts": 1678056532511820000, "dur": 9183000, "relative_dur": 0.21078847698840814, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9.18 ms"}}}, "is_backward_op": true, "id": "w25xJKV8EFvNPjCw", "pretty_name": "Global", "trace_file": "/results/GNN/GNN.183.pt.trace.json", "trace_disk_size": "40.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 9183000, "runtime_str": "9.18 ms", "start_timestamp": "22:48:52.347.347608", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 263}, {"name": "Node", "type": "Node", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 182, in forward\n    with hotline.annotate('Node'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 182, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 183, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS2\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 183, "resources": {"cpu4": {"time": {"ts": 1678056532349614000, "dur": 946000, "relative_dur": 0.08718894009216589, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "946 us"}}, "gpu3": {"time": {"ts": 1678056532521004000, "dur": 10850000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "10.8 ms"}}}, "is_backward_op": true, "id": "9XQlvR6zh8w0icmo", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.186.pt.trace.json", "trace_disk_size": "15.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 10850000, "runtime_str": "10.8 ms", "start_timestamp": "22:48:52.349.349614", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 107}], "resources": {"cpu4": {"time": {"ts": 1678056532349614000, "dur": 946000, "relative_dur": 0.021714679214966143, "relative_gap_to_previous": 0.0006427177780328245, "parent_is_longest": true, "runtime_str": "946 us"}}, "gpu3": {"time": {"ts": 1678056532521004000, "dur": 10850000, "relative_dur": 0.2490531389877195, "relative_gap_to_previous": 2.295420635831516e-05, "parent_is_longest": true, "runtime_str": "10.8 ms"}}}, "is_backward_op": true, "id": "vlq2tPnj8xpNbl3e", "pretty_name": "Node", "trace_file": "/results/GNN/GNN.185.pt.trace.json", "trace_disk_size": "15.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 10850000, "runtime_str": "10.8 ms", "start_timestamp": "22:48:52.349.349614", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 107}, {"name": "Edge", "type": "Edge", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 156, in forward\n    with hotline.annotate('Edge'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 156, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 157, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS1\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 157, "resources": {"cpu4": {"time": {"ts": 1678056532350576000, "dur": 969000, "relative_dur": 0.04118147046323842, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "969 us"}}, "gpu3": {"time": {"ts": 1678056532531855000, "dur": 23530000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "23.5 ms"}}}, "is_backward_op": true, "id": "N1MvVmRdUPg2tf6Y", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.188.pt.trace.json", "trace_disk_size": "15.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 23530000, "runtime_str": "23.5 ms", "start_timestamp": "22:48:52.350.350576", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 113}], "resources": {"cpu4": {"time": {"ts": 1678056532350576000, "dur": 969000, "relative_dur": 0.02224262596120739, "relative_gap_to_previous": 0.0003672673017330426, "parent_is_longest": true, "runtime_str": "969 us"}}, "gpu3": {"time": {"ts": 1678056532531855000, "dur": 23530000, "relative_dur": 0.5401124756111557, "relative_gap_to_previous": 2.295420635831516e-05, "parent_is_longest": true, "runtime_str": "23.5 ms"}}}, "is_backward_op": true, "id": "NLvSwfM9nZmgSE9f", "pretty_name": "Edge", "trace_file": "/results/GNN/GNN.187.pt.trace.json", "trace_disk_size": "15.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 23530000, "runtime_str": "23.5 ms", "start_timestamp": "22:48:52.350.350576", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 113}], "resources": {"cpu4": {"time": {"ts": 1678056532347608000, "dur": 3937000, "relative_dur": 0.01766627478079819, "relative_gap_to_previous": 7.179588430093245e-05, "parent_is_longest": true, "runtime_str": "3.94 ms"}}, "gpu3": {"time": {"ts": 1678056532511820000, "dur": 43565000, "relative_dur": 0.19548673122313262, "relative_gap_to_previous": 4.487242768808278e-06, "parent_is_longest": true, "runtime_str": "43.6 ms"}}}, "is_backward_op": true, "id": "UgZ8mX6SaKxhFLNK", "pretty_name": "Layer1", "trace_file": "/results/GNN/GNN.182.pt.trace.json", "trace_disk_size": "70.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 43565000, "runtime_str": "43.6 ms", "start_timestamp": "22:48:52.347.347608", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 483}], "resources": {"cpu4": {"time": {"ts": 1678056532332491000, "dur": 19054000, "relative_dur": 0.0816559172041398, "relative_gap_to_previous": 8.999550022498874e-05, "parent_is_longest": true, "runtime_str": "19.1 ms"}}, "gpu3": {"time": {"ts": 1678056532332531000, "dur": 222854000, "relative_dur": 0.9550408193876021, "relative_gap_to_previous": 0.000359982000899955, "parent_is_longest": true, "runtime_str": "223 ms"}}}, "is_backward_op": true, "id": "0RbHrdvXojBL198Q", "pretty_name": "Graph Network", "trace_file": "/results/GNN/GNN.153.pt.trace.json", "trace_disk_size": "333.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 222854000, "runtime_str": "223 ms", "start_timestamp": "22:48:52.332.332491", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 2286}, {"name": "Edge Embedder", "type": "Edge Embedder", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 86, in forward\n    with hotline.annotate('Edge Embedder'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 86, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 87, in forward\n    with hotline.annotate('Linear'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 87, "resources": {"cpu4": {"time": {"ts": 1678056532351561000, "dur": 1547000, "relative_dur": 0.18234323432343233, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.55 ms"}}, "gpu3": {"time": {"ts": 1678056532555386000, "dur": 8484000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "8.48 ms"}}}, "is_backward_op": true, "id": "GV3JIGjMYoPWAe6e", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.190.pt.trace.json", "trace_disk_size": "31.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 8484000, "runtime_str": "8.48 ms", "start_timestamp": "22:48:52.351.351561", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 207}], "resources": {"cpu4": {"time": {"ts": 1678056532351561000, "dur": 1547000, "relative_dur": 0.0066296685165741715, "relative_gap_to_previous": 6.856800017142e-05, "parent_is_longest": true, "runtime_str": "1.55 ms"}}, "gpu3": {"time": {"ts": 1678056532555386000, "dur": 8484000, "relative_dur": 0.036358182090895454, "relative_gap_to_previous": 4.28550001071375e-06, "parent_is_longest": true, "runtime_str": "8.48 ms"}}}, "is_backward_op": true, "id": "8TVFACiMFQRXhLwE", "pretty_name": "Edge Embedder", "trace_file": "/results/GNN/GNN.189.pt.trace.json", "trace_disk_size": "31.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 8484000, "runtime_str": "8.48 ms", "start_timestamp": "22:48:52.351.351561", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 207}, {"name": "Node Embedder", "type": "Node Embedder", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 79, in forward\n    with hotline.annotate('Node Embedder'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 79, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 80, in forward\n    with hotline.annotate('Linear'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 80, "resources": {"cpu4": {"time": {"ts": 1678056532353137000, "dur": 320000, "relative_dur": 0.6986899563318777, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "320 us"}}, "gpu3": {"time": {"ts": 1678056532563871000, "dur": 458000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "458 us"}}}, "is_backward_op": true, "id": "kRotryxBgymCbMYB", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.192.pt.trace.json", "trace_disk_size": "5.3 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 458000, "runtime_str": "458 us", "start_timestamp": "22:48:52.353.353137", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 40}], "resources": {"cpu4": {"time": {"ts": 1678056532353137000, "dur": 320000, "relative_dur": 0.0013713600034284, "relative_gap_to_previous": 0.00012427950031069875, "parent_is_longest": true, "runtime_str": "320 us"}}, "gpu3": {"time": {"ts": 1678056532563871000, "dur": 458000, "relative_dur": 0.0019627590049068975, "relative_gap_to_previous": 4.28550001071375e-06, "parent_is_longest": true, "runtime_str": "458 us"}}}, "is_backward_op": true, "id": "GvXQmgr5aormx8HG", "pretty_name": "Node Embedder", "trace_file": "/results/GNN/GNN.191.pt.trace.json", "trace_disk_size": "5.3 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 458000, "runtime_str": "458 us", "start_timestamp": "22:48:52.353.353137", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 40}], "idx": 47, "id": "62IsbeBTLj9XSnCJ", "pretty_name": "Backward", "trace_file": "/results/GNN/GNN.150.pt.trace.json", "trace_disk_size": "395.3 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py", "runtime": 233345000, "runtime_str": "233 ms", "start_timestamp": "22:48:52.330.330807", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 2695}, {"name": "Optimizer", "type": "training loop", "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056532353835000, "dur": 9808000, "relative_dur": 0.02536116648954188, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9.81 ms"}}, "gpu3": {"time": {"ts": 1678056532564337000, "dur": 1882000, "relative_dur": 0.004866406538878244, "relative_gap_to_previous": 2.585763304398642e-06, "parent_is_longest": true, "runtime_str": "1.88 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 86, in update_params\n    with hotline.annotate('Optimizer'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py", "source_file_num": 86, "ops": [{"name": "aten::sqrt(13%) and 9 others\u2026", "type": "generated", "generated_depth": 1, "instances": 686, "resources": {"cpu2": {"time": {"ts": 1678056532353835000, "dur": 9793000, "relative_dur": 0.9984706362153344, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9.79 ms"}, "res_name": "aten::sqrt(13%) and 9 others\u2026"}, "gpu3": {"time": {"ts": 1678056532564337000, "dur": 1882000, "relative_dur": 0.191884176182708, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.88 ms"}, "res_name": "vectorized_elementwise_kernel<4 addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4> addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4>(14%) and 6 others\u2026"}}, "id": "ISh5tbO4cpBqVrQ9", "pretty_name": "aten::sqrt(13%) and 9 others\u2026", "trace_file": "/results/GNN/GNN.194.pt.trace.json", "trace_disk_size": "366.9 kB", "runtime": 9793000, "runtime_str": "9.79 ms", "start_timestamp": "22:48:52.353.353835", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2048}], "idx": 48, "id": "2dSuQV9hVlSbqQIv", "pretty_name": "Optimizer", "trace_file": "/results/GNN/GNN.193.pt.trace.json", "trace_disk_size": "367.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py", "runtime": 9808000, "runtime_str": "9.81 ms", "start_timestamp": "22:48:52.353.353835", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2049}], "resources": {"cpu2": {"time": {"ts": 1678056532179261000, "dur": 51854000, "parent_is_longest": true, "runtime_str": "51.9 ms"}}, "cpu4": {"time": {"ts": 1678056532330807000, "dur": 22820000, "parent_is_longest": false, "runtime_str": "22.8 ms"}}, "gpu3": {"time": {"ts": 1678056532179486000, "dur": 386733000, "parent_is_longest": true, "runtime_str": "387 ms"}}}, "source_file_name": "/home/ubuntu/algorithmic-efficiency/submission_runner.py", "source_file_num": 354, "id": "uQopymyKZF02QU9M", "pretty_name": "GNN Training Iteration", "total_accuracy_str": "97.89%", "trace_file": "/results/GNN/GNN.1.pt.trace.json", "trace_disk_size": "3.1 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/submission_runner.py", "config": {"trace_filepath": "/home/ubuntu/cpath/results/GNN.worker0.pt.trace.json", "output_dir": "/home/ubuntu/cpath/results", "ui_traces_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/GNN", "ui_model_path": "/home/ubuntu/cpath/results/ui/src/results/GNN.js", "results_summary_csv_filepath": "/home/ubuntu/cpath/results/results_summary.csv", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN", "run_name": "GNN", "model_name": "GNN", "backend": "torch", "test": false, "is_test_accuracy": true, "view_manual_annotations": false, "source_file_name": "/home/ubuntu/algorithmic-efficiency/submission_runner.py", "source_file_num": 354, "num_gpus": 1, "slice_idx": 0, "drop_flow_view": "", "last_found_was_fused": false, "count_sum_greater_than_1": 0, "count_sum_less_than_1": 0, "tiny_op_threshold": 0.05, "max_generated_depth": 2, "remove_slice_args": true, "write_model_ops_to_file": true, "op_idx": 1}, "metadata": {}, "metadata.model": "GNN", "metadata.batch_size": 6144, "metadata.optimizer": "Adam", "metadata.dataset": "OGBG MOLPCBA", "trace_event_count": 7201, "pytorch_version": "1.13.1+cu117", "gpu_model": "NVIDIA GeForce RTX 3090", "gpu_cuda_version": "11.7", "hotline_traces_trace_disk_size": "6.0 MB", "hotline_annotation_count": "194", "processed_datetime": "05/03/2023 22:48:58", "runtime_without_profiling": "1.71 s \u00b11%", "runtime_with_profiling": "1.69 s \u00b11%", "runtime_profiling_overhead_factor": "0.01\u00d7 faster", "hotline_analysis_time": "2.56 s", "runtime": 386733000, "runtime_str": "387 ms", "start_timestamp": "22:48:52.179.179261", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3"}]