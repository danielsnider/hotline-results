[{"name": "GNN Training Iteration", "type": "root", "ops": [{"name": "Load Data", "type": "training loop", "instances": 29, "resources": {"cpu2": {"time": {"ts": 1677892474321455000, "dur": 1557000, "relative_dur": 0.003857961598786861, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu3": {"time": {"ts": 1677892474321675000, "dur": 2334000, "relative_dur": 0.005783225672169899, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 379, in train_once\n    with hotline.annotate('Load Data'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/submission_runner.py", "source_file_num": 379, "ops": [{"name": "aten::lift_fresh", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474321455000, "dur": 6000, "relative_dur": 0.002570694087403599, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "6 us"}, "res_name": "aten::lift_fresh"}}, "id": "N60DpYDj6vFFZjo9", "pretty_name": "aten::lift_fresh", "trace_file": "/results/GNN/GNN.3.pt.trace.json", "trace_disk_size": "99 Bytes", "runtime": 6000, "runtime_str": "6 us", "start_timestamp": "01:14:34.321.321455", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::to", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474321488000, "dur": 82000, "relative_dur": 0.03513281919451585, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "82 us"}}, "gpu3": {"time": {"ts": 1677892474321675000, "dur": 368000, "relative_dur": 0.15766923736075408, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "368 us"}}}, "ops": [{"name": "aten::empty_strided", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474321500000, "dur": 36000, "relative_dur": 0.09782608695652174, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "36 us"}, "res_name": "aten::empty_strided"}}, "id": "O4Ht4n70hNyqOE1m", "pretty_name": "aten::empty_strided", "trace_file": "/results/GNN/GNN.5.pt.trace.json", "trace_disk_size": "103 Bytes", "runtime": 36000, "runtime_str": "36 us", "start_timestamp": "01:14:34.321.321500", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "cudaMemcpyAsync", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474321562000, "dur": 1000, "relative_dur": 0.002717391304347826, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "cudaMemcpyAsync"}, "gpu3": {"time": {"ts": 1677892474321675000, "dur": 368000, "relative_dur": 1.0, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "368 us"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "eKldCn7GAvSStd83", "pretty_name": "cudaMemcpyAsync", "trace_file": "/results/GNN/GNN.6.pt.trace.json", "trace_disk_size": "226 Bytes", "runtime": 368000, "runtime_str": "368 us", "start_timestamp": "01:14:34.321.321562", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 2}, {"name": "cudaStreamSynchronize", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474321998000, "dur": 1000, "relative_dur": 0.002717391304347826, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "cudaStreamSynchronize"}}, "id": "7R8SEd9JkYJAxcuG", "pretty_name": "cudaStreamSynchronize", "trace_file": "/results/GNN/GNN.7.pt.trace.json", "trace_disk_size": "111 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "01:14:34.321.321998", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "hm2HJbF4uDdV8Qw0", "pretty_name": "aten::to", "trace_file": "/results/GNN/GNN.4.pt.trace.json", "trace_disk_size": "723 Bytes", "runtime": 368000, "runtime_str": "368 us", "start_timestamp": "01:14:34.321.321488", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 7}, {"name": "aten::view", "type": "generated", "generated_depth": 1, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1677892474322078000, "dur": 27000, "relative_dur": 0.011568123393316195, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "27 us"}}}, "ops": [{"name": "aten::lift_fresh", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474322105000, "dur": 0, "relative_dur": 0.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "0 us"}, "res_name": "aten::lift_fresh"}}, "id": "1W344WKMbOD4xQFY", "pretty_name": "aten::lift_fresh", "trace_file": "/results/GNN/GNN.9.pt.trace.json", "trace_disk_size": "99 Bytes", "runtime": 0, "runtime_str": "0 us", "start_timestamp": "01:14:34.322.322105", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "wbgUc63SmQGIQ44d", "pretty_name": "aten::view", "trace_file": "/results/GNN/GNN.8.pt.trace.json", "trace_disk_size": "192 Bytes", "runtime": 27000, "runtime_str": "27 us", "start_timestamp": "01:14:34.322.322078", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::to", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474322107000, "dur": 19000, "relative_dur": 0.008140531276778063, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "19 us"}}, "gpu3": {"time": {"ts": 1677892474322199000, "dur": 279000, "relative_dur": 0.11953727506426735, "relative_gap_to_previous": 0.06683804627249357, "parent_is_longest": true, "runtime_str": "279 us"}}}, "ops": [{"name": "aten::empty_strided", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474322109000, "dur": 7000, "relative_dur": 0.025089605734767026, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "7 us"}, "res_name": "aten::empty_strided"}}, "id": "kEFiUvYHxIH78zBL", "pretty_name": "aten::empty_strided", "trace_file": "/results/GNN/GNN.11.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 7000, "runtime_str": "7 us", "start_timestamp": "01:14:34.322.322109", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "cudaMemcpyAsync", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474322120000, "dur": 1000, "relative_dur": 0.0035842293906810036, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "cudaMemcpyAsync"}, "gpu3": {"time": {"ts": 1677892474322199000, "dur": 279000, "relative_dur": 1.0, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "279 us"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "2ubeZuXd2LtTvhQc", "pretty_name": "cudaMemcpyAsync", "trace_file": "/results/GNN/GNN.12.pt.trace.json", "trace_disk_size": "226 Bytes", "runtime": 279000, "runtime_str": "279 us", "start_timestamp": "01:14:34.322.322120", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 2}, {"name": "cudaStreamSynchronize", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474322428000, "dur": 1000, "relative_dur": 0.0035842293906810036, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "cudaStreamSynchronize"}}, "id": "pepXEhNWPcEopFO4", "pretty_name": "cudaStreamSynchronize", "trace_file": "/results/GNN/GNN.13.pt.trace.json", "trace_disk_size": "111 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "01:14:34.322.322428", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "VffNozCX5N92V5zD", "pretty_name": "aten::to", "trace_file": "/results/GNN/GNN.10.pt.trace.json", "trace_disk_size": "722 Bytes", "runtime": 279000, "runtime_str": "279 us", "start_timestamp": "01:14:34.322.322107", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 7}, {"name": "aten::view", "type": "generated", "generated_depth": 1, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1677892474322490000, "dur": 15000, "relative_dur": 0.006426735218508998, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "15 us"}}}, "ops": [{"name": "aten::lift_fresh", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474322505000, "dur": 0, "relative_dur": 0.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "0 us"}, "res_name": "aten::lift_fresh"}}, "id": "x4ux8aj7cxRDQdRq", "pretty_name": "aten::lift_fresh", "trace_file": "/results/GNN/GNN.15.pt.trace.json", "trace_disk_size": "99 Bytes", "runtime": 0, "runtime_str": "0 us", "start_timestamp": "01:14:34.322.322505", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "c1gyPYXKQpGizwRU", "pretty_name": "aten::view", "trace_file": "/results/GNN/GNN.14.pt.trace.json", "trace_disk_size": "191 Bytes", "runtime": 15000, "runtime_str": "15 us", "start_timestamp": "01:14:34.322.322490", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::to", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474322507000, "dur": 17000, "relative_dur": 0.00728363324764353, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "17 us"}}, "gpu3": {"time": {"ts": 1677892474322597000, "dur": 194000, "relative_dur": 0.0831191088260497, "relative_gap_to_previous": 0.05098543273350471, "parent_is_longest": true, "runtime_str": "194 us"}}}, "ops": [{"name": "aten::empty_strided", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474322509000, "dur": 6000, "relative_dur": 0.030927835051546393, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "6 us"}, "res_name": "aten::empty_strided"}}, "id": "c7CIoGtNgcjwcXFc", "pretty_name": "aten::empty_strided", "trace_file": "/results/GNN/GNN.17.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 6000, "runtime_str": "6 us", "start_timestamp": "01:14:34.322.322509", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "cudaMemcpyAsync", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474322519000, "dur": 1000, "relative_dur": 0.005154639175257732, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "cudaMemcpyAsync"}, "gpu3": {"time": {"ts": 1677892474322597000, "dur": 194000, "relative_dur": 1.0, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "194 us"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "n2bg6M6ILhzw84Be", "pretty_name": "cudaMemcpyAsync", "trace_file": "/results/GNN/GNN.18.pt.trace.json", "trace_disk_size": "226 Bytes", "runtime": 194000, "runtime_str": "194 us", "start_timestamp": "01:14:34.322.322519", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 2}, {"name": "cudaStreamSynchronize", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474322751000, "dur": 1000, "relative_dur": 0.005154639175257732, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "cudaStreamSynchronize"}}, "id": "aXivMkmwHJXyQJcM", "pretty_name": "cudaStreamSynchronize", "trace_file": "/results/GNN/GNN.19.pt.trace.json", "trace_disk_size": "111 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "01:14:34.322.322751", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "kWCDoHRYKy13C3mH", "pretty_name": "aten::to", "trace_file": "/results/GNN/GNN.16.pt.trace.json", "trace_disk_size": "722 Bytes", "runtime": 194000, "runtime_str": "194 us", "start_timestamp": "01:14:34.322.322507", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 7}, {"name": "aten::view(75%) and 1 other\u2026", "type": "generated", "generated_depth": 1, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1677892474322802000, "dur": 17000, "relative_dur": 0.00728363324764353, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "17 us"}}}, "ops": [{"name": "aten::view", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474322802000, "dur": 3000, "relative_dur": 0.17647058823529413, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "aten::view"}}, "id": "qTdTgvykKCbmOkYj", "pretty_name": "aten::view", "trace_file": "/results/GNN/GNN.21.pt.trace.json", "trace_disk_size": "93 Bytes", "runtime": 3000, "runtime_str": "3 us", "start_timestamp": "01:14:34.322.322802", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::lift_fresh", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474322818000, "dur": 1000, "relative_dur": 0.058823529411764705, "relative_gap_to_previous": 0.7647058823529411, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::lift_fresh"}}, "id": "2svsNg3kukS8RjJH", "pretty_name": "aten::lift_fresh", "trace_file": "/results/GNN/GNN.22.pt.trace.json", "trace_disk_size": "99 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "01:14:34.322.322818", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "SVtMKVtdPsGm1A2l", "pretty_name": "aten::view(75%) and 1 other\u2026", "trace_file": "/results/GNN/GNN.20.pt.trace.json", "trace_disk_size": "191 Bytes", "runtime": 17000, "runtime_str": "17 us", "start_timestamp": "01:14:34.322.322802", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::to", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474322820000, "dur": 19000, "relative_dur": 0.008140531276778063, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "19 us"}}, "gpu3": {"time": {"ts": 1677892474322911000, "dur": 166000, "relative_dur": 0.07112253641816624, "relative_gap_to_previous": 0.05141388174807198, "parent_is_longest": true, "runtime_str": "166 us"}}}, "ops": [{"name": "aten::empty_strided", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474322822000, "dur": 7000, "relative_dur": 0.04216867469879518, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "7 us"}, "res_name": "aten::empty_strided"}}, "id": "FTZ2HXx2ZrHZGtda", "pretty_name": "aten::empty_strided", "trace_file": "/results/GNN/GNN.24.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 7000, "runtime_str": "7 us", "start_timestamp": "01:14:34.322.322822", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "cudaMemcpyAsync", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474322833000, "dur": 1000, "relative_dur": 0.006024096385542169, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "cudaMemcpyAsync"}, "gpu3": {"time": {"ts": 1677892474322911000, "dur": 166000, "relative_dur": 1.0, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "166 us"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "fQS88xQmpCSi5vxE", "pretty_name": "cudaMemcpyAsync", "trace_file": "/results/GNN/GNN.25.pt.trace.json", "trace_disk_size": "226 Bytes", "runtime": 166000, "runtime_str": "166 us", "start_timestamp": "01:14:34.322.322833", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 2}, {"name": "cudaStreamSynchronize", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474323035000, "dur": 1000, "relative_dur": 0.006024096385542169, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "cudaStreamSynchronize"}}, "id": "wnx1GTXxncO2XIFe", "pretty_name": "cudaStreamSynchronize", "trace_file": "/results/GNN/GNN.26.pt.trace.json", "trace_disk_size": "111 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "01:14:34.323.323035", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "oMxFb1layKa1rbJW", "pretty_name": "aten::to", "trace_file": "/results/GNN/GNN.23.pt.trace.json", "trace_disk_size": "722 Bytes", "runtime": 166000, "runtime_str": "166 us", "start_timestamp": "01:14:34.322.322820", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 7}, {"name": "aten::to(90%) and 2 others\u2026", "type": "generated", "generated_depth": 1, "instances": 8, "resources": {"cpu2": {"time": {"ts": 1677892474323087000, "dur": 92000, "relative_dur": 0.03941730934018852, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "92 us"}}, "gpu3": {"time": {"ts": 1677892474323137000, "dur": 53000, "relative_dur": 0.022707797772065125, "relative_gap_to_previous": 0.02570694087403599, "parent_is_longest": true, "runtime_str": "53 us"}}}, "ops": [{"name": "aten::view(67%) and 1 other\u2026", "type": "generated", "generated_depth": 2, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1677892474323087000, "dur": 20000, "relative_dur": 0.21739130434782608, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "20 us"}}}, "ops": [{"name": "aten::view", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474323087000, "dur": 2000, "relative_dur": 0.1, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "aten::view"}}, "id": "7CIzCZ1fVzvEudUM", "pretty_name": "aten::view", "trace_file": "/results/GNN/GNN.29.pt.trace.json", "trace_disk_size": "93 Bytes", "runtime": 2000, "runtime_str": "2 us", "start_timestamp": "01:14:34.323.323087", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::lift_fresh", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474323106000, "dur": 1000, "relative_dur": 0.05, "relative_gap_to_previous": 0.85, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::lift_fresh"}}, "id": "lZRDRztgdTNpoOaj", "pretty_name": "aten::lift_fresh", "trace_file": "/results/GNN/GNN.30.pt.trace.json", "trace_disk_size": "99 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "01:14:34.323.323106", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "8skb9ufJmh8RQt4A", "pretty_name": "aten::view(67%) and 1 other\u2026", "trace_file": "/results/GNN/GNN.28.pt.trace.json", "trace_disk_size": "191 Bytes", "runtime": 20000, "runtime_str": "20 us", "start_timestamp": "01:14:34.323.323087", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::to", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474323108000, "dur": 18000, "relative_dur": 0.1956521739130435, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "18 us"}}, "gpu3": {"time": {"ts": 1677892474323137000, "dur": 3000, "relative_dur": 0.03260869565217391, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "3 us"}}}, "ops": [{"name": "aten::empty_strided", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474323110000, "dur": 7000, "relative_dur": 0.3888888888888889, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "7 us"}, "res_name": "aten::empty_strided"}}, "id": "4adXmUqd5OYvTrxC", "pretty_name": "aten::empty_strided", "trace_file": "/results/GNN/GNN.32.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 7000, "runtime_str": "7 us", "start_timestamp": "01:14:34.323.323110", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::copy_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474323118000, "dur": 7000, "relative_dur": 0.3888888888888889, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "7 us"}, "res_name": "aten::copy_"}, "gpu3": {"time": {"ts": 1677892474323137000, "dur": 3000, "relative_dur": 0.16666666666666666, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "pyPP6KN7KjCiaNKf", "pretty_name": "aten::copy_", "trace_file": "/results/GNN/GNN.33.pt.trace.json", "trace_disk_size": "426 Bytes", "runtime": 7000, "runtime_str": "7 us", "start_timestamp": "01:14:34.323.323118", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 4}], "id": "y7SWPtauGK0IZdG3", "pretty_name": "aten::to", "trace_file": "/results/GNN/GNN.31.pt.trace.json", "trace_disk_size": "715 Bytes", "runtime": 18000, "runtime_str": "18 us", "start_timestamp": "01:14:34.323.323108", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 7}, {"name": "aten::view(50%) and 1 other\u2026", "type": "generated", "generated_depth": 2, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1677892474323149000, "dur": 13000, "relative_dur": 0.14130434782608695, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "13 us"}}}, "ops": [{"name": "aten::view", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474323149000, "dur": 1000, "relative_dur": 0.07692307692307693, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::view"}}, "id": "mK8G2PNVoEgtsBYO", "pretty_name": "aten::view", "trace_file": "/results/GNN/GNN.35.pt.trace.json", "trace_disk_size": "93 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "01:14:34.323.323149", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::lift_fresh", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474323161000, "dur": 1000, "relative_dur": 0.07692307692307693, "relative_gap_to_previous": 0.8461538461538461, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::lift_fresh"}}, "id": "8wnU7A36qHOCs0Qp", "pretty_name": "aten::lift_fresh", "trace_file": "/results/GNN/GNN.36.pt.trace.json", "trace_disk_size": "99 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "01:14:34.323.323161", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "oH2TVhyDnSxVbq1g", "pretty_name": "aten::view(50%) and 1 other\u2026", "trace_file": "/results/GNN/GNN.34.pt.trace.json", "trace_disk_size": "191 Bytes", "runtime": 13000, "runtime_str": "13 us", "start_timestamp": "01:14:34.323.323149", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::to", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474323163000, "dur": 17000, "relative_dur": 0.18478260869565216, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "17 us"}}, "gpu3": {"time": {"ts": 1677892474323187000, "dur": 3000, "relative_dur": 0.03260869565217391, "relative_gap_to_previous": 0.5108695652173914, "parent_is_longest": true, "runtime_str": "3 us"}}}, "ops": [{"name": "aten::empty_strided", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474323165000, "dur": 6000, "relative_dur": 0.35294117647058826, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "6 us"}, "res_name": "aten::empty_strided"}}, "id": "vEMNFvcSALZKGg1d", "pretty_name": "aten::empty_strided", "trace_file": "/results/GNN/GNN.38.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 6000, "runtime_str": "6 us", "start_timestamp": "01:14:34.323.323165", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::copy_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474323172000, "dur": 7000, "relative_dur": 0.4117647058823529, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "7 us"}, "res_name": "aten::copy_"}, "gpu3": {"time": {"ts": 1677892474323187000, "dur": 3000, "relative_dur": 0.17647058823529413, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "EkumB6VjtetS4NZA", "pretty_name": "aten::copy_", "trace_file": "/results/GNN/GNN.39.pt.trace.json", "trace_disk_size": "426 Bytes", "runtime": 7000, "runtime_str": "7 us", "start_timestamp": "01:14:34.323.323172", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 4}], "id": "We26QpyJUvOxzcMa", "pretty_name": "aten::to", "trace_file": "/results/GNN/GNN.37.pt.trace.json", "trace_disk_size": "715 Bytes", "runtime": 17000, "runtime_str": "17 us", "start_timestamp": "01:14:34.323.323163", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 7}, {"name": "aten::view(67%) and 1 other\u2026", "type": "generated", "generated_depth": 2, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1677892474323198000, "dur": 15000, "relative_dur": 0.16304347826086957, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "15 us"}}}, "ops": [{"name": "aten::view", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474323198000, "dur": 2000, "relative_dur": 0.13333333333333333, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "aten::view"}}, "id": "pwt7MEyMu6MPKb98", "pretty_name": "aten::view", "trace_file": "/results/GNN/GNN.41.pt.trace.json", "trace_disk_size": "93 Bytes", "runtime": 2000, "runtime_str": "2 us", "start_timestamp": "01:14:34.323.323198", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::lift_fresh", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474323212000, "dur": 1000, "relative_dur": 0.06666666666666667, "relative_gap_to_previous": 0.8, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::lift_fresh"}}, "id": "PJPR24IAcPgS0ce2", "pretty_name": "aten::lift_fresh", "trace_file": "/results/GNN/GNN.42.pt.trace.json", "trace_disk_size": "99 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "01:14:34.323.323212", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "aFbXjhrClQoD90Ak", "pretty_name": "aten::view(67%) and 1 other\u2026", "trace_file": "/results/GNN/GNN.40.pt.trace.json", "trace_disk_size": "191 Bytes", "runtime": 15000, "runtime_str": "15 us", "start_timestamp": "01:14:34.323.323198", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}], "id": "R9FevOC4Nn9tlsFS", "pretty_name": "aten::to(90%) and 2 others\u2026", "trace_file": "/results/GNN/GNN.27.pt.trace.json", "trace_disk_size": "2.0 kB", "runtime": 92000, "runtime_str": "92 us", "start_timestamp": "01:14:34.323.323087", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 20}, {"name": "aten::to", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474323214000, "dur": 17000, "relative_dur": 0.00728363324764353, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "17 us"}}, "gpu3": {"time": {"ts": 1677892474323303000, "dur": 211000, "relative_dur": 0.09040274207369323, "relative_gap_to_previous": 0.048414738646101116, "parent_is_longest": true, "runtime_str": "211 us"}}}, "ops": [{"name": "aten::empty_strided", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474323216000, "dur": 6000, "relative_dur": 0.02843601895734597, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "6 us"}, "res_name": "aten::empty_strided"}}, "id": "PxxA1uyFyPKKhKrp", "pretty_name": "aten::empty_strided", "trace_file": "/results/GNN/GNN.44.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 6000, "runtime_str": "6 us", "start_timestamp": "01:14:34.323.323216", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "cudaMemcpyAsync", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474323226000, "dur": 1000, "relative_dur": 0.004739336492890996, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "cudaMemcpyAsync"}, "gpu3": {"time": {"ts": 1677892474323303000, "dur": 211000, "relative_dur": 1.0, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "211 us"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "VvuSNjj9m00qGPDw", "pretty_name": "cudaMemcpyAsync", "trace_file": "/results/GNN/GNN.45.pt.trace.json", "trace_disk_size": "226 Bytes", "runtime": 211000, "runtime_str": "211 us", "start_timestamp": "01:14:34.323.323226", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 2}, {"name": "cudaStreamSynchronize", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474323461000, "dur": 1000, "relative_dur": 0.004739336492890996, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "cudaStreamSynchronize"}}, "id": "AZeUcJTKsXc0DpPL", "pretty_name": "cudaStreamSynchronize", "trace_file": "/results/GNN/GNN.46.pt.trace.json", "trace_disk_size": "111 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "01:14:34.323.323461", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "CokM3VzNKGUfSbxw", "pretty_name": "aten::to", "trace_file": "/results/GNN/GNN.43.pt.trace.json", "trace_disk_size": "722 Bytes", "runtime": 211000, "runtime_str": "211 us", "start_timestamp": "01:14:34.323.323214", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 7}, {"name": "aten::lift_fresh", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474323526000, "dur": 1000, "relative_dur": 0.0004284490145672665, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::lift_fresh"}}, "id": "b1cEOJAWiOBQhzeO", "pretty_name": "aten::lift_fresh", "trace_file": "/results/GNN/GNN.47.pt.trace.json", "trace_disk_size": "99 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "01:14:34.323.323526", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::to", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474323528000, "dur": 378000, "relative_dur": 0.16195372750642673, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "378 us"}}, "gpu3": {"time": {"ts": 1677892474323978000, "dur": 31000, "relative_dur": 0.013281919451585262, "relative_gap_to_previous": 0.19880034275921166, "parent_is_longest": true, "runtime_str": "31 us"}}}, "ops": [{"name": "aten::empty_strided", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474323530000, "dur": 7000, "relative_dur": 0.018518518518518517, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "7 us"}, "res_name": "aten::empty_strided"}}, "id": "N8VvViIW1q06VrUY", "pretty_name": "aten::empty_strided", "trace_file": "/results/GNN/GNN.49.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 7000, "runtime_str": "7 us", "start_timestamp": "01:14:34.323.323530", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::to", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474323541000, "dur": 332000, "relative_dur": 0.8783068783068783, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "332 us"}, "res_name": "aten::to"}}, "id": "Scy2hkOWkDRVWHkW", "pretty_name": "aten::to", "trace_file": "/results/GNN/GNN.50.pt.trace.json", "trace_disk_size": "387 Bytes", "runtime": 332000, "runtime_str": "332 us", "start_timestamp": "01:14:34.323.323541", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 4}, {"name": "aten::expand_as", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474323876000, "dur": 18000, "relative_dur": 0.047619047619047616, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "18 us"}, "res_name": "aten::expand_as"}}, "id": "Jl0TjCpOYwomZ6jG", "pretty_name": "aten::expand_as", "trace_file": "/results/GNN/GNN.51.pt.trace.json", "trace_disk_size": "291 Bytes", "runtime": 18000, "runtime_str": "18 us", "start_timestamp": "01:14:34.323.323876", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}], "id": "zMiFfg2icdedygVU", "pretty_name": "aten::to", "trace_file": "/results/GNN/GNN.48.pt.trace.json", "trace_disk_size": "1.5 kB", "runtime": 378000, "runtime_str": "378 us", "start_timestamp": "01:14:34.323.323528", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 15}, {"name": "aten::zeros(88%) and 1 other\u2026", "type": "generated", "generated_depth": 1, "instances": 3, "resources": {"cpu2": {"time": {"ts": 1677892474324024000, "dur": 784000, "relative_dur": 0.33590402742073694, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "784 us"}, "res_name": "aten::zeros(88%) and 1 other\u2026"}}, "id": "5n0n2Qc04xImCUO9", "pretty_name": "aten::zeros(88%) and 1 other\u2026", "trace_file": "/results/GNN/GNN.52.pt.trace.json", "trace_disk_size": "466 Bytes", "runtime": 784000, "runtime_str": "784 us", "start_timestamp": "01:14:34.324.324024", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 5}], "idx": 1, "id": "YRzyYUxrBMazGRvN", "pretty_name": "Load Data", "trace_file": "/results/GNN/GNN.2.pt.trace.json", "trace_disk_size": "8.3 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/submission_runner.py", "runtime": 2334000, "runtime_str": "2 ms", "start_timestamp": "01:14:34.321.321455", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 83}, {"name": "Forward", "type": "training loop", "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474324821000, "dur": 15447000, "relative_dur": 0.038274844455016464, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "15 ms"}}, "gpu3": {"time": {"ts": 1677892474325799000, "dur": 145271000, "relative_dur": 0.35995500283710086, "relative_gap_to_previous": 0.004435293039067746, "parent_is_longest": true, "runtime_str": "145 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 78, in forward\n    with hotline.annotate(\"Forward\"):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 78, "ops": [{"idx": 3, "name": "Node Embedder", "type": "Node Embedder", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 79, in forward\n    with hotline.annotate('Node Embedder'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 79, "ops": [{"idx": 4, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 80, in forward\n    with hotline.annotate('Linear'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 80, "resources": {"cpu2": {"time": {"ts": 1677892474324822000, "dur": 1118000, "relative_dur": 0.7236245954692556, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 ms"}}, "gpu3": {"time": {"ts": 1677892474325799000, "dur": 1545000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 ms"}}}, "id": "h8g93IdV9OV6myFD", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.55.pt.trace.json", "trace_disk_size": "6.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 1545000, "runtime_str": "2 ms", "start_timestamp": "01:14:34.324.324822", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 64}], "resources": {"cpu2": {"time": {"ts": 1677892474324822000, "dur": 1118000, "relative_dur": 0.007695961341217449, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 ms"}}, "gpu3": {"time": {"ts": 1677892474325799000, "dur": 1545000, "relative_dur": 0.010635295413399784, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 ms"}}}, "id": "uhi4hTkPAJNhRPLQ", "pretty_name": "Node Embedder", "trace_file": "/results/GNN/GNN.54.pt.trace.json", "trace_disk_size": "6.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 1545000, "runtime_str": "2 ms", "start_timestamp": "01:14:34.324.324822", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 64}, {"idx": 5, "name": "Edge Embedder", "type": "Edge Embedder", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 86, in forward\n    with hotline.annotate('Edge Embedder'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 86, "ops": [{"idx": 6, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 87, in forward\n    with hotline.annotate('Linear'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 87, "resources": {"cpu2": {"time": {"ts": 1677892474326061000, "dur": 194000, "relative_dur": 0.4429223744292237, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "194 us"}}, "gpu3": {"time": {"ts": 1677892474327345000, "dur": 438000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "438 us"}}}, "id": "28k1ydnG8ZExCShI", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.57.pt.trace.json", "trace_disk_size": "1.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 438000, "runtime_str": "438 us", "start_timestamp": "01:14:34.326.326061", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 18}], "resources": {"cpu2": {"time": {"ts": 1677892474326061000, "dur": 194000, "relative_dur": 0.0013354351522327237, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "194 us"}}, "gpu3": {"time": {"ts": 1677892474327345000, "dur": 438000, "relative_dur": 0.003015054622051201, "relative_gap_to_previous": 6.88368635171507e-06, "parent_is_longest": true, "runtime_str": "438 us"}}}, "id": "rGE2NI9GLODxTIC6", "pretty_name": "Edge Embedder", "trace_file": "/results/GNN/GNN.56.pt.trace.json", "trace_disk_size": "1.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 438000, "runtime_str": "438 us", "start_timestamp": "01:14:34.326.326061", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 18}, {"idx": 7, "name": "Graph Network", "type": "Graph Network", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 91, in forward\n    with hotline.annotate('Graph Network'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 91, "ops": [{"idx": 8, "name": "Layer1", "type": "Layer1", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 93, in forward\n    with hotline.annotate(f'Layer{idx+1}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 93, "ops": [{"idx": 9, "name": "Edge", "type": "Edge", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 156, in forward\n    with hotline.annotate('Edge'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 156, "ops": [{"idx": 10, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 157, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS1\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 157, "resources": {"cpu2": {"time": {"ts": 1677892474326364000, "dur": 832000, "relative_dur": 0.06666132521432577, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "832 us"}}, "gpu3": {"time": {"ts": 1677892474327784000, "dur": 12481000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12 ms"}}}, "id": "MXy7qEyaeNrkPaHp", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.61.pt.trace.json", "trace_disk_size": "12.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 12481000, "runtime_str": "12 ms", "start_timestamp": "01:14:34.326.326364", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 82}], "resources": {"cpu2": {"time": {"ts": 1677892474326364000, "dur": 832000, "relative_dur": 0.03262233375156838, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "832 us"}}, "gpu3": {"time": {"ts": 1677892474327784000, "dur": 12481000, "relative_dur": 0.4893742158092848, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12 ms"}}}, "id": "XdrFEPuhKZyZQO8J", "pretty_name": "Edge", "trace_file": "/results/GNN/GNN.60.pt.trace.json", "trace_disk_size": "12.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 12481000, "runtime_str": "12 ms", "start_timestamp": "01:14:34.326.326364", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 82}, {"idx": 11, "name": "Node", "type": "Node", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 182, in forward\n    with hotline.annotate('Node'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 182, "ops": [{"idx": 12, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 183, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS2\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 183, "resources": {"cpu2": {"time": {"ts": 1677892474329418000, "dur": 886000, "relative_dur": 0.08587767761946302, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "886 us"}}, "gpu3": {"time": {"ts": 1677892474340266000, "dur": 10317000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "10 ms"}}}, "id": "TgGsLAiKexz7lAfz", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.63.pt.trace.json", "trace_disk_size": "15.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 10317000, "runtime_str": "10 ms", "start_timestamp": "01:14:34.329.329418", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 114}], "resources": {"cpu2": {"time": {"ts": 1677892474329418000, "dur": 886000, "relative_dur": 0.0347396486825596, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "886 us"}}, "gpu3": {"time": {"ts": 1677892474340266000, "dur": 10317000, "relative_dur": 0.40452478042659973, "relative_gap_to_previous": 3.920953575909661e-05, "parent_is_longest": true, "runtime_str": "10 ms"}}}, "id": "wpayQEOMkApwdiGg", "pretty_name": "Node", "trace_file": "/results/GNN/GNN.62.pt.trace.json", "trace_disk_size": "15.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 10317000, "runtime_str": "10 ms", "start_timestamp": "01:14:34.329.329418", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 114}, {"idx": 13, "name": "Global", "type": "Global", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 201, in forward\n    with hotline.annotate('Global'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 201, "ops": [{"idx": 14, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 202, in forward\n    with hotline.annotate('Linear'): # Should be replaced with THIS3\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 202, "resources": {"cpu2": {"time": {"ts": 1677892474345423000, "dur": 1002000, "relative_dur": 0.37056213017751477, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 ms"}}, "gpu3": {"time": {"ts": 1677892474350584000, "dur": 2704000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 ms"}}}, "id": "rbRZuif9sSPQhhhT", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.65.pt.trace.json", "trace_disk_size": "22.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 2704000, "runtime_str": "3 ms", "start_timestamp": "01:14:34.345.345423", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 163}], "resources": {"cpu2": {"time": {"ts": 1677892474345423000, "dur": 1002000, "relative_dur": 0.039287954830614806, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 ms"}}, "gpu3": {"time": {"ts": 1677892474350584000, "dur": 2704000, "relative_dur": 0.10602258469259725, "relative_gap_to_previous": 3.920953575909661e-05, "parent_is_longest": true, "runtime_str": "3 ms"}}}, "id": "sON5C3fkipoMY7g0", "pretty_name": "Global", "trace_file": "/results/GNN/GNN.64.pt.trace.json", "trace_disk_size": "22.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 2704000, "runtime_str": "3 ms", "start_timestamp": "01:14:34.345.345423", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 163}], "resources": {"cpu2": {"time": {"ts": 1677892474326364000, "dur": 2752000, "relative_dur": 0.01922364955957445, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 ms"}}, "gpu3": {"time": {"ts": 1677892474327784000, "dur": 25504000, "relative_dur": 0.17815405463931208, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "26 ms"}}}, "id": "XRiONU34RVZerk8h", "pretty_name": "Layer1", "trace_file": "/results/GNN/GNN.59.pt.trace.json", "trace_disk_size": "50.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 25504000, "runtime_str": "26 ms", "start_timestamp": "01:14:34.326.326364", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 359}, {"idx": 15, "name": "Layer2", "type": "Layer2", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 93, in forward\n    with hotline.annotate(f'Layer{idx+1}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 93, "ops": [{"idx": 16, "name": "Edge", "type": "Edge", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 156, in forward\n    with hotline.annotate('Edge'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 156, "ops": [{"idx": 17, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 157, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS1\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 157, "resources": {"cpu2": {"time": {"ts": 1677892474352541000, "dur": 851000, "relative_dur": 0.05844378820135979, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "851 us"}}, "gpu3": {"time": {"ts": 1677892474353289000, "dur": 14561000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "15 ms"}}}, "id": "pVS4FIgCmjlaNw0l", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.68.pt.trace.json", "trace_disk_size": "14.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 14561000, "runtime_str": "15 ms", "start_timestamp": "01:14:34.352.352541", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 100}], "resources": {"cpu2": {"time": {"ts": 1677892474352541000, "dur": 851000, "relative_dur": 0.029285247255583468, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "851 us"}}, "gpu3": {"time": {"ts": 1677892474353289000, "dur": 14561000, "relative_dur": 0.5010840015141609, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "15 ms"}}}, "id": "lmbfHjyVRtRCD42Z", "pretty_name": "Edge", "trace_file": "/results/GNN/GNN.67.pt.trace.json", "trace_disk_size": "14.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 14561000, "runtime_str": "15 ms", "start_timestamp": "01:14:34.352.352541", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 100}, {"idx": 18, "name": "Node", "type": "Node", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 182, in forward\n    with hotline.annotate('Node'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 182, "ops": [{"idx": 19, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 183, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS2\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 183, "resources": {"cpu2": {"time": {"ts": 1677892474354898000, "dur": 832000, "relative_dur": 0.07123287671232877, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "832 us"}}, "gpu3": {"time": {"ts": 1677892474367852000, "dur": 11680000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12 ms"}}}, "id": "WdQRHbgiWaM3qe0A", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.70.pt.trace.json", "trace_disk_size": "15.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11680000, "runtime_str": "12 ms", "start_timestamp": "01:14:34.354.354898", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 114}], "resources": {"cpu2": {"time": {"ts": 1677892474354898000, "dur": 832000, "relative_dur": 0.02863140507243883, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "832 us"}}, "gpu3": {"time": {"ts": 1677892474367852000, "dur": 11680000, "relative_dur": 0.4019408789015451, "relative_gap_to_previous": 6.882549296259335e-05, "parent_is_longest": true, "runtime_str": "12 ms"}}}, "id": "TWMEq24yiv1h9qdg", "pretty_name": "Node", "trace_file": "/results/GNN/GNN.69.pt.trace.json", "trace_disk_size": "15.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11680000, "runtime_str": "12 ms", "start_timestamp": "01:14:34.354.354898", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 114}, {"idx": 20, "name": "Global", "type": "Global", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 201, in forward\n    with hotline.annotate('Global'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 201, "ops": [{"idx": 21, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 202, in forward\n    with hotline.annotate('Linear'): # Should be replaced with THIS3\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 202, "resources": {"cpu2": {"time": {"ts": 1677892474373150000, "dur": 983000, "relative_dur": 0.34920071047957374, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "983 us"}}, "gpu3": {"time": {"ts": 1677892474379533000, "dur": 2815000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 ms"}}}, "id": "zbIfFSvVg994fMf4", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.72.pt.trace.json", "trace_disk_size": "22.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 2815000, "runtime_str": "3 ms", "start_timestamp": "01:14:34.373.373150", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 163}], "resources": {"cpu2": {"time": {"ts": 1677892474373150000, "dur": 983000, "relative_dur": 0.033827729791114626, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "983 us"}}, "gpu3": {"time": {"ts": 1677892474379533000, "dur": 2815000, "relative_dur": 0.09687188134485013, "relative_gap_to_previous": 3.441274648129667e-05, "parent_is_longest": true, "runtime_str": "3 ms"}}}, "id": "rT6dz3MewPlJl1Af", "pretty_name": "Global", "trace_file": "/results/GNN/GNN.71.pt.trace.json", "trace_disk_size": "22.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 2815000, "runtime_str": "3 ms", "start_timestamp": "01:14:34.373.373150", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 163}], "resources": {"cpu2": {"time": {"ts": 1677892474352541000, "dur": 2690000, "relative_dur": 0.01879055861746195, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 ms"}}, "gpu3": {"time": {"ts": 1677892474353289000, "dur": 29059000, "relative_dur": 0.2029869304330211, "relative_gap_to_previous": 6.985337776008159e-06, "parent_is_longest": true, "runtime_str": "29 ms"}}}, "id": "QMKKQuonbJf9vEGe", "pretty_name": "Layer2", "trace_file": "/results/GNN/GNN.66.pt.trace.json", "trace_disk_size": "52.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 29059000, "runtime_str": "29 ms", "start_timestamp": "01:14:34.352.352541", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 377}, {"idx": 22, "name": "Layer3", "type": "Layer3", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 93, in forward\n    with hotline.annotate(f'Layer{idx+1}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 93, "ops": [{"idx": 23, "name": "Edge", "type": "Edge", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 156, in forward\n    with hotline.annotate('Edge'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 156, "ops": [{"idx": 24, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 157, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS1\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 157, "resources": {"cpu2": {"time": {"ts": 1677892474381497000, "dur": 839000, "relative_dur": 0.056316284064975165, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "839 us"}}, "gpu3": {"time": {"ts": 1677892474382349000, "dur": 14898000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "15 ms"}}}, "id": "r9SBPQa4owqRiEdD", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.75.pt.trace.json", "trace_disk_size": "14.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 14898000, "runtime_str": "15 ms", "start_timestamp": "01:14:34.381.381497", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 100}], "resources": {"cpu2": {"time": {"ts": 1677892474381497000, "dur": 839000, "relative_dur": 0.028563646886596534, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "839 us"}}, "gpu3": {"time": {"ts": 1677892474382349000, "dur": 14898000, "relative_dur": 0.5072004902461444, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "15 ms"}}}, "id": "Mtq5fRXqd7qqS21M", "pretty_name": "Edge", "trace_file": "/results/GNN/GNN.74.pt.trace.json", "trace_disk_size": "14.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 14898000, "runtime_str": "15 ms", "start_timestamp": "01:14:34.381.381497", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 100}, {"idx": 25, "name": "Node", "type": "Node", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 182, in forward\n    with hotline.annotate('Node'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 182, "ops": [{"idx": 26, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 183, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS2\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 183, "resources": {"cpu2": {"time": {"ts": 1677892474383996000, "dur": 810000, "relative_dur": 0.06951596292481978, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "810 us"}}, "gpu3": {"time": {"ts": 1677892474397248000, "dur": 11652000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12 ms"}}}, "id": "NqjDS89c718nCHyo", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.77.pt.trace.json", "trace_disk_size": "15.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11652000, "runtime_str": "12 ms", "start_timestamp": "01:14:34.383.383996", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 114}], "resources": {"cpu2": {"time": {"ts": 1677892474383996000, "dur": 810000, "relative_dur": 0.027576345623531815, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "810 us"}}, "gpu3": {"time": {"ts": 1677892474397248000, "dur": 11652000, "relative_dur": 0.39669083852517617, "relative_gap_to_previous": 3.4044871140162734e-05, "parent_is_longest": true, "runtime_str": "12 ms"}}}, "id": "gSJa0L0oPA3L49MX", "pretty_name": "Node", "trace_file": "/results/GNN/GNN.76.pt.trace.json", "trace_disk_size": "15.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11652000, "runtime_str": "12 ms", "start_timestamp": "01:14:34.383.383996", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 114}, {"idx": 27, "name": "Global", "type": "Global", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 201, in forward\n    with hotline.annotate('Global'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 201, "ops": [{"idx": 28, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 202, in forward\n    with hotline.annotate('Linear'): # Should be replaced with THIS3\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 202, "resources": {"cpu2": {"time": {"ts": 1677892474402561000, "dur": 945000, "relative_dur": 0.3349875930521092, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "945 us"}}, "gpu3": {"time": {"ts": 1677892474408901000, "dur": 2821000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 ms"}}}, "id": "uosD2AMCqJoOIj5y", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.79.pt.trace.json", "trace_disk_size": "22.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 2821000, "runtime_str": "3 ms", "start_timestamp": "01:14:34.402.402561", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 163}], "resources": {"cpu2": {"time": {"ts": 1677892474402561000, "dur": 945000, "relative_dur": 0.03217240322745379, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "945 us"}}, "gpu3": {"time": {"ts": 1677892474408901000, "dur": 2821000, "relative_dur": 0.09604058148639907, "relative_gap_to_previous": 3.4044871140162734e-05, "parent_is_longest": true, "runtime_str": "3 ms"}}}, "id": "NWSNSc12urAvXK8R", "pretty_name": "Global", "trace_file": "/results/GNN/GNN.78.pt.trace.json", "trace_disk_size": "22.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 2821000, "runtime_str": "3 ms", "start_timestamp": "01:14:34.402.402561", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 163}], "resources": {"cpu2": {"time": {"ts": 1677892474381497000, "dur": 2618000, "relative_dur": 0.01828761429758936, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 ms"}}, "gpu3": {"time": {"ts": 1677892474382349000, "dur": 29373000, "relative_dur": 0.20518032649468765, "relative_gap_to_previous": 6.985337776008159e-06, "parent_is_longest": true, "runtime_str": "29 ms"}}}, "id": "2I0im3Xay8kqzCZ1", "pretty_name": "Layer3", "trace_file": "/results/GNN/GNN.73.pt.trace.json", "trace_disk_size": "52.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 29373000, "runtime_str": "29 ms", "start_timestamp": "01:14:34.381.381497", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 377}, {"idx": 29, "name": "Layer4", "type": "Layer4", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 93, in forward\n    with hotline.annotate(f'Layer{idx+1}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 93, "ops": [{"idx": 30, "name": "Edge", "type": "Edge", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 156, in forward\n    with hotline.annotate('Edge'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 156, "ops": [{"idx": 31, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 157, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS1\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 157, "resources": {"cpu2": {"time": {"ts": 1677892474410869000, "dur": 857000, "relative_dur": 0.05632969633232549, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "857 us"}}, "gpu3": {"time": {"ts": 1677892474411723000, "dur": 15214000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "15 ms"}}}, "id": "COJYOTYYEhpEcYUH", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.82.pt.trace.json", "trace_disk_size": "14.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 15214000, "runtime_str": "15 ms", "start_timestamp": "01:14:34.410.410869", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 100}], "resources": {"cpu2": {"time": {"ts": 1677892474410869000, "dur": 857000, "relative_dur": 0.02881931600363184, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "857 us"}}, "gpu3": {"time": {"ts": 1677892474411723000, "dur": 15214000, "relative_dur": 0.5116185223795272, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "15 ms"}}}, "id": "HsXCFKBZsrdlIWM3", "pretty_name": "Edge", "trace_file": "/results/GNN/GNN.81.pt.trace.json", "trace_disk_size": "14.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 15214000, "runtime_str": "15 ms", "start_timestamp": "01:14:34.410.410869", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 100}, {"idx": 32, "name": "Node", "type": "Node", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 182, in forward\n    with hotline.annotate('Node'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 182, "ops": [{"idx": 33, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 183, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS2\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 183, "resources": {"cpu2": {"time": {"ts": 1677892474413396000, "dur": 800000, "relative_dur": 0.06830601092896176, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "800 us"}}, "gpu3": {"time": {"ts": 1677892474426938000, "dur": 11712000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12 ms"}}}, "id": "dMzr69BFUPEX14sb", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.84.pt.trace.json", "trace_disk_size": "15.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11712000, "runtime_str": "12 ms", "start_timestamp": "01:14:34.413.413396", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 114}], "resources": {"cpu2": {"time": {"ts": 1677892474413396000, "dur": 800000, "relative_dur": 0.02690251202206006, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "800 us"}}, "gpu3": {"time": {"ts": 1677892474426938000, "dur": 11712000, "relative_dur": 0.39385277600295926, "relative_gap_to_previous": 3.3628140027575076e-05, "parent_is_longest": true, "runtime_str": "12 ms"}}}, "id": "yqCanpDMKFgi0YIq", "pretty_name": "Node", "trace_file": "/results/GNN/GNN.83.pt.trace.json", "trace_disk_size": "15.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11712000, "runtime_str": "12 ms", "start_timestamp": "01:14:34.413.413396", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 114}, {"idx": 34, "name": "Global", "type": "Global", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 201, in forward\n    with hotline.annotate('Global'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 201, "ops": [{"idx": 35, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 202, in forward\n    with hotline.annotate('Linear'): # Should be replaced with THIS3\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 202, "resources": {"cpu2": {"time": {"ts": 1677892474432226000, "dur": 972000, "relative_dur": 0.3460306158775365, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "972 us"}}, "gpu3": {"time": {"ts": 1677892474438651000, "dur": 2809000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 ms"}}}, "id": "t9UwX0cgeiQcXL8Z", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.86.pt.trace.json", "trace_disk_size": "22.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 2809000, "runtime_str": "3 ms", "start_timestamp": "01:14:34.432.432226", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 163}], "resources": {"cpu2": {"time": {"ts": 1677892474432226000, "dur": 972000, "relative_dur": 0.03268655210680297, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "972 us"}}, "gpu3": {"time": {"ts": 1677892474438651000, "dur": 2809000, "relative_dur": 0.09446144533745839, "relative_gap_to_previous": 3.3628140027575076e-05, "parent_is_longest": true, "runtime_str": "3 ms"}}}, "id": "GSoNOnzUlGhjZxYW", "pretty_name": "Global", "trace_file": "/results/GNN/GNN.85.pt.trace.json", "trace_disk_size": "22.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 2809000, "runtime_str": "3 ms", "start_timestamp": "01:14:34.432.432226", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 163}], "resources": {"cpu2": {"time": {"ts": 1677892474410869000, "dur": 2656000, "relative_dur": 0.01855305713307767, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 ms"}}, "gpu3": {"time": {"ts": 1677892474411723000, "dur": 29737000, "relative_dur": 0.20772298944515463, "relative_gap_to_previous": 6.985337776008159e-06, "parent_is_longest": true, "runtime_str": "30 ms"}}}, "id": "G9qgluA0iUVPfNK9", "pretty_name": "Layer4", "trace_file": "/results/GNN/GNN.80.pt.trace.json", "trace_disk_size": "52.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 29737000, "runtime_str": "30 ms", "start_timestamp": "01:14:34.410.410869", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 377}, {"idx": 36, "name": "Layer5", "type": "Layer5", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 93, in forward\n    with hotline.annotate(f'Layer{idx+1}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 93, "ops": [{"idx": 37, "name": "Edge", "type": "Edge", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 156, in forward\n    with hotline.annotate('Edge'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 156, "ops": [{"idx": 38, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 157, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS1\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 157, "resources": {"cpu2": {"time": {"ts": 1677892474440621000, "dur": 837000, "relative_dur": 0.05578140619793402, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "837 us"}}, "gpu3": {"time": {"ts": 1677892474441461000, "dur": 15005000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "15 ms"}}}, "id": "iug1VIdewJb6tPHv", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.89.pt.trace.json", "trace_disk_size": "14.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 15005000, "runtime_str": "15 ms", "start_timestamp": "01:14:34.440.440621", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 100}], "resources": {"cpu2": {"time": {"ts": 1677892474440621000, "dur": 837000, "relative_dur": 0.0283921302578019, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "837 us"}}, "gpu3": {"time": {"ts": 1677892474441461000, "dur": 15005000, "relative_dur": 0.5089891451831751, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "15 ms"}}}, "id": "zQdMfEGRqXrdUy1R", "pretty_name": "Edge", "trace_file": "/results/GNN/GNN.88.pt.trace.json", "trace_disk_size": "14.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 15005000, "runtime_str": "15 ms", "start_timestamp": "01:14:34.440.440621", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 100}, {"idx": 39, "name": "Node", "type": "Node", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 182, in forward\n    with hotline.annotate('Node'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 182, "ops": [{"idx": 40, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 183, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS2\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 183, "resources": {"cpu2": {"time": {"ts": 1677892474443112000, "dur": 818000, "relative_dur": 0.07011228250621411, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "818 us"}}, "gpu3": {"time": {"ts": 1677892474456467000, "dur": 11667000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12 ms"}}}, "id": "TotUtAdV5Wry2Zdw", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.91.pt.trace.json", "trace_disk_size": "15.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11667000, "runtime_str": "12 ms", "start_timestamp": "01:14:34.443.443112", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 114}], "resources": {"cpu2": {"time": {"ts": 1677892474443112000, "dur": 818000, "relative_dur": 0.02774762550881954, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "818 us"}}, "gpu3": {"time": {"ts": 1677892474456467000, "dur": 11667000, "relative_dur": 0.39575983717774765, "relative_gap_to_previous": 3.3921302578019e-05, "parent_is_longest": true, "runtime_str": "12 ms"}}}, "id": "JuQNChDEp7czO88k", "pretty_name": "Node", "trace_file": "/results/GNN/GNN.90.pt.trace.json", "trace_disk_size": "15.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11667000, "runtime_str": "12 ms", "start_timestamp": "01:14:34.443.443112", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 114}, {"idx": 41, "name": "Global", "type": "Global", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 201, in forward\n    with hotline.annotate('Global'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 201, "ops": [{"idx": 42, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 202, in forward\n    with hotline.annotate('Linear'): # Should be replaced with THIS3\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 202, "resources": {"cpu2": {"time": {"ts": 1677892474461746000, "dur": 951000, "relative_dur": 0.33891660727013545, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "951 us"}}, "gpu3": {"time": {"ts": 1677892474468135000, "dur": 2806000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 ms"}}}, "id": "OzXQ14a8gcWbiqgn", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.93.pt.trace.json", "trace_disk_size": "22.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 2806000, "runtime_str": "3 ms", "start_timestamp": "01:14:34.461.461746", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 163}], "resources": {"cpu2": {"time": {"ts": 1677892474461746000, "dur": 951000, "relative_dur": 0.03225915875169606, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "951 us"}}, "gpu3": {"time": {"ts": 1677892474468135000, "dur": 2806000, "relative_dur": 0.0951831750339213, "relative_gap_to_previous": 3.3921302578019e-05, "parent_is_longest": true, "runtime_str": "3 ms"}}}, "id": "8tZWHmei6JEj3U7r", "pretty_name": "Global", "trace_file": "/results/GNN/GNN.92.pt.trace.json", "trace_disk_size": "22.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 2806000, "runtime_str": "3 ms", "start_timestamp": "01:14:34.461.461746", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 163}], "resources": {"cpu2": {"time": {"ts": 1677892474440621000, "dur": 2630000, "relative_dur": 0.018371438350901458, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 ms"}}, "gpu3": {"time": {"ts": 1677892474441461000, "dur": 29480000, "relative_dur": 0.20592775763672053, "relative_gap_to_previous": 6.985337776008159e-06, "parent_is_longest": true, "runtime_str": "29 ms"}}}, "id": "dJOpLrWowfrSdEA7", "pretty_name": "Layer5", "trace_file": "/results/GNN/GNN.87.pt.trace.json", "trace_disk_size": "52.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 29480000, "runtime_str": "29 ms", "start_timestamp": "01:14:34.440.440621", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 377}], "resources": {"cpu2": {"time": {"ts": 1677892474326364000, "dur": 13394000, "relative_dur": 0.09220009499487165, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "13 ms"}}, "gpu3": {"time": {"ts": 1677892474327784000, "dur": 143157000, "relative_dur": 0.9854478870524743, "relative_gap_to_previous": 6.88368635171507e-06, "parent_is_longest": true, "runtime_str": "143 ms"}}}, "id": "zGEOcocKKSzG7ig9", "pretty_name": "Graph Network", "trace_file": "/results/GNN/GNN.58.pt.trace.json", "trace_disk_size": "260.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 143157000, "runtime_str": "143 ms", "start_timestamp": "01:14:34.326.326364", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1867}, {"idx": 43, "name": "Decoder", "type": "Decoder", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 97, in forward\n    with hotline.annotate('Decoder'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 97, "ops": [{"idx": 44, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('Linear'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 98, "resources": {"cpu2": {"time": {"ts": 1677892474470099000, "dur": 473000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "473 us"}}, "gpu3": {"time": {"ts": 1677892474470942000, "dur": 128000, "relative_dur": 0.27061310782241016, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "128 us"}}}, "id": "0QjkHnXrtVgzYu9E", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.95.pt.trace.json", "trace_disk_size": "5.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 473000, "runtime_str": "473 us", "start_timestamp": "01:14:34.470.470099", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 40}], "resources": {"cpu2": {"time": {"ts": 1677892474470099000, "dur": 473000, "relative_dur": 0.0032559836443612285, "relative_gap_to_previous": 8.260423622058084e-05, "parent_is_longest": true, "runtime_str": "473 us"}}, "gpu3": {"time": {"ts": 1677892474470942000, "dur": 128000, "relative_dur": 0.000881111853019529, "relative_gap_to_previous": 6.88368635171507e-06, "parent_is_longest": true, "runtime_str": "128 us"}}}, "id": "u7ZLk5BZ0HOXC33q", "pretty_name": "Decoder", "trace_file": "/results/GNN/GNN.94.pt.trace.json", "trace_disk_size": "5.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 473000, "runtime_str": "473 us", "start_timestamp": "01:14:34.470.470099", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 40}], "is_model_pass": "Forward", "idx": 2, "id": "cXlFJjzoV6QD0Ssm", "pretty_name": "Forward", "trace_file": "/results/GNN/GNN.53.pt.trace.json", "trace_disk_size": "274.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 145271000, "runtime_str": "145 ms", "start_timestamp": "01:14:34.324.324821", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1990}, {"name": "Calc Loss", "type": "training loop", "instances": 24, "resources": {"cpu2": {"time": {"ts": 1677892474470672000, "dur": 747000, "relative_dur": 0.001850929553175199, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "747 us"}}, "gpu3": {"time": {"ts": 1677892474471071000, "dur": 235000, "relative_dur": 0.000582287074961408, "relative_gap_to_previous": 2.4778173402613105e-06, "parent_is_longest": true, "runtime_str": "235 us"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 76, in update_params\n    with hotline.annotate('Calc Loss'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py", "source_file_num": 76, "ops": [{"name": "aten::zeros(89%) and 1 other\u2026", "type": "generated", "generated_depth": 1, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1677892474470672000, "dur": 15000, "relative_dur": 0.020080321285140562, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "15 us"}}}, "ops": [{"name": "aten::zeros", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474470672000, "dur": 8000, "relative_dur": 0.5333333333333333, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "8 us"}}}, "ops": [{"name": "aten::empty", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474470673000, "dur": 5000, "relative_dur": 0.625, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5 us"}, "res_name": "aten::empty"}}, "id": "Ptq0cWQXlBEXfLvL", "pretty_name": "aten::empty", "trace_file": "/results/GNN/GNN.99.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 5000, "runtime_str": "5 us", "start_timestamp": "01:14:34.470.470673", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::zero_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474470679000, "dur": 0, "relative_dur": 0.0, "relative_gap_to_previous": 0.125, "parent_is_longest": true, "runtime_str": "0 us"}, "res_name": "aten::zero_"}}, "id": "3OE2NscOn1krfFle", "pretty_name": "aten::zero_", "trace_file": "/results/GNN/GNN.100.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 0, "runtime_str": "0 us", "start_timestamp": "01:14:34.470.470679", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "dUeNph9VE9rnodEW", "pretty_name": "aten::zeros", "trace_file": "/results/GNN/GNN.98.pt.trace.json", "trace_disk_size": "280 Bytes", "runtime": 8000, "runtime_str": "8 us", "start_timestamp": "01:14:34.470.470672", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::empty", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474470686000, "dur": 1000, "relative_dur": 0.06666666666666667, "relative_gap_to_previous": 0.4, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::empty"}}, "id": "Jv8hlCy59KbSXVUR", "pretty_name": "aten::empty", "trace_file": "/results/GNN/GNN.101.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "01:14:34.470.470686", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "w3770NfL9pMqflkq", "pretty_name": "aten::zeros(89%) and 1 other\u2026", "trace_file": "/results/GNN/GNN.97.pt.trace.json", "trace_disk_size": "373 Bytes", "runtime": 15000, "runtime_str": "15 us", "start_timestamp": "01:14:34.470.470672", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 4}, {"name": "aten::where", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474470701000, "dur": 68000, "relative_dur": 0.09103078982597054, "relative_gap_to_previous": 0.018741633199464525, "parent_is_longest": true, "runtime_str": "68 us"}}, "gpu3": {"time": {"ts": 1677892474471071000, "dur": 15000, "relative_dur": 0.020080321285140562, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "15 us"}}}, "ops": [{"name": "aten::scalar_tensor", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474470703000, "dur": 29000, "relative_dur": 0.4264705882352941, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "29 us"}}, "gpu3": {"time": {"ts": 1677892474471071000, "dur": 2000, "relative_dur": 0.029411764705882353, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 us"}}}, "ops": [{"name": "aten::empty", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474470705000, "dur": 7000, "relative_dur": 0.2413793103448276, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "7 us"}, "res_name": "aten::empty"}}, "id": "qx3sJeXN3dqWgwIQ", "pretty_name": "aten::empty", "trace_file": "/results/GNN/GNN.104.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 7000, "runtime_str": "7 us", "start_timestamp": "01:14:34.470.470705", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::fill_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474470713000, "dur": 19000, "relative_dur": 0.6551724137931034, "relative_gap_to_previous": 0.034482758620689655, "parent_is_longest": true, "runtime_str": "19 us"}, "res_name": "aten::fill_"}, "gpu3": {"time": {"ts": 1677892474471071000, "dur": 2000, "relative_dur": 0.06896551724137931, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>"}}, "id": "yeWHYdrtUrAbTRQg", "pretty_name": "aten::fill_", "trace_file": "/results/GNN/GNN.105.pt.trace.json", "trace_disk_size": "459 Bytes", "runtime": 19000, "runtime_str": "19 us", "start_timestamp": "01:14:34.470.470713", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}], "id": "DfVWnoky60xTxZoH", "pretty_name": "aten::scalar_tensor", "trace_file": "/results/GNN/GNN.103.pt.trace.json", "trace_disk_size": "654 Bytes", "runtime": 29000, "runtime_str": "29 us", "start_timestamp": "01:14:34.470.470703", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 5}, {"name": "aten::to", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474470733000, "dur": 0, "relative_dur": 0.0, "relative_gap_to_previous": 0.014705882352941176, "parent_is_longest": true, "runtime_str": "0 us"}, "res_name": "aten::to"}}, "id": "PFf1rsRF0wm9ysjq", "pretty_name": "aten::to", "trace_file": "/results/GNN/GNN.106.pt.trace.json", "trace_disk_size": "91 Bytes", "runtime": 0, "runtime_str": "0 us", "start_timestamp": "01:14:34.470.470733", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "S9O5b2DBKH4LXUZN", "pretty_name": "aten::where", "trace_file": "/results/GNN/GNN.102.pt.trace.json", "trace_disk_size": "2.2 kB", "runtime": 68000, "runtime_str": "68 us", "start_timestamp": "01:14:34.470.470701", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 12}, {"name": "aten::mul(37%) and 2 others\u2026", "type": "generated", "generated_depth": 1, "instances": 3, "resources": {"cpu2": {"time": {"ts": 1677892474470777000, "dur": 81000, "relative_dur": 0.10843373493975904, "relative_gap_to_previous": 0.0107095046854083, "parent_is_longest": true, "runtime_str": "81 us"}}, "gpu3": {"time": {"ts": 1677892474471087000, "dur": 20000, "relative_dur": 0.02677376171352075, "relative_gap_to_previous": 0.0013386880856760374, "parent_is_longest": true, "runtime_str": "20 us"}}}, "ops": [{"name": "aten::mul", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474470777000, "dur": 25000, "relative_dur": 0.30864197530864196, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "25 us"}, "res_name": "aten::mul"}, "gpu3": {"time": {"ts": 1677892474471087000, "dur": 5000, "relative_dur": 0.06172839506172839, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5 us"}, "res_name": "vectorized_elementwise_kernel<4 AUnaryFunctor  binary_ernal::MulFunctor Array<char 2> AUnaryFunctor  binary_ernal::MulFunctor Array<char 2>"}}, "id": "vnjx1qJIkV0tnbv8", "pretty_name": "aten::mul", "trace_file": "/results/GNN/GNN.108.pt.trace.json", "trace_disk_size": "586 Bytes", "runtime": 25000, "runtime_str": "25 us", "start_timestamp": "01:14:34.470.470777", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::add", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474470808000, "dur": 22000, "relative_dur": 0.2716049382716049, "relative_gap_to_previous": 0.07407407407407407, "parent_is_longest": true, "runtime_str": "22 us"}, "res_name": "aten::add"}, "gpu3": {"time": {"ts": 1677892474471094000, "dur": 5000, "relative_dur": 0.06172839506172839, "relative_gap_to_previous": 0.024691358024691357, "parent_is_longest": true, "runtime_str": "5 us"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctorOnSelf_add Array<char 2> CUDAFunctorOnSelf_add Array<char 2>"}}, "id": "oYlhZJQXDK4v63fZ", "pretty_name": "aten::add", "trace_file": "/results/GNN/GNN.109.pt.trace.json", "trace_disk_size": "476 Bytes", "runtime": 22000, "runtime_str": "22 us", "start_timestamp": "01:14:34.470.470808", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::ge", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474470837000, "dur": 21000, "relative_dur": 0.25925925925925924, "relative_gap_to_previous": 0.08641975308641975, "parent_is_longest": true, "runtime_str": "21 us"}, "res_name": "aten::ge"}, "gpu3": {"time": {"ts": 1677892474471099000, "dur": 8000, "relative_dur": 0.09876543209876543, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "8 us"}, "res_name": "vectorized_elementwise_kernel<4 compare_scalar_kernelTensorIteratorBase& OpType ::{lambda#1} Array<char 2> compare_scalar_kernelTensorIteratorBase& OpType ::{lambda#1} Array<char 2>"}}, "id": "gIAYxMCxqWk0NPHp", "pretty_name": "aten::ge", "trace_file": "/results/GNN/GNN.110.pt.trace.json", "trace_disk_size": "663 Bytes", "runtime": 21000, "runtime_str": "21 us", "start_timestamp": "01:14:34.470.470837", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}], "id": "CBsc3JZVxwYL3VmI", "pretty_name": "aten::mul(37%) and 2 others\u2026", "trace_file": "/results/GNN/GNN.107.pt.trace.json", "trace_disk_size": "1.7 kB", "runtime": 81000, "runtime_str": "81 us", "start_timestamp": "01:14:34.470.470777", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 9}, {"name": "aten::where", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474470862000, "dur": 45000, "relative_dur": 0.060240963855421686, "relative_gap_to_previous": 0.00535475234270415, "parent_is_longest": true, "runtime_str": "45 us"}}, "gpu3": {"time": {"ts": 1677892474471109000, "dur": 9000, "relative_dur": 0.012048192771084338, "relative_gap_to_previous": 0.002677376171352075, "parent_is_longest": true, "runtime_str": "9 us"}}}, "ops": [{"name": "aten::scalar_tensor", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474470862000, "dur": 17000, "relative_dur": 0.37777777777777777, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "17 us"}}, "gpu3": {"time": {"ts": 1677892474471109000, "dur": 2000, "relative_dur": 0.044444444444444446, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 us"}}}, "ops": [{"name": "aten::empty", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474470863000, "dur": 5000, "relative_dur": 0.29411764705882354, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5 us"}, "res_name": "aten::empty"}}, "id": "DJYzYtjoTx94gIpr", "pretty_name": "aten::empty", "trace_file": "/results/GNN/GNN.113.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 5000, "runtime_str": "5 us", "start_timestamp": "01:14:34.470.470863", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::fill_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474470868000, "dur": 10000, "relative_dur": 0.5882352941176471, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "10 us"}, "res_name": "aten::fill_"}, "gpu3": {"time": {"ts": 1677892474471109000, "dur": 2000, "relative_dur": 0.11764705882352941, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>"}}, "id": "dZleutMnFYDzqTJH", "pretty_name": "aten::fill_", "trace_file": "/results/GNN/GNN.114.pt.trace.json", "trace_disk_size": "458 Bytes", "runtime": 10000, "runtime_str": "10 us", "start_timestamp": "01:14:34.470.470868", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}], "id": "Pj69JGPuAPP6IlW3", "pretty_name": "aten::scalar_tensor", "trace_file": "/results/GNN/GNN.112.pt.trace.json", "trace_disk_size": "653 Bytes", "runtime": 17000, "runtime_str": "17 us", "start_timestamp": "01:14:34.470.470862", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 5}, {"name": "aten::to", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474470880000, "dur": 0, "relative_dur": 0.0, "relative_gap_to_previous": 0.022222222222222223, "parent_is_longest": true, "runtime_str": "0 us"}, "res_name": "aten::to"}}, "id": "TOOuV8cfY2DC3ogy", "pretty_name": "aten::to", "trace_file": "/results/GNN/GNN.115.pt.trace.json", "trace_disk_size": "91 Bytes", "runtime": 0, "runtime_str": "0 us", "start_timestamp": "01:14:34.470.470880", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "8sknToJzMopmx7nB", "pretty_name": "aten::where", "trace_file": "/results/GNN/GNN.111.pt.trace.json", "trace_disk_size": "2.2 kB", "runtime": 45000, "runtime_str": "45 us", "start_timestamp": "01:14:34.470.470862", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 12}, {"name": "aten::where(14%) and 6 others\u2026", "type": "generated", "generated_depth": 1, "instances": 9, "resources": {"cpu2": {"time": {"ts": 1677892474470911000, "dur": 201000, "relative_dur": 0.26907630522088355, "relative_gap_to_previous": 0.00535475234270415, "parent_is_longest": true, "runtime_str": "201 us"}}, "gpu3": {"time": {"ts": 1677892474471119000, "dur": 84000, "relative_dur": 0.11244979919678715, "relative_gap_to_previous": 0.0013386880856760374, "parent_is_longest": true, "runtime_str": "84 us"}}}, "ops": [{"name": "aten::neg", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474470911000, "dur": 22000, "relative_dur": 0.10945273631840796, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "22 us"}, "res_name": "aten::neg"}, "gpu3": {"time": {"ts": 1677892474471119000, "dur": 9000, "relative_dur": 0.04477611940298507, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9 us"}, "res_name": "vectorized_elementwise_kernel<4 neg_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda#1} Array<char 2> neg_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda#1} Array<char 2>"}}, "id": "xJ46fOojTP97R49t", "pretty_name": "aten::neg", "trace_file": "/results/GNN/GNN.117.pt.trace.json", "trace_disk_size": "676 Bytes", "runtime": 22000, "runtime_str": "22 us", "start_timestamp": "01:14:34.470.470911", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::where", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474470935000, "dur": 23000, "relative_dur": 0.11442786069651742, "relative_gap_to_previous": 0.009950248756218905, "parent_is_longest": true, "runtime_str": "23 us"}}, "gpu3": {"time": {"ts": 1677892474471129000, "dur": 11000, "relative_dur": 0.05472636815920398, "relative_gap_to_previous": 0.004975124378109453, "parent_is_longest": true, "runtime_str": "11 us"}}}, "ops": [{"name": "aten::empty", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474470938000, "dur": 3000, "relative_dur": 0.13043478260869565, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "aten::empty"}}, "id": "5GNN49eEXSCOcPCp", "pretty_name": "aten::empty", "trace_file": "/results/GNN/GNN.119.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 3000, "runtime_str": "3 us", "start_timestamp": "01:14:34.470.470938", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::resize_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474470943000, "dur": 4000, "relative_dur": 0.17391304347826086, "relative_gap_to_previous": 0.08695652173913043, "parent_is_longest": true, "runtime_str": "4 us"}, "res_name": "aten::resize_"}}, "id": "mfmQBPMsnruaqWNt", "pretty_name": "aten::resize_", "trace_file": "/results/GNN/GNN.120.pt.trace.json", "trace_disk_size": "96 Bytes", "runtime": 4000, "runtime_str": "4 us", "start_timestamp": "01:14:34.470.470943", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "cudaLaunchKernel", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474470949000, "dur": 6000, "relative_dur": 0.2608695652173913, "relative_gap_to_previous": 0.08695652173913043, "parent_is_longest": true, "runtime_str": "6 us"}, "res_name": "cudaLaunchKernel"}, "gpu3": {"time": {"ts": 1677892474471129000, "dur": 11000, "relative_dur": 0.4782608695652174, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "11 us"}, "res_name": "vectorized_elementwise_kernel<4 where_kernel_implTensorIterator&::{lambda#1}::operator const::{lambda#14}::operator const::{lambdabool  #1} Array<char 4> where_kernel_implTensorIterator&::{lambda#1}::operator const::{lambda#14}::operator const::{lambdabool  #1} Array<char 4>"}}, "id": "C5oTI4mAia9JAZ1x", "pretty_name": "cudaLaunchKernel", "trace_file": "/results/GNN/GNN.121.pt.trace.json", "trace_disk_size": "653 Bytes", "runtime": 11000, "runtime_str": "11 us", "start_timestamp": "01:14:34.470.470949", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 2}], "id": "ujro8FX5NNjKGkZy", "pretty_name": "aten::where", "trace_file": "/results/GNN/GNN.118.pt.trace.json", "trace_disk_size": "935 Bytes", "runtime": 23000, "runtime_str": "23 us", "start_timestamp": "01:14:34.470.470935", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 5}, {"name": "aten::mul", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474470962000, "dur": 19000, "relative_dur": 0.0945273631840796, "relative_gap_to_previous": 0.01990049751243781, "parent_is_longest": true, "runtime_str": "19 us"}, "res_name": "aten::mul"}, "gpu3": {"time": {"ts": 1677892474471141000, "dur": 13000, "relative_dur": 0.06467661691542288, "relative_gap_to_previous": 0.004975124378109453, "parent_is_longest": true, "runtime_str": "13 us"}, "res_name": "vectorized_elementwise_kernel<4 BinaryFunctor  binary_ernal::MulFunctor Array<char 3> BinaryFunctor  binary_ernal::MulFunctor Array<char 3>"}}, "id": "25gEBYPiVTKOKOIL", "pretty_name": "aten::mul", "trace_file": "/results/GNN/GNN.122.pt.trace.json", "trace_disk_size": "587 Bytes", "runtime": 19000, "runtime_str": "19 us", "start_timestamp": "01:14:34.470.470962", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::sub", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474470985000, "dur": 20000, "relative_dur": 0.09950248756218906, "relative_gap_to_previous": 0.01990049751243781, "parent_is_longest": true, "runtime_str": "20 us"}, "res_name": "aten::sub"}, "gpu3": {"time": {"ts": 1677892474471156000, "dur": 9000, "relative_dur": 0.04477611940298507, "relative_gap_to_previous": 0.009950248756218905, "parent_is_longest": true, "runtime_str": "9 us"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>"}}, "id": "1IaxY9JEUdfJQMLW", "pretty_name": "aten::sub", "trace_file": "/results/GNN/GNN.123.pt.trace.json", "trace_disk_size": "464 Bytes", "runtime": 20000, "runtime_str": "20 us", "start_timestamp": "01:14:34.470.470985", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::neg", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474471010000, "dur": 13000, "relative_dur": 0.06467661691542288, "relative_gap_to_previous": 0.024875621890547265, "parent_is_longest": true, "runtime_str": "13 us"}, "res_name": "aten::neg"}, "gpu3": {"time": {"ts": 1677892474471166000, "dur": 9000, "relative_dur": 0.04477611940298507, "relative_gap_to_previous": 0.004975124378109453, "parent_is_longest": true, "runtime_str": "9 us"}, "res_name": "vectorized_elementwise_kernel<4 neg_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda#1} Array<char 2> neg_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda#1} Array<char 2>"}}, "id": "KSqR2nuqIFc5yez9", "pretty_name": "aten::neg", "trace_file": "/results/GNN/GNN.124.pt.trace.json", "trace_disk_size": "676 Bytes", "runtime": 13000, "runtime_str": "13 us", "start_timestamp": "01:14:34.471.471010", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::exp", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474471027000, "dur": 22000, "relative_dur": 0.10945273631840796, "relative_gap_to_previous": 0.01990049751243781, "parent_is_longest": true, "runtime_str": "22 us"}, "res_name": "aten::exp"}, "gpu3": {"time": {"ts": 1677892474471176000, "dur": 5000, "relative_dur": 0.024875621890547265, "relative_gap_to_previous": 0.004975124378109453, "parent_is_longest": true, "runtime_str": "5 us"}, "res_name": "vectorized_elementwise_kernel<4 exp_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#4}::operator const::{lambda#1} Array<char 2> exp_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#4}::operator const::{lambda#1} Array<char 2>"}}, "id": "EROyqEEyvtfPzmh1", "pretty_name": "aten::exp", "trace_file": "/results/GNN/GNN.125.pt.trace.json", "trace_disk_size": "674 Bytes", "runtime": 22000, "runtime_str": "22 us", "start_timestamp": "01:14:34.471.471027", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::add", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474471055000, "dur": 16000, "relative_dur": 0.07960199004975124, "relative_gap_to_previous": 0.029850746268656716, "parent_is_longest": true, "runtime_str": "16 us"}, "res_name": "aten::add"}, "gpu3": {"time": {"ts": 1677892474471182000, "dur": 5000, "relative_dur": 0.024875621890547265, "relative_gap_to_previous": 0.004975124378109453, "parent_is_longest": true, "runtime_str": "5 us"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctorOnSelf_add Array<char 2> CUDAFunctorOnSelf_add Array<char 2>"}}, "id": "ZAFQiumFvbcy3IFB", "pretty_name": "aten::add", "trace_file": "/results/GNN/GNN.126.pt.trace.json", "trace_disk_size": "476 Bytes", "runtime": 16000, "runtime_str": "16 us", "start_timestamp": "01:14:34.471.471055", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::log", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474471075000, "dur": 21000, "relative_dur": 0.1044776119402985, "relative_gap_to_previous": 0.01990049751243781, "parent_is_longest": true, "runtime_str": "21 us"}, "res_name": "aten::log"}, "gpu3": {"time": {"ts": 1677892474471188000, "dur": 5000, "relative_dur": 0.024875621890547265, "relative_gap_to_previous": 0.004975124378109453, "parent_is_longest": true, "runtime_str": "5 us"}, "res_name": "vectorized_elementwise_kernel<4 log_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#4}::operator const::{lambda#1} Array<char 2> log_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#4}::operator const::{lambda#1} Array<char 2>"}}, "id": "v64AlfFF5p0W73fD", "pretty_name": "aten::log", "trace_file": "/results/GNN/GNN.127.pt.trace.json", "trace_disk_size": "674 Bytes", "runtime": 21000, "runtime_str": "21 us", "start_timestamp": "01:14:34.471.471075", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::add", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474471098000, "dur": 14000, "relative_dur": 0.06965174129353234, "relative_gap_to_previous": 0.009950248756218905, "parent_is_longest": true, "runtime_str": "14 us"}, "res_name": "aten::add"}, "gpu3": {"time": {"ts": 1677892474471194000, "dur": 9000, "relative_dur": 0.04477611940298507, "relative_gap_to_previous": 0.004975124378109453, "parent_is_longest": true, "runtime_str": "9 us"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>"}}, "id": "kLIX7YeckcxhbEWD", "pretty_name": "aten::add", "trace_file": "/results/GNN/GNN.128.pt.trace.json", "trace_disk_size": "464 Bytes", "runtime": 14000, "runtime_str": "14 us", "start_timestamp": "01:14:34.471.471098", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}], "id": "AGC7sMTVOzXy6Jnx", "pretty_name": "aten::where(14%) and 6 others\u2026", "trace_file": "/results/GNN/GNN.116.pt.trace.json", "trace_disk_size": "5.6 kB", "runtime": 201000, "runtime_str": "201 us", "start_timestamp": "01:14:34.470.470911", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 29}, {"name": "aten::where", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474471118000, "dur": 46000, "relative_dur": 0.06157965194109773, "relative_gap_to_previous": 0.008032128514056224, "parent_is_longest": true, "runtime_str": "46 us"}}, "gpu3": {"time": {"ts": 1677892474471205000, "dur": 12000, "relative_dur": 0.01606425702811245, "relative_gap_to_previous": 0.002677376171352075, "parent_is_longest": true, "runtime_str": "12 us"}}}, "ops": [{"name": "aten::scalar_tensor", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474471119000, "dur": 17000, "relative_dur": 0.3695652173913043, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "17 us"}}, "gpu3": {"time": {"ts": 1677892474471205000, "dur": 2000, "relative_dur": 0.043478260869565216, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 us"}}}, "ops": [{"name": "aten::empty", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474471120000, "dur": 5000, "relative_dur": 0.29411764705882354, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5 us"}, "res_name": "aten::empty"}}, "id": "Lk8zPxWEaAmiRerO", "pretty_name": "aten::empty", "trace_file": "/results/GNN/GNN.131.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 5000, "runtime_str": "5 us", "start_timestamp": "01:14:34.471.471120", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::fill_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474471126000, "dur": 10000, "relative_dur": 0.5882352941176471, "relative_gap_to_previous": 0.058823529411764705, "parent_is_longest": true, "runtime_str": "10 us"}, "res_name": "aten::fill_"}, "gpu3": {"time": {"ts": 1677892474471205000, "dur": 2000, "relative_dur": 0.11764705882352941, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>"}}, "id": "mmSb9M1qTpXU5HyQ", "pretty_name": "aten::fill_", "trace_file": "/results/GNN/GNN.132.pt.trace.json", "trace_disk_size": "458 Bytes", "runtime": 10000, "runtime_str": "10 us", "start_timestamp": "01:14:34.471.471126", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}], "id": "jzUR1bQgKChj5uos", "pretty_name": "aten::scalar_tensor", "trace_file": "/results/GNN/GNN.130.pt.trace.json", "trace_disk_size": "653 Bytes", "runtime": 17000, "runtime_str": "17 us", "start_timestamp": "01:14:34.471.471119", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 5}, {"name": "aten::to", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474471137000, "dur": 1000, "relative_dur": 0.021739130434782608, "relative_gap_to_previous": 0.021739130434782608, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::to"}}, "id": "dy5vQY0LKOt7RlUl", "pretty_name": "aten::to", "trace_file": "/results/GNN/GNN.133.pt.trace.json", "trace_disk_size": "91 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "01:14:34.471.471137", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "2p7tqGTIatE66TAG", "pretty_name": "aten::where", "trace_file": "/results/GNN/GNN.129.pt.trace.json", "trace_disk_size": "2.2 kB", "runtime": 46000, "runtime_str": "46 us", "start_timestamp": "01:14:34.471.471118", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 12}, {"name": "aten::sum(76%) and 4 others\u2026", "type": "generated", "generated_depth": 1, "instances": 7, "resources": {"cpu2": {"time": {"ts": 1677892474471173000, "dur": 246000, "relative_dur": 0.3293172690763052, "relative_gap_to_previous": 0.012048192771084338, "parent_is_longest": true, "runtime_str": "246 us"}}, "gpu3": {"time": {"ts": 1677892474471218000, "dur": 88000, "relative_dur": 0.11780455153949129, "relative_gap_to_previous": 0.0013386880856760374, "parent_is_longest": true, "runtime_str": "88 us"}}}, "ops": [{"name": "aten::sum", "type": "generated", "generated_depth": 2, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1677892474471173000, "dur": 104000, "relative_dur": 0.42276422764227645, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "104 us"}, "res_name": "aten::sum"}, "gpu3": {"time": {"ts": 1677892474471218000, "dur": 66000, "relative_dur": 0.2682926829268293, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "66 us"}, "res_name": "unrolled_elementwise_kernel<direct_copy_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#8}::operator const::{lambdalong#1} Array<char 2> TrivialOffsetCalculator<1  char memory::LoadWithCast<1> Array<char 2>::StoreWithCast<1> direct_copy_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#8}::operator const::{lambdalong#1} Array<char 2> TrivialOffsetCalculator<1  char memory::LoadWithCast<1> Array<char 2>::StoreWithCast<1>(39%) and 3 others\u2026"}}, "id": "ONVMGtY9FxWYjHzx", "pretty_name": "aten::sum", "trace_file": "/results/GNN/GNN.135.pt.trace.json", "trace_disk_size": "3.4 kB", "runtime": 104000, "runtime_str": "104 us", "start_timestamp": "01:14:34.471.471173", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 20}, {"name": "aten::div", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474471281000, "dur": 24000, "relative_dur": 0.0975609756097561, "relative_gap_to_previous": 0.016260162601626018, "parent_is_longest": true, "runtime_str": "24 us"}, "res_name": "aten::div"}, "gpu3": {"time": {"ts": 1677892474471303000, "dur": 3000, "relative_dur": 0.012195121951219513, "relative_gap_to_previous": 0.07723577235772358, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "unrolled_elementwise_kernel<BinaryFunctor  binary_ernal::DivFunctor Array<char 3> TrivialOffsetCalculator<2  TrivialOffsetCalculator<1  memory::LoadWithCast<2> memory::StoreWithCast<1> BinaryFunctor  binary_ernal::DivFunctor Array<char 3> TrivialOffsetCalculator<2  TrivialOffsetCalculator<1  memory::LoadWithCast<2> memory::StoreWithCast<1>"}}, "id": "b8svOoBdSTkAHCTD", "pretty_name": "aten::div", "trace_file": "/results/GNN/GNN.136.pt.trace.json", "trace_disk_size": "899 Bytes", "runtime": 24000, "runtime_str": "24 us", "start_timestamp": "01:14:34.471.471281", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::zeros(88%) and 2 others\u2026", "type": "generated", "generated_depth": 2, "instances": 4, "resources": {"cpu2": {"time": {"ts": 1677892474471394000, "dur": 25000, "relative_dur": 0.1016260162601626, "relative_gap_to_previous": 0.3617886178861789, "parent_is_longest": true, "runtime_str": "25 us"}}}, "ops": [{"name": "aten::zeros", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474471394000, "dur": 5000, "relative_dur": 0.2, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5 us"}, "res_name": "aten::zeros"}}, "id": "6OOy6fvvtfFZHMdp", "pretty_name": "aten::zeros", "trace_file": "/results/GNN/GNN.138.pt.trace.json", "trace_disk_size": "280 Bytes", "runtime": 5000, "runtime_str": "5 us", "start_timestamp": "01:14:34.471.471394", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::empty", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474471406000, "dur": 1000, "relative_dur": 0.04, "relative_gap_to_previous": 0.28, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::empty"}}, "id": "VlU8NW3gBWiVJF2h", "pretty_name": "aten::empty", "trace_file": "/results/GNN/GNN.139.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "01:14:34.471.471406", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::zeros", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474471417000, "dur": 2000, "relative_dur": 0.08, "relative_gap_to_previous": 0.4, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "aten::zeros"}}, "id": "G518jVPNvlskdJIs", "pretty_name": "aten::zeros", "trace_file": "/results/GNN/GNN.140.pt.trace.json", "trace_disk_size": "187 Bytes", "runtime": 2000, "runtime_str": "2 us", "start_timestamp": "01:14:34.471.471417", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::zero_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474471419000, "dur": 0, "relative_dur": 0.0, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "0 us"}, "res_name": "aten::zero_"}}, "id": "C2ZwQUJSiiMd72hP", "pretty_name": "aten::zero_", "trace_file": "/results/GNN/GNN.141.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 0, "runtime_str": "0 us", "start_timestamp": "01:14:34.471.471419", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "eUdGbah7ymOLkZa0", "pretty_name": "aten::zeros(88%) and 2 others\u2026", "trace_file": "/results/GNN/GNN.137.pt.trace.json", "trace_disk_size": "652 Bytes", "runtime": 25000, "runtime_str": "25 us", "start_timestamp": "01:14:34.471.471394", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 7}], "id": "NT2bP65XJeqok8lo", "pretty_name": "aten::sum(76%) and 4 others\u2026", "trace_file": "/results/GNN/GNN.134.pt.trace.json", "trace_disk_size": "5.0 kB", "runtime": 246000, "runtime_str": "246 us", "start_timestamp": "01:14:34.471.471173", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 30}], "idx": 45, "id": "l53zjg1WwGteWza6", "pretty_name": "Calc Loss", "trace_file": "/results/GNN/GNN.96.pt.trace.json", "trace_disk_size": "19.3 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py", "runtime": 747000, "runtime_str": "747 us", "start_timestamp": "01:14:34.470.470672", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 108}, {"name": "Zero Grad", "type": "training loop", "instances": 4, "resources": {"cpu2": {"time": {"ts": 1677892474471423000, "dur": 1041000, "relative_dur": 0.002579407851212024, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 ms"}}, "gpu3": {"time": {"ts": 1677892474471452000, "dur": 1013000, "relative_dur": 0.0025100289656847076, "relative_gap_to_previous": 0.00036176133167815136, "parent_is_longest": true, "runtime_str": "1 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 80, in update_params\n    with hotline.annotate('Zero Grad'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py", "source_file_num": 80, "ops": [{"name": "aten::zero_(100%) and 1 other\u2026", "type": "generated", "generated_depth": 2, "instances": 67, "resources": {"cpu2": {"time": {"ts": 1677892474471423000, "dur": 900000, "relative_dur": 0.8645533141210374, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "900 us"}, "res_name": "aten::zero_(100%) and 1 other\u2026"}, "gpu3": {"time": {"ts": 1677892474471452000, "dur": 872000, "relative_dur": 0.8376560999039385, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "872 us"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>"}}, "id": "gDd28MXzMziitnXa", "pretty_name": "aten::zero_(100%) and 1 other\u2026", "trace_file": "/results/GNN/GNN.143.pt.trace.json", "trace_disk_size": "36.4 kB", "runtime": 900000, "runtime_str": "900 us", "start_timestamp": "01:14:34.471.471423", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 265}, {"name": "aten::ones_like(81%) and 2 others\u2026", "type": "generated", "generated_depth": 1, "instances": 3, "resources": {"cpu2": {"time": {"ts": 1677892474472403000, "dur": 61000, "relative_dur": 0.05859750240153699, "relative_gap_to_previous": 0.07684918347742556, "parent_is_longest": true, "runtime_str": "61 us"}}, "gpu3": {"time": {"ts": 1677892474472463000, "dur": 2000, "relative_dur": 0.0019212295869356388, "relative_gap_to_previous": 0.1335254562920269, "parent_is_longest": true, "runtime_str": "2 us"}}}, "ops": [{"name": "aten::zeros", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474472403000, "dur": 5000, "relative_dur": 0.08196721311475409, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5 us"}}}, "ops": [{"name": "aten::empty", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474472404000, "dur": 2000, "relative_dur": 0.4, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "aten::empty"}}, "id": "NciKoD9hHwCjMbS5", "pretty_name": "aten::empty", "trace_file": "/results/GNN/GNN.146.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 2000, "runtime_str": "2 us", "start_timestamp": "01:14:34.472.472404", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::zero_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474472407000, "dur": 1000, "relative_dur": 0.2, "relative_gap_to_previous": 0.2, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::zero_"}}, "id": "DxONHviSVdL0xJKm", "pretty_name": "aten::zero_", "trace_file": "/results/GNN/GNN.147.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "01:14:34.472.472407", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "BFKtdmm85n3DRQ6V", "pretty_name": "aten::zeros", "trace_file": "/results/GNN/GNN.145.pt.trace.json", "trace_disk_size": "280 Bytes", "runtime": 5000, "runtime_str": "5 us", "start_timestamp": "01:14:34.472.472403", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::empty", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474472415000, "dur": 1000, "relative_dur": 0.01639344262295082, "relative_gap_to_previous": 0.11475409836065574, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::empty"}}, "id": "eAe2tCoKj1m7jy0k", "pretty_name": "aten::empty", "trace_file": "/results/GNN/GNN.148.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "01:14:34.472.472415", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::ones_like", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474472438000, "dur": 26000, "relative_dur": 0.4262295081967213, "relative_gap_to_previous": 0.36065573770491804, "parent_is_longest": true, "runtime_str": "26 us"}}, "gpu3": {"time": {"ts": 1677892474472463000, "dur": 2000, "relative_dur": 0.03278688524590164, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "2 us"}}}, "ops": [{"name": "aten::empty_like", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474472439000, "dur": 9000, "relative_dur": 0.34615384615384615, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9 us"}, "res_name": "aten::empty_like"}}, "id": "NqoTE9jpcTGI8i4g", "pretty_name": "aten::empty_like", "trace_file": "/results/GNN/GNN.150.pt.trace.json", "trace_disk_size": "200 Bytes", "runtime": 9000, "runtime_str": "9 us", "start_timestamp": "01:14:34.472.472439", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::fill_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474472449000, "dur": 15000, "relative_dur": 0.5769230769230769, "relative_gap_to_previous": 0.038461538461538464, "parent_is_longest": true, "runtime_str": "15 us"}, "res_name": "aten::fill_"}, "gpu3": {"time": {"ts": 1677892474472463000, "dur": 2000, "relative_dur": 0.07692307692307693, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>"}}, "id": "OWqgwIy8zKMXCyuB", "pretty_name": "aten::fill_", "trace_file": "/results/GNN/GNN.151.pt.trace.json", "trace_disk_size": "458 Bytes", "runtime": 15000, "runtime_str": "15 us", "start_timestamp": "01:14:34.472.472449", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}], "id": "YbR3y2yp8WgNvMLH", "pretty_name": "aten::ones_like", "trace_file": "/results/GNN/GNN.149.pt.trace.json", "trace_disk_size": "755 Bytes", "runtime": 26000, "runtime_str": "26 us", "start_timestamp": "01:14:34.472.472438", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 6}], "id": "LPfEjzvoZU1BORer", "pretty_name": "aten::ones_like(81%) and 2 others\u2026", "trace_file": "/results/GNN/GNN.144.pt.trace.json", "trace_disk_size": "1.1 kB", "runtime": 61000, "runtime_str": "61 us", "start_timestamp": "01:14:34.472.472403", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 10}], "idx": 46, "id": "bj3kngLqAELAtkOx", "pretty_name": "Zero Grad", "trace_file": "/results/GNN/GNN.142.pt.trace.json", "trace_disk_size": "37.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py", "runtime": 1041000, "runtime_str": "1 ms", "start_timestamp": "01:14:34.471.471423", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 276}, {"name": "Backward", "type": "training loop", "instances": 217, "resources": {"cpu2": {"time": {"ts": 1677892474495287000, "dur": 65000, "relative_dur": 0.0555452313166378, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "65 us"}}, "cpu4": {"time": {"ts": 1677892474472717000, "dur": 22417000, "relative_dur": 0.0555452313166378, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "22 ms"}}, "gpu3": {"time": {"ts": 1677892474472895000, "dur": 250417000, "relative_dur": 0.6204875848962166, "relative_gap_to_previous": 0.0010654614563123635, "parent_is_longest": true, "runtime_str": "250 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 83, in update_params\n    with hotline.annotate('Backward'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py", "source_file_num": 83, "is_model_pass": "Backward", "ops": [{"name": "Decoder", "type": "Decoder", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 97, in forward\n    with hotline.annotate('Decoder'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 97, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('Linear'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 98, "resources": {"cpu4": {"time": {"ts": 1677892474472717000, "dur": 1655000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu3": {"time": {"ts": 1677892474472895000, "dur": 1449000, "relative_dur": 0.8755287009063444, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 ms"}}}, "is_backward_op": true, "id": "uDgxgKtBTboht2VQ", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.154.pt.trace.json", "trace_disk_size": "22.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 1655000, "runtime_str": "2 ms", "start_timestamp": "01:14:34.472.472717", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu4", "trace_event_count": 140}], "resources": {"cpu4": {"time": {"ts": 1677892474472717000, "dur": 1655000, "relative_dur": 0.006608976227652276, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu3": {"time": {"ts": 1677892474472895000, "dur": 1449000, "relative_dur": 0.00578634837091731, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 ms"}}}, "is_backward_op": true, "id": "XNnhLjfjzjJIM1Oy", "pretty_name": "Decoder", "trace_file": "/results/GNN/GNN.153.pt.trace.json", "trace_disk_size": "22.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 1655000, "runtime_str": "2 ms", "start_timestamp": "01:14:34.472.472717", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu4", "trace_event_count": 140}, {"name": "Graph Network", "type": "Graph Network", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 91, in forward\n    with hotline.annotate('Graph Network'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 91, "ops": [{"name": "Layer5", "type": "Layer5", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 93, in forward\n    with hotline.annotate(f'Layer{idx+1}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 93, "ops": [{"name": "Global", "type": "Global", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 201, in forward\n    with hotline.annotate('Global'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 201, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 202, in forward\n    with hotline.annotate('Linear'): # Should be replaced with THIS3\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 202, "resources": {"cpu4": {"time": {"ts": 1677892474474395000, "dur": 780000, "relative_dur": 0.935251798561151, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "780 us"}}, "gpu3": {"time": {"ts": 1677892474474439000, "dur": 834000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "834 us"}}}, "is_backward_op": true, "id": "Qqr7Ya5CRXec2zQ2", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.158.pt.trace.json", "trace_disk_size": "11.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 834000, "runtime_str": "834 us", "start_timestamp": "01:14:34.474.474395", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 81}], "resources": {"cpu4": {"time": {"ts": 1677892474474395000, "dur": 780000, "relative_dur": 0.02057070520597078, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "780 us"}}, "gpu3": {"time": {"ts": 1677892474474439000, "dur": 834000, "relative_dur": 0.021994830950999526, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "834 us"}}}, "is_backward_op": true, "id": "lGoydPXmZ1K5MftH", "pretty_name": "Global", "trace_file": "/results/GNN/GNN.157.pt.trace.json", "trace_disk_size": "11.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 834000, "runtime_str": "834 us", "start_timestamp": "01:14:34.474.474395", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 81}, {"name": "Node", "type": "Node", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 182, in forward\n    with hotline.annotate('Node'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 182, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 183, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS2\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 183, "resources": {"cpu4": {"time": {"ts": 1677892474475191000, "dur": 913000, "relative_dur": 0.08253480383294161, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "913 us"}}, "gpu3": {"time": {"ts": 1677892474475274000, "dur": 11062000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "11 ms"}}}, "is_backward_op": true, "id": "PnENtD1yeh32mwzE", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.160.pt.trace.json", "trace_disk_size": "14.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11062000, "runtime_str": "11 ms", "start_timestamp": "01:14:34.475.475191", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 103}], "resources": {"cpu4": {"time": {"ts": 1677892474475191000, "dur": 913000, "relative_dur": 0.024078274170578617, "relative_gap_to_previous": 0.00042196318371222113, "parent_is_longest": true, "runtime_str": "913 us"}}, "gpu3": {"time": {"ts": 1677892474475274000, "dur": 11062000, "relative_dur": 0.29173479613903686, "relative_gap_to_previous": 2.637269898201382e-05, "parent_is_longest": true, "runtime_str": "11 ms"}}}, "is_backward_op": true, "id": "X0aZ0dHhCQ0UY9Ah", "pretty_name": "Node", "trace_file": "/results/GNN/GNN.159.pt.trace.json", "trace_disk_size": "14.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11062000, "runtime_str": "11 ms", "start_timestamp": "01:14:34.475.475191", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 103}, {"name": "Edge", "type": "Edge", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 156, in forward\n    with hotline.annotate('Edge'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 156, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 157, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS1\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 157, "resources": {"cpu4": {"time": {"ts": 1677892474476120000, "dur": 1085000, "relative_dur": 0.04169869331283628, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 ms"}}, "gpu3": {"time": {"ts": 1677892474486337000, "dur": 26020000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "26 ms"}}}, "is_backward_op": true, "id": "aPA9PNXlXelC7Vg2", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.162.pt.trace.json", "trace_disk_size": "18.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 26020000, "runtime_str": "26 ms", "start_timestamp": "01:14:34.476.476120", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 128}], "resources": {"cpu4": {"time": {"ts": 1677892474476120000, "dur": 1085000, "relative_dur": 0.028614378395484995, "relative_gap_to_previous": 0.00042196318371222113, "parent_is_longest": true, "runtime_str": "1 ms"}}, "gpu3": {"time": {"ts": 1677892474486337000, "dur": 26020000, "relative_dur": 0.6862176275119996, "relative_gap_to_previous": 2.637269898201382e-05, "parent_is_longest": true, "runtime_str": "26 ms"}}}, "is_backward_op": true, "id": "X34lyuNelaE8QcaU", "pretty_name": "Edge", "trace_file": "/results/GNN/GNN.161.pt.trace.json", "trace_disk_size": "18.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 26020000, "runtime_str": "26 ms", "start_timestamp": "01:14:34.476.476120", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 128}], "resources": {"cpu4": {"time": {"ts": 1677892474474395000, "dur": 2810000, "relative_dur": 0.01188914745081447, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 ms"}}, "gpu3": {"time": {"ts": 1677892474474439000, "dur": 37918000, "relative_dur": 0.16043156335942457, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "38 ms"}}}, "is_backward_op": true, "id": "x8wDWR5brnGtwVP5", "pretty_name": "Layer5", "trace_file": "/results/GNN/GNN.156.pt.trace.json", "trace_disk_size": "43.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 37918000, "runtime_str": "38 ms", "start_timestamp": "01:14:34.474.474395", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 312}, {"name": "Layer4", "type": "Layer4", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 93, in forward\n    with hotline.annotate(f'Layer{idx+1}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 93, "ops": [{"name": "Global", "type": "Global", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 201, in forward\n    with hotline.annotate('Global'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 201, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 202, in forward\n    with hotline.annotate('Linear'): # Should be replaced with THIS3\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 202, "resources": {"cpu4": {"time": {"ts": 1677892474477221000, "dur": 1953000, "relative_dur": 0.1697817960532035, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu3": {"time": {"ts": 1677892474512359000, "dur": 11503000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12 ms"}}}, "is_backward_op": true, "id": "NxIhiPX38G3cVc0F", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.165.pt.trace.json", "trace_disk_size": "39.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11503000, "runtime_str": "12 ms", "start_timestamp": "01:14:34.477.477221", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 261}], "resources": {"cpu4": {"time": {"ts": 1677892474477221000, "dur": 1953000, "relative_dur": 0.03879156238827315, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu3": {"time": {"ts": 1677892474512359000, "dur": 11503000, "relative_dur": 0.228478925833234, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12 ms"}}}, "is_backward_op": true, "id": "aNL6ekk2n3Ayns3C", "pretty_name": "Global", "trace_file": "/results/GNN/GNN.164.pt.trace.json", "trace_disk_size": "39.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11503000, "runtime_str": "12 ms", "start_timestamp": "01:14:34.477.477221", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 261}, {"name": "Node", "type": "Node", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 182, in forward\n    with hotline.annotate('Node'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 182, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 183, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS2\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 183, "resources": {"cpu4": {"time": {"ts": 1677892474479191000, "dur": 925000, "relative_dur": 0.07573896667485466, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "925 us"}}, "gpu3": {"time": {"ts": 1677892474523864000, "dur": 12213000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12 ms"}}}, "is_backward_op": true, "id": "JJ8bJeMfStKQppsB", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.167.pt.trace.json", "trace_disk_size": "14.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 12213000, "runtime_str": "12 ms", "start_timestamp": "01:14:34.479.479191", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 106}], "resources": {"cpu4": {"time": {"ts": 1677892474479191000, "dur": 925000, "relative_dur": 0.018372859810114012, "relative_gap_to_previous": 0.0003376633694831764, "parent_is_longest": true, "runtime_str": "925 us"}}, "gpu3": {"time": {"ts": 1677892474523864000, "dur": 12213000, "relative_dur": 0.24258133714694316, "relative_gap_to_previous": 3.97251022921384e-05, "parent_is_longest": true, "runtime_str": "12 ms"}}}, "is_backward_op": true, "id": "oUYyFnr3MCyslZJH", "pretty_name": "Node", "trace_file": "/results/GNN/GNN.166.pt.trace.json", "trace_disk_size": "14.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 12213000, "runtime_str": "12 ms", "start_timestamp": "01:14:34.479.479191", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 106}, {"name": "Edge", "type": "Edge", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 156, in forward\n    with hotline.annotate('Edge'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 156, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 157, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS1\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 157, "resources": {"cpu4": {"time": {"ts": 1677892474480132000, "dur": 1126000, "relative_dur": 0.04228790325609344, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 ms"}}, "gpu3": {"time": {"ts": 1677892474536078000, "dur": 26627000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "27 ms"}}}, "is_backward_op": true, "id": "PLaibQDKX74qSL2Q", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.169.pt.trace.json", "trace_disk_size": "18.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 26627000, "runtime_str": "27 ms", "start_timestamp": "01:14:34.480.480132", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 128}], "resources": {"cpu4": {"time": {"ts": 1677892474480132000, "dur": 1126000, "relative_dur": 0.022365232590473922, "relative_gap_to_previous": 0.0003178008183371072, "parent_is_longest": true, "runtime_str": "1 ms"}}, "gpu3": {"time": {"ts": 1677892474536078000, "dur": 26627000, "relative_dur": 0.5288801493663846, "relative_gap_to_previous": 1.98625511460692e-05, "parent_is_longest": true, "runtime_str": "27 ms"}}}, "is_backward_op": true, "id": "xRnA1UscF1FhwNoe", "pretty_name": "Edge", "trace_file": "/results/GNN/GNN.168.pt.trace.json", "trace_disk_size": "18.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 26627000, "runtime_str": "27 ms", "start_timestamp": "01:14:34.480.480132", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 128}], "resources": {"cpu4": {"time": {"ts": 1677892474477221000, "dur": 4037000, "relative_dur": 0.017080600803892534, "relative_gap_to_previous": 6.769621324307172e-05, "parent_is_longest": true, "runtime_str": "4 ms"}}, "gpu3": {"time": {"ts": 1677892474512359000, "dur": 50346000, "relative_dur": 0.21301459699598055, "relative_gap_to_previous": 8.462026655383965e-06, "parent_is_longest": true, "runtime_str": "50 ms"}}}, "is_backward_op": true, "id": "42oC6vBnf4sJqhER", "pretty_name": "Layer4", "trace_file": "/results/GNN/GNN.163.pt.trace.json", "trace_disk_size": "72.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 50346000, "runtime_str": "50 ms", "start_timestamp": "01:14:34.477.477221", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 495}, {"name": "Layer3", "type": "Layer3", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 93, in forward\n    with hotline.annotate(f'Layer{idx+1}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 93, "ops": [{"name": "Global", "type": "Global", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 201, in forward\n    with hotline.annotate('Global'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 201, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 202, in forward\n    with hotline.annotate('Linear'): # Should be replaced with THIS3\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 202, "resources": {"cpu4": {"time": {"ts": 1677892474481274000, "dur": 1907000, "relative_dur": 0.15000393298198694, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu3": {"time": {"ts": 1677892474562707000, "dur": 12713000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "13 ms"}}}, "is_backward_op": true, "id": "ygLjzGX2D5Jm9Smj", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.172.pt.trace.json", "trace_disk_size": "40.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 12713000, "runtime_str": "13 ms", "start_timestamp": "01:14:34.481.481274", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 264}], "resources": {"cpu4": {"time": {"ts": 1677892474481274000, "dur": 1907000, "relative_dur": 0.03777284791823476, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu3": {"time": {"ts": 1677892474562707000, "dur": 12713000, "relative_dur": 0.25181238363110564, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "13 ms"}}}, "is_backward_op": true, "id": "gTpkP9fPlCxkuVZl", "pretty_name": "Global", "trace_file": "/results/GNN/GNN.171.pt.trace.json", "trace_disk_size": "40.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 12713000, "runtime_str": "13 ms", "start_timestamp": "01:14:34.481.481274", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 264}, {"name": "Node", "type": "Node", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 182, in forward\n    with hotline.annotate('Node'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 182, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 183, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS2\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 183, "resources": {"cpu4": {"time": {"ts": 1677892474483196000, "dur": 907000, "relative_dur": 0.07814250021538727, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "907 us"}}, "gpu3": {"time": {"ts": 1677892474575420000, "dur": 11607000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12 ms"}}}, "is_backward_op": true, "id": "Fo513E4lyWOg6FBL", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.174.pt.trace.json", "trace_disk_size": "14.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11607000, "runtime_str": "12 ms", "start_timestamp": "01:14:34.483.483196", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 106}], "resources": {"cpu4": {"time": {"ts": 1677892474483196000, "dur": 907000, "relative_dur": 0.0179653765400309, "relative_gap_to_previous": 0.0002971120706730579, "parent_is_longest": true, "runtime_str": "907 us"}}, "gpu3": {"time": {"ts": 1677892474575420000, "dur": 11607000, "relative_dur": 0.22990532028681218, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "12 ms"}}}, "is_backward_op": true, "id": "2RPt3VxCkYN0p9L5", "pretty_name": "Node", "trace_file": "/results/GNN/GNN.173.pt.trace.json", "trace_disk_size": "14.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 11607000, "runtime_str": "12 ms", "start_timestamp": "01:14:34.483.483196", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 106}, {"name": "Edge", "type": "Edge", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 156, in forward\n    with hotline.annotate('Edge'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 156, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 157, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS1\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 157, "resources": {"cpu4": {"time": {"ts": 1677892474484119000, "dur": 1070000, "relative_dur": 0.04089432447926619, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 ms"}}, "gpu3": {"time": {"ts": 1677892474587028000, "dur": 26165000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "26 ms"}}}, "is_backward_op": true, "id": "IhqxnQJIBqcwsUU9", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.176.pt.trace.json", "trace_disk_size": "18.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 26165000, "runtime_str": "26 ms", "start_timestamp": "01:14:34.484.484119", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 128}], "resources": {"cpu4": {"time": {"ts": 1677892474484119000, "dur": 1070000, "relative_dur": 0.02119399437467813, "relative_gap_to_previous": 0.0003169195420512617, "parent_is_longest": true, "runtime_str": "1 ms"}}, "gpu3": {"time": {"ts": 1677892474587028000, "dur": 26165000, "relative_dur": 0.518262488610704, "relative_gap_to_previous": 1.9807471378203857e-05, "parent_is_longest": true, "runtime_str": "26 ms"}}}, "is_backward_op": true, "id": "38AXQZXklP5A8NIq", "pretty_name": "Edge", "trace_file": "/results/GNN/GNN.175.pt.trace.json", "trace_disk_size": "18.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 26165000, "runtime_str": "26 ms", "start_timestamp": "01:14:34.484.484119", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 128}], "resources": {"cpu4": {"time": {"ts": 1677892474481274000, "dur": 3915000, "relative_dur": 0.016564417177914112, "relative_gap_to_previous": 6.769621324307172e-05, "parent_is_longest": true, "runtime_str": "4 ms"}}, "gpu3": {"time": {"ts": 1677892474562707000, "dur": 50486000, "relative_dur": 0.21360693886185741, "relative_gap_to_previous": 8.462026655383965e-06, "parent_is_longest": true, "runtime_str": "50 ms"}}}, "is_backward_op": true, "id": "dL1vnarD9BL4E1Mo", "pretty_name": "Layer3", "trace_file": "/results/GNN/GNN.170.pt.trace.json", "trace_disk_size": "73.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 50486000, "runtime_str": "50 ms", "start_timestamp": "01:14:34.481.481274", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 498}, {"name": "Layer2", "type": "Layer2", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 93, in forward\n    with hotline.annotate(f'Layer{idx+1}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 93, "ops": [{"name": "Global", "type": "Global", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 201, in forward\n    with hotline.annotate('Global'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 201, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 202, in forward\n    with hotline.annotate('Linear'): # Should be replaced with THIS3\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 202, "resources": {"cpu4": {"time": {"ts": 1677892474485205000, "dur": 1937000, "relative_dur": 0.15315885190163675, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu3": {"time": {"ts": 1677892474613194000, "dur": 12647000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "13 ms"}}}, "is_backward_op": true, "id": "q8ua5uHnmXbVbeu6", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.179.pt.trace.json", "trace_disk_size": "40.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 12647000, "runtime_str": "13 ms", "start_timestamp": "01:14:34.485.485205", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 264}], "resources": {"cpu4": {"time": {"ts": 1677892474485205000, "dur": 1937000, "relative_dur": 0.03764673870792195, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu3": {"time": {"ts": 1677892474613194000, "dur": 12647000, "relative_dur": 0.2458019124621006, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "13 ms"}}}, "is_backward_op": true, "id": "5q14EHJRUVAcDSoR", "pretty_name": "Global", "trace_file": "/results/GNN/GNN.178.pt.trace.json", "trace_disk_size": "40.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 12647000, "runtime_str": "13 ms", "start_timestamp": "01:14:34.485.485205", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 264}, {"name": "Node", "type": "Node", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 182, in forward\n    with hotline.annotate('Node'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 182, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 183, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS2\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 183, "resources": {"cpu4": {"time": {"ts": 1677892474487159000, "dur": 943000, "relative_dur": 0.07725075776193988, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "943 us"}}, "gpu3": {"time": {"ts": 1677892474625842000, "dur": 12207000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12 ms"}}}, "is_backward_op": true, "id": "KIYm02Lg7ij0pnB9", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.181.pt.trace.json", "trace_disk_size": "14.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 12207000, "runtime_str": "12 ms", "start_timestamp": "01:14:34.487.487159", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 106}], "resources": {"cpu4": {"time": {"ts": 1677892474487159000, "dur": 943000, "relative_dur": 0.018327761797403405, "relative_gap_to_previous": 0.0003304050377050455, "parent_is_longest": true, "runtime_str": "943 us"}}, "gpu3": {"time": {"ts": 1677892474625842000, "dur": 12207000, "relative_dur": 0.23725025266267588, "relative_gap_to_previous": 1.943559045323797e-05, "parent_is_longest": true, "runtime_str": "12 ms"}}}, "is_backward_op": true, "id": "h2bGEPX5dijTf8C1", "pretty_name": "Node", "trace_file": "/results/GNN/GNN.180.pt.trace.json", "trace_disk_size": "14.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 12207000, "runtime_str": "12 ms", "start_timestamp": "01:14:34.487.487159", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 106}, {"name": "Edge", "type": "Edge", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 156, in forward\n    with hotline.annotate('Edge'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 156, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 157, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS1\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 157, "resources": {"cpu4": {"time": {"ts": 1677892474488118000, "dur": 1068000, "relative_dur": 0.04015641449842081, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 ms"}}, "gpu3": {"time": {"ts": 1677892474638050000, "dur": 26596000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "27 ms"}}}, "is_backward_op": true, "id": "2WyM8SQ8bvvbsdXq", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.183.pt.trace.json", "trace_disk_size": "18.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 26596000, "runtime_str": "27 ms", "start_timestamp": "01:14:34.488.488118", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 128}], "resources": {"cpu4": {"time": {"ts": 1677892474488118000, "dur": 1068000, "relative_dur": 0.020757210604058152, "relative_gap_to_previous": 0.0003109694472518075, "parent_is_longest": true, "runtime_str": "1 ms"}}, "gpu3": {"time": {"ts": 1677892474638050000, "dur": 26596000, "relative_dur": 0.516908963694317, "relative_gap_to_previous": 1.943559045323797e-05, "parent_is_longest": true, "runtime_str": "27 ms"}}}, "is_backward_op": true, "id": "rCKn9ZbGGfDJryal", "pretty_name": "Edge", "trace_file": "/results/GNN/GNN.182.pt.trace.json", "trace_disk_size": "18.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 26596000, "runtime_str": "27 ms", "start_timestamp": "01:14:34.488.488118", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 128}], "resources": {"cpu4": {"time": {"ts": 1677892474485205000, "dur": 3981000, "relative_dur": 0.01684366405754178, "relative_gap_to_previous": 6.769621324307172e-05, "parent_is_longest": true, "runtime_str": "4 ms"}}, "gpu3": {"time": {"ts": 1677892474613194000, "dur": 51452000, "relative_dur": 0.21769409773640788, "relative_gap_to_previous": 4.231013327691982e-06, "parent_is_longest": true, "runtime_str": "51 ms"}}}, "is_backward_op": true, "id": "lYvobXIMijYyFwOM", "pretty_name": "Layer2", "trace_file": "/results/GNN/GNN.177.pt.trace.json", "trace_disk_size": "73.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 51452000, "runtime_str": "51 ms", "start_timestamp": "01:14:34.485.485205", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 498}, {"name": "Layer1", "type": "Layer1", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 93, in forward\n    with hotline.annotate(f'Layer{idx+1}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 93, "ops": [{"name": "Global", "type": "Global", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 201, in forward\n    with hotline.annotate('Global'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 201, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 202, in forward\n    with hotline.annotate('Linear'): # Should be replaced with THIS3\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 202, "resources": {"cpu4": {"time": {"ts": 1677892474489202000, "dur": 2011000, "relative_dur": 0.15975532252939306, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu3": {"time": {"ts": 1677892474664647000, "dur": 12588000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "13 ms"}}}, "is_backward_op": true, "id": "59dwNw4k43DZZoL1", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.186.pt.trace.json", "trace_disk_size": "40.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 12588000, "runtime_str": "13 ms", "start_timestamp": "01:14:34.489.489202", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 263}], "resources": {"cpu4": {"time": {"ts": 1677892474489202000, "dur": 2011000, "relative_dur": 0.043582852932252614, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu3": {"time": {"ts": 1677892474664647000, "dur": 12588000, "relative_dur": 0.2728100212387846, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "13 ms"}}}, "is_backward_op": true, "id": "Ggi8ZTqcLDmhSnd0", "pretty_name": "Global", "trace_file": "/results/GNN/GNN.185.pt.trace.json", "trace_disk_size": "40.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 12588000, "runtime_str": "13 ms", "start_timestamp": "01:14:34.489.489202", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 263}, {"name": "Node", "type": "Node", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 182, in forward\n    with hotline.annotate('Node'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 182, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 183, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS2\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 183, "resources": {"cpu4": {"time": {"ts": 1677892474491230000, "dur": 892000, "relative_dur": 0.08532619093170078, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "892 us"}}, "gpu3": {"time": {"ts": 1677892474677236000, "dur": 10454000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "10 ms"}}}, "is_backward_op": true, "id": "NdQdQu22Z2p62EQf", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.188.pt.trace.json", "trace_disk_size": "14.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 10454000, "runtime_str": "10 ms", "start_timestamp": "01:14:34.491.491230", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 107}], "resources": {"cpu4": {"time": {"ts": 1677892474491230000, "dur": 892000, "relative_dur": 0.019331628451302502, "relative_gap_to_previous": 0.0003684278964934333, "parent_is_longest": true, "runtime_str": "892 us"}}, "gpu3": {"time": {"ts": 1677892474677236000, "dur": 10454000, "relative_dur": 0.226561484114256, "relative_gap_to_previous": 2.1672229205496076e-05, "parent_is_longest": true, "runtime_str": "10 ms"}}}, "is_backward_op": true, "id": "EDHp1jxW5TbqvbVd", "pretty_name": "Node", "trace_file": "/results/GNN/GNN.187.pt.trace.json", "trace_disk_size": "14.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 10454000, "runtime_str": "10 ms", "start_timestamp": "01:14:34.491.491230", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 107}, {"name": "Edge", "type": "Edge", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 156, in forward\n    with hotline.annotate('Edge'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 156, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 95, in forward\n    graph = layer(graph)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 157, in forward\n    with hotline.annotate('Linear'):  # Should be replaced with THIS1\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 157, "resources": {"cpu4": {"time": {"ts": 1677892474492138000, "dur": 991000, "relative_dur": 0.042906005108888604, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "991 us"}}, "gpu3": {"time": {"ts": 1677892474687692000, "dur": 23097000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "23 ms"}}}, "is_backward_op": true, "id": "60aQhnQZeXNBzuWP", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.190.pt.trace.json", "trace_disk_size": "15.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 23097000, "runtime_str": "23 ms", "start_timestamp": "01:14:34.492.492138", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 113}], "resources": {"cpu4": {"time": {"ts": 1677892474492138000, "dur": 991000, "relative_dur": 0.021477179142646612, "relative_gap_to_previous": 0.0003467556672879372, "parent_is_longest": true, "runtime_str": "991 us"}}, "gpu3": {"time": {"ts": 1677892474687692000, "dur": 23097000, "relative_dur": 0.5005634779593429, "relative_gap_to_previous": 4.334445841099215e-05, "parent_is_longest": true, "runtime_str": "23 ms"}}}, "is_backward_op": true, "id": "JRvpgFflHyz3zebQ", "pretty_name": "Edge", "trace_file": "/results/GNN/GNN.189.pt.trace.json", "trace_disk_size": "15.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 23097000, "runtime_str": "23 ms", "start_timestamp": "01:14:34.492.492138", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 113}], "resources": {"cpu4": {"time": {"ts": 1677892474489202000, "dur": 3927000, "relative_dur": 0.016615189337846413, "relative_gap_to_previous": 6.769621324307172e-05, "parent_is_longest": true, "runtime_str": "4 ms"}}, "gpu3": {"time": {"ts": 1677892474664647000, "dur": 46142000, "relative_dur": 0.19522741696636345, "relative_gap_to_previous": 4.231013327691982e-06, "parent_is_longest": true, "runtime_str": "46 ms"}}}, "is_backward_op": true, "id": "nUfpBfDG4L8Yx2UM", "pretty_name": "Layer1", "trace_file": "/results/GNN/GNN.184.pt.trace.json", "trace_disk_size": "70.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 46142000, "runtime_str": "46 ms", "start_timestamp": "01:14:34.489.489202", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 483}], "resources": {"cpu4": {"time": {"ts": 1677892474474395000, "dur": 18734000, "relative_dur": 0.07481121489355755, "relative_gap_to_previous": 9.184679953837e-05, "parent_is_longest": true, "runtime_str": "19 ms"}}, "gpu3": {"time": {"ts": 1677892474474439000, "dur": 236350000, "relative_dur": 0.9438256987345108, "relative_gap_to_previous": 0.00037936721548457173, "parent_is_longest": true, "runtime_str": "236 ms"}}}, "is_backward_op": true, "id": "tXHWWEbHFzxoArTv", "pretty_name": "Graph Network", "trace_file": "/results/GNN/GNN.155.pt.trace.json", "trace_disk_size": "333.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 236350000, "runtime_str": "236 ms", "start_timestamp": "01:14:34.474.474395", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 2286}, {"name": "Edge Embedder", "type": "Edge Embedder", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 86, in forward\n    with hotline.annotate('Edge Embedder'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 86, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 87, in forward\n    with hotline.annotate('Linear'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 87, "resources": {"cpu4": {"time": {"ts": 1677892474493152000, "dur": 1504000, "relative_dur": 0.12480292091942577, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu3": {"time": {"ts": 1677892474710790000, "dur": 12051000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12 ms"}}}, "is_backward_op": true, "id": "HhafFFejTbjqG6xh", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.192.pt.trace.json", "trace_disk_size": "31.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 12051000, "runtime_str": "12 ms", "start_timestamp": "01:14:34.493.493152", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 207}], "resources": {"cpu4": {"time": {"ts": 1677892474493152000, "dur": 1504000, "relative_dur": 0.006005982021987325, "relative_gap_to_previous": 9.184679953837e-05, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu3": {"time": {"ts": 1677892474710790000, "dur": 12051000, "relative_dur": 0.04812372961899552, "relative_gap_to_previous": 3.993339110363913e-06, "parent_is_longest": true, "runtime_str": "12 ms"}}}, "is_backward_op": true, "id": "iy6JZtj9M7SdeIFu", "pretty_name": "Edge Embedder", "trace_file": "/results/GNN/GNN.191.pt.trace.json", "trace_disk_size": "31.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 12051000, "runtime_str": "12 ms", "start_timestamp": "01:14:34.493.493152", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 207}, {"name": "Node Embedder", "type": "Node Embedder", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 79, in forward\n    with hotline.annotate('Node Embedder'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 79, "ops": [{"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 68, in update_params\n    logits, new_model_state = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/workload.py\", line 166, in model_fn\n    logits = model(augmented_and_preprocessed_input_batch['inputs'])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py\", line 80, in forward\n    with hotline.annotate('Linear'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "source_file_num": 80, "resources": {"cpu4": {"time": {"ts": 1677892474494672000, "dur": 296000, "relative_dur": 0.6434782608695652, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "296 us"}}, "gpu3": {"time": {"ts": 1677892474722843000, "dur": 460000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "460 us"}}}, "is_backward_op": true, "id": "TJDdl0dauDxhFi1E", "pretty_name": "Linear", "trace_file": "/results/GNN/GNN.194.pt.trace.json", "trace_disk_size": "5.3 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 460000, "runtime_str": "460 us", "start_timestamp": "01:14:34.494.494672", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 40}], "resources": {"cpu4": {"time": {"ts": 1677892474494672000, "dur": 296000, "relative_dur": 0.0011820283766677182, "relative_gap_to_previous": 6.38934257658226e-05, "parent_is_longest": true, "runtime_str": "296 us"}}, "gpu3": {"time": {"ts": 1677892474722843000, "dur": 460000, "relative_dur": 0.0018369359907674, "relative_gap_to_previous": 7.986678220727825e-06, "parent_is_longest": true, "runtime_str": "460 us"}}}, "is_backward_op": true, "id": "92praESJs9NlJdXW", "pretty_name": "Node Embedder", "trace_file": "/results/GNN/GNN.193.pt.trace.json", "trace_disk_size": "5.3 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/ogbg/ogbg_pytorch/models.py", "runtime": 460000, "runtime_str": "460 us", "start_timestamp": "01:14:34.494.494672", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 40}], "idx": 47, "id": "NXth0Ew51UILDG01", "pretty_name": "Backward", "trace_file": "/results/GNN/GNN.152.pt.trace.json", "trace_disk_size": "395.3 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py", "runtime": 250417000, "runtime_str": "250 ms", "start_timestamp": "01:14:34.472.472717", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 2695}, {"name": "Optimizer", "type": "training loop", "instances": 1, "resources": {"cpu2": {"time": {"ts": 1677892474495355000, "dur": 9612000, "relative_dur": 0.023816780274591717, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "10 ms"}}, "gpu3": {"time": {"ts": 1677892474723313000, "dur": 1943000, "relative_dur": 0.004814399092127727, "relative_gap_to_previous": 2.4778173402613105e-06, "parent_is_longest": true, "runtime_str": "2 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 684, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 657, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 592, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size,\n  File \"submission_runner.py\", line 390, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py\", line 86, in update_params\n    with hotline.annotate('Optimizer'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py", "source_file_num": 86, "ops": [{"name": "aten::sqrt(13%) and 9 others\u2026", "type": "generated", "generated_depth": 1, "instances": 679, "resources": {"cpu2": {"time": {"ts": 1677892474495356000, "dur": 9596000, "relative_dur": 0.9983354140657511, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "10 ms"}, "res_name": "aten::sqrt(13%) and 9 others\u2026"}, "gpu3": {"time": {"ts": 1677892474723313000, "dur": 1943000, "relative_dur": 0.20214315439034541, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 ms"}, "res_name": "vectorized_elementwise_kernel<4 addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4> addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4>(14%) and 6 others\u2026"}}, "id": "WfR0B5dlVQnaMqI4", "pretty_name": "aten::sqrt(13%) and 9 others\u2026", "trace_file": "/results/GNN/GNN.196.pt.trace.json", "trace_disk_size": "366.9 kB", "runtime": 9596000, "runtime_str": "10 ms", "start_timestamp": "01:14:34.495.495356", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2048}], "idx": 48, "id": "yAkFvxj6xR8587qT", "pretty_name": "Optimizer", "trace_file": "/results/GNN/GNN.195.pt.trace.json", "trace_disk_size": "367.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/reference_algorithms/development_algorithms/ogbg/ogbg_pytorch/submission.py", "runtime": 9612000, "runtime_str": "10 ms", "start_timestamp": "01:14:34.495.495355", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2049}], "resources": {"cpu2": {"time": {"ts": 1677892474321455000, "dur": 51387000, "parent_is_longest": true, "runtime_str": "51 ms"}}, "cpu4": {"time": {"ts": 1677892474472717000, "dur": 22417000, "parent_is_longest": false, "runtime_str": "22 ms"}}, "gpu3": {"time": {"ts": 1677892474321675000, "dur": 403581000, "parent_is_longest": true, "runtime_str": "404 ms"}}}, "source_file_name": "/home/ubuntu/algorithmic-efficiency/submission_runner.py", "source_file_num": 354, "id": "SbLICa2amFH7bjji", "pretty_name": "GNN Training Iteration", "total_accuracy_str": "97.89%", "trace_file": "/results/GNN/GNN.1.pt.trace.json", "trace_disk_size": "3.1 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN/home/ubuntu/algorithmic-efficiency/submission_runner.py", "config": {"trace_filepath": "/home/ubuntu/cpath/results/GNN.worker0.pt.trace.json", "output_dir": "/home/ubuntu/cpath/results", "ui_traces_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/GNN", "ui_model_path": "/home/ubuntu/cpath/results/ui/src/results/GNN.js", "results_summary_csv_filepath": "/home/ubuntu/cpath/results/results_summary.csv", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/GNN", "run_name": "GNN", "model_name": "GNN", "backend": "torch", "test": false, "is_test_accuracy": true, "view_manual_annotations": false, "source_file_name": "/home/ubuntu/algorithmic-efficiency/submission_runner.py", "source_file_num": 354, "num_gpus": 1, "slice_idx": 0, "drop_flow_view": "", "last_found_was_fused": false, "count_sum_greater_than_1": 0, "count_sum_less_than_1": 0, "tiny_op_threshold": 0.05, "max_generated_depth": 2, "remove_slice_args": true, "write_model_ops_to_file": true, "op_idx": 1}, "metadata": {}, "metadata.model": "GNN", "metadata.batch_size": 6144, "metadata.optimizer": "Adam", "metadata.dataset": "OGBG MOLPCBA", "trace_event_count": 7201, "gpu_model": "NVIDIA GeForce RTX 3090", "gpu_cuda_version": "11.7", "hotline_traces_trace_disk_size": "6.0 MB", "hotline_annotation_count": "196", "processed_datetime": "04/03/2023 01:14:45", "runtime_without_profiling": "1 s, 661 ms \u00b11%", "runtime_with_profiling": "1 s, 688 ms \u00b11%", "runtime_profiling_overhead_factor": "0.02\u00d7 slower", "hotline_analysis_time": "2 s, 527 ms", "runtime": 403581000, "runtime_str": "404 ms", "start_timestamp": "01:14:34.321.321455", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3"}]
