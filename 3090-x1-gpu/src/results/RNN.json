export const model =
[{"name": "RNN Training Iteration", "type": "root", "ops": [{"name": "Load Data", "type": "training loop", "instances": 36, "resources": {"cpu2": {"time": {"ts": 1678056027807183000, "dur": 454243000, "relative_dur": 0.2647487893056743, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "454 ms"}}, "cpu6": {"time": {"ts": 1678056027992252000, "dur": 125065000, "relative_dur": 0.07289227865815028, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "125 ms"}}, "gpu3": {"time": {"ts": 1678056028260616000, "dur": 6623000, "relative_dur": 0.0038601172314630737, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "6.62 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 256, in train_once\n    with hotline.annotate('Load Data'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/submission_runner.py", "source_file_num": 256, "ops": [{"name": "aten::randperm(58%) and 6 others\u2026", "type": "generated", "generated_depth": 1, "instances": 16, "resources": {"cpu2": {"time": {"ts": 1678056027807183000, "dur": 120907000, "relative_dur": 0.26617251118894514, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "121 ms"}, "res_name": "aten::randperm(58%) and 6 others\u2026"}}, "id": "HcCXbYgx2pEUsfaT", "pretty_name": "aten::randperm(58%) and 6 others\u2026", "trace_file": "/results/RNN/RNN.3.pt.trace.json", "trace_disk_size": "3.1 kB", "runtime": 120907000, "runtime_str": "121 ms", "start_timestamp": "22:40:27.807.807183", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 32}, {"name": "enumerateDataLoader#_MultiProcessingDataLoaderIter.__next__", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056027928172000, "dur": 216528000, "relative_dur": 0.47667878206158376, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "217 ms"}, "res_name": "enumerateDataLoader#_MultiProcessingDataLoaderIter.__next__"}}, "id": "sJyb4n1jUsTAx5gK", "pretty_name": "enumerateDataLoader#_MultiProcessingDataLoaderIter.__next__", "trace_file": "/results/RNN/RNN.4.pt.trace.json", "trace_disk_size": "252 Bytes", "runtime": 216528000, "runtime_str": "217 ms", "start_timestamp": "22:40:27.928.928172", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::to(99%) and 4 others\u2026", "type": "generated", "generated_depth": 1, "instances": 11, "resources": {"cpu2": {"time": {"ts": 1678056028255233000, "dur": 6193000, "relative_dur": 0.013633671845245826, "relative_gap_to_previous": 0.22960397848728545, "parent_is_longest": true, "runtime_str": "6.19 ms"}}, "gpu3": {"time": {"ts": 1678056028260616000, "dur": 6623000, "relative_dur": 0.014580301732772987, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "6.62 ms"}}}, "ops": [{"name": "aten::zeros(94%) and 1 other\u2026", "type": "generated", "generated_depth": 2, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1678056028255233000, "dur": 54000, "relative_dur": 0.008153404801449495, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "54 us"}}}, "ops": [{"name": "aten::zeros", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056028255233000, "dur": 30000, "relative_dur": 0.5555555555555556, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "30 us"}, "res_name": "aten::zeros"}}, "id": "y7N750bOstbeceq9", "pretty_name": "aten::zeros", "trace_file": "/results/RNN/RNN.7.pt.trace.json", "trace_disk_size": "282 Bytes", "runtime": 30000, "runtime_str": "30 us", "start_timestamp": "22:40:28.255.255233", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::empty", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056028255285000, "dur": 2000, "relative_dur": 0.037037037037037035, "relative_gap_to_previous": 0.4074074074074074, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "aten::empty"}}, "id": "XjsVOGanApzhaRms", "pretty_name": "aten::empty", "trace_file": "/results/RNN/RNN.8.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 2000, "runtime_str": "2 us", "start_timestamp": "22:40:28.255.255285", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "SiEV9CdO0fJG3VmM", "pretty_name": "aten::zeros(94%) and 1 other\u2026", "trace_file": "/results/RNN/RNN.6.pt.trace.json", "trace_disk_size": "375 Bytes", "runtime": 54000, "runtime_str": "54 us", "start_timestamp": "22:40:28.255.255233", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 4}, {"name": "aten::to", "type": "generated", "generated_depth": 2, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1678056028255316000, "dur": 5153000, "relative_dur": 0.7780462026272082, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5.15 ms"}, "res_name": "aten::to"}, "gpu3": {"time": {"ts": 1678056028260616000, "dur": 5929000, "relative_dur": 0.8952136494035935, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "5.93 ms"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "p3T7vf8f8tW1td0q", "pretty_name": "aten::to", "trace_file": "/results/RNN/RNN.9.pt.trace.json", "trace_disk_size": "1.1 kB", "runtime": 5929000, "runtime_str": "5.93 ms", "start_timestamp": "22:40:28.255.255316", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 11}, {"name": "aten::to(80%) and 3 others\u2026", "type": "generated", "generated_depth": 2, "instances": 7, "resources": {"cpu2": {"time": {"ts": 1678056028266938000, "dur": 590000, "relative_dur": 0.08908349690472596, "relative_gap_to_previous": 0.0350294428506719, "parent_is_longest": true, "runtime_str": "590 us"}}, "gpu3": {"time": {"ts": 1678056028267099000, "dur": 140000, "relative_dur": 0.02113845689264684, "relative_gap_to_previous": 0.08364789370375962, "parent_is_longest": true, "runtime_str": "140 us"}}}, "ops": [{"name": "aten::to(87%) and 2 others\u2026", "type": "generated", "generated_depth": 3, "instances": 6, "resources": {"cpu2": {"time": {"ts": 1678056028266938000, "dur": 171000, "relative_dur": 0.28983050847457625, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "171 us"}, "res_name": "aten::to(87%) and 2 others\u2026"}, "gpu3": {"time": {"ts": 1678056028267099000, "dur": 140000, "relative_dur": 0.23728813559322035, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "140 us"}, "res_name": "Memcpy HtoD Pinned -> Device"}}, "id": "lilB8bPAcOKpr4qZ", "pretty_name": "aten::to(87%) and 2 others\u2026", "trace_file": "/results/RNN/RNN.11.pt.trace.json", "trace_disk_size": "2.0 kB", "runtime": 171000, "runtime_str": "171 us", "start_timestamp": "22:40:28.266.266938", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 20}, {"name": "aten::zeros", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056028267642000, "dur": 21000, "relative_dur": 0.03559322033898305, "relative_gap_to_previous": 0.6745762711864407, "parent_is_longest": true, "runtime_str": "21 us"}, "res_name": "aten::zeros"}}, "id": "3y0VEhnvZ1F4KPvY", "pretty_name": "aten::zeros", "trace_file": "/results/RNN/RNN.12.pt.trace.json", "trace_disk_size": "281 Bytes", "runtime": 21000, "runtime_str": "21 us", "start_timestamp": "22:40:28.267.267642", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}], "id": "X4C16UG97qgFQhBF", "pretty_name": "aten::to(80%) and 3 others\u2026", "trace_file": "/results/RNN/RNN.10.pt.trace.json", "trace_disk_size": "2.3 kB", "runtime": 590000, "runtime_str": "590 us", "start_timestamp": "22:40:28.266.266938", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 23}], "id": "tDWtzc9vwFymzf6w", "pretty_name": "aten::to(99%) and 4 others\u2026", "trace_file": "/results/RNN/RNN.5.pt.trace.json", "trace_disk_size": "3.8 kB", "runtime": 6623000, "runtime_str": "6.62 ms", "start_timestamp": "22:40:28.255.255233", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 38}], "idx": 1, "id": "1Fggoz8CmElYq1Ru", "pretty_name": "Load Data", "trace_file": "/results/RNN/RNN.2.pt.trace.json", "trace_disk_size": "8.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/submission_runner.py", "runtime": 454243000, "runtime_str": "454 ms", "start_timestamp": "22:40:27.807.807183", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 80}, {"name": "Forward", "type": "training loop", "instances": 136, "resources": {"cpu2": {"time": {"ts": 1678056028267693000, "dur": 270641000, "relative_dur": 0.1577390891801899, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "271 ms"}}, "gpu10": {"time": {"ts": 1678056028452881000, "dur": 207446000, "relative_dur": 0.12090682156093746, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "207 ms"}}, "gpu3": {"time": {"ts": 1678056028268720000, "dur": 394239000, "relative_dur": 0.22977634866597776, "relative_gap_to_previous": 0.0008631788645322078, "parent_is_longest": true, "runtime_str": "394 ms"}}, "gpu7": {"time": {"ts": 1678056028358257000, "dur": 267965000, "relative_dur": 0.1561794223054511, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "268 ms"}}, "gpu8": {"time": {"ts": 1678056028358258000, "dur": 273341000, "relative_dur": 0.15931274409864835, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "273 ms"}}, "gpu9": {"time": {"ts": 1678056028452841000, "dur": 207369000, "relative_dur": 0.12086194325400364, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "207 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 74, in update_params\n    with hotline.annotate('Forward'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "source_file_num": 74, "ops": [{"idx": 3, "name": "MaskConv", "type": "MaskConv", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 179, in forward\n    with hotline.annotate('MaskConv'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 179, "ops": [{"idx": 4, "name": "Conv2d", "type": "Conv2d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu2": {"time": {"ts": 1678056028267696000, "dur": 2191000, "relative_dur": 0.015537133820745017, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.19 ms"}}, "gpu3": {"time": {"ts": 1678056028268720000, "dur": 12099000, "relative_dur": 0.08579816617854585, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12.1 ms"}}}, "id": "3njffaiHAbLlEbrX", "pretty_name": "Conv2d", "trace_file": "/results/RNN/RNN.15.pt.trace.json", "trace_disk_size": "12.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 12099000, "runtime_str": "12.1 ms", "start_timestamp": "22:40:28.267.267696", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 86}, {"idx": 5, "name": "BatchNorm2d", "type": "BatchNorm2d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu2": {"time": {"ts": 1678056028269913000, "dur": 15765000, "relative_dur": 0.11179503180467604, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "15.8 ms"}}, "gpu3": {"time": {"ts": 1678056028280820000, "dur": 26370000, "relative_dur": 0.18699873064949615, "relative_gap_to_previous": 7.091343596871299e-06, "parent_is_longest": true, "runtime_str": "26.4 ms"}}}, "id": "e93GojMT2XEqUWnd", "pretty_name": "BatchNorm2d", "trace_file": "/results/RNN/RNN.16.pt.trace.json", "trace_disk_size": "144.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 26370000, "runtime_str": "26.4 ms", "start_timestamp": "22:40:28.269.269913", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1248}, {"idx": 6, "name": "Hardtanh", "type": "Hardtanh", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu2": {"time": {"ts": 1678056028302076000, "dur": 12734000, "relative_dur": 0.09030116936255912, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12.7 ms"}}, "gpu3": {"time": {"ts": 1678056028310552000, "dur": 23935000, "relative_dur": 0.16973130899111455, "relative_gap_to_previous": 0.02384109717268131, "parent_is_longest": true, "runtime_str": "23.9 ms"}}}, "id": "LUDP4WmBL7m52wiQ", "pretty_name": "Hardtanh", "trace_file": "/results/RNN/RNN.17.pt.trace.json", "trace_disk_size": "143.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 23935000, "runtime_str": "23.9 ms", "start_timestamp": "22:40:28.302.302076", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1241}, {"idx": 7, "name": "Conv2d", "type": "Conv2d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu2": {"time": {"ts": 1678056028329514000, "dur": 19483000, "relative_dur": 0.13816064729784353, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "19.5 ms"}}, "gpu3": {"time": {"ts": 1678056028337950000, "dur": 39532000, "relative_dur": 0.2803349950715162, "relative_gap_to_previous": 0.02455732287596531, "parent_is_longest": true, "runtime_str": "39.5 ms"}}, "gpu7": {"time": {"ts": 1678056028358257000, "dur": 18549000, "relative_dur": 0.13153733237836573, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "18.6 ms"}}, "gpu8": {"time": {"ts": 1678056028358258000, "dur": 18561000, "relative_dur": 0.1316224285015282, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "18.6 ms"}}}, "id": "ELOEMvsHilAUsv6F", "pretty_name": "Conv2d", "trace_file": "/results/RNN/RNN.18.pt.trace.json", "trace_disk_size": "577.3 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 39532000, "runtime_str": "39.5 ms", "start_timestamp": "22:40:28.329.329514", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 4187}, {"idx": 8, "name": "BatchNorm2d", "type": "BatchNorm2d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu2": {"time": {"ts": 1678056028362753000, "dur": 9084000, "relative_dur": 0.06441776523397888, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9.08 ms"}}, "gpu3": {"time": {"ts": 1678056028377491000, "dur": 15470000, "relative_dur": 0.109703085443599, "relative_gap_to_previous": 6.382209237184169e-05, "parent_is_longest": true, "runtime_str": "15.5 ms"}}}, "id": "Zkup6DpSabXuXqQ0", "pretty_name": "BatchNorm2d", "trace_file": "/results/RNN/RNN.19.pt.trace.json", "trace_disk_size": "144.3 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 15470000, "runtime_str": "15.5 ms", "start_timestamp": "22:40:28.362.362753", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1248}, {"idx": 9, "name": "Hardtanh", "type": "Hardtanh", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu2": {"time": {"ts": 1678056028390574000, "dur": 8562000, "relative_dur": 0.060716083876412065, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "8.56 ms"}}, "gpu3": {"time": {"ts": 1678056028395097000, "dur": 14640000, "relative_dur": 0.10381727025819582, "relative_gap_to_previous": 0.015147109922917096, "parent_is_longest": true, "runtime_str": "14.6 ms"}}}, "id": "k6G8zTOBDjd3uKhS", "pretty_name": "Hardtanh", "trace_file": "/results/RNN/RNN.20.pt.trace.json", "trace_disk_size": "143.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 14640000, "runtime_str": "14.6 ms", "start_timestamp": "22:40:28.390.390574", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1241}], "resources": {"cpu2": {"time": {"ts": 1678056028267696000, "dur": 67918000, "relative_dur": 0.1722762080869726, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "67.9 ms"}}, "gpu3": {"time": {"ts": 1678056028268720000, "dur": 141017000, "relative_dur": 0.35769419057982593, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "141 ms"}}, "gpu7": {"time": {"ts": 1678056028358257000, "dur": 18549000, "relative_dur": 0.04705013963610906, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "18.6 ms"}}, "gpu8": {"time": {"ts": 1678056028358258000, "dur": 18561000, "relative_dur": 0.047080578025005135, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "18.6 ms"}}}, "id": "jNyX5dn10VAPSncy", "pretty_name": "MaskConv", "trace_file": "/results/RNN/RNN.14.pt.trace.json", "trace_disk_size": "1.2 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 141017000, "runtime_str": "141 ms", "start_timestamp": "22:40:28.267.267696", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 9251}, {"idx": 10, "name": "BatchRNN-0", "type": "BatchRNN-0", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 190, in forward\n    with hotline.annotate(f'BatchRNN-{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 190, "ops": [{"idx": 11, "name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 101, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 101, "resources": {"cpu2": {"time": {"ts": 1678056028407439000, "dur": 44748000, "relative_dur": 0.6227194923391642, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "44.8 ms"}}, "gpu10": {"time": {"ts": 1678056028452881000, "dur": 29382000, "relative_dur": 0.40888406462656035, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "29.4 ms"}}, "gpu3": {"time": {"ts": 1678056028412169000, "dur": 23669000, "relative_dur": 0.3293811491949512, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "23.7 ms"}}, "gpu7": {"time": {"ts": 1678056028436329000, "dur": 8392000, "relative_dur": 0.11678425806092486, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "8.39 ms"}}, "gpu8": {"time": {"ts": 1678056028444541000, "dur": 8478000, "relative_dur": 0.11798104621550537, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "8.48 ms"}}, "gpu9": {"time": {"ts": 1678056028452841000, "dur": 29232000, "relative_dur": 0.4067966434267106, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "29.2 ms"}}}, "id": "ZvgNzXfzGl5KHthB", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.22.pt.trace.json", "trace_disk_size": "2.3 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 44748000, "runtime_str": "44.8 ms", "start_timestamp": "22:40:28.407.407439", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 13929}, {"idx": 12, "name": "Sum", "type": "Sum", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 108, in forward\n    with hotline.annotate('Sum'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1678056028469929000, "dur": 1998000, "relative_dur": 0.02780445038199808, "relative_gap_to_previous": 0.004230506965028737, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu3": {"time": {"ts": 1678056028482265000, "dur": 1763000, "relative_dur": 0.024534157168900207, "relative_gap_to_previous": 0.6460846936361486, "parent_is_longest": true, "runtime_str": "1.76 ms"}}}, "id": "wPvJklF0nssnVfGE", "pretty_name": "Sum", "trace_file": "/results/RNN/RNN.23.pt.trace.json", "trace_disk_size": "100.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 1998000, "runtime_str": "2 ms", "start_timestamp": "22:40:28.469.469929", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 620}], "resources": {"cpu2": {"time": {"ts": 1678056028407439000, "dur": 47118000, "relative_dur": 0.11951633400044136, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "47.1 ms"}}, "gpu10": {"time": {"ts": 1678056028452881000, "dur": 29382000, "relative_dur": 0.07452839521204142, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "29.4 ms"}}, "gpu3": {"time": {"ts": 1678056028412169000, "dur": 71859000, "relative_dur": 0.1822726823069255, "relative_gap_to_previous": 0.006168846816271348, "parent_is_longest": true, "runtime_str": "71.9 ms"}}, "gpu7": {"time": {"ts": 1678056028436329000, "dur": 8392000, "relative_dur": 0.02128657996798896, "relative_gap_to_previous": 0.15098201852175963, "parent_is_longest": false, "runtime_str": "8.39 ms"}}, "gpu8": {"time": {"ts": 1678056028444541000, "dur": 8478000, "relative_dur": 0.021504721755077505, "relative_gap_to_previous": 0.17177904773500338, "parent_is_longest": false, "runtime_str": "8.48 ms"}}, "gpu9": {"time": {"ts": 1678056028452841000, "dur": 29232000, "relative_dur": 0.07414791535084048, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "29.2 ms"}}}, "id": "DE9bDYfE3sJZvPpR", "pretty_name": "BatchRNN-0", "trace_file": "/results/RNN/RNN.21.pt.trace.json", "trace_disk_size": "2.4 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 71859000, "runtime_str": "71.9 ms", "start_timestamp": "22:40:28.407.407439", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 14549}, {"idx": 13, "name": "BatchRNN-1", "type": "BatchRNN-1", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 190, in forward\n    with hotline.annotate(f'BatchRNN-{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 190, "ops": [{"idx": 14, "name": "BatchNorm", "type": "BatchNorm", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('BatchNorm'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 98, "ops": [{"idx": 15, "name": "BatchNorm1d", "type": "BatchNorm1d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 99, in forward\n    x = self.batch_norm(x)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 33, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 33, "resources": {"cpu2": {"time": {"ts": 1678056028471999000, "dur": 953000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "953 us"}}, "gpu3": {"time": {"ts": 1678056028484029000, "dur": 789000, "relative_dur": 0.8279118572927597, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "789 us"}}}, "id": "KLUE09y2A76etHqA", "pretty_name": "BatchNorm1d", "trace_file": "/results/RNN/RNN.26.pt.trace.json", "trace_disk_size": "14.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 953000, "runtime_str": "953 us", "start_timestamp": "22:40:28.471.471999", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 137}], "resources": {"cpu2": {"time": {"ts": 1678056028471999000, "dur": 953000, "relative_dur": 0.021435479880339187, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "953 us"}}, "gpu3": {"time": {"ts": 1678056028484029000, "dur": 789000, "relative_dur": 0.0177466879596932, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "789 us"}}}, "id": "wj9nT6dWEjww1YRH", "pretty_name": "BatchNorm", "trace_file": "/results/RNN/RNN.25.pt.trace.json", "trace_disk_size": "14.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 953000, "runtime_str": "953 us", "start_timestamp": "22:40:28.471.471999", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 137}, {"idx": 16, "name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 101, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 101, "resources": {"cpu2": {"time": {"ts": 1678056028473000000, "dur": 34488000, "relative_dur": 0.7757259497514564, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "34.5 ms"}}, "gpu10": {"time": {"ts": 1678056028497724000, "dur": 28999000, "relative_dur": 0.6522638835781281, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "29 ms"}}, "gpu3": {"time": {"ts": 1678056028484827000, "dur": 1703000, "relative_dur": 0.038304955127195846, "relative_gap_to_previous": 0.00020243370296227985, "parent_is_longest": true, "runtime_str": "1.70 ms"}}, "gpu7": {"time": {"ts": 1678056028487114000, "dur": 5410000, "relative_dur": 0.12168514811399267, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5.41 ms"}}, "gpu8": {"time": {"ts": 1678056028492408000, "dur": 5387000, "relative_dur": 0.12116781753975572, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5.39 ms"}}, "gpu9": {"time": {"ts": 1678056028497693000, "dur": 28842000, "relative_dur": 0.6487325400931195, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "28.8 ms"}}}, "id": "bhOV10ADt9LqDa4l", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.27.pt.trace.json", "trace_disk_size": "2.2 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 34488000, "runtime_str": "34.5 ms", "start_timestamp": "22:40:28.473.473000", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 12589}, {"idx": 17, "name": "Sum", "type": "Sum", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 108, in forward\n    with hotline.annotate('Sum'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1678056028519554000, "dur": 1959000, "relative_dur": 0.04406306934478958, "relative_gap_to_previous": 0.0008997053464990215, "parent_is_longest": true, "runtime_str": "1.96 ms"}}, "gpu3": {"time": {"ts": 1678056028526725000, "dur": 1763000, "relative_dur": 0.039654513146944376, "relative_gap_to_previous": 0.9040914100632043, "parent_is_longest": true, "runtime_str": "1.76 ms"}}}, "id": "3yq8wypKakPY0mBe", "pretty_name": "Sum", "trace_file": "/results/RNN/RNN.28.pt.trace.json", "trace_disk_size": "100.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 1959000, "runtime_str": "1.96 ms", "start_timestamp": "22:40:28.519.519554", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 620}], "resources": {"cpu2": {"time": {"ts": 1678056028471999000, "dur": 37562000, "relative_dur": 0.09527723030953306, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "37.6 ms"}}, "gpu10": {"time": {"ts": 1678056028497724000, "dur": 28999000, "relative_dur": 0.073556903299775, "relative_gap_to_previous": 0.039217327560185575, "parent_is_longest": false, "runtime_str": "29 ms"}}, "gpu3": {"time": {"ts": 1678056028484029000, "dur": 44459000, "relative_dur": 0.11277169432755257, "relative_gap_to_previous": 2.536532408006311e-06, "parent_is_longest": true, "runtime_str": "44.5 ms"}}, "gpu7": {"time": {"ts": 1678056028487114000, "dur": 5410000, "relative_dur": 0.013722640327314142, "relative_gap_to_previous": 0.10753121837261154, "parent_is_longest": false, "runtime_str": "5.41 ms"}}, "gpu8": {"time": {"ts": 1678056028492408000, "dur": 5387000, "relative_dur": 0.013664300081929997, "relative_gap_to_previous": 0.09991147501896058, "parent_is_longest": false, "runtime_str": "5.39 ms"}}, "gpu9": {"time": {"ts": 1678056028497693000, "dur": 28842000, "relative_dur": 0.07315866771171801, "relative_gap_to_previous": 0.03962063621305858, "parent_is_longest": false, "runtime_str": "28.8 ms"}}}, "id": "SHExpfI3Nj8Ca3Ip", "pretty_name": "BatchRNN-1", "trace_file": "/results/RNN/RNN.24.pt.trace.json", "trace_disk_size": "2.3 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 44459000, "runtime_str": "44.5 ms", "start_timestamp": "22:40:28.471.471999", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 13346}, {"idx": 18, "name": "BatchRNN-2", "type": "BatchRNN-2", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 190, in forward\n    with hotline.annotate(f'BatchRNN-{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 190, "ops": [{"idx": 19, "name": "BatchNorm", "type": "BatchNorm", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('BatchNorm'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 98, "ops": [{"idx": 20, "name": "BatchNorm1d", "type": "BatchNorm1d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 99, in forward\n    x = self.batch_norm(x)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 33, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 33, "resources": {"cpu2": {"time": {"ts": 1678056028521591000, "dur": 884000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "884 us"}}, "gpu3": {"time": {"ts": 1678056028528489000, "dur": 789000, "relative_dur": 0.8925339366515838, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "789 us"}}}, "id": "BNmlKjQJOHtJY0L0", "pretty_name": "BatchNorm1d", "trace_file": "/results/RNN/RNN.31.pt.trace.json", "trace_disk_size": "14.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 884000, "runtime_str": "884 us", "start_timestamp": "22:40:28.521.521591", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 137}], "resources": {"cpu2": {"time": {"ts": 1678056028521591000, "dur": 884000, "relative_dur": 0.01982018340395955, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "884 us"}}, "gpu3": {"time": {"ts": 1678056028528489000, "dur": 789000, "relative_dur": 0.017690186318692406, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "789 us"}}}, "id": "VRwSsXtVZzl5DRiw", "pretty_name": "BatchNorm", "trace_file": "/results/RNN/RNN.30.pt.trace.json", "trace_disk_size": "14.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 884000, "runtime_str": "884 us", "start_timestamp": "22:40:28.521.521591", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 137}, {"idx": 21, "name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 101, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 101, "resources": {"cpu2": {"time": {"ts": 1678056028522525000, "dur": 35321000, "relative_dur": 0.7919329163023251, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "35.3 ms"}}, "gpu10": {"time": {"ts": 1678056028542152000, "dur": 29176000, "relative_dur": 0.6541557364184659, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "29.2 ms"}}, "gpu3": {"time": {"ts": 1678056028529282000, "dur": 1694000, "relative_dur": 0.03798121118360575, "relative_gap_to_previous": 8.968408780072195e-05, "parent_is_longest": true, "runtime_str": "1.69 ms"}}, "gpu7": {"time": {"ts": 1678056028531574000, "dur": 5412000, "relative_dur": 0.12134257079437681, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5.41 ms"}}, "gpu8": {"time": {"ts": 1678056028536873000, "dur": 5352000, "relative_dur": 0.11999730947736598, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5.35 ms"}}, "gpu9": {"time": {"ts": 1678056028542113000, "dur": 29138000, "relative_dur": 0.6533037375843591, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "29.1 ms"}}}, "id": "7WuL5dyIz5MCxOwR", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.32.pt.trace.json", "trace_disk_size": "2.2 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 35321000, "runtime_str": "35.3 ms", "start_timestamp": "22:40:28.522.522525", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 12589}, {"idx": 22, "name": "Sum", "type": "Sum", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 108, in forward\n    with hotline.annotate('Sum'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1678056028564981000, "dur": 1957000, "relative_dur": 0.043877939956503215, "relative_gap_to_previous": 0.0038339947534808635, "parent_is_longest": true, "runtime_str": "1.96 ms"}}, "gpu3": {"time": {"ts": 1678056028571329000, "dur": 1761000, "relative_dur": 0.03948341965426784, "relative_gap_to_previous": 0.9047554987556333, "parent_is_longest": true, "runtime_str": "1.76 ms"}}}, "id": "iXrVkC6sa9vQJFhd", "pretty_name": "Sum", "trace_file": "/results/RNN/RNN.33.pt.trace.json", "trace_disk_size": "100.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 1957000, "runtime_str": "1.96 ms", "start_timestamp": "22:40:28.564.564981", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 620}], "resources": {"cpu2": {"time": {"ts": 1678056028521591000, "dur": 38449000, "relative_dur": 0.09752713455543464, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "38.5 ms"}}, "gpu10": {"time": {"ts": 1678056028542152000, "dur": 29176000, "relative_dur": 0.07400586953599213, "relative_gap_to_previous": 0.03913615852312937, "parent_is_longest": false, "runtime_str": "29.2 ms"}}, "gpu3": {"time": {"ts": 1678056028528489000, "dur": 44601000, "relative_dur": 0.11313188192948948, "relative_gap_to_previous": 2.536532408006311e-06, "parent_is_longest": true, "runtime_str": "44.6 ms"}}, "gpu7": {"time": {"ts": 1678056028531574000, "dur": 5412000, "relative_dur": 0.013727713392130154, "relative_gap_to_previous": 0.09905159053264644, "parent_is_longest": false, "runtime_str": "5.41 ms"}}, "gpu8": {"time": {"ts": 1678056028536873000, "dur": 5352000, "relative_dur": 0.013575521447649777, "relative_gap_to_previous": 0.09912261344007062, "parent_is_longest": false, "runtime_str": "5.35 ms"}}, "gpu9": {"time": {"ts": 1678056028542113000, "dur": 29138000, "relative_dur": 0.07390948130448789, "relative_gap_to_previous": 0.03951410185192231, "parent_is_longest": false, "runtime_str": "29.1 ms"}}}, "id": "yLYB6Q3scaAKwXF7", "pretty_name": "BatchRNN-2", "trace_file": "/results/RNN/RNN.29.pt.trace.json", "trace_disk_size": "2.3 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 44601000, "runtime_str": "44.6 ms", "start_timestamp": "22:40:28.521.521591", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 13346}, {"idx": 23, "name": "BatchRNN-3", "type": "BatchRNN-3", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 190, in forward\n    with hotline.annotate(f'BatchRNN-{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 190, "ops": [{"idx": 24, "name": "BatchNorm", "type": "BatchNorm", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('BatchNorm'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 98, "ops": [{"idx": 25, "name": "BatchNorm1d", "type": "BatchNorm1d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 99, in forward\n    x = self.batch_norm(x)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 33, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 33, "resources": {"cpu2": {"time": {"ts": 1678056028567009000, "dur": 885000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "885 us"}}, "gpu3": {"time": {"ts": 1678056028573091000, "dur": 787000, "relative_dur": 0.8892655367231639, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "787 us"}}}, "id": "GXqnNNuEEeWFeIZl", "pretty_name": "BatchNorm1d", "trace_file": "/results/RNN/RNN.36.pt.trace.json", "trace_disk_size": "14.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 885000, "runtime_str": "885 us", "start_timestamp": "22:40:28.567.567009", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 137}], "resources": {"cpu2": {"time": {"ts": 1678056028567009000, "dur": 885000, "relative_dur": 0.01989524087853787, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "885 us"}}, "gpu3": {"time": {"ts": 1678056028573091000, "dur": 787000, "relative_dur": 0.01769215205808961, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "787 us"}}}, "id": "9158lirQYcAIftIL", "pretty_name": "BatchNorm", "trace_file": "/results/RNN/RNN.35.pt.trace.json", "trace_disk_size": "14.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 885000, "runtime_str": "885 us", "start_timestamp": "22:40:28.567.567009", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 137}, {"idx": 26, "name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 101, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 101, "resources": {"cpu2": {"time": {"ts": 1678056028567943000, "dur": 35659000, "relative_dur": 0.8016320841669852, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "35.7 ms"}}, "gpu10": {"time": {"ts": 1678056028586845000, "dur": 28961000, "relative_dur": 0.6510577074387969, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "29 ms"}}, "gpu3": {"time": {"ts": 1678056028573882000, "dur": 1676000, "relative_dur": 0.037677314929298836, "relative_gap_to_previous": 8.99219926713576e-05, "parent_is_longest": true, "runtime_str": "1.68 ms"}}, "gpu7": {"time": {"ts": 1678056028576164000, "dur": 5424000, "relative_dur": 0.1219342220623609, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5.42 ms"}}, "gpu8": {"time": {"ts": 1678056028581476000, "dur": 5452000, "relative_dur": 0.1225636760110604, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5.45 ms"}}, "gpu9": {"time": {"ts": 1678056028586820000, "dur": 28936000, "relative_dur": 0.6504956949846009, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "28.9 ms"}}}, "id": "fUqz9fPbcHgVVgAR", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.37.pt.trace.json", "trace_disk_size": "2.2 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 35659000, "runtime_str": "35.7 ms", "start_timestamp": "22:40:28.567.567943", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 12589}, {"idx": 27, "name": "Sum", "type": "Sum", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 108, in forward\n    with hotline.annotate('Sum'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1678056028609812000, "dur": 1932000, "relative_dur": 0.04343232246026572, "relative_gap_to_previous": 0.0015286738754130792, "parent_is_longest": true, "runtime_str": "1.93 ms"}}, "gpu3": {"time": {"ts": 1678056028615807000, "dur": 1767000, "relative_dur": 0.03972304026257222, "relative_gap_to_previous": 0.904817570757368, "parent_is_longest": true, "runtime_str": "1.77 ms"}}}, "id": "HwwmCp5lNIq4b9rV", "pretty_name": "Sum", "trace_file": "/results/RNN/RNN.38.pt.trace.json", "trace_disk_size": "100.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 1932000, "runtime_str": "1.93 ms", "start_timestamp": "22:40:28.609.609812", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 620}], "resources": {"cpu2": {"time": {"ts": 1678056028567009000, "dur": 38661000, "relative_dur": 0.09806487942593199, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "38.7 ms"}}, "gpu10": {"time": {"ts": 1678056028586845000, "dur": 28961000, "relative_dur": 0.07346051506827077, "relative_gap_to_previous": 0.039359373375033924, "parent_is_longest": false, "runtime_str": "29 ms"}}, "gpu3": {"time": {"ts": 1678056028573091000, "dur": 44483000, "relative_dur": 0.11283257110534473, "relative_gap_to_previous": 2.536532408006311e-06, "parent_is_longest": true, "runtime_str": "44.5 ms"}}, "gpu7": {"time": {"ts": 1678056028576164000, "dur": 5424000, "relative_dur": 0.01375815178102623, "relative_gap_to_previous": 0.09937626668087125, "parent_is_longest": false, "runtime_str": "5.42 ms"}}, "gpu8": {"time": {"ts": 1678056028581476000, "dur": 5452000, "relative_dur": 0.013829174688450407, "relative_gap_to_previous": 0.09956143354665571, "parent_is_longest": false, "runtime_str": "5.45 ms"}}, "gpu9": {"time": {"ts": 1678056028586820000, "dur": 28936000, "relative_dur": 0.07339710175807061, "relative_gap_to_previous": 0.039491273060250257, "parent_is_longest": false, "runtime_str": "28.9 ms"}}}, "id": "OvGf7stdKHHmHse5", "pretty_name": "BatchRNN-3", "trace_file": "/results/RNN/RNN.34.pt.trace.json", "trace_disk_size": "2.3 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 44483000, "runtime_str": "44.5 ms", "start_timestamp": "22:40:28.567.567009", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 13346}, {"idx": 28, "name": "BatchRNN-4", "type": "BatchRNN-4", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 190, in forward\n    with hotline.annotate(f'BatchRNN-{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 190, "ops": [{"idx": 29, "name": "BatchNorm", "type": "BatchNorm", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('BatchNorm'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 98, "ops": [{"idx": 30, "name": "BatchNorm1d", "type": "BatchNorm1d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 99, in forward\n    x = self.batch_norm(x)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 33, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 33, "resources": {"cpu2": {"time": {"ts": 1678056028611817000, "dur": 893000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "893 us"}}, "gpu3": {"time": {"ts": 1678056028617575000, "dur": 796000, "relative_dur": 0.8913773796192609, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "796 us"}}}, "id": "7UPZtWWYVaT12mFs", "pretty_name": "BatchNorm1d", "trace_file": "/results/RNN/RNN.41.pt.trace.json", "trace_disk_size": "14.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 893000, "runtime_str": "893 us", "start_timestamp": "22:40:28.611.611817", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 137}], "resources": {"cpu2": {"time": {"ts": 1678056028611817000, "dur": 893000, "relative_dur": 0.020058400718778076, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "893 us"}}, "gpu3": {"time": {"ts": 1678056028617575000, "dur": 796000, "relative_dur": 0.017879604672057504, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "796 us"}}}, "id": "kNTe2itgVbnGbsGV", "pretty_name": "BatchNorm", "trace_file": "/results/RNN/RNN.40.pt.trace.json", "trace_disk_size": "14.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 893000, "runtime_str": "893 us", "start_timestamp": "22:40:28.611.611817", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 137}, {"idx": 31, "name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 101, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 101, "resources": {"cpu2": {"time": {"ts": 1678056028612762000, "dur": 35398000, "relative_dur": 0.7951033243486074, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "35.4 ms"}}, "gpu10": {"time": {"ts": 1678056028631527000, "dur": 28800000, "relative_dur": 0.6469002695417789, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "28.8 ms"}}, "gpu3": {"time": {"ts": 1678056028618376000, "dur": 1687000, "relative_dur": 0.03789308176100629, "relative_gap_to_previous": 0.00011230907457322552, "parent_is_longest": true, "runtime_str": "1.69 ms"}}, "gpu7": {"time": {"ts": 1678056028620703000, "dur": 5519000, "relative_dur": 0.12396675651392633, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5.52 ms"}}, "gpu8": {"time": {"ts": 1678056028626105000, "dur": 5494000, "relative_dur": 0.12340521114106019, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5.49 ms"}}, "gpu9": {"time": {"ts": 1678056028631484000, "dur": 28726000, "relative_dur": 0.6452380952380953, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "28.7 ms"}}}, "id": "VN4tcieVZFIWGyro", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.42.pt.trace.json", "trace_disk_size": "2.2 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 35398000, "runtime_str": "35.4 ms", "start_timestamp": "22:40:28.612.612762", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 12589}, {"idx": 32, "name": "Sum", "type": "Sum", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 108, in forward\n    with hotline.annotate('Sum'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 108, "resources": {"cpu2": {"time": {"ts": 1678056028654035000, "dur": 1934000, "relative_dur": 0.04344115004492363, "relative_gap_to_previous": 0.0014375561545372866, "parent_is_longest": true, "runtime_str": "1.93 ms"}}, "gpu3": {"time": {"ts": 1678056028660328000, "dur": 1767000, "relative_dur": 0.0396900269541779, "relative_gap_to_previous": 0.9044249775381851, "parent_is_longest": true, "runtime_str": "1.77 ms"}}}, "id": "lZtaUgGRxx25x0A2", "pretty_name": "Sum", "trace_file": "/results/RNN/RNN.43.pt.trace.json", "trace_disk_size": "100.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 1934000, "runtime_str": "1.93 ms", "start_timestamp": "22:40:28.654.654035", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 620}], "resources": {"cpu2": {"time": {"ts": 1678056028611817000, "dur": 38406000, "relative_dur": 0.09741806366189038, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "38.4 ms"}}, "gpu10": {"time": {"ts": 1678056028631527000, "dur": 28800000, "relative_dur": 0.07305213335058175, "relative_gap_to_previous": 0.03987682598626721, "parent_is_longest": false, "runtime_str": "28.8 ms"}}, "gpu3": {"time": {"ts": 1678056028617575000, "dur": 44520000, "relative_dur": 0.11292642280444096, "relative_gap_to_previous": 2.536532408006311e-06, "parent_is_longest": true, "runtime_str": "44.5 ms"}}, "gpu7": {"time": {"ts": 1678056028620703000, "dur": 5519000, "relative_dur": 0.01399912235978683, "relative_gap_to_previous": 0.09921646513916685, "parent_is_longest": false, "runtime_str": "5.52 ms"}}, "gpu8": {"time": {"ts": 1678056028626105000, "dur": 5494000, "relative_dur": 0.013935709049586673, "relative_gap_to_previous": 0.09937373014846324, "parent_is_longest": false, "runtime_str": "5.49 ms"}}, "gpu9": {"time": {"ts": 1678056028631484000, "dur": 28726000, "relative_dur": 0.07286442995238929, "relative_gap_to_previous": 0.03989458171312326, "parent_is_longest": false, "runtime_str": "28.7 ms"}}}, "id": "4HD4M2ixY4O2JaT5", "pretty_name": "BatchRNN-4", "trace_file": "/results/RNN/RNN.39.pt.trace.json", "trace_disk_size": "2.3 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 44520000, "runtime_str": "44.5 ms", "start_timestamp": "22:40:28.611.611817", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 13346}, {"idx": 33, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 193, in forward\n    with hotline.annotate('Linear'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 193, "resources": {"cpu2": {"time": {"ts": 1678056028656038000, "dur": 426000, "relative_dur": 0.0010805628058106885, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "426 us"}}, "gpu3": {"time": {"ts": 1678056028662097000, "dur": 845000, "relative_dur": 0.0021433698847653326, "relative_gap_to_previous": 5.073064816012622e-06, "parent_is_longest": true, "runtime_str": "845 us"}}}, "id": "lQMBE62XPSzru1cs", "pretty_name": "Linear", "trace_file": "/results/RNN/RNN.44.pt.trace.json", "trace_disk_size": "5.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 845000, "runtime_str": "845 us", "start_timestamp": "22:40:28.656.656038", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 39}, {"idx": 34, "name": "SoftMax", "type": "SoftMax", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 197, in forward\n    with hotline.annotate('SoftMax'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 197, "resources": {"cpu2": {"time": {"ts": 1678056028656471000, "dur": 178000, "relative_dur": 0.00045150276862512335, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "178 us"}}, "gpu3": {"time": {"ts": 1678056028662943000, "dur": 16000, "relative_dur": 4.058451852810097e-05, "relative_gap_to_previous": 2.536532408006311e-06, "parent_is_longest": true, "runtime_str": "16 us"}}}, "id": "ErUGk35wxGuEiuGe", "pretty_name": "SoftMax", "trace_file": "/results/RNN/RNN.45.pt.trace.json", "trace_disk_size": "1.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 178000, "runtime_str": "178 us", "start_timestamp": "22:40:28.656.656471", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 9}], "is_model_pass": "Forward", "idx": 2, "id": "TVdHgyFrV5dTiyeh", "pretty_name": "Forward", "trace_file": "/results/RNN/RNN.13.pt.trace.json", "trace_disk_size": "12.8 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "runtime": 394239000, "runtime_str": "394 ms", "start_timestamp": "22:40:28.267.267693", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 78013}, {"name": "Calc Loss", "type": "training loop", "instances": 10, "resources": {"cpu2": {"time": {"ts": 1678056028658549000, "dur": 409000, "relative_dur": 0.0002383795783887056, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "409 us"}}, "gpu3": {"time": {"ts": 1678056028662964000, "dur": 737000, "relative_dur": 0.00042954950922365775, "relative_gap_to_previous": 2.914175774923051e-06, "parent_is_longest": true, "runtime_str": "737 us"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 79, in update_params\n    with hotline.annotate('Calc Loss'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "source_file_num": 79, "ops": [{"name": "aten::to(97%) and 2 others\u2026", "type": "generated", "generated_depth": 2, "instances": 5, "resources": {"cpu2": {"time": {"ts": 1678056028658551000, "dur": 178000, "relative_dur": 0.24151967435549526, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "178 us"}, "res_name": "aten::to(97%) and 2 others\u2026"}, "gpu3": {"time": {"ts": 1678056028662964000, "dur": 656000, "relative_dur": 0.8900949796472184, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "656 us"}, "res_name": "ctc_loss_log_alpha_gpu_kernellong>  const long const long long const long const long  long long long long long long long const long long long(98%) and 3 others\u2026"}}, "id": "LPJoJIwcpR6KvybM", "pretty_name": "aten::to(97%) and 2 others\u2026", "trace_file": "/results/RNN/RNN.47.pt.trace.json", "trace_disk_size": "5.7 kB", "runtime": 656000, "runtime_str": "656 us", "start_timestamp": "22:40:28.658.658551", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 55}, {"name": "aten::to", "type": "generated", "generated_depth": 1, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1678056028663165000, "dur": 27000, "relative_dur": 0.036635006784260515, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "27 us"}, "res_name": "aten::to"}, "gpu3": {"time": {"ts": 1678056028663622000, "dur": 1000, "relative_dur": 0.0013568521031207597, "relative_gap_to_previous": 0.0027137042062415195, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "Tpfxh48tF0CPFEAk", "pretty_name": "aten::to", "trace_file": "/results/RNN/RNN.48.pt.trace.json", "trace_disk_size": "1.1 kB", "runtime": 27000, "runtime_str": "27 us", "start_timestamp": "22:40:28.663.663165", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 11}, {"name": "aten::mean(47%) and 4 others\u2026", "type": "generated", "generated_depth": 1, "instances": 7, "resources": {"cpu2": {"time": {"ts": 1678056028663631000, "dur": 189000, "relative_dur": 0.2564450474898236, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "189 us"}}, "gpu3": {"time": {"ts": 1678056028663660000, "dur": 41000, "relative_dur": 0.05563093622795115, "relative_gap_to_previous": 0.050203527815468114, "parent_is_longest": true, "runtime_str": "41 us"}}}, "ops": [{"name": "aten::div", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056028663631000, "dur": 29000, "relative_dur": 0.15343915343915343, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "29 us"}, "res_name": "aten::div"}, "gpu3": {"time": {"ts": 1678056028663660000, "dur": 2000, "relative_dur": 0.010582010582010581, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "vectorized_elementwise_kernel<4 BinaryFunctor  binary_ernal::DivFunctor Array<char 3> BinaryFunctor  binary_ernal::DivFunctor Array<char 3>"}}, "id": "2cl9nenJoPi17Znb", "pretty_name": "aten::div", "trace_file": "/results/RNN/RNN.50.pt.trace.json", "trace_disk_size": "587 Bytes", "runtime": 29000, "runtime_str": "29 us", "start_timestamp": "22:40:28.663.663631", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::mean", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056028663666000, "dur": 33000, "relative_dur": 0.1746031746031746, "relative_gap_to_previous": 0.031746031746031744, "parent_is_longest": true, "runtime_str": "33 us"}}, "gpu3": {"time": {"ts": 1678056028663698000, "dur": 3000, "relative_dur": 0.015873015873015872, "relative_gap_to_previous": 0.19047619047619047, "parent_is_longest": true, "runtime_str": "3 us"}}}, "ops": [{"name": "aten::as_strided", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056028663676000, "dur": 1000, "relative_dur": 0.030303030303030304, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::as_strided"}}, "id": "2EpMWAAsZtUEjxLp", "pretty_name": "aten::as_strided", "trace_file": "/results/RNN/RNN.52.pt.trace.json", "trace_disk_size": "99 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "22:40:28.663.663676", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "cudaLaunchKernel", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056028663686000, "dur": 10000, "relative_dur": 0.30303030303030304, "relative_gap_to_previous": 0.2727272727272727, "parent_is_longest": true, "runtime_str": "10 us"}, "res_name": "cudaLaunchKernel"}, "gpu3": {"time": {"ts": 1678056028663698000, "dur": 3000, "relative_dur": 0.09090909090909091, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "reduce_kernel<512 1 ReduceOpMeanOps>    4>ReduceOpMeanOps>    4>"}}, "id": "ykMUwYvjZ69F22KV", "pretty_name": "cudaLaunchKernel", "trace_file": "/results/RNN/RNN.53.pt.trace.json", "trace_disk_size": "403 Bytes", "runtime": 10000, "runtime_str": "10 us", "start_timestamp": "22:40:28.663.663686", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}], "id": "J4OAdWkahZ4qF76J", "pretty_name": "aten::mean", "trace_file": "/results/RNN/RNN.51.pt.trace.json", "trace_disk_size": "687 Bytes", "runtime": 33000, "runtime_str": "33 us", "start_timestamp": "22:40:28.663.663666", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 5}, {"name": "aten::zeros(88%) and 2 others\u2026", "type": "generated", "generated_depth": 2, "instances": 5, "resources": {"cpu2": {"time": {"ts": 1678056028663789000, "dur": 31000, "relative_dur": 0.164021164021164, "relative_gap_to_previous": 0.47619047619047616, "parent_is_longest": true, "runtime_str": "31 us"}}}, "ops": [{"name": "aten::zeros", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056028663789000, "dur": 5000, "relative_dur": 0.16129032258064516, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5 us"}, "res_name": "aten::zeros"}}, "id": "ztV1nVuQRQT2o3r8", "pretty_name": "aten::zeros", "trace_file": "/results/RNN/RNN.55.pt.trace.json", "trace_disk_size": "187 Bytes", "runtime": 5000, "runtime_str": "5 us", "start_timestamp": "22:40:28.663.663789", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::empty", "type": "generated", "generated_depth": 3, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1678056028663794000, "dur": 8000, "relative_dur": 0.25806451612903225, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "8 us"}, "res_name": "aten::empty"}}, "id": "kKC67nugWVkxPesv", "pretty_name": "aten::empty", "trace_file": "/results/RNN/RNN.56.pt.trace.json", "trace_disk_size": "187 Bytes", "runtime": 8000, "runtime_str": "8 us", "start_timestamp": "22:40:28.663.663794", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::zeros", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056028663818000, "dur": 2000, "relative_dur": 0.06451612903225806, "relative_gap_to_previous": 0.5161290322580645, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "aten::zeros"}}, "id": "wyXSYOQ6wg4pC9D4", "pretty_name": "aten::zeros", "trace_file": "/results/RNN/RNN.57.pt.trace.json", "trace_disk_size": "187 Bytes", "runtime": 2000, "runtime_str": "2 us", "start_timestamp": "22:40:28.663.663818", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::zero_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056028663820000, "dur": 0, "relative_dur": 0.0, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "0 us"}, "res_name": "aten::zero_"}}, "id": "lN5NV0StzKUWLs1m", "pretty_name": "aten::zero_", "trace_file": "/results/RNN/RNN.58.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 0, "runtime_str": "0 us", "start_timestamp": "22:40:28.663.663820", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "nzUJuEcTholgyIju", "pretty_name": "aten::zeros(88%) and 2 others\u2026", "trace_file": "/results/RNN/RNN.54.pt.trace.json", "trace_disk_size": "652 Bytes", "runtime": 31000, "runtime_str": "31 us", "start_timestamp": "22:40:28.663.663789", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 7}], "id": "XUGOUX7JvI0kLj0I", "pretty_name": "aten::mean(47%) and 4 others\u2026", "trace_file": "/results/RNN/RNN.49.pt.trace.json", "trace_disk_size": "1.9 kB", "runtime": 189000, "runtime_str": "189 us", "start_timestamp": "22:40:28.663.663631", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 15}], "idx": 35, "id": "ndDDUB2gdbi1WMYP", "pretty_name": "Calc Loss", "trace_file": "/results/RNN/RNN.46.pt.trace.json", "trace_disk_size": "8.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "runtime": 737000, "runtime_str": "737 us", "start_timestamp": "22:40:28.658.658549", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 82}, {"name": "Zero Grad", "type": "training loop", "instances": 5, "resources": {"cpu2": {"time": {"ts": 1678056028663824000, "dur": 1029000, "relative_dur": 0.000599737374479164, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.03 ms"}}, "gpu3": {"time": {"ts": 1678056028663862000, "dur": 993000, "relative_dur": 0.000578755308899718, "relative_gap_to_previous": 9.383645995252225e-05, "parent_is_longest": true, "runtime_str": "993 us"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 82, in update_params\n    with hotline.annotate('Zero Grad'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "source_file_num": 82, "ops": [{"name": "aten::zero_(100%) and 1 other\u2026", "type": "generated", "generated_depth": 2, "instances": 60, "resources": {"cpu2": {"time": {"ts": 1678056028663825000, "dur": 881000, "relative_dur": 0.8561710398445093, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "881 us"}, "res_name": "aten::zero_(100%) and 1 other\u2026"}, "gpu3": {"time": {"ts": 1678056028663862000, "dur": 845000, "relative_dur": 0.8211856171039844, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "845 us"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>"}}, "id": "8uvN5TzVz7hiXASE", "pretty_name": "aten::zero_(100%) and 1 other\u2026", "trace_file": "/results/RNN/RNN.60.pt.trace.json", "trace_disk_size": "32.6 kB", "runtime": 881000, "runtime_str": "881 us", "start_timestamp": "22:40:28.663.663825", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 237}, {"name": "aten::ones_like(84%) and 3 others\u2026", "type": "generated", "generated_depth": 1, "instances": 4, "resources": {"cpu2": {"time": {"ts": 1678056028664790000, "dur": 63000, "relative_dur": 0.061224489795918366, "relative_gap_to_previous": 0.08163265306122448, "parent_is_longest": true, "runtime_str": "63 us"}}, "gpu3": {"time": {"ts": 1678056028664854000, "dur": 1000, "relative_dur": 0.0009718172983479105, "relative_gap_to_previous": 0.14285714285714285, "parent_is_longest": true, "runtime_str": "1 us"}}}, "ops": [{"name": "aten::zeros", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056028664790000, "dur": 4000, "relative_dur": 0.06349206349206349, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4 us"}, "res_name": "aten::zeros"}}, "id": "cBk1zxFwfjYoKhEQ", "pretty_name": "aten::zeros", "trace_file": "/results/RNN/RNN.62.pt.trace.json", "trace_disk_size": "187 Bytes", "runtime": 4000, "runtime_str": "4 us", "start_timestamp": "22:40:28.664.664790", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::empty", "type": "generated", "generated_depth": 2, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1678056028664794000, "dur": 8000, "relative_dur": 0.12698412698412698, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "8 us"}}}, "ops": [{"name": "aten::zero_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056028664794000, "dur": 0, "relative_dur": 0.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "0 us"}, "res_name": "aten::zero_"}}, "id": "ZtORDIWnQLkQnSzg", "pretty_name": "aten::zero_", "trace_file": "/results/RNN/RNN.64.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 0, "runtime_str": "0 us", "start_timestamp": "22:40:28.664.664794", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}], "id": "D3VnbeOBzXiY47Li", "pretty_name": "aten::empty", "trace_file": "/results/RNN/RNN.63.pt.trace.json", "trace_disk_size": "187 Bytes", "runtime": 8000, "runtime_str": "8 us", "start_timestamp": "22:40:28.664.664794", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::ones_like", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056028664827000, "dur": 26000, "relative_dur": 0.4126984126984127, "relative_gap_to_previous": 0.3968253968253968, "parent_is_longest": true, "runtime_str": "26 us"}}, "gpu3": {"time": {"ts": 1678056028664854000, "dur": 1000, "relative_dur": 0.015873015873015872, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "1 us"}}}, "ops": [{"name": "aten::empty_like", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056028664829000, "dur": 8000, "relative_dur": 0.3076923076923077, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "8 us"}, "res_name": "aten::empty_like"}}, "id": "cc0JRKOEyf9PTBIB", "pretty_name": "aten::empty_like", "trace_file": "/results/RNN/RNN.66.pt.trace.json", "trace_disk_size": "200 Bytes", "runtime": 8000, "runtime_str": "8 us", "start_timestamp": "22:40:28.664.664829", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::fill_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056028664838000, "dur": 15000, "relative_dur": 0.5769230769230769, "relative_gap_to_previous": 0.038461538461538464, "parent_is_longest": true, "runtime_str": "15 us"}, "res_name": "aten::fill_"}, "gpu3": {"time": {"ts": 1678056028664854000, "dur": 1000, "relative_dur": 0.038461538461538464, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>"}}, "id": "jbMbNgTgeVK3e7lm", "pretty_name": "aten::fill_", "trace_file": "/results/RNN/RNN.67.pt.trace.json", "trace_disk_size": "458 Bytes", "runtime": 15000, "runtime_str": "15 us", "start_timestamp": "22:40:28.664.664838", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}], "id": "Rwn9KqeA3r9aF39E", "pretty_name": "aten::ones_like", "trace_file": "/results/RNN/RNN.65.pt.trace.json", "trace_disk_size": "755 Bytes", "runtime": 26000, "runtime_str": "26 us", "start_timestamp": "22:40:28.664.664827", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 6}], "id": "L5Tdy0n8J5g58lKU", "pretty_name": "aten::ones_like(84%) and 3 others\u2026", "trace_file": "/results/RNN/RNN.61.pt.trace.json", "trace_disk_size": "1.1 kB", "runtime": 63000, "runtime_str": "63 us", "start_timestamp": "22:40:28.664.664790", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 10}], "idx": 36, "id": "R68FWFsZ2KlwekMV", "pretty_name": "Zero Grad", "trace_file": "/results/RNN/RNN.59.pt.trace.json", "trace_disk_size": "33.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "runtime": 1029000, "runtime_str": "1.03 ms", "start_timestamp": "22:40:28.663.663824", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 248}, {"name": "Backward", "type": "training loop", "instances": 1042, "resources": {"cpu11": {"time": {"ts": 1678056028665715000, "dur": 864790000, "relative_dur": 0.5040300136791411, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "865 ms"}}, "cpu2": {"time": {"ts": 1678056029618659000, "dur": 57000, "relative_dur": 0.5040300136791411, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "57 us"}}, "gpu12": {"time": {"ts": 1678056028790146000, "dur": 825115000, "relative_dur": 0.4809060289051267, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "825 ms"}}, "gpu13": {"time": {"ts": 1678056028790148000, "dur": 842668000, "relative_dur": 0.49113653438057153, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "843 ms"}}, "gpu14": {"time": {"ts": 1678056028835991000, "dur": 811717000, "relative_dur": 0.47309720349864287, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "812 ms"}}, "gpu15": {"time": {"ts": 1678056028836008000, "dur": 810963000, "relative_dur": 0.4726577457917845, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "811 ms"}}, "gpu3": {"time": {"ts": 1678056028665927000, "dur": 1117168000, "relative_dur": 0.651124784423847, "relative_gap_to_previous": 0.0006247992861435022, "parent_is_longest": true, "runtime_str": "1.12 s"}}, "gpu4": {"time": {"ts": 1678056028825138000, "dur": 854377000, "relative_dur": 0.49796095121028633, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "854 ms"}}, "gpu5": {"time": {"ts": 1678056028830362000, "dur": 849160000, "relative_dur": 0.4949203002067316, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "849 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 85, in update_params\n    with hotline.annotate('Backward'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "source_file_num": 85, "ops": [{"name": "SoftMax", "type": "SoftMax", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 197, in forward\n    with hotline.annotate('SoftMax'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 197, "resources": {"cpu11": {"time": {"ts": 1678056028665715000, "dur": 1096000, "relative_dur": 0.0009810520888532432, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.10 ms"}}, "gpu3": {"time": {"ts": 1678056028665927000, "dur": 2460000, "relative_dur": 0.002201996476805637, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.46 ms"}}}, "is_backward_op": true, "id": "dDVU3lEeylyPCsj2", "pretty_name": "SoftMax", "trace_file": "/results/RNN/RNN.69.pt.trace.json", "trace_disk_size": "21.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 2460000, "runtime_str": "2.46 ms", "start_timestamp": "22:40:28.665.665715", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 137}, {"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 193, in forward\n    with hotline.annotate('Linear'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 193, "resources": {"cpu11": {"time": {"ts": 1678056028666889000, "dur": 193000, "relative_dur": 0.00017275826017214957, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "193 us"}}, "gpu3": {"time": {"ts": 1678056028668388000, "dur": 460000, "relative_dur": 0.0004117554387522736, "relative_gap_to_previous": 8.951205190266818e-07, "parent_is_longest": true, "runtime_str": "460 us"}}}, "is_backward_op": true, "id": "CoYClP9SfKc2MiqM", "pretty_name": "Linear", "trace_file": "/results/RNN/RNN.70.pt.trace.json", "trace_disk_size": "3.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 460000, "runtime_str": "460 us", "start_timestamp": "22:40:28.666.666889", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 31}, {"name": "BatchRNN-4", "type": "BatchRNN-4", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 190, in forward\n    with hotline.annotate(f'BatchRNN-{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 190, "ops": [{"name": "Sum", "type": "Sum", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 108, in forward\n    with hotline.annotate('Sum'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 108, "resources": {"cpu11": {"time": {"ts": 1678056028667089000, "dur": 265000, "relative_dur": 0.0013602997792721114, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "265 us"}}, "gpu3": {"time": {"ts": 1678056028668849000, "dur": 983000, "relative_dur": 0.005045942200092398, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "983 us"}}}, "is_backward_op": true, "id": "K3I9mN8o4orkJKmP", "pretty_name": "Sum", "trace_file": "/results/RNN/RNN.72.pt.trace.json", "trace_disk_size": "6.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 983000, "runtime_str": "983 us", "start_timestamp": "22:40:28.667.667089", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 54}, {"name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 101, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 101, "resources": {"cpu11": {"time": {"ts": 1678056028667358000, "dur": 153011000, "relative_dur": 0.785437092551717, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "153 ms"}}, "gpu12": {"time": {"ts": 1678056028790146000, "dur": 46591000, "relative_dur": 0.2391612340228941, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "46.6 ms"}}, "gpu13": {"time": {"ts": 1678056028790148000, "dur": 56025000, "relative_dur": 0.28758790616498126, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "56 ms"}}, "gpu14": {"time": {"ts": 1678056028835991000, "dur": 23509000, "relative_dur": 0.1206765566449361, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "23.5 ms"}}, "gpu15": {"time": {"ts": 1678056028836008000, "dur": 22826000, "relative_dur": 0.11717057645911401, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "22.8 ms"}}, "gpu3": {"time": {"ts": 1678056028669834000, "dur": 166156000, "relative_dur": 0.8529130948103281, "relative_gap_to_previous": 1.0266413428468765e-05, "parent_is_longest": true, "runtime_str": "166 ms"}}, "gpu4": {"time": {"ts": 1678056028825138000, "dur": 17109000, "relative_dur": 0.08782403367383605, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "17.1 ms"}}, "gpu5": {"time": {"ts": 1678056028830362000, "dur": 16888000, "relative_dur": 0.08668959498999025, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "16.9 ms"}}}, "is_backward_op": true, "id": "1QcJ2lnYrrtxrlK1", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.73.pt.trace.json", "trace_disk_size": "3.1 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 166156000, "runtime_str": "166 ms", "start_timestamp": "22:40:28.667.667358", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 19194}, {"name": "BatchNorm", "type": "BatchNorm", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('BatchNorm'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 98, "ops": [{"name": "BatchNorm1d", "type": "BatchNorm1d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 99, in forward\n    x = self.batch_norm(x)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 33, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 33, "resources": {"cpu11": {"time": {"ts": 1678056028822651000, "dur": 12629000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12.6 ms"}}, "gpu3": {"time": {"ts": 1678056028859502000, "dur": 4157000, "relative_dur": 0.3291630374534801, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4.16 ms"}}}, "is_backward_op": true, "id": "6ZkELc0VM9vgaEVp", "pretty_name": "BatchNorm1d", "trace_file": "/results/RNN/RNN.75.pt.trace.json", "trace_disk_size": "763.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 12629000, "runtime_str": "12.6 ms", "start_timestamp": "22:40:28.822.822651", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7585}], "resources": {"cpu11": {"time": {"ts": 1678056028822651000, "dur": 12629000, "relative_dur": 0.06482726759406601, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12.6 ms"}}, "gpu3": {"time": {"ts": 1678056028859502000, "dur": 4157000, "relative_dur": 0.021338740311072326, "relative_gap_to_previous": 0.1206919562650788, "parent_is_longest": true, "runtime_str": "4.16 ms"}}}, "is_backward_op": true, "id": "lvWfwjBaG2h1SdXg", "pretty_name": "BatchNorm", "trace_file": "/results/RNN/RNN.74.pt.trace.json", "trace_disk_size": "763.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 12629000, "runtime_str": "12.6 ms", "start_timestamp": "22:40:28.822.822651", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7585}], "resources": {"cpu11": {"time": {"ts": 1678056028667089000, "dur": 165921000, "relative_dur": 0.14851929163742605, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "166 ms"}}, "gpu12": {"time": {"ts": 1678056028790146000, "dur": 46591000, "relative_dur": 0.04170456010197213, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "46.6 ms"}}, "gpu13": {"time": {"ts": 1678056028790148000, "dur": 56025000, "relative_dur": 0.05014912707846984, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "56 ms"}}, "gpu14": {"time": {"ts": 1678056028835991000, "dur": 23509000, "relative_dur": 0.02104338828179826, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "23.5 ms"}}, "gpu15": {"time": {"ts": 1678056028836008000, "dur": 22826000, "relative_dur": 0.02043202096730304, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "22.8 ms"}}, "gpu3": {"time": {"ts": 1678056028668849000, "dur": 194810000, "relative_dur": 0.17437842831158787, "relative_gap_to_previous": 8.951205190266818e-07, "parent_is_longest": true, "runtime_str": "195 ms"}}, "gpu4": {"time": {"ts": 1678056028825138000, "dur": 17109000, "relative_dur": 0.015314616960027498, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "17.1 ms"}}, "gpu5": {"time": {"ts": 1678056028830362000, "dur": 16888000, "relative_dur": 0.015116795325322601, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "16.9 ms"}}}, "is_backward_op": true, "id": "GOgLTVr2DIQkOnZA", "pretty_name": "BatchRNN-4", "trace_file": "/results/RNN/RNN.71.pt.trace.json", "trace_disk_size": "3.9 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 194810000, "runtime_str": "195 ms", "start_timestamp": "22:40:28.667.667089", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 26833}, {"name": "BatchRNN-3", "type": "BatchRNN-3", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 190, in forward\n    with hotline.annotate(f'BatchRNN-{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 190, "ops": [{"name": "Sum", "type": "Sum", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 108, in forward\n    with hotline.annotate('Sum'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 108, "resources": {"cpu11": {"time": {"ts": 1678056028838777000, "dur": 84000, "relative_dur": 0.00043667895259434083, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "84 us"}}, "gpu3": {"time": {"ts": 1678056028863661000, "dur": 5000, "relative_dur": 2.5992794797282192e-05, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5 us"}}}, "is_backward_op": true, "id": "u7RIw7jC0nVsEBcx", "pretty_name": "Sum", "trace_file": "/results/RNN/RNN.77.pt.trace.json", "trace_disk_size": "3.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 84000, "runtime_str": "84 us", "start_timestamp": "22:40:28.838.838777", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 24}, {"name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 101, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 101, "resources": {"cpu11": {"time": {"ts": 1678056028838864000, "dur": 160605000, "relative_dur": 0.8349145616835013, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "161 ms"}}, "gpu12": {"time": {"ts": 1678056028983567000, "dur": 54819000, "relative_dur": 0.2849798035984425, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "54.8 ms"}}, "gpu13": {"time": {"ts": 1678056028983568000, "dur": 48944000, "relative_dur": 0.2544382697116359, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "48.9 ms"}}, "gpu14": {"time": {"ts": 1678056029032222000, "dur": 19784000, "relative_dur": 0.10284829045388619, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "19.8 ms"}}, "gpu15": {"time": {"ts": 1678056029032098000, "dur": 19261000, "relative_dur": 0.10012944411809047, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "19.3 ms"}}, "gpu3": {"time": {"ts": 1678056028863668000, "dur": 164943000, "relative_dur": 0.8574659104496234, "relative_gap_to_previous": 1.0397117918912877e-05, "parent_is_longest": true, "runtime_str": "165 ms"}}, "gpu4": {"time": {"ts": 1678056029017933000, "dur": 21928000, "relative_dur": 0.11399400086296078, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "21.9 ms"}}, "gpu5": {"time": {"ts": 1678056029022921000, "dur": 11318000, "relative_dur": 0.058837290303127975, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "11.3 ms"}}}, "is_backward_op": true, "id": "i3gvaEy1M20XMHvr", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.78.pt.trace.json", "trace_disk_size": "3.1 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 164943000, "runtime_str": "165 ms", "start_timestamp": "22:40:28.838.838864", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 19194}, {"name": "BatchNorm", "type": "BatchNorm", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('BatchNorm'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 98, "ops": [{"name": "BatchNorm1d", "type": "BatchNorm1d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 99, in forward\n    x = self.batch_norm(x)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 33, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 33, "resources": {"cpu11": {"time": {"ts": 1678056029017242000, "dur": 12622000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12.6 ms"}}, "gpu3": {"time": {"ts": 1678056029052009000, "dur": 4013000, "relative_dur": 0.317936935509428, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4.01 ms"}}}, "is_backward_op": true, "id": "VbS4RjR3Xr95B3WA", "pretty_name": "BatchNorm1d", "trace_file": "/results/RNN/RNN.80.pt.trace.json", "trace_disk_size": "763.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 12622000, "runtime_str": "12.6 ms", "start_timestamp": "22:40:29.017.17242", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7585}], "resources": {"cpu11": {"time": {"ts": 1678056029017242000, "dur": 12622000, "relative_dur": 0.06561621118625917, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12.6 ms"}}, "gpu3": {"time": {"ts": 1678056029052009000, "dur": 4013000, "relative_dur": 0.02086181710429869, "relative_gap_to_previous": 0.12163588253336176, "parent_is_longest": true, "runtime_str": "4.01 ms"}}}, "is_backward_op": true, "id": "Tyq7S57pBpdNAcB2", "pretty_name": "BatchNorm", "trace_file": "/results/RNN/RNN.79.pt.trace.json", "trace_disk_size": "763.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 12622000, "runtime_str": "12.6 ms", "start_timestamp": "22:40:29.017.17242", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7585}], "resources": {"cpu11": {"time": {"ts": 1678056028838777000, "dur": 173326000, "relative_dur": 0.15514765908081865, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "173 ms"}}, "gpu12": {"time": {"ts": 1678056028983567000, "dur": 54819000, "relative_dur": 0.049069611732523666, "relative_gap_to_previous": 0.13143054580868768, "parent_is_longest": false, "runtime_str": "54.8 ms"}}, "gpu13": {"time": {"ts": 1678056028983568000, "dur": 48944000, "relative_dur": 0.04381077868324191, "relative_gap_to_previous": 0.12298508371167094, "parent_is_longest": false, "runtime_str": "48.9 ms"}}, "gpu14": {"time": {"ts": 1678056029032222000, "dur": 19784000, "relative_dur": 0.017709064348423873, "relative_gap_to_previous": 0.15460700628732651, "parent_is_longest": false, "runtime_str": "19.8 ms"}}, "gpu15": {"time": {"ts": 1678056029032098000, "dur": 19261000, "relative_dur": 0.01724091631697292, "relative_gap_to_previous": 0.15509216160863898, "parent_is_longest": false, "runtime_str": "19.3 ms"}}, "gpu3": {"time": {"ts": 1678056028863661000, "dur": 192361000, "relative_dur": 0.17218627816049153, "relative_gap_to_previous": 1.7902410380533635e-06, "parent_is_longest": true, "runtime_str": "192 ms"}}, "gpu4": {"time": {"ts": 1678056029017933000, "dur": 21928000, "relative_dur": 0.019628202741217078, "relative_gap_to_previous": 0.15726014350572162, "parent_is_longest": false, "runtime_str": "21.9 ms"}}, "gpu5": {"time": {"ts": 1678056029022921000, "dur": 11318000, "relative_dur": 0.010130974034343983, "relative_gap_to_previous": 0.15724671669793622, "parent_is_longest": false, "runtime_str": "11.3 ms"}}}, "is_backward_op": true, "id": "qRgMs6VXEkUHwA5G", "pretty_name": "BatchRNN-3", "trace_file": "/results/RNN/RNN.76.pt.trace.json", "trace_disk_size": "3.9 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 192361000, "runtime_str": "192 ms", "start_timestamp": "22:40:28.838.838777", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 26803}, {"name": "BatchRNN-2", "type": "BatchRNN-2", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 190, in forward\n    with hotline.annotate(f'BatchRNN-{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 190, "ops": [{"name": "Sum", "type": "Sum", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 108, in forward\n    with hotline.annotate('Sum'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 108, "resources": {"cpu11": {"time": {"ts": 1678056029033368000, "dur": 87000, "relative_dur": 0.0004504714416639483, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "87 us"}}, "gpu3": {"time": {"ts": 1678056029056023000, "dur": 6000, "relative_dur": 3.106699597682402e-05, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "6 us"}}}, "is_backward_op": true, "id": "9rA8roqv2EHdqITN", "pretty_name": "Sum", "trace_file": "/results/RNN/RNN.82.pt.trace.json", "trace_disk_size": "3.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 87000, "runtime_str": "87 us", "start_timestamp": "22:40:29.033.33368", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 24}, {"name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 101, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 101, "resources": {"cpu11": {"time": {"ts": 1678056029033459000, "dur": 158926000, "relative_dur": 0.8228922337687891, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "159 ms"}}, "gpu12": {"time": {"ts": 1678056029175876000, "dur": 50263000, "relative_dur": 0.26025340313051765, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "50.3 ms"}}, "gpu13": {"time": {"ts": 1678056029175875000, "dur": 49814000, "relative_dur": 0.2579285562649186, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "49.8 ms"}}, "gpu14": {"time": {"ts": 1678056029221518000, "dur": 23523000, "relative_dur": 0.12179815772713858, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "23.5 ms"}}, "gpu15": {"time": {"ts": 1678056029221489000, "dur": 22925000, "relative_dur": 0.11870181379478179, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "22.9 ms"}}, "gpu3": {"time": {"ts": 1678056029056030000, "dur": 165458000, "relative_dur": 0.8567138367222248, "relative_gap_to_previous": 5.1778326628040036e-06, "parent_is_longest": true, "runtime_str": "165 ms"}}, "gpu4": {"time": {"ts": 1678056029210824000, "dur": 16267000, "relative_dur": 0.08422780392583272, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "16.3 ms"}}, "gpu5": {"time": {"ts": 1678056029215888000, "dur": 16734000, "relative_dur": 0.0866458517793622, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "16.7 ms"}}}, "is_backward_op": true, "id": "BurbyPabXJcGf3QF", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.83.pt.trace.json", "trace_disk_size": "3.1 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 165458000, "runtime_str": "165 ms", "start_timestamp": "22:40:29.033.33459", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 19194}, {"name": "BatchNorm", "type": "BatchNorm", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('BatchNorm'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 98, "ops": [{"name": "BatchNorm1d", "type": "BatchNorm1d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 99, in forward\n    x = self.batch_norm(x)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 33, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 33, "resources": {"cpu11": {"time": {"ts": 1678056029208845000, "dur": 12498000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12.5 ms"}}, "gpu3": {"time": {"ts": 1678056029245044000, "dur": 4110000, "relative_dur": 0.32885261641862695, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4.11 ms"}}}, "is_backward_op": true, "id": "WP4bTEHeix0sKMVk", "pretty_name": "BatchNorm1d", "trace_file": "/results/RNN/RNN.85.pt.trace.json", "trace_disk_size": "763.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 12498000, "runtime_str": "12.5 ms", "start_timestamp": "22:40:29.208.208845", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7585}], "resources": {"cpu11": {"time": {"ts": 1678056029208845000, "dur": 12498000, "relative_dur": 0.06471255261972443, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12.5 ms"}}, "gpu3": {"time": {"ts": 1678056029245044000, "dur": 4110000, "relative_dur": 0.021280892244124456, "relative_gap_to_previous": 0.1219690262050111, "parent_is_longest": true, "runtime_str": "4.11 ms"}}}, "is_backward_op": true, "id": "NdBayU7ZnD6Ipi8r", "pretty_name": "BatchNorm", "trace_file": "/results/RNN/RNN.84.pt.trace.json", "trace_disk_size": "763.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 12498000, "runtime_str": "12.5 ms", "start_timestamp": "22:40:29.208.208845", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7585}], "resources": {"cpu11": {"time": {"ts": 1678056029033368000, "dur": 171535000, "relative_dur": 0.15354449823124186, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "172 ms"}}, "gpu12": {"time": {"ts": 1678056029175876000, "dur": 50263000, "relative_dur": 0.0449914426478381, "relative_gap_to_previous": 0.12307012016097847, "parent_is_longest": false, "runtime_str": "50.3 ms"}}, "gpu13": {"time": {"ts": 1678056029175875000, "dur": 49814000, "relative_dur": 0.044589533534795125, "relative_gap_to_previous": 0.12832716296922217, "parent_is_longest": false, "runtime_str": "49.8 ms"}}, "gpu14": {"time": {"ts": 1678056029221518000, "dur": 23523000, "relative_dur": 0.021055919969064633, "relative_gap_to_previous": 0.15173366942125088, "parent_is_longest": false, "runtime_str": "23.5 ms"}}, "gpu15": {"time": {"ts": 1678056029221489000, "dur": 22925000, "relative_dur": 0.02052063789868668, "relative_gap_to_previous": 0.15228685390200936, "parent_is_longest": false, "runtime_str": "22.9 ms"}}, "gpu3": {"time": {"ts": 1678056029056023000, "dur": 193131000, "relative_dur": 0.17287552096014208, "relative_gap_to_previous": 8.951205190266818e-07, "parent_is_longest": true, "runtime_str": "193 ms"}}, "gpu4": {"time": {"ts": 1678056029210824000, "dur": 16267000, "relative_dur": 0.014560925483007033, "relative_gap_to_previous": 0.1530324892943586, "parent_is_longest": false, "runtime_str": "16.3 ms"}}, "gpu5": {"time": {"ts": 1678056029215888000, "dur": 16734000, "relative_dur": 0.014978946765392492, "relative_gap_to_previous": 0.1625977471606777, "parent_is_longest": false, "runtime_str": "16.7 ms"}}}, "is_backward_op": true, "id": "2GbY9jG7nMxDnQSx", "pretty_name": "BatchRNN-2", "trace_file": "/results/RNN/RNN.81.pt.trace.json", "trace_disk_size": "3.9 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 193131000, "runtime_str": "193 ms", "start_timestamp": "22:40:29.033.33368", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 26803}, {"name": "BatchRNN-1", "type": "BatchRNN-1", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 190, in forward\n    with hotline.annotate(f'BatchRNN-{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 190, "ops": [{"name": "Sum", "type": "Sum", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 108, in forward\n    with hotline.annotate('Sum'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 108, "resources": {"cpu11": {"time": {"ts": 1678056029224804000, "dur": 85000, "relative_dur": 0.0004424433282148713, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "85 us"}}, "gpu3": {"time": {"ts": 1678056029249156000, "dur": 5000, "relative_dur": 2.6026078130286547e-05, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5 us"}}}, "is_backward_op": true, "id": "N09qu7GaQCjpdmtC", "pretty_name": "Sum", "trace_file": "/results/RNN/RNN.87.pt.trace.json", "trace_disk_size": "3.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 85000, "runtime_str": "85 us", "start_timestamp": "22:40:29.224.224804", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 24}, {"name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 101, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 101, "resources": {"cpu11": {"time": {"ts": 1678056029224892000, "dur": 160451000, "relative_dur": 0.8351820524165213, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "160 ms"}}, "gpu12": {"time": {"ts": 1678056029368517000, "dur": 45814000, "relative_dur": 0.23847174869218957, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "45.8 ms"}}, "gpu13": {"time": {"ts": 1678056029368518000, "dur": 54958000, "relative_dur": 0.28606824037685763, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "55 ms"}}, "gpu14": {"time": {"ts": 1678056029422032000, "dur": 15087000, "relative_dur": 0.07853108815032663, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "15.1 ms"}}, "gpu15": {"time": {"ts": 1678056029413602000, "dur": 22850000, "relative_dur": 0.11893917705540952, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "22.9 ms"}}, "gpu3": {"time": {"ts": 1678056029249163000, "dur": 164438000, "relative_dur": 0.8559352471176118, "relative_gap_to_previous": 1.041043125211462e-05, "parent_is_longest": true, "runtime_str": "164 ms"}}, "gpu4": {"time": {"ts": 1678056029407914000, "dur": 16938000, "relative_dur": 0.0881659422741587, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "16.9 ms"}}, "gpu5": {"time": {"ts": 1678056029403042000, "dur": 16828000, "relative_dur": 0.0875933685552924, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "16.8 ms"}}}, "is_backward_op": true, "id": "KMvcVwQ3T0QqVm5D", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.88.pt.trace.json", "trace_disk_size": "3.1 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 164438000, "runtime_str": "164 ms", "start_timestamp": "22:40:29.224.224892", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 19194}, {"name": "BatchNorm", "type": "BatchNorm", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('BatchNorm'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 98, "ops": [{"name": "BatchNorm1d", "type": "BatchNorm1d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 99, in forward\n    x = self.batch_norm(x)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 33, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 33, "resources": {"cpu11": {"time": {"ts": 1678056029402667000, "dur": 12485000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12.5 ms"}}, "gpu3": {"time": {"ts": 1678056029437122000, "dur": 4149000, "relative_dur": 0.33231878253904684, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4.15 ms"}}}, "is_backward_op": true, "id": "nucwCyJUzBLQZWsV", "pretty_name": "BatchNorm1d", "trace_file": "/results/RNN/RNN.90.pt.trace.json", "trace_disk_size": "763.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 12485000, "runtime_str": "12.5 ms", "start_timestamp": "22:40:29.402.402667", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7585}], "resources": {"cpu11": {"time": {"ts": 1678056029402667000, "dur": 12485000, "relative_dur": 0.06498711709132551, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12.5 ms"}}, "gpu3": {"time": {"ts": 1678056029437122000, "dur": 4149000, "relative_dur": 0.021596439632511778, "relative_gap_to_previous": 0.12243187674049398, "parent_is_longest": true, "runtime_str": "4.15 ms"}}}, "is_backward_op": true, "id": "c8XAXp5tQL1XlvJk", "pretty_name": "BatchNorm", "trace_file": "/results/RNN/RNN.89.pt.trace.json", "trace_disk_size": "763.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 12485000, "runtime_str": "12.5 ms", "start_timestamp": "22:40:29.402.402667", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7585}], "resources": {"cpu11": {"time": {"ts": 1678056029224804000, "dur": 173037000, "relative_dur": 0.15488896925081994, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "173 ms"}}, "gpu12": {"time": {"ts": 1678056029368517000, "dur": 45814000, "relative_dur": 0.0410090514586884, "relative_gap_to_previous": 0.1274454692579809, "parent_is_longest": false, "runtime_str": "45.8 ms"}}, "gpu13": {"time": {"ts": 1678056029368518000, "dur": 54958000, "relative_dur": 0.04919403348466837, "relative_gap_to_previous": 0.12784916861206191, "parent_is_longest": false, "runtime_str": "55 ms"}}, "gpu14": {"time": {"ts": 1678056029422032000, "dur": 15087000, "relative_dur": 0.013504683270555548, "relative_gap_to_previous": 0.15842827578305144, "parent_is_longest": false, "runtime_str": "15.1 ms"}}, "gpu15": {"time": {"ts": 1678056029413602000, "dur": 22850000, "relative_dur": 0.020453503859759678, "relative_gap_to_previous": 0.15144365037308624, "parent_is_longest": false, "runtime_str": "22.9 ms"}}, "gpu3": {"time": {"ts": 1678056029249156000, "dur": 192115000, "relative_dur": 0.17196607851281095, "relative_gap_to_previous": 1.7902410380533635e-06, "parent_is_longest": true, "runtime_str": "192 ms"}}, "gpu4": {"time": {"ts": 1678056029407914000, "dur": 16938000, "relative_dur": 0.015161551351273936, "relative_gap_to_previous": 0.16185837761196167, "parent_is_longest": false, "runtime_str": "16.9 ms"}}, "gpu5": {"time": {"ts": 1678056029403042000, "dur": 16828000, "relative_dur": 0.015063088094181, "relative_gap_to_previous": 0.1525464388525271, "parent_is_longest": false, "runtime_str": "16.8 ms"}}}, "is_backward_op": true, "id": "VSUhKRzLOMKRZxuf", "pretty_name": "BatchRNN-1", "trace_file": "/results/RNN/RNN.86.pt.trace.json", "trace_disk_size": "3.9 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 192115000, "runtime_str": "192 ms", "start_timestamp": "22:40:29.224.224804", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 26803}, {"name": "BatchRNN-0", "type": "BatchRNN-0", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 190, in forward\n    with hotline.annotate(f'BatchRNN-{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 190, "ops": [{"name": "Sum", "type": "Sum", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 108, in forward\n    with hotline.annotate('Sum'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 108, "resources": {"cpu11": {"time": {"ts": 1678056029418601000, "dur": 86000, "relative_dur": 0.0004960288850308865, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "86 us"}}, "gpu3": {"time": {"ts": 1678056029441272000, "dur": 6000, "relative_dur": 3.460666639750371e-05, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "6 us"}}}, "is_backward_op": true, "id": "mdxMosELs1THi4Og", "pretty_name": "Sum", "trace_file": "/results/RNN/RNN.92.pt.trace.json", "trace_disk_size": "3.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 86000, "runtime_str": "86 us", "start_timestamp": "22:40:29.418.418601", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 24}, {"name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 101, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 101, "resources": {"cpu11": {"time": {"ts": 1678056029418690000, "dur": 158698000, "relative_dur": 0.9153347906585072, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "159 ms"}}, "gpu12": {"time": {"ts": 1678056029560716000, "dur": 54545000, "relative_dur": 0.31460343644197325, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "54.5 ms"}}, "gpu13": {"time": {"ts": 1678056029560715000, "dur": 72101000, "relative_dur": 0.4158625423210691, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "72.1 ms"}}, "gpu14": {"time": {"ts": 1678056029632119000, "dur": 15589000, "relative_dur": 0.08991388707844754, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "15.6 ms"}}, "gpu15": {"time": {"ts": 1678056029631923000, "dur": 15048000, "relative_dur": 0.0867935193249393, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "15.1 ms"}}, "gpu3": {"time": {"ts": 1678056029441279000, "dur": 173370000, "relative_dur": 0.9999596255558696, "relative_gap_to_previous": 5.767777732917284e-06, "parent_is_longest": true, "runtime_str": "173 ms"}}, "gpu4": {"time": {"ts": 1678056029595195000, "dur": 31168000, "relative_dur": 0.17977009637956592, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "31.2 ms"}}, "gpu5": {"time": {"ts": 1678056029604440000, "dur": 32993000, "relative_dur": 0.19029629074213997, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "33 ms"}}}, "is_backward_op": true, "id": "yxKtIO7jD4bOXGEf", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.93.pt.trace.json", "trace_disk_size": "3.1 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 173370000, "runtime_str": "173 ms", "start_timestamp": "22:40:29.418.418690", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 19194}], "resources": {"cpu11": {"time": {"ts": 1678056029418601000, "dur": 158787000, "relative_dur": 0.1421335018546897, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "159 ms"}}, "gpu12": {"time": {"ts": 1678056029560716000, "dur": 54545000, "relative_dur": 0.048824348710310356, "relative_gap_to_previous": 0.13103221717772082, "parent_is_longest": false, "runtime_str": "54.5 ms"}}, "gpu13": {"time": {"ts": 1678056029560715000, "dur": 72101000, "relative_dur": 0.06453908454234278, "relative_gap_to_previous": 0.12284544491070278, "parent_is_longest": false, "runtime_str": "72.1 ms"}}, "gpu14": {"time": {"ts": 1678056029632119000, "dur": 15589000, "relative_dur": 0.013954033771106942, "relative_gap_to_previous": 0.17454850121020293, "parent_is_longest": false, "runtime_str": "15.6 ms"}}, "gpu15": {"time": {"ts": 1678056029631923000, "dur": 15048000, "relative_dur": 0.013469773570313507, "relative_gap_to_previous": 0.1749701029746645, "parent_is_longest": false, "runtime_str": "15.1 ms"}}, "gpu3": {"time": {"ts": 1678056029441272000, "dur": 173377000, "relative_dur": 0.155193310227289, "relative_gap_to_previous": 8.951205190266818e-07, "parent_is_longest": true, "runtime_str": "173 ms"}}, "gpu4": {"time": {"ts": 1678056029595195000, "dur": 31168000, "relative_dur": 0.027899116337023615, "relative_gap_to_previous": 0.15247751457256206, "parent_is_longest": false, "runtime_str": "31.2 ms"}}, "gpu5": {"time": {"ts": 1678056029604440000, "dur": 32993000, "relative_dur": 0.02953271128424731, "relative_gap_to_previous": 0.16521239419675465, "parent_is_longest": false, "runtime_str": "33 ms"}}}, "is_backward_op": true, "id": "pWf9T5aB7M377xDs", "pretty_name": "BatchRNN-0", "trace_file": "/results/RNN/RNN.91.pt.trace.json", "trace_disk_size": "3.1 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 173377000, "runtime_str": "173 ms", "start_timestamp": "22:40:29.418.418601", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 19218}, {"name": "MaskConv", "type": "MaskConv", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 179, in forward\n    with hotline.annotate('MaskConv'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 179, "ops": [{"name": "Hardtanh", "type": "Hardtanh", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu11": {"time": {"ts": 1678056029593786000, "dur": 12527000, "relative_dur": 0.09253486585509987, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12.5 ms"}}, "gpu3": {"time": {"ts": 1678056029647711000, "dur": 8567000, "relative_dur": 0.06328300437300556, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "8.57 ms"}}}, "is_backward_op": true, "id": "NYFTd6F34iTZA8an", "pretty_name": "Hardtanh", "trace_file": "/results/RNN/RNN.95.pt.trace.json", "trace_disk_size": "765.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 12527000, "runtime_str": "12.5 ms", "start_timestamp": "22:40:29.593.593786", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7593}, {"name": "BatchNorm2d", "type": "BatchNorm2d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu11": {"time": {"ts": 1678056029609753000, "dur": 132000, "relative_dur": 0.0009750620494031439, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "132 us"}}, "gpu3": {"time": {"ts": 1678056029656280000, "dur": 4192000, "relative_dur": 0.030965606902257418, "relative_gap_to_previous": 1.4773667415199149e-05, "parent_is_longest": true, "runtime_str": "4.19 ms"}}}, "is_backward_op": true, "id": "z5mCxz2qjlbJrigq", "pretty_name": "BatchNorm2d", "trace_file": "/results/RNN/RNN.96.pt.trace.json", "trace_disk_size": "3.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 4192000, "runtime_str": "4.19 ms", "start_timestamp": "22:40:29.609.609753", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 25}, {"name": "Conv2d", "type": "Conv2d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu11": {"time": {"ts": 1678056029609901000, "dur": 7613000, "relative_dur": 0.05623596501595556, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "7.61 ms"}}, "gpu3": {"time": {"ts": 1678056029660474000, "dur": 94409000, "relative_dur": 0.6973835835007682, "relative_gap_to_previous": 1.4773667415199149e-05, "parent_is_longest": true, "runtime_str": "94.4 ms"}}, "gpu4": {"time": {"ts": 1678056029661915000, "dur": 17600000, "relative_dur": 0.1300082732537525, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "17.6 ms"}}, "gpu5": {"time": {"ts": 1678056029661914000, "dur": 17608000, "relative_dur": 0.1300673679234133, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "17.6 ms"}}}, "is_backward_op": true, "id": "L16ZPw7Ck5SzIq3Y", "pretty_name": "Conv2d", "trace_file": "/results/RNN/RNN.97.pt.trace.json", "trace_disk_size": "444.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 94409000, "runtime_str": "94.4 ms", "start_timestamp": "22:40:29.609.609901", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 2988}, {"name": "Hardtanh", "type": "Hardtanh", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu11": {"time": {"ts": 1678056029617534000, "dur": 125000, "relative_dur": 0.0009233542134499468, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "125 us"}}, "gpu3": {"time": {"ts": 1678056029754885000, "dur": 4747000, "relative_dur": 0.03506529960997518, "relative_gap_to_previous": 1.4773667415199149e-05, "parent_is_longest": true, "runtime_str": "4.75 ms"}}}, "is_backward_op": true, "id": "sJVAZZoLu5bcYvZc", "pretty_name": "Hardtanh", "trace_file": "/results/RNN/RNN.98.pt.trace.json", "trace_disk_size": "4.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 4747000, "runtime_str": "4.75 ms", "start_timestamp": "22:40:29.617.617534", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 28}, {"name": "BatchNorm2d", "type": "BatchNorm2d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu11": {"time": {"ts": 1678056029617673000, "dur": 104000, "relative_dur": 0.0007682307055903557, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "104 us"}}, "gpu3": {"time": {"ts": 1678056029759634000, "dur": 8716000, "relative_dur": 0.0643836425954379, "relative_gap_to_previous": 1.4773667415199149e-05, "parent_is_longest": true, "runtime_str": "8.72 ms"}}}, "is_backward_op": true, "id": "fzWu24FP22UmtqTQ", "pretty_name": "BatchNorm2d", "trace_file": "/results/RNN/RNN.99.pt.trace.json", "trace_disk_size": "3.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 8716000, "runtime_str": "8.72 ms", "start_timestamp": "22:40:29.617.617673", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 25}, {"name": "Conv2d", "type": "Conv2d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu11": {"time": {"ts": 1678056029617790000, "dur": 252000, "relative_dur": 0.0018614820943150929, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "252 us"}}, "gpu3": {"time": {"ts": 1678056029768351000, "dur": 14736000, "relative_dur": 0.10885238151518734, "relative_gap_to_previous": 7.3868337075995745e-06, "parent_is_longest": true, "runtime_str": "14.7 ms"}}}, "is_backward_op": true, "id": "KvM3cbdMUsm38b97", "pretty_name": "Conv2d", "trace_file": "/results/RNN/RNN.100.pt.trace.json", "trace_disk_size": "7.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 14736000, "runtime_str": "14.7 ms", "start_timestamp": "22:40:29.617.617790", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 47}], "resources": {"cpu11": {"time": {"ts": 1678056029593786000, "dur": 20787000, "relative_dur": 0.018606870229007633, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "20.8 ms"}}, "gpu3": {"time": {"ts": 1678056029647711000, "dur": 135376000, "relative_dur": 0.12117783538375607, "relative_gap_to_previous": 0.029594474600060153, "parent_is_longest": true, "runtime_str": "135 ms"}}, "gpu4": {"time": {"ts": 1678056029661915000, "dur": 17600000, "relative_dur": 0.015754121134869598, "relative_gap_to_previous": 0.03182332469243659, "parent_is_longest": false, "runtime_str": "17.6 ms"}}, "gpu5": {"time": {"ts": 1678056029661914000, "dur": 17608000, "relative_dur": 0.015761282099021813, "relative_gap_to_previous": 0.021913445426292196, "parent_is_longest": false, "runtime_str": "17.6 ms"}}}, "is_backward_op": true, "id": "fdVpnFXlQObjKjie", "pretty_name": "MaskConv", "trace_file": "/results/RNN/RNN.94.pt.trace.json", "trace_disk_size": "1.2 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 135376000, "runtime_str": "135 ms", "start_timestamp": "22:40:29.593.593786", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 10706}], "is_model_pass": "Backward", "idx": 37, "id": "m3xigFRPNjHemi6s", "pretty_name": "Backward", "trace_file": "/results/RNN/RNN.68.pt.trace.json", "trace_disk_size": "20.0 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "runtime": 1117168000, "runtime_str": "1.12 s", "start_timestamp": "22:40:28.665.665715", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 137351}, {"name": "Optimizer", "type": "training loop", "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056029618724000, "dur": 35497000, "relative_dur": 0.020688899496488708, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "35.5 ms"}}, "gpu3": {"time": {"ts": 1678056029783096000, "dur": 6382000, "relative_dur": 0.0037196539591117825, "relative_gap_to_previous": 5.828351549846103e-07, "parent_is_longest": true, "runtime_str": "6.38 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 88, in update_params\n    with hotline.annotate('Optimizer'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "source_file_num": 88, "ops": [{"name": "aten::add_(38%) and 9 others\u2026", "type": "generated", "generated_depth": 1, "instances": 185, "resources": {"cpu2": {"time": {"ts": 1678056029618725000, "dur": 3524000, "relative_dur": 0.0992759951545201, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3.52 ms"}}, "gpu3": {"time": {"ts": 1678056029783096000, "dur": 1692000, "relative_dur": 0.04766599994365721, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.69 ms"}}}, "ops": [{"name": "aten::sqrt(13%) and 9 others\u2026", "type": "generated", "generated_depth": 2, "instances": 94, "resources": {"cpu2": {"time": {"ts": 1678056029618725000, "dur": 1900000, "relative_dur": 0.5391600454029511, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.90 ms"}, "res_name": "aten::sqrt(13%) and 9 others\u2026"}, "gpu3": {"time": {"ts": 1678056029783096000, "dur": 625000, "relative_dur": 0.17735527809307605, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "625 us"}, "res_name": "vectorized_elementwise_kernel<4 addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4> addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4>(18%) and 6 others\u2026"}}, "id": "Sn98e1ihdxJs8mrq", "pretty_name": "aten::sqrt(13%) and 9 others\u2026", "trace_file": "/results/RNN/RNN.103.pt.trace.json", "trace_disk_size": "50.2 kB", "runtime": 1900000, "runtime_str": "1.90 ms", "start_timestamp": "22:40:29.618.618725", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 281}, {"name": "aten::add_", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056029620629000, "dur": 297000, "relative_dur": 0.08427922814982974, "relative_gap_to_previous": 0.0011350737797956867, "parent_is_longest": true, "runtime_str": "297 us"}}}, "ops": [{"name": "aten::copy_(67%) and 1 other\u2026", "type": "generated", "generated_depth": 3, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1678056029620920000, "dur": 4000, "relative_dur": 0.013468013468013467, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4 us"}, "res_name": "aten::copy_(67%) and 1 other\u2026"}}, "id": "9drAJTKDNpAkxGTQ", "pretty_name": "aten::copy_(67%) and 1 other\u2026", "trace_file": "/results/RNN/RNN.105.pt.trace.json", "trace_disk_size": "195 Bytes", "runtime": 4000, "runtime_str": "4 us", "start_timestamp": "22:40:29.620.620920", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}], "id": "sgDQLgOQSytMgDoe", "pretty_name": "aten::add_", "trace_file": "/results/RNN/RNN.104.pt.trace.json", "trace_disk_size": "475 Bytes", "runtime": 297000, "runtime_str": "297 us", "start_timestamp": "22:40:29.620.620629", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 5}, {"name": "aten::sqrt(13%) and 7 others\u2026", "type": "generated", "generated_depth": 2, "instances": 90, "resources": {"cpu2": {"time": {"ts": 1678056029620931000, "dur": 1318000, "relative_dur": 0.37400681044267875, "relative_gap_to_previous": 0.0014188422247446084, "parent_is_longest": true, "runtime_str": "1.32 ms"}, "res_name": "aten::sqrt(13%) and 7 others\u2026"}, "gpu3": {"time": {"ts": 1678056029783722000, "dur": 1066000, "relative_dur": 0.3024971623155505, "relative_gap_to_previous": 0.00028376844494892167, "parent_is_longest": true, "runtime_str": "1.07 ms"}, "res_name": "vectorized_elementwise_kernel<4 addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4> addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4>(18%) and 6 others\u2026"}}, "id": "uy1ToZPsdnZv17It", "pretty_name": "aten::sqrt(13%) and 7 others\u2026", "trace_file": "/results/RNN/RNN.106.pt.trace.json", "trace_disk_size": "48.8 kB", "runtime": 1318000, "runtime_str": "1.32 ms", "start_timestamp": "22:40:29.620.620931", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 271}], "id": "kpe7quCeC7YiuqKV", "pretty_name": "aten::add_(38%) and 9 others\u2026", "trace_file": "/results/RNN/RNN.102.pt.trace.json", "trace_disk_size": "99.5 kB", "runtime": 3524000, "runtime_str": "3.52 ms", "start_timestamp": "22:40:29.618.618725", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 557}, {"name": "aten::addcdiv_", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1678056029622253000, "dur": 25463000, "relative_dur": 0.7173282249204158, "relative_gap_to_previous": 0.00011268557906301941, "parent_is_longest": true, "runtime_str": "25.5 ms"}, "res_name": "aten::addcdiv_"}, "gpu3": {"time": {"ts": 1678056029784789000, "dur": 2000, "relative_dur": 5.634278953150971e-05, "relative_gap_to_previous": 2.8171394765754853e-05, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "vectorized_elementwise_kernel<4 addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4> addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4>"}}, "id": "nV9ctZS7fwjDpYKL", "pretty_name": "aten::addcdiv_", "trace_file": "/results/RNN/RNN.107.pt.trace.json", "trace_disk_size": "764 Bytes", "runtime": 25463000, "runtime_str": "25.5 ms", "start_timestamp": "22:40:29.622.622253", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::mul_(27%) and 7 others\u2026", "type": "generated", "generated_depth": 1, "instances": 425, "resources": {"cpu2": {"time": {"ts": 1678056029647722000, "dur": 6483000, "relative_dur": 0.1826351522663887, "relative_gap_to_previous": 0.0001690283685945291, "parent_is_longest": true, "runtime_str": "6.48 ms"}, "res_name": "aten::mul_(27%) and 7 others\u2026"}, "gpu3": {"time": {"ts": 1678056029784792000, "dur": 4686000, "relative_dur": 0.13201115587232723, "relative_gap_to_previous": 2.8171394765754853e-05, "parent_is_longest": true, "runtime_str": "4.69 ms"}, "res_name": "vectorized_elementwise_kernel<4 addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4> addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4>(18%) and 6 others\u2026"}}, "id": "AcR41ly15pn1wew6", "pretty_name": "aten::mul_(27%) and 7 others\u2026", "trace_file": "/results/RNN/RNN.108.pt.trace.json", "trace_disk_size": "228.0 kB", "runtime": 6483000, "runtime_str": "6.48 ms", "start_timestamp": "22:40:29.647.647722", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1271}], "idx": 38, "id": "INFOXsVCVQmEpkyr", "pretty_name": "Optimizer", "trace_file": "/results/RNN/RNN.101.pt.trace.json", "trace_disk_size": "328.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "runtime": 35497000, "runtime_str": "35.5 ms", "start_timestamp": "22:40:29.618.618724", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1832}], "resources": {"cpu11": {"time": {"ts": 1678056028665715000, "dur": 864790000, "parent_is_longest": false, "runtime_str": "865 ms"}}, "cpu2": {"time": {"ts": 1678056027807183000, "dur": 1715751000, "parent_is_longest": true, "runtime_str": "1.72 s"}}, "cpu6": {"time": {"ts": 1678056027992252000, "dur": 125065000, "parent_is_longest": false, "runtime_str": "125 ms"}}, "gpu10": {"time": {"ts": 1678056028452881000, "dur": 207446000, "parent_is_longest": false, "runtime_str": "207 ms"}}, "gpu12": {"time": {"ts": 1678056028790146000, "dur": 825115000, "parent_is_longest": false, "runtime_str": "825 ms"}}, "gpu13": {"time": {"ts": 1678056028790148000, "dur": 842668000, "parent_is_longest": false, "runtime_str": "843 ms"}}, "gpu14": {"time": {"ts": 1678056028835991000, "dur": 811717000, "parent_is_longest": false, "runtime_str": "812 ms"}}, "gpu15": {"time": {"ts": 1678056028836008000, "dur": 810963000, "parent_is_longest": false, "runtime_str": "811 ms"}}, "gpu3": {"time": {"ts": 1678056028260616000, "dur": 1528862000, "parent_is_longest": true, "runtime_str": "1.53 s"}}, "gpu4": {"time": {"ts": 1678056028825138000, "dur": 854377000, "parent_is_longest": false, "runtime_str": "854 ms"}}, "gpu5": {"time": {"ts": 1678056028830362000, "dur": 849160000, "parent_is_longest": false, "runtime_str": "849 ms"}}, "gpu7": {"time": {"ts": 1678056028358257000, "dur": 267965000, "parent_is_longest": false, "runtime_str": "268 ms"}}, "gpu8": {"time": {"ts": 1678056028358258000, "dur": 273341000, "parent_is_longest": false, "runtime_str": "273 ms"}}, "gpu9": {"time": {"ts": 1678056028452841000, "dur": 207369000, "parent_is_longest": false, "runtime_str": "207 ms"}}}, "source_file_name": "/home/ubuntu/algorithmic-efficiency/submission_runner.py", "source_file_num": 236, "id": "IXKS4QUjc9Z6V8ra", "pretty_name": "RNN Training Iteration", "total_accuracy_str": "98.41%", "trace_file": "/results/RNN/RNN.1.pt.trace.json", "trace_disk_size": "79.5 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/submission_runner.py", "config": {"trace_filepath": "/home/ubuntu/cpath/results/RNN.worker0.pt.trace.json", "output_dir": "/home/ubuntu/cpath/results", "ui_traces_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/RNN", "ui_model_path": "/home/ubuntu/cpath/results/ui/src/results/RNN.js", "results_summary_csv_filepath": "/home/ubuntu/cpath/results/results_summary.csv", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN", "run_name": "RNN", "model_name": "RNN", "backend": "torch", "test": false, "is_test_accuracy": true, "view_manual_annotations": false, "source_file_name": "/home/ubuntu/algorithmic-efficiency/submission_runner.py", "source_file_num": 236, "num_gpus": 1, "slice_idx": 0, "drop_flow_view": "", "last_found_was_fused": false, "count_sum_greater_than_1": 0, "count_sum_less_than_1": 0, "tiny_op_threshold": 0.05, "max_generated_depth": 2, "remove_slice_args": true, "write_model_ops_to_file": true, "op_idx": 1}, "metadata": {}, "metadata.model": "RNN", "metadata.dataset": "LibriSpeech", "metadata.batch_size": 64, "metadata.optimizer": "Adam", "trace_event_count": 217606, "pytorch_version": "1.13.1+cu117", "gpu_model": "NVIDIA GeForce RTX 3090", "gpu_cuda_version": "11.7", "hotline_traces_trace_disk_size": "155.1 MB", "hotline_annotation_count": "108", "processed_datetime": "05/03/2023 22:41:22", "runtime_without_profiling": "1.75 s \u00b11%", "runtime_with_profiling": "1.82 s \u00b10.3%", "runtime_profiling_overhead_factor": "0.04\u00d7 slower", "hotline_analysis_time": "23.8 s", "runtime": 1715751000, "runtime_str": "1.72 s", "start_timestamp": "22:40:27.807.807183", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2"}]