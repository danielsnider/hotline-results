[{"name": "RNN Training Iteration", "type": "root", "ops": [{"name": "Load Data", "type": "training loop", "instances": 36, "resources": {"cpu3": {"time": {"ts": 1677891892949087000, "dur": 492595000, "relative_dur": 0.28133366991675274, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "493 ms"}}, "cpu6": {"time": {"ts": 1677891893140623000, "dur": 134532000, "relative_dur": 0.07683468423601655, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "135 ms"}}, "gpu2": {"time": {"ts": 1677891893440809000, "dur": 7406000, "relative_dur": 0.0042297570202772476, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "7 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 256, in train_once\n    with hotline.annotate('Load Data'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/submission_runner.py", "source_file_num": 256, "ops": [{"name": "aten::randperm(57%) and 6 others\u2026", "type": "generated", "generated_depth": 1, "instances": 16, "resources": {"cpu3": {"time": {"ts": 1677891892949087000, "dur": 128260000, "relative_dur": 0.26037617109390065, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "128 ms"}, "res_name": "aten::randperm(57%) and 6 others\u2026"}}, "id": "mKk5mqPmeAUfN1fj", "pretty_name": "aten::randperm(57%) and 6 others\u2026", "trace_file": "/results/RNN/RNN.3.pt.trace.json", "trace_disk_size": "3.1 kB", "runtime": 128260000, "runtime_str": "128 ms", "start_timestamp": "01:04:52.949.949087", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 32}, {"name": "enumerateDataLoader#_MultiProcessingDataLoaderIter.__next__", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu3": {"time": {"ts": 1677891893077549000, "dur": 225421000, "relative_dur": 0.45761934246186015, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "225 ms"}, "res_name": "enumerateDataLoader#_MultiProcessingDataLoaderIter.__next__"}}, "id": "ZtlDYQkecD7i3m3E", "pretty_name": "enumerateDataLoader#_MultiProcessingDataLoaderIter.__next__", "trace_file": "/results/RNN/RNN.4.pt.trace.json", "trace_disk_size": "252 Bytes", "runtime": 225421000, "runtime_str": "225 ms", "start_timestamp": "01:04:53.077.77549", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 2}, {"name": "aten::to(99%) and 4 others\u2026", "type": "generated", "generated_depth": 1, "instances": 11, "resources": {"cpu3": {"time": {"ts": 1677891893435477000, "dur": 6205000, "relative_dur": 0.012596554979242582, "relative_gap_to_previous": 0.2547874014149555, "parent_is_longest": true, "runtime_str": "6 ms"}}, "gpu2": {"time": {"ts": 1677891893440809000, "dur": 7406000, "relative_dur": 0.015034663364427166, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "7 ms"}}}, "ops": [{"name": "aten::zeros(88%) and 1 other\u2026", "type": "generated", "generated_depth": 2, "instances": 2, "resources": {"cpu3": {"time": {"ts": 1677891893435477000, "dur": 57000, "relative_dur": 0.00769646232784229, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "57 us"}}}, "ops": [{"name": "aten::zeros", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu3": {"time": {"ts": 1677891893435477000, "dur": 30000, "relative_dur": 0.5263157894736842, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "30 us"}, "res_name": "aten::zeros"}}, "id": "wP6yC81Kna1cPMIO", "pretty_name": "aten::zeros", "trace_file": "/results/RNN/RNN.7.pt.trace.json", "trace_disk_size": "282 Bytes", "runtime": 30000, "runtime_str": "30 us", "start_timestamp": "01:04:53.435.435477", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 3}, {"name": "aten::empty", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu3": {"time": {"ts": 1677891893435530000, "dur": 4000, "relative_dur": 0.07017543859649122, "relative_gap_to_previous": 0.40350877192982454, "parent_is_longest": true, "runtime_str": "4 us"}, "res_name": "aten::empty"}}, "id": "0RgpNFg57hYNivy9", "pretty_name": "aten::empty", "trace_file": "/results/RNN/RNN.8.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 4000, "runtime_str": "4 us", "start_timestamp": "01:04:53.435.435530", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 1}], "id": "FFWUUc9fmU1JlN5w", "pretty_name": "aten::zeros(88%) and 1 other\u2026", "trace_file": "/results/RNN/RNN.6.pt.trace.json", "trace_disk_size": "375 Bytes", "runtime": 57000, "runtime_str": "57 us", "start_timestamp": "01:04:53.435.435477", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 4}, {"name": "aten::to", "type": "generated", "generated_depth": 2, "instances": 2, "resources": {"cpu3": {"time": {"ts": 1677891893435565000, "dur": 5073000, "relative_dur": 0.6849851471779638, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5 ms"}, "res_name": "aten::to"}, "gpu2": {"time": {"ts": 1677891893440809000, "dur": 6660000, "relative_dur": 0.8992708614636781, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "7 ms"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "r3yqs5BnnD4jfctP", "pretty_name": "aten::to", "trace_file": "/results/RNN/RNN.9.pt.trace.json", "trace_disk_size": "1.1 kB", "runtime": 6660000, "runtime_str": "7 ms", "start_timestamp": "01:04:53.435.435565", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 11}, {"name": "aten::to(81%) and 3 others\u2026", "type": "generated", "generated_depth": 2, "instances": 7, "resources": {"cpu3": {"time": {"ts": 1677891893447886000, "dur": 658000, "relative_dur": 0.0888468809073724, "relative_gap_to_previous": 0.03348636240885768, "parent_is_longest": true, "runtime_str": "658 us"}}, "gpu2": {"time": {"ts": 1677891893448063000, "dur": 152000, "relative_dur": 0.020523899540912775, "relative_gap_to_previous": 0.08020523899540913, "parent_is_longest": true, "runtime_str": "152 us"}}}, "ops": [{"name": "aten::to(86%) and 2 others\u2026", "type": "generated", "generated_depth": 3, "instances": 6, "resources": {"cpu3": {"time": {"ts": 1677891893447886000, "dur": 197000, "relative_dur": 0.2993920972644377, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "197 us"}, "res_name": "aten::to(86%) and 2 others\u2026"}, "gpu2": {"time": {"ts": 1677891893448063000, "dur": 152000, "relative_dur": 0.23100303951367782, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "152 us"}, "res_name": "Memcpy HtoD Pinned -> Device"}}, "id": "imd1fCukdnFZxPEn", "pretty_name": "aten::to(86%) and 2 others\u2026", "trace_file": "/results/RNN/RNN.11.pt.trace.json", "trace_disk_size": "2.0 kB", "runtime": 197000, "runtime_str": "197 us", "start_timestamp": "01:04:53.447.447886", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 20}, {"name": "aten::zeros", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu3": {"time": {"ts": 1677891893448664000, "dur": 18000, "relative_dur": 0.02735562310030395, "relative_gap_to_previous": 0.6732522796352584, "parent_is_longest": true, "runtime_str": "18 us"}, "res_name": "aten::zeros"}}, "id": "SbXiq1PSNw5ob7k5", "pretty_name": "aten::zeros", "trace_file": "/results/RNN/RNN.12.pt.trace.json", "trace_disk_size": "281 Bytes", "runtime": 18000, "runtime_str": "18 us", "start_timestamp": "01:04:53.448.448664", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 3}], "id": "zcBac9RpNf4AEtod", "pretty_name": "aten::to(81%) and 3 others\u2026", "trace_file": "/results/RNN/RNN.10.pt.trace.json", "trace_disk_size": "2.3 kB", "runtime": 658000, "runtime_str": "658 us", "start_timestamp": "01:04:53.447.447886", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 23}], "id": "PwlsHEKUI2WXa6yp", "pretty_name": "aten::to(99%) and 4 others\u2026", "trace_file": "/results/RNN/RNN.5.pt.trace.json", "trace_disk_size": "3.8 kB", "runtime": 7406000, "runtime_str": "7 ms", "start_timestamp": "01:04:53.435.435477", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 38}], "idx": 1, "id": "dPq24aCaHkN9emiS", "pretty_name": "Load Data", "trace_file": "/results/RNN/RNN.2.pt.trace.json", "trace_disk_size": "8.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/submission_runner.py", "runtime": 492595000, "runtime_str": "493 ms", "start_timestamp": "01:04:52.949.949087", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 80}, {"name": "Forward", "type": "training loop", "instances": 136, "resources": {"cpu3": {"time": {"ts": 1677891893448727000, "dur": 272905000, "relative_dur": 0.15586306233037567, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "273 ms"}}, "gpu10": {"time": {"ts": 1677891893633838000, "dur": 206632000, "relative_dur": 0.11801284804400866, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "207 ms"}}, "gpu2": {"time": {"ts": 1677891893449906000, "dur": 393195000, "relative_dur": 0.22456377418146262, "relative_gap_to_previous": 0.0009657735783538786, "parent_is_longest": true, "runtime_str": "393 ms"}}, "gpu7": {"time": {"ts": 1677891893540143000, "dur": 266655000, "relative_dur": 0.15229352663273418, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "267 ms"}}, "gpu8": {"time": {"ts": 1677891893540157000, "dur": 271918000, "relative_dur": 0.15529936125300411, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "272 ms"}}, "gpu9": {"time": {"ts": 1677891893633801000, "dur": 206595000, "relative_dur": 0.11799171639267862, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "207 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 74, in update_params\n    with hotline.annotate('Forward'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "source_file_num": 74, "ops": [{"idx": 3, "name": "MaskConv", "type": "MaskConv", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 179, in forward\n    with hotline.annotate('MaskConv'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 179, "ops": [{"idx": 4, "name": "Conv2d", "type": "Conv2d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu3": {"time": {"ts": 1677891893448729000, "dur": 2489000, "relative_dur": 0.017666515246152974, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu2": {"time": {"ts": 1677891893449906000, "dur": 12189000, "relative_dur": 0.08651553006643575, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12 ms"}}}, "id": "XTiyW3Rf2ajniA4t", "pretty_name": "Conv2d", "trace_file": "/results/RNN/RNN.15.pt.trace.json", "trace_disk_size": "12.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 12189000, "runtime_str": "12 ms", "start_timestamp": "01:04:53.448.448729", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 86}, {"idx": 5, "name": "BatchNorm2d", "type": "BatchNorm2d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu3": {"time": {"ts": 1677891893451247000, "dur": 13647000, "relative_dur": 0.0968641757992164, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "14 ms"}}, "gpu2": {"time": {"ts": 1677891893462101000, "dur": 23516000, "relative_dur": 0.16691272500141957, "relative_gap_to_previous": 4.258701947646357e-05, "parent_is_longest": true, "runtime_str": "24 ms"}}}, "id": "VMLgrUUOInnFS3Ac", "pretty_name": "BatchNorm2d", "trace_file": "/results/RNN/RNN.16.pt.trace.json", "trace_disk_size": "144.3 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 23516000, "runtime_str": "24 ms", "start_timestamp": "01:04:53.451.451247", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 1248}, {"idx": 6, "name": "Hardtanh", "type": "Hardtanh", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu3": {"time": {"ts": 1677891893480321000, "dur": 15443000, "relative_dur": 0.10961189029583783, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "15 ms"}}, "gpu2": {"time": {"ts": 1677891893490727000, "dur": 23371000, "relative_dur": 0.16588353869740502, "relative_gap_to_previous": 0.036269944920788146, "parent_is_longest": true, "runtime_str": "23 ms"}}}, "id": "DqhokMGlwZFbhLRR", "pretty_name": "Hardtanh", "trace_file": "/results/RNN/RNN.17.pt.trace.json", "trace_disk_size": "143.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 23371000, "runtime_str": "23 ms", "start_timestamp": "01:04:53.480.480321", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 1241}, {"idx": 7, "name": "Conv2d", "type": "Conv2d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu3": {"time": {"ts": 1677891893509215000, "dur": 21666000, "relative_dur": 0.15378172732950995, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "22 ms"}}, "gpu2": {"time": {"ts": 1677891893520138000, "dur": 39228000, "relative_dur": 0.27843393333711886, "relative_gap_to_previous": 0.04287093293964, "parent_is_longest": true, "runtime_str": "39 ms"}}, "gpu7": {"time": {"ts": 1677891893540143000, "dur": 18556000, "relative_dur": 0.131707455567543, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "19 ms"}}, "gpu8": {"time": {"ts": 1677891893540157000, "dur": 18551000, "relative_dur": 0.13167196638464596, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "19 ms"}}}, "id": "vSj7gfe5Te6F88An", "pretty_name": "Conv2d", "trace_file": "/results/RNN/RNN.18.pt.trace.json", "trace_disk_size": "577.3 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 39228000, "runtime_str": "39 ms", "start_timestamp": "01:04:53.509.509215", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 4187}, {"idx": 8, "name": "BatchNorm2d", "type": "BatchNorm2d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu3": {"time": {"ts": 1677891893544219000, "dur": 9008000, "relative_dur": 0.06393731190733065, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9 ms"}}, "gpu2": {"time": {"ts": 1677891893559370000, "dur": 14871000, "relative_dur": 0.10555192777241497, "relative_gap_to_previous": 2.8391346317642383e-05, "parent_is_longest": true, "runtime_str": "15 ms"}}}, "id": "lWqaicrWZ7Axv2ja", "pretty_name": "BatchNorm2d", "trace_file": "/results/RNN/RNN.19.pt.trace.json", "trace_disk_size": "144.3 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 14871000, "runtime_str": "15 ms", "start_timestamp": "01:04:53.544.544219", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 1248}, {"idx": 9, "name": "Hardtanh", "type": "Hardtanh", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu3": {"time": {"ts": 1677891893571840000, "dur": 8727000, "relative_dur": 0.061942819828516266, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9 ms"}}, "gpu2": {"time": {"ts": 1677891893576531000, "dur": 14263000, "relative_dur": 0.10123644313213333, "relative_gap_to_previous": 0.016254045766850266, "parent_is_longest": true, "runtime_str": "14 ms"}}}, "id": "cXrx0wFQaLbdNztf", "pretty_name": "Hardtanh", "trace_file": "/results/RNN/RNN.20.pt.trace.json", "trace_disk_size": "143.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 14263000, "runtime_str": "14 ms", "start_timestamp": "01:04:53.571.571840", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 1241}], "resources": {"cpu3": {"time": {"ts": 1677891893448729000, "dur": 71075000, "relative_dur": 0.18076272587393025, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "71 ms"}}, "gpu2": {"time": {"ts": 1677891893449906000, "dur": 140888000, "relative_dur": 0.3583158483704015, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "141 ms"}}, "gpu7": {"time": {"ts": 1677891893540143000, "dur": 18556000, "relative_dur": 0.04719286867839113, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "19 ms"}}, "gpu8": {"time": {"ts": 1677891893540157000, "dur": 18551000, "relative_dur": 0.0471801523417134, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "19 ms"}}}, "id": "hOA8qITHfTWWosxf", "pretty_name": "MaskConv", "trace_file": "/results/RNN/RNN.14.pt.trace.json", "trace_disk_size": "1.2 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 140888000, "runtime_str": "141 ms", "start_timestamp": "01:04:53.448.448729", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 9251}, {"idx": 10, "name": "BatchRNN-0", "type": "BatchRNN-0", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 190, in forward\n    with hotline.annotate(f'BatchRNN-{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 190, "ops": [{"idx": 11, "name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 101, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 101, "resources": {"cpu3": {"time": {"ts": 1677891893588473000, "dur": 44636000, "relative_dur": 0.6237911565766672, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "45 ms"}}, "gpu10": {"time": {"ts": 1677891893633838000, "dur": 29233000, "relative_dur": 0.4085331768125664, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "29 ms"}}, "gpu2": {"time": {"ts": 1677891893593277000, "dur": 23330000, "relative_dur": 0.3260383475879032, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "23 ms"}}, "gpu7": {"time": {"ts": 1677891893617082000, "dur": 8574000, "relative_dur": 0.11982223712896194, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "9 ms"}}, "gpu8": {"time": {"ts": 1677891893625480000, "dur": 8498000, "relative_dur": 0.11876013192464643, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "8 ms"}}, "gpu9": {"time": {"ts": 1677891893633801000, "dur": 29143000, "relative_dur": 0.4072754206495612, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "29 ms"}}}, "id": "XE8PsNxGcvxR4fsW", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.22.pt.trace.json", "trace_disk_size": "2.3 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 44636000, "runtime_str": "45 ms", "start_timestamp": "01:04:53.588.588473", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 13934}, {"idx": 12, "name": "Sum", "type": "Sum", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 108, in forward\n    with hotline.annotate('Sum'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 108, "resources": {"cpu3": {"time": {"ts": 1677891893650260000, "dur": 2017000, "relative_dur": 0.028187713119794285, "relative_gap_to_previous": 0.003381966571636201, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu2": {"time": {"ts": 1677891893663073000, "dur": 1760000, "relative_dur": 0.024596120520990552, "relative_gap_to_previous": 0.6493655318911062, "parent_is_longest": true, "runtime_str": "2 ms"}}}, "id": "KKypr5PGEkwBYTQ3", "pretty_name": "Sum", "trace_file": "/results/RNN/RNN.23.pt.trace.json", "trace_disk_size": "101.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 2017000, "runtime_str": "2 ms", "start_timestamp": "01:04:53.650.650260", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 610}], "resources": {"cpu3": {"time": {"ts": 1677891893588473000, "dur": 46943000, "relative_dur": 0.11938859853253475, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "47 ms"}}, "gpu10": {"time": {"ts": 1677891893633838000, "dur": 29233000, "relative_dur": 0.07434733402001552, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "29 ms"}}, "gpu2": {"time": {"ts": 1677891893593277000, "dur": 71556000, "relative_dur": 0.18198603746232786, "relative_gap_to_previous": 0.006314932794160658, "parent_is_longest": true, "runtime_str": "72 ms"}}, "gpu7": {"time": {"ts": 1677891893617082000, "dur": 8574000, "relative_dur": 0.021805974134971196, "relative_gap_to_previous": 0.14848357685118072, "parent_is_longest": false, "runtime_str": "9 ms"}}, "gpu8": {"time": {"ts": 1677891893625480000, "dur": 8498000, "relative_dur": 0.021612685817469703, "relative_gap_to_previous": 0.1698190465290759, "parent_is_longest": false, "runtime_str": "8 ms"}}, "gpu9": {"time": {"ts": 1677891893633801000, "dur": 29143000, "relative_dur": 0.07411843995981637, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "29 ms"}}}, "id": "9jfcm6dSb8OMIIw6", "pretty_name": "BatchRNN-0", "trace_file": "/results/RNN/RNN.21.pt.trace.json", "trace_disk_size": "2.4 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 71556000, "runtime_str": "72 ms", "start_timestamp": "01:04:53.588.588473", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 14544}, {"idx": 13, "name": "BatchRNN-1", "type": "BatchRNN-1", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 190, in forward\n    with hotline.annotate(f'BatchRNN-{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 190, "ops": [{"idx": 14, "name": "BatchNorm", "type": "BatchNorm", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('BatchNorm'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 98, "ops": [{"idx": 15, "name": "BatchNorm1d", "type": "BatchNorm1d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 99, in forward\n    x = self.batch_norm(x)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 33, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 33, "resources": {"cpu3": {"time": {"ts": 1677891893652330000, "dur": 958000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "958 us"}}, "gpu2": {"time": {"ts": 1677891893664834000, "dur": 783000, "relative_dur": 0.8173277661795407, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "783 us"}}}, "id": "joAD8dVQNo3MFXUG", "pretty_name": "BatchNorm1d", "trace_file": "/results/RNN/RNN.26.pt.trace.json", "trace_disk_size": "15.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 958000, "runtime_str": "958 us", "start_timestamp": "01:04:53.652.652330", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 137}], "resources": {"cpu3": {"time": {"ts": 1677891893652330000, "dur": 958000, "relative_dur": 0.021529541317392185, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "958 us"}}, "gpu2": {"time": {"ts": 1677891893664834000, "dur": 783000, "relative_dur": 0.017596691911814278, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "783 us"}}}, "id": "iAeMY6qIlPg2Ghz4", "pretty_name": "BatchNorm", "trace_file": "/results/RNN/RNN.25.pt.trace.json", "trace_disk_size": "15.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 958000, "runtime_str": "958 us", "start_timestamp": "01:04:53.652.652330", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 137}, {"idx": 16, "name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 101, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 101, "resources": {"cpu3": {"time": {"ts": 1677891893653349000, "dur": 34962000, "relative_dur": 0.785715890958941, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "35 ms"}}, "gpu10": {"time": {"ts": 1677891893678869000, "dur": 28697000, "relative_dur": 0.6449198822392521, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "29 ms"}}, "gpu2": {"time": {"ts": 1677891893665622000, "dur": 1909000, "relative_dur": 0.042901768658561254, "relative_gap_to_previous": 0.0001123671258736544, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu7": {"time": {"ts": 1677891893668156000, "dur": 5480000, "relative_dur": 0.12315436995752523, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5 ms"}}, "gpu8": {"time": {"ts": 1677891893673521000, "dur": 5426000, "relative_dur": 0.12194080499808976, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5 ms"}}, "gpu9": {"time": {"ts": 1677891893678835000, "dur": 28625000, "relative_dur": 0.6433017956266714, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "29 ms"}}}, "id": "NdJjofKYqg3yrUOs", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.27.pt.trace.json", "trace_disk_size": "2.2 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 34962000, "runtime_str": "35 ms", "start_timestamp": "01:04:53.653.653349", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 12594}, {"idx": 17, "name": "Sum", "type": "Sum", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 108, in forward\n    with hotline.annotate('Sum'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 108, "resources": {"cpu3": {"time": {"ts": 1677891893701018000, "dur": 1965000, "relative_dur": 0.04416028046834618, "relative_gap_to_previous": 0.005550936018158528, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu2": {"time": {"ts": 1677891893707568000, "dur": 1763000, "relative_dur": 0.03962064858305054, "relative_gap_to_previous": 0.8997685237207003, "parent_is_longest": true, "runtime_str": "2 ms"}}}, "id": "ltnfvbElSJczrOjC", "pretty_name": "Sum", "trace_file": "/results/RNN/RNN.28.pt.trace.json", "trace_disk_size": "101.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 1965000, "runtime_str": "2 ms", "start_timestamp": "01:04:53.701.701018", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 610}], "resources": {"cpu3": {"time": {"ts": 1677891893652330000, "dur": 38240000, "relative_dur": 0.09725454291127812, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "38 ms"}}, "gpu10": {"time": {"ts": 1677891893678869000, "dur": 28697000, "relative_dur": 0.07298414272816287, "relative_gap_to_previous": 0.04017853736695533, "parent_is_longest": false, "runtime_str": "29 ms"}}, "gpu2": {"time": {"ts": 1677891893664834000, "dur": 44497000, "relative_dur": 0.1131677666297893, "relative_gap_to_previous": 2.543267335545976e-06, "parent_is_longest": true, "runtime_str": "44 ms"}}, "gpu7": {"time": {"ts": 1677891893668156000, "dur": 5480000, "relative_dur": 0.013937104998791947, "relative_gap_to_previous": 0.10808886176070398, "parent_is_longest": false, "runtime_str": "5 ms"}}, "gpu8": {"time": {"ts": 1677891893673521000, "dur": 5426000, "relative_dur": 0.013799768562672465, "relative_gap_to_previous": 0.10056842024949453, "parent_is_longest": false, "runtime_str": "5 ms"}}, "gpu9": {"time": {"ts": 1677891893678835000, "dur": 28625000, "relative_dur": 0.07280102748000356, "relative_gap_to_previous": 0.0404150612291611, "parent_is_longest": false, "runtime_str": "29 ms"}}}, "id": "msN6UFQK08inh2dt", "pretty_name": "BatchRNN-1", "trace_file": "/results/RNN/RNN.24.pt.trace.json", "trace_disk_size": "2.3 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 44497000, "runtime_str": "44 ms", "start_timestamp": "01:04:53.652.652330", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 13341}, {"idx": 18, "name": "BatchRNN-2", "type": "BatchRNN-2", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 190, in forward\n    with hotline.annotate(f'BatchRNN-{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 190, "ops": [{"idx": 19, "name": "BatchNorm", "type": "BatchNorm", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('BatchNorm'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 98, "ops": [{"idx": 20, "name": "BatchNorm1d", "type": "BatchNorm1d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 99, in forward\n    x = self.batch_norm(x)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 33, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 33, "resources": {"cpu3": {"time": {"ts": 1677891893703035000, "dur": 896000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "896 us"}}, "gpu2": {"time": {"ts": 1677891893709333000, "dur": 783000, "relative_dur": 0.8738839285714286, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "783 us"}}}, "id": "KC9Ch0mHPIfA8TXB", "pretty_name": "BatchNorm1d", "trace_file": "/results/RNN/RNN.31.pt.trace.json", "trace_disk_size": "14.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 896000, "runtime_str": "896 us", "start_timestamp": "01:04:53.703.703035", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 137}], "resources": {"cpu3": {"time": {"ts": 1677891893703035000, "dur": 896000, "relative_dur": 0.02010546392909234, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "896 us"}}, "gpu2": {"time": {"ts": 1677891893709333000, "dur": 783000, "relative_dur": 0.01756984180410636, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "783 us"}}}, "id": "47o39HrkI2i3V3Lc", "pretty_name": "BatchNorm", "trace_file": "/results/RNN/RNN.30.pt.trace.json", "trace_disk_size": "14.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 896000, "runtime_str": "896 us", "start_timestamp": "01:04:53.703.703035", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 137}, {"idx": 21, "name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 101, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 101, "resources": {"cpu3": {"time": {"ts": 1677891893703982000, "dur": 34327000, "relative_dur": 0.7702681476495007, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "34 ms"}}, "gpu10": {"time": {"ts": 1677891893723269000, "dur": 28864000, "relative_dur": 0.647683159430046, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "29 ms"}}, "gpu2": {"time": {"ts": 1677891893710117000, "dur": 1782000, "relative_dur": 0.03998653651969034, "relative_gap_to_previous": 2.2439133849433412e-05, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu7": {"time": {"ts": 1677891893712460000, "dur": 5491000, "relative_dur": 0.12321328396723887, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5 ms"}}, "gpu8": {"time": {"ts": 1677891893717857000, "dur": 5490000, "relative_dur": 0.12319084483338943, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5 ms"}}, "gpu9": {"time": {"ts": 1677891893723234000, "dur": 28712000, "relative_dur": 0.6442724110849322, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "29 ms"}}}, "id": "cpZAx3stlBrNjt2Y", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.32.pt.trace.json", "trace_disk_size": "2.2 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 34327000, "runtime_str": "34 ms", "start_timestamp": "01:04:53.703.703982", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 12594}, {"idx": 22, "name": "Sum", "type": "Sum", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 108, in forward\n    with hotline.annotate('Sum'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 108, "resources": {"cpu3": {"time": {"ts": 1677891893744718000, "dur": 1992000, "relative_dur": 0.04469875462807136, "relative_gap_to_previous": 0.0022214742510939076, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu2": {"time": {"ts": 1677891893752134000, "dur": 1764000, "relative_dur": 0.039582632110400535, "relative_gap_to_previous": 0.9028385504319534, "parent_is_longest": true, "runtime_str": "2 ms"}}}, "id": "CvC0wnBcCFO2qmsN", "pretty_name": "Sum", "trace_file": "/results/RNN/RNN.33.pt.trace.json", "trace_disk_size": "101.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 1992000, "runtime_str": "2 ms", "start_timestamp": "01:04:53.744.744718", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 610}], "resources": {"cpu3": {"time": {"ts": 1677891893703035000, "dur": 37413000, "relative_dur": 0.09515126082478159, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "37 ms"}}, "gpu10": {"time": {"ts": 1677891893723269000, "dur": 28864000, "relative_dur": 0.07340886837319904, "relative_gap_to_previous": 0.03993692697007846, "parent_is_longest": false, "runtime_str": "29 ms"}}, "gpu2": {"time": {"ts": 1677891893709333000, "dur": 44565000, "relative_dur": 0.11334070880860642, "relative_gap_to_previous": 5.086534671091952e-06, "parent_is_longest": true, "runtime_str": "45 ms"}}, "gpu7": {"time": {"ts": 1677891893712460000, "dur": 5491000, "relative_dur": 0.013965080939482954, "relative_gap_to_previous": 0.09873981103523696, "parent_is_longest": false, "runtime_str": "5 ms"}}, "gpu8": {"time": {"ts": 1677891893717857000, "dur": 5490000, "relative_dur": 0.013962537672147408, "relative_gap_to_previous": 0.09895853202609392, "parent_is_longest": false, "runtime_str": "5 ms"}}, "gpu9": {"time": {"ts": 1677891893723234000, "dur": 28712000, "relative_dur": 0.07302229173819606, "relative_gap_to_previous": 0.040117498950902226, "parent_is_longest": false, "runtime_str": "29 ms"}}}, "id": "FqoajKS2rCwuY1Ov", "pretty_name": "BatchRNN-2", "trace_file": "/results/RNN/RNN.29.pt.trace.json", "trace_disk_size": "2.3 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 44565000, "runtime_str": "45 ms", "start_timestamp": "01:04:53.703.703035", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 13341}, {"idx": 23, "name": "BatchRNN-3", "type": "BatchRNN-3", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 190, in forward\n    with hotline.annotate(f'BatchRNN-{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 190, "ops": [{"idx": 24, "name": "BatchNorm", "type": "BatchNorm", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('BatchNorm'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 98, "ops": [{"idx": 25, "name": "BatchNorm1d", "type": "BatchNorm1d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 99, in forward\n    x = self.batch_norm(x)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 33, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 33, "resources": {"cpu3": {"time": {"ts": 1677891893746762000, "dur": 939000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "939 us"}}, "gpu2": {"time": {"ts": 1677891893753900000, "dur": 787000, "relative_dur": 0.838125665601704, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "787 us"}}}, "id": "2HhmlYETeWtkgX9V", "pretty_name": "BatchNorm1d", "trace_file": "/results/RNN/RNN.36.pt.trace.json", "trace_disk_size": "14.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 939000, "runtime_str": "939 us", "start_timestamp": "01:04:53.746.746762", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 137}], "resources": {"cpu3": {"time": {"ts": 1677891893746762000, "dur": 939000, "relative_dur": 0.021200695400871508, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "939 us"}}, "gpu2": {"time": {"ts": 1677891893753900000, "dur": 787000, "relative_dur": 0.017768846944074417, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "787 us"}}}, "id": "o7OYSVcSOcnJPvjI", "pretty_name": "BatchNorm", "trace_file": "/results/RNN/RNN.35.pt.trace.json", "trace_disk_size": "14.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 939000, "runtime_str": "939 us", "start_timestamp": "01:04:53.746.746762", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 137}, {"idx": 26, "name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 101, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 101, "resources": {"cpu3": {"time": {"ts": 1677891893747752000, "dur": 35180000, "relative_dur": 0.7942922941455375, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "35 ms"}}, "gpu10": {"time": {"ts": 1677891893767762000, "dur": 28663000, "relative_dur": 0.6471517915603622, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "29 ms"}}, "gpu2": {"time": {"ts": 1677891893754690000, "dur": 1759000, "relative_dur": 0.03971461470727687, "relative_gap_to_previous": 6.773385112099524e-05, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu7": {"time": {"ts": 1677891893757076000, "dur": 5444000, "relative_dur": 0.12291436183423268, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5 ms"}}, "gpu8": {"time": {"ts": 1677891893762417000, "dur": 5410000, "relative_dur": 0.12214671152152808, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5 ms"}}, "gpu9": {"time": {"ts": 1677891893767725000, "dur": 28567000, "relative_dur": 0.6449843083244903, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "29 ms"}}}, "id": "qnUNO1xC6KhuV84U", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.37.pt.trace.json", "trace_disk_size": "2.2 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 35180000, "runtime_str": "35 ms", "start_timestamp": "01:04:53.747.747752", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 12594}, {"idx": 27, "name": "Sum", "type": "Sum", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 108, in forward\n    with hotline.annotate('Sum'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 108, "resources": {"cpu3": {"time": {"ts": 1677891893790135000, "dur": 1984000, "relative_dur": 0.044794653541351516, "relative_gap_to_previous": 0.0017836580795195412, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu2": {"time": {"ts": 1677891893796426000, "dur": 1765000, "relative_dur": 0.039850082409518865, "relative_gap_to_previous": 0.9025987220880088, "parent_is_longest": true, "runtime_str": "2 ms"}}}, "id": "37sgk0AM9Lg9OnkC", "pretty_name": "Sum", "trace_file": "/results/RNN/RNN.38.pt.trace.json", "trace_disk_size": "101.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 1984000, "runtime_str": "2 ms", "start_timestamp": "01:04:53.790.790135", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 610}], "resources": {"cpu3": {"time": {"ts": 1677891893746762000, "dur": 38279000, "relative_dur": 0.09735373033736441, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "38 ms"}}, "gpu10": {"time": {"ts": 1677891893767762000, "dur": 28663000, "relative_dur": 0.07289767163875431, "relative_gap_to_previous": 0.039748725187248056, "parent_is_longest": false, "runtime_str": "29 ms"}}, "gpu2": {"time": {"ts": 1677891893753900000, "dur": 44291000, "relative_dur": 0.11264385355866682, "relative_gap_to_previous": 5.086534671091952e-06, "parent_is_longest": true, "runtime_str": "44 ms"}}, "gpu7": {"time": {"ts": 1677891893757076000, "dur": 5444000, "relative_dur": 0.013845547374712292, "relative_gap_to_previous": 0.09950533450323631, "parent_is_longest": false, "runtime_str": "5 ms"}}, "gpu8": {"time": {"ts": 1677891893762417000, "dur": 5410000, "relative_dur": 0.013759076285303729, "relative_gap_to_previous": 0.09936545479978127, "parent_is_longest": false, "runtime_str": "5 ms"}}, "gpu9": {"time": {"ts": 1677891893767725000, "dur": 28567000, "relative_dur": 0.07265351797454189, "relative_gap_to_previous": 0.04013021528757996, "parent_is_longest": false, "runtime_str": "29 ms"}}}, "id": "0qRMlcSeevEpcbZ8", "pretty_name": "BatchRNN-3", "trace_file": "/results/RNN/RNN.34.pt.trace.json", "trace_disk_size": "2.3 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 44291000, "runtime_str": "44 ms", "start_timestamp": "01:04:53.746.746762", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 13341}, {"idx": 28, "name": "BatchRNN-4", "type": "BatchRNN-4", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 190, in forward\n    with hotline.annotate(f'BatchRNN-{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 190, "ops": [{"idx": 29, "name": "BatchNorm", "type": "BatchNorm", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('BatchNorm'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 98, "ops": [{"idx": 30, "name": "BatchNorm1d", "type": "BatchNorm1d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 99, in forward\n    x = self.batch_norm(x)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 33, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 33, "resources": {"cpu3": {"time": {"ts": 1677891893792169000, "dur": 895000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "895 us"}}, "gpu2": {"time": {"ts": 1677891893798193000, "dur": 789000, "relative_dur": 0.8815642458100559, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "789 us"}}}, "id": "fsTM6tICf3HZ955I", "pretty_name": "BatchNorm1d", "trace_file": "/results/RNN/RNN.41.pt.trace.json", "trace_disk_size": "14.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 895000, "runtime_str": "895 us", "start_timestamp": "01:04:53.792.792169", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 137}], "resources": {"cpu3": {"time": {"ts": 1677891893792169000, "dur": 895000, "relative_dur": 0.020323357100685772, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "895 us"}}, "gpu2": {"time": {"ts": 1677891893798193000, "dur": 789000, "relative_dur": 0.017916344974794496, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "789 us"}}}, "id": "cytEJdbZkyIwJygu", "pretty_name": "BatchNorm", "trace_file": "/results/RNN/RNN.40.pt.trace.json", "trace_disk_size": "14.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 895000, "runtime_str": "895 us", "start_timestamp": "01:04:53.792.792169", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 137}, {"idx": 31, "name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 101, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 101, "resources": {"cpu3": {"time": {"ts": 1677891893793116000, "dur": 35258000, "relative_dur": 0.8006267314591944, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "35 ms"}}, "gpu10": {"time": {"ts": 1677891893812000000, "dur": 28470000, "relative_dur": 0.6464871247558927, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "28 ms"}}, "gpu2": {"time": {"ts": 1677891893798990000, "dur": 1724000, "relative_dur": 0.03914800853808075, "relative_gap_to_previous": 0.0001816612925200963, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu7": {"time": {"ts": 1677891893801357000, "dur": 5441000, "relative_dur": 0.12355238657523049, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5 ms"}}, "gpu8": {"time": {"ts": 1677891893806686000, "dur": 5389000, "relative_dur": 0.12237158817384985, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5 ms"}}, "gpu9": {"time": {"ts": 1677891893811965000, "dur": 28431000, "relative_dur": 0.6456015259548572, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "28 ms"}}}, "id": "IH5NRbMv7p0OKk8L", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.42.pt.trace.json", "trace_disk_size": "2.2 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 35258000, "runtime_str": "35 ms", "start_timestamp": "01:04:53.793.793116", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 12594}, {"idx": 32, "name": "Sum", "type": "Sum", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 108, in forward\n    with hotline.annotate('Sum'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 108, "resources": {"cpu3": {"time": {"ts": 1677891893834511000, "dur": 2021000, "relative_dur": 0.045892184022889325, "relative_gap_to_previous": 0.0016349516326808666, "parent_is_longest": true, "runtime_str": "2 ms"}}, "gpu2": {"time": {"ts": 1677891893840470000, "dur": 1761000, "relative_dur": 0.03998819201598619, "relative_gap_to_previous": 0.9027657931786185, "parent_is_longest": true, "runtime_str": "2 ms"}}}, "id": "eTYsToL399eVsihu", "pretty_name": "Sum", "trace_file": "/results/RNN/RNN.43.pt.trace.json", "trace_disk_size": "101.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 2021000, "runtime_str": "2 ms", "start_timestamp": "01:04:53.834.834511", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 610}], "resources": {"cpu3": {"time": {"ts": 1677891893792169000, "dur": 38348000, "relative_dur": 0.09752921578351709, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "38 ms"}}, "gpu10": {"time": {"ts": 1677891893812000000, "dur": 28470000, "relative_dur": 0.07240682104299394, "relative_gap_to_previous": 0.03961138875112857, "parent_is_longest": false, "runtime_str": "28 ms"}}, "gpu2": {"time": {"ts": 1677891893798193000, "dur": 44038000, "relative_dur": 0.11200040692277369, "relative_gap_to_previous": 5.086534671091952e-06, "parent_is_longest": true, "runtime_str": "44 ms"}}, "gpu7": {"time": {"ts": 1677891893801357000, "dur": 5441000, "relative_dur": 0.013837917572705655, "relative_gap_to_previous": 0.09877287351059906, "parent_is_longest": false, "runtime_str": "5 ms"}}, "gpu8": {"time": {"ts": 1677891893806686000, "dur": 5389000, "relative_dur": 0.013705667671257265, "relative_gap_to_previous": 0.09882882539198108, "parent_is_longest": false, "runtime_str": "5 ms"}}, "gpu9": {"time": {"ts": 1677891893811965000, "dur": 28431000, "relative_dur": 0.07230763361690765, "relative_gap_to_previous": 0.03986062895001208, "parent_is_longest": false, "runtime_str": "28 ms"}}}, "id": "ND8Q3IuRvWM1u5Bl", "pretty_name": "BatchRNN-4", "trace_file": "/results/RNN/RNN.39.pt.trace.json", "trace_disk_size": "2.3 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 44038000, "runtime_str": "44 ms", "start_timestamp": "01:04:53.792.792169", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 13341}, {"idx": 33, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 193, in forward\n    with hotline.annotate('Linear'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 193, "resources": {"cpu3": {"time": {"ts": 1677891893836587000, "dur": 417000, "relative_dur": 0.001060542478922672, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "417 us"}}, "gpu2": {"time": {"ts": 1677891893842232000, "dur": 853000, "relative_dur": 0.0021694070372207173, "relative_gap_to_previous": 2.543267335545976e-06, "parent_is_longest": true, "runtime_str": "853 us"}}}, "id": "sQFWP139Kbi6CzrC", "pretty_name": "Linear", "trace_file": "/results/RNN/RNN.44.pt.trace.json", "trace_disk_size": "5.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 853000, "runtime_str": "853 us", "start_timestamp": "01:04:53.836.836587", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 39}, {"idx": 34, "name": "SoftMax", "type": "SoftMax", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 197, in forward\n    with hotline.annotate('SoftMax'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 197, "resources": {"cpu3": {"time": {"ts": 1677891893837011000, "dur": 178000, "relative_dur": 0.00045270158572718373, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "178 us"}}, "gpu2": {"time": {"ts": 1677891893843086000, "dur": 15000, "relative_dur": 3.814901003318964e-05, "relative_gap_to_previous": 2.543267335545976e-06, "parent_is_longest": true, "runtime_str": "15 us"}}}, "id": "yhmlc9H2GOOHPR2J", "pretty_name": "SoftMax", "trace_file": "/results/RNN/RNN.45.pt.trace.json", "trace_disk_size": "1.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 178000, "runtime_str": "178 us", "start_timestamp": "01:04:53.837.837011", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 9}], "is_model_pass": "Forward", "idx": 2, "id": "iMdEukB26qlNhdLC", "pretty_name": "Forward", "trace_file": "/results/RNN/RNN.13.pt.trace.json", "trace_disk_size": "12.8 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "runtime": 393195000, "runtime_str": "393 ms", "start_timestamp": "01:04:53.448.448727", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 77988}, {"name": "Calc Loss", "type": "training loop", "instances": 9, "resources": {"cpu3": {"time": {"ts": 1677891893839178000, "dur": 407000, "relative_dur": 0.00023244816463041312, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "407 us"}}, "gpu2": {"time": {"ts": 1677891893843110000, "dur": 724000, "relative_dur": 0.00041349501521478895, "relative_gap_to_previous": 5.1401314046037305e-06, "parent_is_longest": true, "runtime_str": "724 us"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 79, in update_params\n    with hotline.annotate('Calc Loss'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "source_file_num": 79, "ops": [{"name": "aten::to(97%) and 2 others\u2026", "type": "generated", "generated_depth": 2, "instances": 5, "resources": {"cpu3": {"time": {"ts": 1677891893839180000, "dur": 179000, "relative_dur": 0.2472375690607735, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "179 us"}, "res_name": "aten::to(97%) and 2 others\u2026"}, "gpu2": {"time": {"ts": 1677891893843110000, "dur": 645000, "relative_dur": 0.8908839779005525, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "645 us"}, "res_name": "ctc_loss_log_alpha_gpu_kernellong>  const long const long long const long const long  long long long long long long long const long long long(98%) and 3 others\u2026"}}, "id": "RSDYEE2yGLHG7RCw", "pretty_name": "aten::to(97%) and 2 others\u2026", "trace_file": "/results/RNN/RNN.47.pt.trace.json", "trace_disk_size": "5.7 kB", "runtime": 645000, "runtime_str": "645 us", "start_timestamp": "01:04:53.839.839180", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 55}, {"name": "aten::to", "type": "generated", "generated_depth": 1, "instances": 2, "resources": {"cpu3": {"time": {"ts": 1677891893843304000, "dur": 27000, "relative_dur": 0.03729281767955801, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "27 us"}, "res_name": "aten::to"}, "gpu2": {"time": {"ts": 1677891893843756000, "dur": 0, "relative_dur": 0.0, "relative_gap_to_previous": 0.0013812154696132596, "parent_is_longest": true, "runtime_str": "0 us"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "9fPHXDGrPisZBYPQ", "pretty_name": "aten::to", "trace_file": "/results/RNN/RNN.48.pt.trace.json", "trace_disk_size": "1.1 kB", "runtime": 27000, "runtime_str": "27 us", "start_timestamp": "01:04:53.843.843304", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 11}, {"name": "aten::mean(48%) and 4 others\u2026", "type": "generated", "generated_depth": 1, "instances": 6, "resources": {"cpu3": {"time": {"ts": 1677891893843765000, "dur": 188000, "relative_dur": 0.2596685082872928, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "188 us"}}, "gpu2": {"time": {"ts": 1677891893843793000, "dur": 41000, "relative_dur": 0.05662983425414365, "relative_gap_to_previous": 0.05110497237569061, "parent_is_longest": true, "runtime_str": "41 us"}}}, "ops": [{"name": "aten::div", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu3": {"time": {"ts": 1677891893843765000, "dur": 28000, "relative_dur": 0.14893617021276595, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "28 us"}, "res_name": "aten::div"}, "gpu2": {"time": {"ts": 1677891893843793000, "dur": 2000, "relative_dur": 0.010638297872340425, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "vectorized_elementwise_kernel<4 BinaryFunctor  binary_ernal::DivFunctor Array<char 3> BinaryFunctor  binary_ernal::DivFunctor Array<char 3>"}}, "id": "gILkjhJJwysa534H", "pretty_name": "aten::div", "trace_file": "/results/RNN/RNN.50.pt.trace.json", "trace_disk_size": "587 Bytes", "runtime": 28000, "runtime_str": "28 us", "start_timestamp": "01:04:53.843.843765", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 3}, {"name": "aten::mean", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu3": {"time": {"ts": 1677891893843799000, "dur": 34000, "relative_dur": 0.18085106382978725, "relative_gap_to_previous": 0.031914893617021274, "parent_is_longest": true, "runtime_str": "34 us"}}, "gpu2": {"time": {"ts": 1677891893843831000, "dur": 3000, "relative_dur": 0.015957446808510637, "relative_gap_to_previous": 0.19148936170212766, "parent_is_longest": true, "runtime_str": "3 us"}}}, "ops": [{"name": "aten::as_strided", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu3": {"time": {"ts": 1677891893843809000, "dur": 1000, "relative_dur": 0.029411764705882353, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::as_strided"}}, "id": "1ecslSvanCvVxfce", "pretty_name": "aten::as_strided", "trace_file": "/results/RNN/RNN.52.pt.trace.json", "trace_disk_size": "99 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "01:04:53.843.843809", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 1}, {"name": "cudaLaunchKernel", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu3": {"time": {"ts": 1677891893843820000, "dur": 10000, "relative_dur": 0.29411764705882354, "relative_gap_to_previous": 0.29411764705882354, "parent_is_longest": true, "runtime_str": "10 us"}, "res_name": "cudaLaunchKernel"}, "gpu2": {"time": {"ts": 1677891893843831000, "dur": 3000, "relative_dur": 0.08823529411764706, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "3 us"}, "res_name": "reduce_kernel<512 1 ReduceOpMeanOps>    4>ReduceOpMeanOps>    4>"}}, "id": "GNyLsUCgu1gSnk92", "pretty_name": "cudaLaunchKernel", "trace_file": "/results/RNN/RNN.53.pt.trace.json", "trace_disk_size": "403 Bytes", "runtime": 10000, "runtime_str": "10 us", "start_timestamp": "01:04:53.843.843820", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 2}], "id": "yGXQ2ZYx5d2UHc29", "pretty_name": "aten::mean", "trace_file": "/results/RNN/RNN.51.pt.trace.json", "trace_disk_size": "687 Bytes", "runtime": 34000, "runtime_str": "34 us", "start_timestamp": "01:04:53.843.843799", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 5}, {"name": "aten::zeros(89%) and 2 others\u2026", "type": "generated", "generated_depth": 2, "instances": 4, "resources": {"cpu3": {"time": {"ts": 1677891893843924000, "dur": 29000, "relative_dur": 0.15425531914893617, "relative_gap_to_previous": 0.48404255319148937, "parent_is_longest": true, "runtime_str": "29 us"}}}, "ops": [{"name": "aten::zeros", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu3": {"time": {"ts": 1677891893843924000, "dur": 6000, "relative_dur": 0.20689655172413793, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "6 us"}, "res_name": "aten::zeros"}}, "id": "UwuzTCnitzV4yuLx", "pretty_name": "aten::zeros", "trace_file": "/results/RNN/RNN.55.pt.trace.json", "trace_disk_size": "280 Bytes", "runtime": 6000, "runtime_str": "6 us", "start_timestamp": "01:04:53.843.843924", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 3}, {"name": "aten::empty", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu3": {"time": {"ts": 1677891893843937000, "dur": 1000, "relative_dur": 0.034482758620689655, "relative_gap_to_previous": 0.2413793103448276, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::empty"}}, "id": "uhOqMW68PsqMg4q6", "pretty_name": "aten::empty", "trace_file": "/results/RNN/RNN.56.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "01:04:53.843.843937", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 1}, {"name": "aten::zeros", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu3": {"time": {"ts": 1677891893843951000, "dur": 2000, "relative_dur": 0.06896551724137931, "relative_gap_to_previous": 0.4482758620689655, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "aten::zeros"}}, "id": "Dv1WbZE55RKAVz4M", "pretty_name": "aten::zeros", "trace_file": "/results/RNN/RNN.57.pt.trace.json", "trace_disk_size": "187 Bytes", "runtime": 2000, "runtime_str": "2 us", "start_timestamp": "01:04:53.843.843951", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 2}, {"name": "aten::zero_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu3": {"time": {"ts": 1677891893843953000, "dur": 0, "relative_dur": 0.0, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "0 us"}, "res_name": "aten::zero_"}}, "id": "eEUDEILQevIOyP8z", "pretty_name": "aten::zero_", "trace_file": "/results/RNN/RNN.58.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 0, "runtime_str": "0 us", "start_timestamp": "01:04:53.843.843953", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 1}], "id": "VoBkruHdHjbCKAer", "pretty_name": "aten::zeros(89%) and 2 others\u2026", "trace_file": "/results/RNN/RNN.54.pt.trace.json", "trace_disk_size": "652 Bytes", "runtime": 29000, "runtime_str": "29 us", "start_timestamp": "01:04:53.843.843924", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 7}], "id": "8fqhied6lt9f3Chv", "pretty_name": "aten::mean(48%) and 4 others\u2026", "trace_file": "/results/RNN/RNN.49.pt.trace.json", "trace_disk_size": "1.9 kB", "runtime": 188000, "runtime_str": "188 us", "start_timestamp": "01:04:53.843.843765", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 15}], "idx": 35, "id": "RtNEQnHcyHsUxNr0", "pretty_name": "Calc Loss", "trace_file": "/results/RNN/RNN.46.pt.trace.json", "trace_disk_size": "8.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "runtime": 724000, "runtime_str": "724 us", "start_timestamp": "01:04:53.839.839178", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 82}, {"name": "Zero Grad", "type": "training loop", "instances": 4, "resources": {"cpu3": {"time": {"ts": 1677891893843957000, "dur": 1081000, "relative_dur": 0.0006173868942640703, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 ms"}}, "gpu2": {"time": {"ts": 1677891893843993000, "dur": 1046000, "relative_dur": 0.0005973974943572779, "relative_gap_to_previous": 9.080898814799923e-05, "parent_is_longest": true, "runtime_str": "1 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 82, in update_params\n    with hotline.annotate('Zero Grad'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "source_file_num": 82, "ops": [{"name": "aten::zero_(100%) and 1 other\u2026", "type": "generated", "generated_depth": 2, "instances": 60, "resources": {"cpu3": {"time": {"ts": 1677891893843957000, "dur": 932000, "relative_dur": 0.8621646623496763, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "932 us"}, "res_name": "aten::zero_(100%) and 1 other\u2026"}, "gpu2": {"time": {"ts": 1677891893843993000, "dur": 897000, "relative_dur": 0.8297872340425532, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "897 us"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>"}}, "id": "oJIpTJd5Ai9AyxBp", "pretty_name": "aten::zero_(100%) and 1 other\u2026", "trace_file": "/results/RNN/RNN.60.pt.trace.json", "trace_disk_size": "32.6 kB", "runtime": 932000, "runtime_str": "932 us", "start_timestamp": "01:04:53.843.843957", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 237}, {"name": "aten::ones_like(84%) and 2 others\u2026", "type": "generated", "generated_depth": 1, "instances": 3, "resources": {"cpu3": {"time": {"ts": 1677891893844973000, "dur": 65000, "relative_dur": 0.060129509713228495, "relative_gap_to_previous": 0.07770582793709528, "parent_is_longest": true, "runtime_str": "65 us"}}, "gpu2": {"time": {"ts": 1677891893845038000, "dur": 1000, "relative_dur": 0.0009250693802035153, "relative_gap_to_previous": 0.13691026827012026, "parent_is_longest": true, "runtime_str": "1 us"}}}, "ops": [{"name": "aten::zeros", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu3": {"time": {"ts": 1677891893844973000, "dur": 5000, "relative_dur": 0.07692307692307693, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5 us"}}}, "ops": [{"name": "aten::empty", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu3": {"time": {"ts": 1677891893844975000, "dur": 1000, "relative_dur": 0.2, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::empty"}}, "id": "JwZhM68DgGSei8SV", "pretty_name": "aten::empty", "trace_file": "/results/RNN/RNN.63.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "01:04:53.844.844975", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 1}, {"name": "aten::zero_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu3": {"time": {"ts": 1677891893844977000, "dur": 1000, "relative_dur": 0.2, "relative_gap_to_previous": 0.2, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "aten::zero_"}}, "id": "fBncM7LtJcskO43t", "pretty_name": "aten::zero_", "trace_file": "/results/RNN/RNN.64.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 1000, "runtime_str": "1 us", "start_timestamp": "01:04:53.844.844977", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 1}], "id": "Y40s2qQ5ne0ym2tQ", "pretty_name": "aten::zeros", "trace_file": "/results/RNN/RNN.62.pt.trace.json", "trace_disk_size": "280 Bytes", "runtime": 5000, "runtime_str": "5 us", "start_timestamp": "01:04:53.844.844973", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 3}, {"name": "aten::empty", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu3": {"time": {"ts": 1677891893844985000, "dur": 0, "relative_dur": 0.0, "relative_gap_to_previous": 0.1076923076923077, "parent_is_longest": true, "runtime_str": "0 us"}, "res_name": "aten::empty"}}, "id": "Y3HIPk4wg5WmWn4c", "pretty_name": "aten::empty", "trace_file": "/results/RNN/RNN.65.pt.trace.json", "trace_disk_size": "94 Bytes", "runtime": 0, "runtime_str": "0 us", "start_timestamp": "01:04:53.844.844985", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 1}, {"name": "aten::ones_like", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu3": {"time": {"ts": 1677891893845011000, "dur": 27000, "relative_dur": 0.4153846153846154, "relative_gap_to_previous": 0.4, "parent_is_longest": true, "runtime_str": "27 us"}}, "gpu2": {"time": {"ts": 1677891893845038000, "dur": 1000, "relative_dur": 0.015384615384615385, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "1 us"}}}, "ops": [{"name": "aten::empty_like", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu3": {"time": {"ts": 1677891893845012000, "dur": 9000, "relative_dur": 0.3333333333333333, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9 us"}, "res_name": "aten::empty_like"}}, "id": "9tcvEsjIsmKhNLTo", "pretty_name": "aten::empty_like", "trace_file": "/results/RNN/RNN.67.pt.trace.json", "trace_disk_size": "200 Bytes", "runtime": 9000, "runtime_str": "9 us", "start_timestamp": "01:04:53.845.845012", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 2}, {"name": "aten::fill_", "type": "generated", "generated_depth": 3, "instances": 1, "resources": {"cpu3": {"time": {"ts": 1677891893845022000, "dur": 16000, "relative_dur": 0.5925925925925926, "relative_gap_to_previous": 0.037037037037037035, "parent_is_longest": true, "runtime_str": "16 us"}, "res_name": "aten::fill_"}, "gpu2": {"time": {"ts": 1677891893845038000, "dur": 1000, "relative_dur": 0.037037037037037035, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>"}}, "id": "inuG680GTWdqNxX9", "pretty_name": "aten::fill_", "trace_file": "/results/RNN/RNN.68.pt.trace.json", "trace_disk_size": "458 Bytes", "runtime": 16000, "runtime_str": "16 us", "start_timestamp": "01:04:53.845.845022", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 3}], "id": "QyLX9Rd6kEp3IHX6", "pretty_name": "aten::ones_like", "trace_file": "/results/RNN/RNN.66.pt.trace.json", "trace_disk_size": "755 Bytes", "runtime": 27000, "runtime_str": "27 us", "start_timestamp": "01:04:53.845.845011", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 6}], "id": "FToBD0c6JpKYUJAb", "pretty_name": "aten::ones_like(84%) and 2 others\u2026", "trace_file": "/results/RNN/RNN.61.pt.trace.json", "trace_disk_size": "1.1 kB", "runtime": 65000, "runtime_str": "65 us", "start_timestamp": "01:04:53.844.844973", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 10}], "idx": 36, "id": "wrPXet3MlYWA1iCl", "pretty_name": "Zero Grad", "trace_file": "/results/RNN/RNN.59.pt.trace.json", "trace_disk_size": "33.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "runtime": 1081000, "runtime_str": "1 ms", "start_timestamp": "01:04:53.843.843957", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 248}, {"name": "Backward", "type": "training loop", "instances": 1027, "resources": {"cpu11": {"time": {"ts": 1677891893846008000, "dur": 857315000, "relative_dur": 0.48963463945976077, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "857 ms"}}, "cpu3": {"time": {"ts": 1677891894793332000, "dur": 51000, "relative_dur": 0.48963463945976077, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "51 us"}}, "gpu12": {"time": {"ts": 1677891893967754000, "dur": 829097000, "relative_dur": 0.4735186141291932, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "829 ms"}}, "gpu13": {"time": {"ts": 1677891893967755000, "dur": 828504000, "relative_dur": 0.473179936582201, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "829 ms"}}, "gpu14": {"time": {"ts": 1677891894021370000, "dur": 801019000, "relative_dur": 0.4574825463982528, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "801 ms"}}, "gpu15": {"time": {"ts": 1677891894021434000, "dur": 800262000, "relative_dur": 0.4570502042345545, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "800 ms"}}, "gpu2": {"time": {"ts": 1677891893846238000, "dur": 1116416000, "relative_dur": 0.6376138824668975, "relative_gap_to_previous": 0.0006847797282355414, "parent_is_longest": true, "runtime_str": "1 s, 116 ms"}}, "gpu4": {"time": {"ts": 1677891894002438000, "dur": 851788000, "relative_dur": 0.48647802765162246, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "852 ms"}}, "gpu5": {"time": {"ts": 1677891894007495000, "dur": 846752000, "relative_dur": 0.48360183856789085, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "847 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 85, in update_params\n    with hotline.annotate('Backward'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "source_file_num": 85, "ops": [{"name": "SoftMax", "type": "SoftMax", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 197, in forward\n    with hotline.annotate('SoftMax'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 197, "resources": {"cpu11": {"time": {"ts": 1677891893846008000, "dur": 1123000, "relative_dur": 0.0010058974432469617, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1 ms"}}, "gpu2": {"time": {"ts": 1677891893846238000, "dur": 2459000, "relative_dur": 0.0022025839830314147, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 ms"}}}, "is_backward_op": true, "id": "XnNqXzBGQiR7ypSg", "pretty_name": "SoftMax", "trace_file": "/results/RNN/RNN.70.pt.trace.json", "trace_disk_size": "21.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 2459000, "runtime_str": "2 ms", "start_timestamp": "01:04:53.846.846008", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 137}, {"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 193, in forward\n    with hotline.annotate('Linear'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 193, "resources": {"cpu11": {"time": {"ts": 1677891893847216000, "dur": 191000, "relative_dur": 0.0001710831804631965, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "191 us"}}, "gpu2": {"time": {"ts": 1677891893848698000, "dur": 454000, "relative_dur": 0.0004066584498968127, "relative_gap_to_previous": 8.957234579224948e-07, "parent_is_longest": true, "runtime_str": "454 us"}}}, "is_backward_op": true, "id": "XBo9UunsV4ruUjYJ", "pretty_name": "Linear", "trace_file": "/results/RNN/RNN.71.pt.trace.json", "trace_disk_size": "3.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 454000, "runtime_str": "454 us", "start_timestamp": "01:04:53.847.847216", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 31}, {"name": "BatchRNN-4", "type": "BatchRNN-4", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 190, in forward\n    with hotline.annotate(f'BatchRNN-{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 190, "ops": [{"name": "Sum", "type": "Sum", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 108, in forward\n    with hotline.annotate('Sum'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 108, "resources": {"cpu11": {"time": {"ts": 1677891893847414000, "dur": 286000, "relative_dur": 0.0014871898871087676, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "286 us"}}, "gpu2": {"time": {"ts": 1677891893849154000, "dur": 983000, "relative_dur": 0.005111565241356359, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "983 us"}}}, "is_backward_op": true, "id": "bRP8co0xqVfVn7l7", "pretty_name": "Sum", "trace_file": "/results/RNN/RNN.73.pt.trace.json", "trace_disk_size": "6.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 983000, "runtime_str": "983 us", "start_timestamp": "01:04:53.847.847414", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 54}, {"name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 101, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 101, "resources": {"cpu11": {"time": {"ts": 1677891893847704000, "dur": 150924000, "relative_dur": 0.7847994633636491, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "151 ms"}}, "gpu12": {"time": {"ts": 1677891893967754000, "dur": 56702000, "relative_dur": 0.2948483950309138, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "57 ms"}}, "gpu13": {"time": {"ts": 1677891893967755000, "dur": 55091000, "relative_dur": 0.28647125199548645, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "55 ms"}}, "gpu14": {"time": {"ts": 1677891894021370000, "dur": 15995000, "relative_dur": 0.08317343442064594, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "16 ms"}}, "gpu15": {"time": {"ts": 1677891894021434000, "dur": 15231000, "relative_dur": 0.07920066143550224, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "15 ms"}}, "gpu2": {"time": {"ts": 1677891893850138000, "dur": 162864000, "relative_dur": 0.8468870411681201, "relative_gap_to_previous": 5.199964640240446e-06, "parent_is_longest": true, "runtime_str": "163 ms"}}, "gpu4": {"time": {"ts": 1677891894002438000, "dur": 16136000, "relative_dur": 0.08390662943491985, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "16 ms"}}, "gpu5": {"time": {"ts": 1677891894007495000, "dur": 17407000, "relative_dur": 0.09051578449266545, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "17 ms"}}}, "is_backward_op": true, "id": "PGvmG1w6kxA7cwHX", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.74.pt.trace.json", "trace_disk_size": "3.1 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 162864000, "runtime_str": "163 ms", "start_timestamp": "01:04:53.847.847704", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 19125}, {"name": "BatchNorm", "type": "BatchNorm", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('BatchNorm'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 98, "ops": [{"name": "BatchNorm1d", "type": "BatchNorm1d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 99, in forward\n    x = self.batch_norm(x)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 33, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 33, "resources": {"cpu11": {"time": {"ts": 1677891894000877000, "dur": 13276000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "13 ms"}}, "gpu2": {"time": {"ts": 1677891894037368000, "dur": 4095000, "relative_dur": 0.30845134076529074, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4 ms"}}}, "is_backward_op": true, "id": "C1IjI5WoZ4cKKsiZ", "pretty_name": "BatchNorm1d", "trace_file": "/results/RNN/RNN.76.pt.trace.json", "trace_disk_size": "763.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 13276000, "runtime_str": "13 ms", "start_timestamp": "01:04:54.000.877", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7585}], "resources": {"cpu11": {"time": {"ts": 1677891894000877000, "dur": 13276000, "relative_dur": 0.06903473056383216, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "13 ms"}}, "gpu2": {"time": {"ts": 1677891894037368000, "dur": 4095000, "relative_dur": 0.021293855201784628, "relative_gap_to_previous": 0.12670233842409873, "parent_is_longest": true, "runtime_str": "4 ms"}}}, "is_backward_op": true, "id": "PNtDSadLz65ImIwq", "pretty_name": "BatchNorm", "trace_file": "/results/RNN/RNN.75.pt.trace.json", "trace_disk_size": "763.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 13276000, "runtime_str": "13 ms", "start_timestamp": "01:04:54.000.877", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7585}], "resources": {"cpu11": {"time": {"ts": 1677891893847414000, "dur": 164506000, "relative_dur": 0.14735188316899794, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "165 ms"}}, "gpu12": {"time": {"ts": 1677891893967754000, "dur": 56702000, "relative_dur": 0.0507893115111213, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "57 ms"}}, "gpu13": {"time": {"ts": 1677891893967755000, "dur": 55091000, "relative_dur": 0.04934630102040816, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "55 ms"}}, "gpu14": {"time": {"ts": 1677891894021370000, "dur": 15995000, "relative_dur": 0.014327096709470305, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "16 ms"}}, "gpu15": {"time": {"ts": 1677891894021434000, "dur": 15231000, "relative_dur": 0.01364276398761752, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "15 ms"}}, "gpu2": {"time": {"ts": 1677891893849154000, "dur": 192309000, "relative_dur": 0.17225568246961706, "relative_gap_to_previous": 1.7914469158449896e-06, "parent_is_longest": true, "runtime_str": "192 ms"}}, "gpu4": {"time": {"ts": 1677891894002438000, "dur": 16136000, "relative_dur": 0.014453393717037378, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "16 ms"}}, "gpu5": {"time": {"ts": 1677891894007495000, "dur": 17407000, "relative_dur": 0.015591858232056867, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "17 ms"}}}, "is_backward_op": true, "id": "FNP85OG7sl3CQvon", "pretty_name": "BatchRNN-4", "trace_file": "/results/RNN/RNN.72.pt.trace.json", "trace_disk_size": "3.9 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 192309000, "runtime_str": "192 ms", "start_timestamp": "01:04:53.847.847414", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 26764}, {"name": "BatchRNN-3", "type": "BatchRNN-3", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 190, in forward\n    with hotline.annotate(f'BatchRNN-{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 190, "ops": [{"name": "Sum", "type": "Sum", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 108, in forward\n    with hotline.annotate('Sum'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 108, "resources": {"cpu11": {"time": {"ts": 1677891894017717000, "dur": 87000, "relative_dur": 0.0004525098693962894, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "87 us"}}, "gpu2": {"time": {"ts": 1677891894041465000, "dur": 5000, "relative_dur": 2.600631433312008e-05, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5 us"}}}, "is_backward_op": true, "id": "TE4z6CPPT2U66B4k", "pretty_name": "Sum", "trace_file": "/results/RNN/RNN.78.pt.trace.json", "trace_disk_size": "3.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 87000, "runtime_str": "87 us", "start_timestamp": "01:04:54.017.17717", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 24}, {"name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 101, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 101, "resources": {"cpu11": {"time": {"ts": 1677891894017807000, "dur": 158170000, "relative_dur": 0.8226837476139207, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "158 ms"}}, "gpu12": {"time": {"ts": 1677891894159974000, "dur": 56598000, "relative_dur": 0.29438107572518607, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "57 ms"}}, "gpu13": {"time": {"ts": 1677891894159973000, "dur": 55724000, "relative_dur": 0.28983517197975667, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "56 ms"}}, "gpu14": {"time": {"ts": 1677891894214151000, "dur": 15443000, "relative_dur": 0.08032310244927468, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "15 ms"}}, "gpu15": {"time": {"ts": 1677891894214206000, "dur": 14683000, "relative_dur": 0.07637014267064043, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "15 ms"}}, "gpu2": {"time": {"ts": 1677891894041471000, "dur": 164278000, "relative_dur": 0.8544530612032601, "relative_gap_to_previous": 5.201262866624016e-06, "parent_is_longest": true, "runtime_str": "164 ms"}}, "gpu4": {"time": {"ts": 1677891894194644000, "dur": 22641000, "relative_dur": 0.11776179256323435, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "23 ms"}}, "gpu5": {"time": {"ts": 1677891894200094000, "dur": 11281000, "relative_dur": 0.058675446398385525, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "11 ms"}}}, "is_backward_op": true, "id": "HJgvsFdeJid69u5O", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.79.pt.trace.json", "trace_disk_size": "3.1 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 164278000, "runtime_str": "164 ms", "start_timestamp": "01:04:54.017.17807", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 19125}, {"name": "BatchNorm", "type": "BatchNorm", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('BatchNorm'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 98, "ops": [{"name": "BatchNorm1d", "type": "BatchNorm1d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 99, in forward\n    x = self.batch_norm(x)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 33, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 33, "resources": {"cpu11": {"time": {"ts": 1677891894193364000, "dur": 13021000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "13 ms"}}, "gpu2": {"time": {"ts": 1677891894229597000, "dur": 4129000, "relative_dur": 0.3171031410797942, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4 ms"}}}, "is_backward_op": true, "id": "S98qAVE5NFbErfTh", "pretty_name": "BatchNorm1d", "trace_file": "/results/RNN/RNN.81.pt.trace.json", "trace_disk_size": "763.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 13021000, "runtime_str": "13 ms", "start_timestamp": "01:04:54.193.193364", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7585}], "resources": {"cpu11": {"time": {"ts": 1677891894193364000, "dur": 13021000, "relative_dur": 0.06772564378631131, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "13 ms"}}, "gpu2": {"time": {"ts": 1677891894229597000, "dur": 4129000, "relative_dur": 0.021476014376290563, "relative_gap_to_previous": 0.12403971684324955, "parent_is_longest": true, "runtime_str": "4 ms"}}}, "is_backward_op": true, "id": "pHWFz14MCDGK4ENp", "pretty_name": "BatchNorm", "trace_file": "/results/RNN/RNN.80.pt.trace.json", "trace_disk_size": "763.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 13021000, "runtime_str": "13 ms", "start_timestamp": "01:04:54.193.193364", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7585}], "resources": {"cpu11": {"time": {"ts": 1677891894017717000, "dur": 171294000, "relative_dur": 0.15343205400137583, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "171 ms"}}, "gpu12": {"time": {"ts": 1677891894159974000, "dur": 56598000, "relative_dur": 0.050696156271497365, "relative_gap_to_previous": 0.12138665157074066, "parent_is_longest": false, "runtime_str": "57 ms"}}, "gpu13": {"time": {"ts": 1677891894159973000, "dur": 55724000, "relative_dur": 0.049913293969273104, "relative_gap_to_previous": 0.12282787061453795, "parent_is_longest": false, "runtime_str": "56 ms"}}, "gpu14": {"time": {"ts": 1677891894214151000, "dur": 15443000, "relative_dur": 0.013832657360697088, "relative_gap_to_previous": 0.15835136723228618, "parent_is_longest": false, "runtime_str": "15 ms"}}, "gpu15": {"time": {"ts": 1677891894214206000, "dur": 14683000, "relative_dur": 0.013151907532675991, "relative_gap_to_previous": 0.15902763844301765, "parent_is_longest": false, "runtime_str": "15 ms"}}, "gpu2": {"time": {"ts": 1677891894041465000, "dur": 192261000, "relative_dur": 0.1722126877436368, "relative_gap_to_previous": 1.7914469158449896e-06, "parent_is_longest": true, "runtime_str": "192 ms"}}, "gpu4": {"time": {"ts": 1677891894194644000, "dur": 22641000, "relative_dur": 0.020280074810823206, "relative_gap_to_previous": 0.15771002923641367, "parent_is_longest": false, "runtime_str": "23 ms"}}, "gpu5": {"time": {"ts": 1677891894200094000, "dur": 11281000, "relative_dur": 0.010104656328823665, "relative_gap_to_previous": 0.15692358404035772, "parent_is_longest": false, "runtime_str": "11 ms"}}}, "is_backward_op": true, "id": "f6qYkpth9ySf5RAU", "pretty_name": "BatchRNN-3", "trace_file": "/results/RNN/RNN.77.pt.trace.json", "trace_disk_size": "3.9 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 192261000, "runtime_str": "192 ms", "start_timestamp": "01:04:54.017.17717", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 26734}, {"name": "BatchRNN-2", "type": "BatchRNN-2", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 190, in forward\n    with hotline.annotate(f'BatchRNN-{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 190, "ops": [{"name": "Sum", "type": "Sum", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 108, in forward\n    with hotline.annotate('Sum'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 108, "resources": {"cpu11": {"time": {"ts": 1677891894209856000, "dur": 82000, "relative_dur": 0.00042734820018657394, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "82 us"}}, "gpu2": {"time": {"ts": 1677891894233727000, "dur": 5000, "relative_dur": 2.6057817084547193e-05, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5 us"}}}, "is_backward_op": true, "id": "OG4dRsLvxUKbuXnk", "pretty_name": "Sum", "trace_file": "/results/RNN/RNN.83.pt.trace.json", "trace_disk_size": "3.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 82000, "runtime_str": "82 us", "start_timestamp": "01:04:54.209.209856", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 24}, {"name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 101, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 101, "resources": {"cpu11": {"time": {"ts": 1677891894209942000, "dur": 156707000, "relative_dur": 0.8166884683736274, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "157 ms"}}, "gpu12": {"time": {"ts": 1677891894351850000, "dur": 57063000, "relative_dur": 0.2973874432591033, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "57 ms"}}, "gpu13": {"time": {"ts": 1677891894351849000, "dur": 55806000, "relative_dur": 0.29083650804404815, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "56 ms"}}, "gpu14": {"time": {"ts": 1677891894406149000, "dur": 15443000, "relative_dur": 0.08048217384733246, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "15 ms"}}, "gpu15": {"time": {"ts": 1677891894406199000, "dur": 14707000, "relative_dur": 0.07664646317248712, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "15 ms"}}, "gpu2": {"time": {"ts": 1677891894233734000, "dur": 164026000, "relative_dur": 0.8548319010219876, "relative_gap_to_previous": 1.0423126833818877e-05, "parent_is_longest": true, "runtime_str": "164 ms"}}, "gpu4": {"time": {"ts": 1677891894386663000, "dur": 22819000, "relative_dur": 0.11892266561045649, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "23 ms"}}, "gpu5": {"time": {"ts": 1677891894392100000, "dur": 11272000, "relative_dur": 0.058744742835403194, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "11 ms"}}}, "is_backward_op": true, "id": "Icl4l72jvYdHkllt", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.84.pt.trace.json", "trace_disk_size": "3.1 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 164026000, "runtime_str": "164 ms", "start_timestamp": "01:04:54.209.209942", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 19125}, {"name": "BatchNorm", "type": "BatchNorm", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('BatchNorm'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 98, "ops": [{"name": "BatchNorm1d", "type": "BatchNorm1d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 99, in forward\n    x = self.batch_norm(x)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 33, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 33, "resources": {"cpu11": {"time": {"ts": 1677891894384157000, "dur": 13983000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "14 ms"}}, "gpu2": {"time": {"ts": 1677891894421595000, "dur": 4013000, "relative_dur": 0.2869913466351999, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4 ms"}}}, "is_backward_op": true, "id": "ZEr3nxaYdupi6fJP", "pretty_name": "BatchNorm1d", "trace_file": "/results/RNN/RNN.86.pt.trace.json", "trace_disk_size": "763.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 13983000, "runtime_str": "14 ms", "start_timestamp": "01:04:54.384.384157", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7585}], "resources": {"cpu11": {"time": {"ts": 1677891894384157000, "dur": 13983000, "relative_dur": 0.07287329125864468, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "14 ms"}}, "gpu2": {"time": {"ts": 1677891894421595000, "dur": 4013000, "relative_dur": 0.02091400399205758, "relative_gap_to_previous": 0.12421761404203648, "parent_is_longest": true, "runtime_str": "4 ms"}}}, "is_backward_op": true, "id": "Gq91K7cAwnrQddJS", "pretty_name": "BatchNorm", "trace_file": "/results/RNN/RNN.85.pt.trace.json", "trace_disk_size": "763.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 13983000, "runtime_str": "14 ms", "start_timestamp": "01:04:54.384.384157", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7585}], "resources": {"cpu11": {"time": {"ts": 1677891894209856000, "dur": 170789000, "relative_dur": 0.15297971365512497, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "171 ms"}}, "gpu12": {"time": {"ts": 1677891894351850000, "dur": 57063000, "relative_dur": 0.051112667679431324, "relative_gap_to_previous": 0.12117167794083926, "parent_is_longest": false, "runtime_str": "57 ms"}}, "gpu13": {"time": {"ts": 1677891894351849000, "dur": 55806000, "relative_dur": 0.049986743292822745, "relative_gap_to_previous": 0.12195454024306351, "parent_is_longest": false, "runtime_str": "56 ms"}}, "gpu14": {"time": {"ts": 1677891894406149000, "dur": 15443000, "relative_dur": 0.013832657360697088, "relative_gap_to_previous": 0.15814445511350608, "parent_is_longest": false, "runtime_str": "15 ms"}}, "gpu15": {"time": {"ts": 1677891894406199000, "dur": 14707000, "relative_dur": 0.013173404895666131, "relative_gap_to_previous": 0.15882072632423755, "parent_is_longest": false, "runtime_str": "15 ms"}}, "gpu2": {"time": {"ts": 1677891894233727000, "dur": 191881000, "relative_dur": 0.17187231282962623, "relative_gap_to_previous": 8.957234579224948e-07, "parent_is_longest": true, "runtime_str": "192 ms"}}, "gpu4": {"time": {"ts": 1677891894386663000, "dur": 22819000, "relative_dur": 0.02043951358633341, "relative_gap_to_previous": 0.15171584785599634, "parent_is_longest": false, "runtime_str": "23 ms"}}, "gpu5": {"time": {"ts": 1677891894392100000, "dur": 11272000, "relative_dur": 0.010096594817702361, "relative_gap_to_previous": 0.16187962193304287, "parent_is_longest": false, "runtime_str": "11 ms"}}}, "is_backward_op": true, "id": "bP7d02yMENCVAyDa", "pretty_name": "BatchRNN-2", "trace_file": "/results/RNN/RNN.82.pt.trace.json", "trace_disk_size": "3.9 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 191881000, "runtime_str": "192 ms", "start_timestamp": "01:04:54.209.209856", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 26734}, {"name": "BatchRNN-1", "type": "BatchRNN-1", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 190, in forward\n    with hotline.annotate(f'BatchRNN-{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 190, "ops": [{"name": "Sum", "type": "Sum", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 108, in forward\n    with hotline.annotate('Sum'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 108, "resources": {"cpu11": {"time": {"ts": 1677891894401724000, "dur": 85000, "relative_dur": 0.0004437738528445904, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "85 us"}}, "gpu2": {"time": {"ts": 1677891894425610000, "dur": 5000, "relative_dur": 2.6104344284975904e-05, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5 us"}}}, "is_backward_op": true, "id": "K58umt7Qx7pSWYh6", "pretty_name": "Sum", "trace_file": "/results/RNN/RNN.88.pt.trace.json", "trace_disk_size": "3.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 85000, "runtime_str": "85 us", "start_timestamp": "01:04:54.401.401724", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 24}, {"name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 101, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 101, "resources": {"cpu11": {"time": {"ts": 1677891894401812000, "dur": 158475000, "relative_dur": 0.8273771921123113, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "158 ms"}}, "gpu12": {"time": {"ts": 1677891894544021000, "dur": 50272000, "relative_dur": 0.26246351917886174, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "50 ms"}}, "gpu13": {"time": {"ts": 1677891894544020000, "dur": 49809000, "relative_dur": 0.260046256898073, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "50 ms"}}, "gpu14": {"time": {"ts": 1677891894589681000, "dur": 23338000, "relative_dur": 0.12184463738455353, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "23 ms"}}, "gpu15": {"time": {"ts": 1677891894589652000, "dur": 22662000, "relative_dur": 0.11831533003722479, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "23 ms"}}, "gpu2": {"time": {"ts": 1677891894425616000, "dur": 164034000, "relative_dur": 0.8564000020883475, "relative_gap_to_previous": 5.2208688569951815e-06, "parent_is_longest": true, "runtime_str": "164 ms"}}, "gpu4": {"time": {"ts": 1677891894578897000, "dur": 16386000, "relative_dur": 0.08554915709072304, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "16 ms"}}, "gpu5": {"time": {"ts": 1677891894584046000, "dur": 16811000, "relative_dur": 0.08776802635494599, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "17 ms"}}}, "is_backward_op": true, "id": "MmfdHX16IF0VcSPK", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.89.pt.trace.json", "trace_disk_size": "3.1 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 164034000, "runtime_str": "164 ms", "start_timestamp": "01:04:54.401.401812", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 19125}, {"name": "BatchNorm", "type": "BatchNorm", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('BatchNorm'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 98, "ops": [{"name": "BatchNorm1d", "type": "BatchNorm1d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 99, in forward\n    x = self.batch_norm(x)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 33, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 33, "resources": {"cpu11": {"time": {"ts": 1677891894577941000, "dur": 12894000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "13 ms"}}, "gpu2": {"time": {"ts": 1677891894613022000, "dur": 4127000, "relative_dur": 0.32007135101597645, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4 ms"}}}, "is_backward_op": true, "id": "X9lGEWeaF2wRXDY8", "pretty_name": "BatchNorm1d", "trace_file": "/results/RNN/RNN.91.pt.trace.json", "trace_disk_size": "763.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 12894000, "runtime_str": "13 ms", "start_timestamp": "01:04:54.577.577941", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7585}], "resources": {"cpu11": {"time": {"ts": 1677891894577941000, "dur": 12894000, "relative_dur": 0.06731788304209586, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "13 ms"}}, "gpu2": {"time": {"ts": 1677891894613022000, "dur": 4127000, "relative_dur": 0.02154652577281911, "relative_gap_to_previous": 0.12202214692569137, "parent_is_longest": true, "runtime_str": "4 ms"}}}, "is_backward_op": true, "id": "i60BtaDFLx0ImOYZ", "pretty_name": "BatchNorm", "trace_file": "/results/RNN/RNN.90.pt.trace.json", "trace_disk_size": "763.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 12894000, "runtime_str": "13 ms", "start_timestamp": "01:04:54.577.577941", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7585}], "resources": {"cpu11": {"time": {"ts": 1677891894401724000, "dur": 171471000, "relative_dur": 0.15359059705342812, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "171 ms"}}, "gpu12": {"time": {"ts": 1677891894544021000, "dur": 50272000, "relative_dur": 0.04502980967667966, "relative_gap_to_previous": 0.12101940495299243, "parent_is_longest": false, "runtime_str": "50 ms"}}, "gpu13": {"time": {"ts": 1677891894544020000, "dur": 49809000, "relative_dur": 0.04461508971566155, "relative_gap_to_previous": 0.12214532933960101, "parent_is_longest": false, "runtime_str": "50 ms"}}, "gpu14": {"time": {"ts": 1677891894589681000, "dur": 23338000, "relative_dur": 0.020904394060995184, "relative_gap_to_previous": 0.15056126031873424, "parent_is_longest": false, "runtime_str": "23 ms"}}, "gpu15": {"time": {"ts": 1677891894589652000, "dur": 22662000, "relative_dur": 0.020298885003439578, "relative_gap_to_previous": 0.1511497506305893, "parent_is_longest": false, "runtime_str": "23 ms"}}, "gpu2": {"time": {"ts": 1677891894425610000, "dur": 191539000, "relative_dur": 0.17156597540701674, "relative_gap_to_previous": 1.7914469158449896e-06, "parent_is_longest": true, "runtime_str": "192 ms"}}, "gpu4": {"time": {"ts": 1677891894578897000, "dur": 16386000, "relative_dur": 0.014677324581518, "relative_gap_to_previous": 0.15174898962393946, "parent_is_longest": false, "runtime_str": "16 ms"}}, "gpu5": {"time": {"ts": 1677891894584046000, "dur": 16811000, "relative_dur": 0.015058007051135061, "relative_gap_to_previous": 0.16183394003668883, "parent_is_longest": false, "runtime_str": "17 ms"}}}, "is_backward_op": true, "id": "jQvhQoYWPHQ8CGA4", "pretty_name": "BatchRNN-1", "trace_file": "/results/RNN/RNN.87.pt.trace.json", "trace_disk_size": "3.9 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 191539000, "runtime_str": "192 ms", "start_timestamp": "01:04:54.401.401724", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 26734}, {"name": "BatchRNN-0", "type": "BatchRNN-0", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 190, in forward\n    with hotline.annotate(f'BatchRNN-{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 190, "ops": [{"name": "Sum", "type": "Sum", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 108, in forward\n    with hotline.annotate('Sum'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 108, "resources": {"cpu11": {"time": {"ts": 1677891894594315000, "dur": 84000, "relative_dur": 0.0004869367619864701, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "84 us"}}, "gpu2": {"time": {"ts": 1677891894617150000, "dur": 5000, "relative_dur": 2.898433107062322e-05, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5 us"}}}, "is_backward_op": true, "id": "IoDR47M0lfYzugh8", "pretty_name": "Sum", "trace_file": "/results/RNN/RNN.93.pt.trace.json", "trace_disk_size": "3.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 84000, "runtime_str": "84 us", "start_timestamp": "01:04:54.594.594315", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 24}, {"name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 191, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 101, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 101, "resources": {"cpu11": {"time": {"ts": 1677891894594403000, "dur": 157080000, "relative_dur": 0.9105717449146992, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "157 ms"}}, "gpu12": {"time": {"ts": 1677891894735329000, "dur": 61522000, "relative_dur": 0.3566348032253764, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "62 ms"}}, "gpu13": {"time": {"ts": 1677891894735328000, "dur": 60931000, "relative_dur": 0.3532088552928287, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "61 ms"}}, "gpu14": {"time": {"ts": 1677891894795224000, "dur": 27165000, "relative_dur": 0.15747187070669597, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "27 ms"}}, "gpu15": {"time": {"ts": 1677891894795782000, "dur": 25914000, "relative_dur": 0.15021999107282602, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "26 ms"}}, "gpu2": {"time": {"ts": 1677891894617157000, "dur": 172500000, "relative_dur": 0.9999594219365011, "relative_gap_to_previous": 1.1593732428249289e-05, "parent_is_longest": true, "runtime_str": "172 ms"}}, "gpu4": {"time": {"ts": 1677891894770165000, "dur": 30615000, "relative_dur": 0.177471059145426, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "31 ms"}}, "gpu5": {"time": {"ts": 1677891894779408000, "dur": 32473000, "relative_dur": 0.18824163657126958, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "32 ms"}}}, "is_backward_op": true, "id": "ScidOcGbml00UPdR", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.94.pt.trace.json", "trace_disk_size": "3.1 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 172500000, "runtime_str": "172 ms", "start_timestamp": "01:04:54.594.594403", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 19125}], "resources": {"cpu11": {"time": {"ts": 1677891894594315000, "dur": 157168000, "relative_dur": 0.14077906443476268, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "157 ms"}}, "gpu12": {"time": {"ts": 1677891894735329000, "dur": 61522000, "relative_dur": 0.05510669857830773, "relative_gap_to_previous": 0.12632925361155697, "parent_is_longest": false, "runtime_str": "62 ms"}}, "gpu13": {"time": {"ts": 1677891894735328000, "dur": 60931000, "relative_dur": 0.054577326014675534, "relative_gap_to_previous": 0.1267439735725751, "parent_is_longest": false, "runtime_str": "61 ms"}}, "gpu14": {"time": {"ts": 1677891894795224000, "dur": 27165000, "relative_dur": 0.024332327734464573, "relative_gap_to_previous": 0.16320529265076816, "parent_is_longest": false, "runtime_str": "27 ms"}}, "gpu15": {"time": {"ts": 1677891894795782000, "dur": 25914000, "relative_dur": 0.02321177768860353, "relative_gap_to_previous": 0.16433659137812429, "parent_is_longest": false, "runtime_str": "26 ms"}}, "gpu2": {"time": {"ts": 1677891894617150000, "dur": 172507000, "relative_dur": 0.15451856655583582, "relative_gap_to_previous": 8.957234579224948e-07, "parent_is_longest": true, "runtime_str": "173 ms"}}, "gpu4": {"time": {"ts": 1677891894770165000, "dur": 30615000, "relative_dur": 0.02742257366429718, "relative_gap_to_previous": 0.15664590976840173, "parent_is_longest": false, "runtime_str": "31 ms"}}, "gpu5": {"time": {"ts": 1677891894779408000, "dur": 32473000, "relative_dur": 0.029086827849117175, "relative_gap_to_previous": 0.15993231913551936, "parent_is_longest": false, "runtime_str": "32 ms"}}}, "is_backward_op": true, "id": "yFv3IQ8Q9X6vP5tO", "pretty_name": "BatchRNN-0", "trace_file": "/results/RNN/RNN.92.pt.trace.json", "trace_disk_size": "3.1 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 172507000, "runtime_str": "173 ms", "start_timestamp": "01:04:54.594.594315", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 19149}, {"name": "MaskConv", "type": "MaskConv", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 179, in forward\n    with hotline.annotate('MaskConv'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 179, "ops": [{"name": "Hardtanh", "type": "Hardtanh", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu11": {"time": {"ts": 1677891894768000000, "dur": 13679000, "relative_dur": 0.09753158600233865, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "14 ms"}}, "gpu2": {"time": {"ts": 1677891894822393000, "dur": 8612000, "relative_dur": 0.06140375894817899, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9 ms"}}}, "is_backward_op": true, "id": "ttJd3dCBk0hnm1xv", "pretty_name": "Hardtanh", "trace_file": "/results/RNN/RNN.96.pt.trace.json", "trace_disk_size": "765.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 13679000, "runtime_str": "14 ms", "start_timestamp": "01:04:54.768.768000", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7593}, {"name": "BatchNorm2d", "type": "BatchNorm2d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu11": {"time": {"ts": 1677891894785728000, "dur": 147000, "relative_dur": 0.0010481133958874028, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "147 us"}}, "gpu2": {"time": {"ts": 1677891894831007000, "dur": 4178000, "relative_dur": 0.029789236517126314, "relative_gap_to_previous": 1.4260046202549696e-05, "parent_is_longest": true, "runtime_str": "4 ms"}}}, "is_backward_op": true, "id": "XF5ijLrPZSe4mB20", "pretty_name": "BatchNorm2d", "trace_file": "/results/RNN/RNN.97.pt.trace.json", "trace_disk_size": "3.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 4178000, "runtime_str": "4 ms", "start_timestamp": "01:04:54.785.785728", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 25}, {"name": "Conv2d", "type": "Conv2d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu11": {"time": {"ts": 1677891894785892000, "dur": 6330000, "relative_dur": 0.04513304623106979, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "6 ms"}}, "gpu2": {"time": {"ts": 1677891894835187000, "dur": 98570000, "relative_dur": 0.7028063770926618, "relative_gap_to_previous": 1.4260046202549696e-05, "parent_is_longest": true, "runtime_str": "99 ms"}}, "gpu4": {"time": {"ts": 1677891894836617000, "dur": 17609000, "relative_dur": 0.1255525767903488, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "18 ms"}}, "gpu5": {"time": {"ts": 1677891894836618000, "dur": 17629000, "relative_dur": 0.1256951772523743, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "18 ms"}}}, "is_backward_op": true, "id": "wMlvgTZFejldBl5f", "pretty_name": "Conv2d", "trace_file": "/results/RNN/RNN.98.pt.trace.json", "trace_disk_size": "444.0 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 98570000, "runtime_str": "99 ms", "start_timestamp": "01:04:54.785.785892", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 2988}, {"name": "Hardtanh", "type": "Hardtanh", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu11": {"time": {"ts": 1677891894792239000, "dur": 124000, "relative_dur": 0.0008841228645580811, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "124 us"}}, "gpu2": {"time": {"ts": 1677891894933759000, "dur": 4746000, "relative_dur": 0.03383908963865043, "relative_gap_to_previous": 1.4260046202549696e-05, "parent_is_longest": true, "runtime_str": "5 ms"}}}, "is_backward_op": true, "id": "Zxh5oRrzYjQRN6L8", "pretty_name": "Hardtanh", "trace_file": "/results/RNN/RNN.99.pt.trace.json", "trace_disk_size": "4.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 4746000, "runtime_str": "5 ms", "start_timestamp": "01:04:54.792.792239", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 28}, {"name": "BatchNorm2d", "type": "BatchNorm2d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu11": {"time": {"ts": 1677891894792376000, "dur": 101000, "relative_dur": 0.0007201323332287596, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "101 us"}}, "gpu2": {"time": {"ts": 1677891894938506000, "dur": 8694000, "relative_dur": 0.06198842084248353, "relative_gap_to_previous": 7.130023101274848e-06, "parent_is_longest": true, "runtime_str": "9 ms"}}}, "is_backward_op": true, "id": "PuEq2KsRnrXunxtx", "pretty_name": "BatchNorm2d", "trace_file": "/results/RNN/RNN.100.pt.trace.json", "trace_disk_size": "3.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 8694000, "runtime_str": "9 ms", "start_timestamp": "01:04:54.792.792376", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 25}, {"name": "Conv2d", "type": "Conv2d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu11": {"time": {"ts": 1677891894792490000, "dur": 254000, "relative_dur": 0.0018110258677238114, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "254 us"}}, "gpu2": {"time": {"ts": 1677891894947201000, "dur": 15444000, "relative_dur": 0.11011607677608876, "relative_gap_to_previous": 7.130023101274848e-06, "parent_is_longest": true, "runtime_str": "15 ms"}}}, "is_backward_op": true, "id": "rERfYIj5u2CDBeJ5", "pretty_name": "Conv2d", "trace_file": "/results/RNN/RNN.101.pt.trace.json", "trace_disk_size": "7.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 15444000, "runtime_str": "15 ms", "start_timestamp": "01:04:54.792.792490", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 47}], "resources": {"cpu11": {"time": {"ts": 1677891894768000000, "dur": 20668000, "relative_dur": 0.018512812428342122, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "21 ms"}}, "gpu2": {"time": {"ts": 1677891894822393000, "dur": 140252000, "relative_dur": 0.12562700642054575, "relative_gap_to_previous": 0.02932240311855079, "parent_is_longest": true, "runtime_str": "140 ms"}}, "gpu4": {"time": {"ts": 1677891894836617000, "dur": 17609000, "relative_dur": 0.015772794370557213, "relative_gap_to_previous": 0.03210004156156845, "parent_is_longest": false, "runtime_str": "18 ms"}}, "gpu5": {"time": {"ts": 1677891894836618000, "dur": 17629000, "relative_dur": 0.015790708839715662, "relative_gap_to_previous": 0.022157511178628755, "parent_is_longest": false, "runtime_str": "18 ms"}}}, "is_backward_op": true, "id": "M8RSBmKJpw8BQtyv", "pretty_name": "MaskConv", "trace_file": "/results/RNN/RNN.95.pt.trace.json", "trace_disk_size": "1.2 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 140252000, "runtime_str": "140 ms", "start_timestamp": "01:04:54.768.768000", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 10706}], "is_model_pass": "Backward", "idx": 37, "id": "sqmAfCPBj2iV0kFU", "pretty_name": "Backward", "trace_file": "/results/RNN/RNN.69.pt.trace.json", "trace_disk_size": "20.0 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "runtime": 1116416000, "runtime_str": "1 s, 116 ms", "start_timestamp": "01:04:53.846.846008", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu2", "trace_event_count": 137006}, {"name": "Optimizer", "type": "training loop", "instances": 1, "resources": {"cpu3": {"time": {"ts": 1677891894793392000, "dur": 35513000, "relative_dur": 0.020282387396854697, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "36 ms"}}, "gpu2": {"time": {"ts": 1677891894962654000, "dur": 6474000, "relative_dur": 0.00369746785704495, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "6 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 88, in update_params\n    with hotline.annotate('Optimizer'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "source_file_num": 88, "ops": [{"name": "aten::add_(39%) and 9 others\u2026", "type": "generated", "generated_depth": 1, "instances": 183, "resources": {"cpu3": {"time": {"ts": 1677891894793393000, "dur": 3536000, "relative_dur": 0.09956917185256103, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4 ms"}}, "gpu2": {"time": {"ts": 1677891894962654000, "dur": 1728000, "relative_dur": 0.04865823782840087, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 ms"}}}, "ops": [{"name": "aten::mul_(24%) and 9 others\u2026", "type": "generated", "generated_depth": 2, "instances": 103, "resources": {"cpu3": {"time": {"ts": 1677891894793393000, "dur": 1972000, "relative_dur": 0.5576923076923077, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 ms"}, "res_name": "aten::mul_(24%) and 9 others\u2026"}, "gpu2": {"time": {"ts": 1677891894962654000, "dur": 897000, "relative_dur": 0.2536764705882353, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "897 us"}, "res_name": "vectorized_elementwise_kernel<4 addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4> addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4>(18%) and 6 others\u2026"}}, "id": "XXgDkyOfHElEUPy0", "pretty_name": "aten::mul_(24%) and 9 others\u2026", "trace_file": "/results/RNN/RNN.104.pt.trace.json", "trace_disk_size": "55.8 kB", "runtime": 1972000, "runtime_str": "2 ms", "start_timestamp": "01:04:54.793.793393", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 312}, {"name": "aten::add_", "type": "generated", "generated_depth": 2, "instances": 1, "resources": {"cpu3": {"time": {"ts": 1677891894795369000, "dur": 366000, "relative_dur": 0.10350678733031674, "relative_gap_to_previous": 0.0011312217194570137, "parent_is_longest": true, "runtime_str": "366 us"}}}, "ops": [{"name": "aten::empty_strided(50%) and 1 other\u2026", "type": "generated", "generated_depth": 3, "instances": 2, "resources": {"cpu3": {"time": {"ts": 1677891894795726000, "dur": 5000, "relative_dur": 0.01366120218579235, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5 us"}, "res_name": "aten::empty_strided(50%) and 1 other\u2026"}}, "id": "MAsfViuOqP4qEzO0", "pretty_name": "aten::empty_strided(50%) and 1 other\u2026", "trace_file": "/results/RNN/RNN.106.pt.trace.json", "trace_disk_size": "195 Bytes", "runtime": 5000, "runtime_str": "5 us", "start_timestamp": "01:04:54.795.795726", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 2}], "id": "pmnWb548XG4QzGGj", "pretty_name": "aten::add_", "trace_file": "/results/RNN/RNN.105.pt.trace.json", "trace_disk_size": "475 Bytes", "runtime": 366000, "runtime_str": "366 us", "start_timestamp": "01:04:54.795.795369", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 5}, {"name": "aten::mul_(24%) and 7 others\u2026", "type": "generated", "generated_depth": 2, "instances": 79, "resources": {"cpu3": {"time": {"ts": 1677891894795741000, "dur": 1188000, "relative_dur": 0.33597285067873306, "relative_gap_to_previous": 0.0016968325791855204, "parent_is_longest": true, "runtime_str": "1 ms"}, "res_name": "aten::mul_(24%) and 7 others\u2026"}, "gpu2": {"time": {"ts": 1677891894963552000, "dur": 830000, "relative_dur": 0.23472850678733032, "relative_gap_to_previous": 0.0002828054298642534, "parent_is_longest": true, "runtime_str": "830 us"}, "res_name": "vectorized_elementwise_kernel<4 addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4> addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4>(18%) and 6 others\u2026"}}, "id": "WPtsCy4f34czegr1", "pretty_name": "aten::mul_(24%) and 7 others\u2026", "trace_file": "/results/RNN/RNN.107.pt.trace.json", "trace_disk_size": "43.2 kB", "runtime": 1188000, "runtime_str": "1 ms", "start_timestamp": "01:04:54.795.795741", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 240}], "id": "iSyRfFQWxHiRkuED", "pretty_name": "aten::add_(39%) and 9 others\u2026", "trace_file": "/results/RNN/RNN.103.pt.trace.json", "trace_disk_size": "99.5 kB", "runtime": 3536000, "runtime_str": "4 ms", "start_timestamp": "01:04:54.793.793393", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 557}, {"name": "aten::addcdiv_", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu3": {"time": {"ts": 1677891894796933000, "dur": 25469000, "relative_dur": 0.71717399262242, "relative_gap_to_previous": 0.00011263480978796497, "parent_is_longest": true, "runtime_str": "25 ms"}, "res_name": "aten::addcdiv_"}, "gpu2": {"time": {"ts": 1677891894964383000, "dur": 2000, "relative_dur": 5.631740489398249e-05, "relative_gap_to_previous": 2.8158702446991244e-05, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "vectorized_elementwise_kernel<4 addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4> addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4>"}}, "id": "Pt8E4RVP290Zcu9p", "pretty_name": "aten::addcdiv_", "trace_file": "/results/RNN/RNN.108.pt.trace.json", "trace_disk_size": "764 Bytes", "runtime": 25469000, "runtime_str": "25 ms", "start_timestamp": "01:04:54.796.796933", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 3}, {"name": "aten::mul_(26%) and 7 others\u2026", "type": "generated", "generated_depth": 1, "instances": 424, "resources": {"cpu3": {"time": {"ts": 1677891894822410000, "dur": 6477000, "relative_dur": 0.18238391574916227, "relative_gap_to_previous": 0.00022526961957592995, "parent_is_longest": true, "runtime_str": "6 ms"}, "res_name": "aten::mul_(26%) and 7 others\u2026"}, "gpu2": {"time": {"ts": 1677891894964387000, "dur": 4741000, "relative_dur": 0.13350040830118548, "relative_gap_to_previous": 5.631740489398249e-05, "parent_is_longest": true, "runtime_str": "5 ms"}, "res_name": "vectorized_elementwise_kernel<4 addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4> addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4>(18%) and 6 others\u2026"}}, "id": "DyecMyKQNRpLXEGk", "pretty_name": "aten::mul_(26%) and 7 others\u2026", "trace_file": "/results/RNN/RNN.109.pt.trace.json", "trace_disk_size": "228.0 kB", "runtime": 6477000, "runtime_str": "6 ms", "start_timestamp": "01:04:54.822.822410", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 1271}], "idx": 38, "id": "egAzgbssIuje02nA", "pretty_name": "Optimizer", "trace_file": "/results/RNN/RNN.102.pt.trace.json", "trace_disk_size": "328.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "runtime": 35513000, "runtime_str": "36 ms", "start_timestamp": "01:04:54.793.793392", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3", "trace_event_count": 1832}], "resources": {"cpu11": {"time": {"ts": 1677891893846008000, "dur": 857315000, "parent_is_longest": false, "runtime_str": "857 ms"}}, "cpu3": {"time": {"ts": 1677891892949087000, "dur": 1750928000, "parent_is_longest": true, "runtime_str": "1 s, 751 ms"}}, "cpu6": {"time": {"ts": 1677891893140623000, "dur": 134532000, "parent_is_longest": false, "runtime_str": "135 ms"}}, "gpu10": {"time": {"ts": 1677891893633838000, "dur": 206632000, "parent_is_longest": false, "runtime_str": "207 ms"}}, "gpu12": {"time": {"ts": 1677891893967754000, "dur": 829097000, "parent_is_longest": false, "runtime_str": "829 ms"}}, "gpu13": {"time": {"ts": 1677891893967755000, "dur": 828504000, "parent_is_longest": false, "runtime_str": "829 ms"}}, "gpu14": {"time": {"ts": 1677891894021370000, "dur": 801019000, "parent_is_longest": false, "runtime_str": "801 ms"}}, "gpu15": {"time": {"ts": 1677891894021434000, "dur": 800262000, "parent_is_longest": false, "runtime_str": "800 ms"}}, "gpu2": {"time": {"ts": 1677891893440809000, "dur": 1528319000, "parent_is_longest": true, "runtime_str": "1 s, 528 ms"}}, "gpu4": {"time": {"ts": 1677891894002438000, "dur": 851788000, "parent_is_longest": false, "runtime_str": "852 ms"}}, "gpu5": {"time": {"ts": 1677891894007495000, "dur": 846752000, "parent_is_longest": false, "runtime_str": "847 ms"}}, "gpu7": {"time": {"ts": 1677891893540143000, "dur": 266655000, "parent_is_longest": false, "runtime_str": "267 ms"}}, "gpu8": {"time": {"ts": 1677891893540157000, "dur": 271918000, "parent_is_longest": false, "runtime_str": "272 ms"}}, "gpu9": {"time": {"ts": 1677891893633801000, "dur": 206595000, "parent_is_longest": false, "runtime_str": "207 ms"}}}, "source_file_name": "/home/ubuntu/algorithmic-efficiency/submission_runner.py", "source_file_num": 236, "id": "H8SJQlcGmmQ5XsOv", "pretty_name": "RNN Training Iteration", "total_accuracy_str": "98.41%", "trace_file": "/results/RNN/RNN.1.pt.trace.json", "trace_disk_size": "79.5 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/submission_runner.py", "config": {"trace_filepath": "/home/ubuntu/cpath/results/RNN.worker0.pt.trace.json", "output_dir": "/home/ubuntu/cpath/results", "ui_traces_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/RNN", "ui_model_path": "/home/ubuntu/cpath/results/ui/src/results/RNN.js", "results_summary_csv_filepath": "/home/ubuntu/cpath/results/results_summary.csv", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN", "run_name": "RNN", "model_name": "RNN", "backend": "torch", "test": false, "is_test_accuracy": true, "view_manual_annotations": false, "source_file_name": "/home/ubuntu/algorithmic-efficiency/submission_runner.py", "source_file_num": 236, "num_gpus": 1, "slice_idx": 0, "drop_flow_view": "", "last_found_was_fused": false, "count_sum_greater_than_1": 0, "count_sum_less_than_1": 0, "tiny_op_threshold": 0.05, "max_generated_depth": 2, "remove_slice_args": true, "write_model_ops_to_file": true, "op_idx": 1}, "metadata": {}, "metadata.model": "RNN", "metadata.dataset": "LibriSpeech", "metadata.batch_size": 64, "metadata.optimizer": "Adam", "trace_event_count": 217236, "gpu_model": "NVIDIA GeForce RTX 3090", "gpu_cuda_version": "11.7", "hotline_traces_trace_disk_size": "155.0 MB", "hotline_annotation_count": "109", "processed_datetime": "04/03/2023 01:05:50", "runtime_without_profiling": "1 s, 739 ms \u00b10.4%", "runtime_with_profiling": "1 s, 845 ms \u00b10.3%", "runtime_profiling_overhead_factor": "0.06\u00d7 slower", "hotline_analysis_time": "25 s, 787 ms", "runtime": 1750928000, "runtime_str": "1 s, 751 ms", "start_timestamp": "01:04:52.949.949087", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu3"}]
