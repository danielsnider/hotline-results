[{"name": "RNN-T Training Iteration", "type": "root", "ops": [{"name": "Load Data", "type": "training loop", "instances": 36, "resources": {"cpu2": {"time": {"ts": 1685410790604527000, "dur": 407551000, "relative_dur": 0.24375511746928322, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "408 ms"}}, "cpu6": {"time": {"ts": 1685410790770475000, "dur": 120671000, "relative_dur": 0.07217298885326223, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "121 ms"}}, "gpu3": {"time": {"ts": 1685410791011158000, "dur": 6753000, "relative_dur": 0.004038950482933595, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "6.75 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 256, in train_once\n    with hotline.annotate('Load Data'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/submission_runner.py", "source_file_num": 256, "ops": [{"name": "aten::randperm(59%) and 6 others\u2026", "type": "generated", "generated_depth": 1, "instances": 16, "resources": {"cpu2": {"time": {"ts": 1685410790604527000, "dur": 107105000, "relative_dur": 0.2628014653380804, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "107 ms"}, "res_name": "aten::randperm(59%) and 6 others\u2026"}}, "id": "dM3F9dlvQgw6TQmS", "pretty_name": "aten::randperm(59%) and 6 others\u2026", "trace_file": "/results/RNN/RNN.3.pt.trace.json", "trace_disk_size": "3.3 kB", "runtime": 107105000, "runtime_str": "107 ms", "start_timestamp": "01:39:50.604.604527", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 32}, {"name": "enumerateDataLoader#_MultiProcessingDataLoaderIter.__next__", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410790711711000, "dur": 203698000, "relative_dur": 0.49980983975011717, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "204 ms"}, "res_name": "aten::empty"}}, "id": "M7Lgv5KQiULYK8Yl", "pretty_name": "enumerateDataLoader#_MultiProcessingDataLoaderIter.__next__", "trace_file": "/results/RNN/RNN.4.pt.trace.json", "trace_disk_size": "268 Bytes", "runtime": 203698000, "runtime_str": "204 ms", "start_timestamp": "01:39:50.711.711711", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 2}, {"name": "aten::to(99%) and 4 others\u2026", "type": "generated", "generated_depth": 1, "instances": 11, "resources": {"cpu2": {"time": {"ts": 1685410791006136000, "dur": 5942000, "relative_dur": 0.014579770384565368, "relative_gap_to_previous": 0.2070832852820874, "parent_is_longest": true, "runtime_str": "5.94 ms"}, "res_name": "aten::to(99%) and 4 others\u2026"}, "gpu3": {"time": {"ts": 1685410791011158000, "dur": 6753000, "relative_dur": 0.016569705386565117, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "6.75 ms"}, "res_name": "Memcpy HtoD Pageable -> Device(99%) and 1 other\u2026"}}, "id": "OiKzTJTMo5drYCIj", "pretty_name": "aten::to(99%) and 4 others\u2026", "trace_file": "/results/RNN/RNN.5.pt.trace.json", "trace_disk_size": "4.1 kB", "runtime": 6753000, "runtime_str": "6.75 ms", "start_timestamp": "01:39:51.006.6136", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 38}], "idx": 1, "id": "N90kSLoyqhksJeUo", "pretty_name": "Load Data", "trace_file": "/results/RNN/RNN.2.pt.trace.json", "trace_disk_size": "8.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/submission_runner.py", "runtime": 407551000, "runtime_str": "408 ms", "start_timestamp": "01:39:50.604.604527", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 80}, {"name": "Forward", "type": "training loop", "instances": 137, "resources": {"cpu2": {"time": {"ts": 1685410791018446000, "dur": 274539000, "relative_dur": 0.1642010109039103, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "275 ms"}}, "gpu10": {"time": {"ts": 1685410791208622000, "dur": 206616000, "relative_dur": 0.12357645386965907, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "207 ms"}}, "gpu3": {"time": {"ts": 1685410791019684000, "dur": 398181000, "relative_dur": 0.23815094657855498, "relative_gap_to_previous": 0.0010604263595796334, "parent_is_longest": true, "runtime_str": "398 ms"}}, "gpu7": {"time": {"ts": 1685410791115832000, "dur": 265604000, "relative_dur": 0.1588570123010654, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "266 ms"}}, "gpu8": {"time": {"ts": 1685410791115832000, "dur": 270873000, "relative_dur": 0.16200838651912805, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "271 ms"}}, "gpu9": {"time": {"ts": 1685410791208581000, "dur": 206523000, "relative_dur": 0.12352083082880125, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "207 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 75, in update_params\n    with hotline.annotate('Forward'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "source_file_num": 75, "is_model_pass": "Forward", "ops": [{"idx": 3, "name": "MaskConv", "type": "MaskConv", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    with hotline.annotate('MaskConv'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 182, "ops": [{"idx": 4, "name": "Conv2d", "type": "Conv2d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 185, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu2": {"time": {"ts": 1685410791018448000, "dur": 2657000, "relative_dur": 0.0181773402384878, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.66 ms"}}, "gpu3": {"time": {"ts": 1685410791019684000, "dur": 12374000, "relative_dur": 0.08465427478774859, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12.4 ms"}}}, "ops": [{"name": "aten::empty", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791018448000, "dur": 5000, "relative_dur": 0.0004040730564085987, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5 us"}, "res_name": "aten::empty"}}, "id": "H84fH1yTdCRyUHC5", "pretty_name": "aten::empty", "trace_file": "/results/RNN/RNN.9.pt.trace.json", "trace_disk_size": "102 Bytes", "runtime": 5000, "runtime_str": "5 us", "start_timestamp": "01:39:51.018.18448", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "Scatter(34%) and 6 others\u2026", "type": "generated", "generated_depth": 1, "instances": 19, "resources": {"cpu2": {"time": {"ts": 1685410791018918000, "dur": 1635000, "relative_dur": 0.13213188944561177, "relative_gap_to_previous": 0.03757879424599968, "parent_is_longest": true, "runtime_str": "1.64 ms"}, "res_name": "Scatter(34%) and 6 others\u2026"}, "gpu3": {"time": {"ts": 1685410791019684000, "dur": 547000, "relative_dur": 0.044205592371100694, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "547 us"}, "res_name": "vectorized_elementwise_kernel<4 BUnaryFunctor  binary_ernal::div_trunc_kernel_cudaTensorIteratorBase&::{lambda#1}::operator const::{lambda#6}::operator const::{lambda #1}> Array<char 2> BUnaryFunctor  binary_ernal::div_trunc_kernel_cudaTensorIteratorBase&::{lambda#1}::operator const::{lambda#6}::operator const::{lambda #1}> Array<char 2>(29%) and 2 others\u2026"}}, "id": "yM3zLLwYbjUTyEKt", "pretty_name": "Scatter(34%) and 6 others\u2026", "trace_file": "/results/RNN/RNN.10.pt.trace.json", "trace_disk_size": "9.6 kB", "runtime": 1635000, "runtime_str": "1.64 ms", "start_timestamp": "01:39:51.018.18918", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 63}, {"name": "aten::conv2d", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791020589000, "dur": 516000, "relative_dur": 0.04170033942136738, "relative_gap_to_previous": 0.0029093260061419106, "parent_is_longest": true, "runtime_str": "516 us"}, "res_name": "aten::cudnn_convolution(62%) and 3 others\u2026"}, "gpu3": {"time": {"ts": 1685410791020724000, "dur": 11334000, "relative_dur": 0.9159528042670114, "relative_gap_to_previous": 0.03984160336188783, "parent_is_longest": true, "runtime_str": "11.3 ms"}, "res_name": "implicit_convolve_sgemm 1024 5 5 3 3 3 1 false false true>    const    const kernel_conv_params  long long      const  const bool(86%) and 2 others\u2026"}}, "id": "1oZGCFtxlkNJbT8T", "pretty_name": "aten::conv2d", "trace_file": "/results/RNN/RNN.11.pt.trace.json", "trace_disk_size": "3.7 kB", "runtime": 11334000, "runtime_str": "11.3 ms", "start_timestamp": "01:39:51.020.20589", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 22}], "id": "G7sk0Biwn0SeMc8q", "pretty_name": "Conv2d", "trace_file": "/results/RNN/RNN.8.pt.trace.json", "trace_disk_size": "13.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 12374000, "runtime_str": "12.4 ms", "start_timestamp": "01:39:51.018.18448", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 86}, {"idx": 5, "name": "BatchNorm2d", "type": "BatchNorm2d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 185, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu2": {"time": {"ts": 1685410791021138000, "dur": 20429000, "relative_dur": 0.13976096489727785, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "20.4 ms"}}, "gpu3": {"time": {"ts": 1685410791032066000, "dur": 29513000, "relative_dur": 0.2019073550841138, "relative_gap_to_previous": 5.473041848246232e-05, "parent_is_longest": true, "runtime_str": "29.5 ms"}}}, "ops": [{"name": "aten::empty", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791021138000, "dur": 33000, "relative_dur": 0.0011181513231457323, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "33 us"}, "res_name": "aten::empty"}}, "id": "AoqSNU9qu11Uk4KC", "pretty_name": "aten::empty", "trace_file": "/results/RNN/RNN.13.pt.trace.json", "trace_disk_size": "103 Bytes", "runtime": 33000, "runtime_str": "33 us", "start_timestamp": "01:39:51.021.21138", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::fill_", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791021183000, "dur": 10223000, "relative_dur": 0.34638972656117645, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "10.2 ms"}, "res_name": "aten::fill_"}}, "id": "tw5rZVECMWE0U5l4", "pretty_name": "aten::fill_", "trace_file": "/results/RNN/RNN.14.pt.trace.json", "trace_disk_size": "106 Bytes", "runtime": 10223000, "runtime_str": "10.2 ms", "start_timestamp": "01:39:51.021.21183", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::to", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791031434000, "dur": 94000, "relative_dur": 0.003185037102293904, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "94 us"}, "res_name": "aten::copy_(99%) and 1 other\u2026"}, "gpu3": {"time": {"ts": 1685410791032066000, "dur": 13266000, "relative_dur": 0.4494968319045844, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "13.3 ms"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "K2ov7GlbADeqoJE1", "pretty_name": "aten::to", "trace_file": "/results/RNN/RNN.15.pt.trace.json", "trace_disk_size": "781 Bytes", "runtime": 13266000, "runtime_str": "13.3 ms", "start_timestamp": "01:39:51.031.31434", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 7}, {"name": "aten::fill_(38%) and 9 others\u2026", "type": "generated", "generated_depth": 1, "instances": 386, "resources": {"cpu2": {"time": {"ts": 1685410791045993000, "dur": 9402000, "relative_dur": 0.31857147697624777, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9.40 ms"}, "res_name": "aten::fill_(38%) and 9 others\u2026"}, "gpu3": {"time": {"ts": 1685410791046499000, "dur": 15080000, "relative_dur": 0.510961271304171, "relative_gap_to_previous": 0.039541896791244535, "parent_is_longest": true, "runtime_str": "15.1 ms"}, "res_name": "cudnn::bn_fw_tr_1C11_kernel_NCHW  512 true 1 true>cudnnTensorStruct  const cudnnTensorStruct   const  const(51%) and 5 others\u2026"}}, "id": "hgDFEs1gx9FGYZh4", "pretty_name": "aten::fill_(38%) and 9 others\u2026", "trace_file": "/results/RNN/RNN.16.pt.trace.json", "trace_disk_size": "152.3 kB", "runtime": 15080000, "runtime_str": "15.1 ms", "start_timestamp": "01:39:51.045.45993", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1239}], "id": "pGvKN8fnMRb3cijx", "pretty_name": "BatchNorm2d", "trace_file": "/results/RNN/RNN.12.pt.trace.json", "trace_disk_size": "153.3 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 29513000, "runtime_str": "29.5 ms", "start_timestamp": "01:39:51.021.21138", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1248}, {"idx": 6, "name": "Hardtanh", "type": "Hardtanh", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 185, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu2": {"time": {"ts": 1685410791056606000, "dur": 15078000, "relative_dur": 0.10315315623482087, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "15.1 ms"}}, "gpu3": {"time": {"ts": 1685410791066966000, "dur": 23508000, "relative_dur": 0.16082533471071553, "relative_gap_to_previous": 0.03685409554562807, "parent_is_longest": true, "runtime_str": "23.5 ms"}}}, "ops": [{"name": "aten::empty", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791056606000, "dur": 190000, "relative_dur": 0.00808235494299813, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "190 us"}, "res_name": "aten::empty"}}, "id": "ddCStyf57z0r4Yoh", "pretty_name": "aten::empty", "trace_file": "/results/RNN/RNN.18.pt.trace.json", "trace_disk_size": "104 Bytes", "runtime": 190000, "runtime_str": "190 us", "start_timestamp": "01:39:51.056.56606", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::fill_", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791056804000, "dur": 9882000, "relative_dur": 0.4203675344563553, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9.88 ms"}, "res_name": "aten::fill_"}}, "id": "NQBEIjVrIQeDH0Za", "pretty_name": "aten::fill_", "trace_file": "/results/RNN/RNN.19.pt.trace.json", "trace_disk_size": "105 Bytes", "runtime": 9882000, "runtime_str": "9.88 ms", "start_timestamp": "01:39:51.056.56804", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::to", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791066729000, "dur": 106000, "relative_dur": 0.0045091032839884295, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "106 us"}, "res_name": "aten::copy_(99%) and 1 other\u2026"}, "gpu3": {"time": {"ts": 1685410791066966000, "dur": 12938000, "relative_dur": 0.5503658329079463, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "12.9 ms"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "IRwfNY0EaqTDbZN5", "pretty_name": "aten::to", "trace_file": "/results/RNN/RNN.20.pt.trace.json", "trace_disk_size": "781 Bytes", "runtime": 12938000, "runtime_str": "12.9 ms", "start_timestamp": "01:39:51.066.66729", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 7}, {"name": "aten::item(35%) and 8 others\u2026", "type": "generated", "generated_depth": 1, "instances": 385, "resources": {"cpu2": {"time": {"ts": 1685410791080490000, "dur": 4287000, "relative_dur": 0.18236345074017357, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4.29 ms"}, "res_name": "aten::item(35%) and 8 others\u2026"}, "gpu3": {"time": {"ts": 1685410791080829000, "dur": 9645000, "relative_dur": 0.4102858601327208, "relative_gap_to_previous": 0.039348306959332995, "parent_is_longest": true, "runtime_str": "9.64 ms"}, "res_name": "Memcpy DtoD Device -> Device(47%) and 4 others\u2026"}}, "id": "hhQBwxoPykkRpT3p", "pretty_name": "aten::item(35%) and 8 others\u2026", "trace_file": "/results/RNN/RNN.21.pt.trace.json", "trace_disk_size": "151.6 kB", "runtime": 9645000, "runtime_str": "9.64 ms", "start_timestamp": "01:39:51.080.80490", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1232}], "id": "MRnWBnjRlRPsNO7s", "pretty_name": "Hardtanh", "trace_file": "/results/RNN/RNN.17.pt.trace.json", "trace_disk_size": "152.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 23508000, "runtime_str": "23.5 ms", "start_timestamp": "01:39:51.056.56606", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1241}, {"idx": 7, "name": "Conv2d", "type": "Conv2d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 185, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu2": {"time": {"ts": 1685410791085513000, "dur": 20714000, "relative_dur": 0.14171073605571557, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "20.7 ms"}}, "gpu3": {"time": {"ts": 1685410791096026000, "dur": 38993000, "relative_dur": 0.26676290098583166, "relative_gap_to_previous": 0.03798291042682885, "parent_is_longest": true, "runtime_str": "39 ms"}}, "gpu7": {"time": {"ts": 1685410791115832000, "dur": 18517000, "relative_dur": 0.12668039487996935, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "18.5 ms"}}, "gpu8": {"time": {"ts": 1685410791115832000, "dur": 18526000, "relative_dur": 0.12674196660076212, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "18.5 ms"}}}, "ops": [{"name": "aten::empty", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791085513000, "dur": 23000, "relative_dur": 0.0005898494601595158, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "23 us"}, "res_name": "aten::empty"}}, "id": "fCpaVCrlSgrLVOEd", "pretty_name": "aten::empty", "trace_file": "/results/RNN/RNN.23.pt.trace.json", "trace_disk_size": "103 Bytes", "runtime": 23000, "runtime_str": "23 us", "start_timestamp": "01:39:51.085.85513", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::fill_", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791085539000, "dur": 10267000, "relative_dur": 0.26330366988946735, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "10.3 ms"}, "res_name": "aten::fill_"}}, "id": "YsWF5jLRWlSefbBO", "pretty_name": "aten::fill_", "trace_file": "/results/RNN/RNN.24.pt.trace.json", "trace_disk_size": "106 Bytes", "runtime": 10267000, "runtime_str": "10.3 ms", "start_timestamp": "01:39:51.085.85539", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::to", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791095829000, "dur": 67000, "relative_dur": 0.0017182571230733722, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "67 us"}, "res_name": "aten::copy_(99%) and 1 other\u2026"}, "gpu3": {"time": {"ts": 1685410791096026000, "dur": 12568000, "relative_dur": 0.3223142615341215, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "12.6 ms"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "ONqGEcD0LVZiWSus", "pretty_name": "aten::to", "trace_file": "/results/RNN/RNN.25.pt.trace.json", "trace_disk_size": "781 Bytes", "runtime": 12568000, "runtime_str": "12.6 ms", "start_timestamp": "01:39:51.095.95829", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 7}, {"name": "aten::item(38%) and 8 others\u2026", "type": "generated", "generated_depth": 1, "instances": 385, "resources": {"cpu2": {"time": {"ts": 1685410791109057000, "dur": 3663000, "relative_dur": 0.09393993793757854, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3.66 ms"}, "res_name": "aten::item(38%) and 8 others\u2026"}, "gpu3": {"time": {"ts": 1685410791109281000, "dur": 6550000, "relative_dur": 0.16797886800194906, "relative_gap_to_previous": 0.017618546918677713, "parent_is_longest": true, "runtime_str": "6.55 ms"}, "res_name": "vectorized_elementwise_kernel<4 masked_fill_kernel<bool>TensorIterator& c10::Scalar const&::{lambda#1}::operator const::{lambda#14}::operator const::{lambda bool#1} Array<char 3> masked_fill_kernel<bool>TensorIterator& c10::Scalar const&::{lambda#1}::operator const::{lambda#14}::operator const::{lambda bool#1} Array<char 3>(49%) and 3 others\u2026"}}, "id": "P3YXsjOrPKH3m1Jy", "pretty_name": "aten::item(38%) and 8 others\u2026", "trace_file": "/results/RNN/RNN.26.pt.trace.json", "trace_disk_size": "149.9 kB", "runtime": 6550000, "runtime_str": "6.55 ms", "start_timestamp": "01:39:51.109.109057", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1221}, {"name": "aten::conv2d", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791113377000, "dur": 6200000, "relative_dur": 0.1590028979560434, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "6.20 ms"}, "res_name": "aten::cudnn_convolution(99%) and 2 others\u2026"}, "gpu3": {"time": {"ts": 1685410791115857000, "dur": 19162000, "relative_dur": 0.49142153719898446, "relative_gap_to_previous": 0.0006667863462672788, "parent_is_longest": true, "runtime_str": "19.2 ms"}, "res_name": "ampere_gcgemm_64x64_nt(39%) and 4 others\u2026"}, "gpu7": {"time": {"ts": 1685410791115832000, "dur": 18517000, "relative_dur": 0.47488010668581543, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "18.5 ms"}, "res_name": "ampere_gcgemm_64x64_nt(38%) and 2 others\u2026"}, "gpu8": {"time": {"ts": 1685410791115832000, "dur": 18526000, "relative_dur": 0.4751109173441387, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "18.5 ms"}, "res_name": "ampere_gcgemm_64x64_nt(42%) and 2 others\u2026"}}, "id": "IdzzOpd3cs6RWi5Y", "pretty_name": "aten::conv2d", "trace_file": "/results/RNN/RNN.27.pt.trace.json", "trace_disk_size": "452.4 kB", "runtime": 19162000, "runtime_str": "19.2 ms", "start_timestamp": "01:39:51.113.113377", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 2957}], "id": "Qzwn2jp99L6H3k3t", "pretty_name": "Conv2d", "trace_file": "/results/RNN/RNN.22.pt.trace.json", "trace_disk_size": "603.3 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 38993000, "runtime_str": "39 ms", "start_timestamp": "01:39:51.085.85513", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 4187}, {"idx": 8, "name": "BatchNorm2d", "type": "BatchNorm2d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 185, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu2": {"time": {"ts": 1685410791119596000, "dur": 8818000, "relative_dur": 0.060326603772294096, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "8.82 ms"}}, "gpu3": {"time": {"ts": 1685410791135022000, "dur": 14384000, "relative_dur": 0.09840529243146726, "relative_gap_to_previous": 2.052390693092337e-05, "parent_is_longest": true, "runtime_str": "14.4 ms"}}}, "ops": [{"name": "aten::empty", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791119596000, "dur": 20000, "relative_dur": 0.0013904338153503894, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "20 us"}, "res_name": "aten::empty"}}, "id": "qoMVLAdN5bhD1Of7", "pretty_name": "aten::empty", "trace_file": "/results/RNN/RNN.29.pt.trace.json", "trace_disk_size": "103 Bytes", "runtime": 20000, "runtime_str": "20 us", "start_timestamp": "01:39:51.119.119596", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::fill_", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791119620000, "dur": 4473000, "relative_dur": 0.31097052280311455, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4.47 ms"}, "res_name": "aten::fill_"}}, "id": "3vF7Jjxp94wMU4Ja", "pretty_name": "aten::fill_", "trace_file": "/results/RNN/RNN.30.pt.trace.json", "trace_disk_size": "105 Bytes", "runtime": 4473000, "runtime_str": "4.47 ms", "start_timestamp": "01:39:51.119.119620", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::to", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791124113000, "dur": 70000, "relative_dur": 0.004866518353726363, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "70 us"}, "res_name": "aten::copy_(99%) and 1 other\u2026"}, "gpu3": {"time": {"ts": 1685410791135022000, "dur": 7074000, "relative_dur": 0.4917964404894327, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "7.07 ms"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "0hpCE43Q3u3u5ckU", "pretty_name": "aten::to", "trace_file": "/results/RNN/RNN.31.pt.trace.json", "trace_disk_size": "780 Bytes", "runtime": 7074000, "runtime_str": "7.07 ms", "start_timestamp": "01:39:51.124.124113", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 7}, {"name": "aten::item(36%) and 10 others\u2026", "type": "generated", "generated_depth": 1, "instances": 387, "resources": {"cpu2": {"time": {"ts": 1685410791142491000, "dur": 3859000, "relative_dur": 0.2682842046718576, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3.86 ms"}, "res_name": "aten::item(36%) and 10 others\u2026"}, "gpu3": {"time": {"ts": 1685410791142704000, "dur": 6702000, "relative_dur": 0.4659343715239155, "relative_gap_to_previous": 0.042269187986651836, "parent_is_longest": true, "runtime_str": "6.70 ms"}, "res_name": "cudnn::bn_fw_tr_1C11_kernel_NCHW  512 true 1 true>cudnnTensorStruct  const cudnnTensorStruct   const  const(49%) and 5 others\u2026"}}, "id": "z7BdmiSd1Mfrzlwv", "pretty_name": "aten::item(36%) and 10 others\u2026", "trace_file": "/results/RNN/RNN.32.pt.trace.json", "trace_disk_size": "152.2 kB", "runtime": 6702000, "runtime_str": "6.70 ms", "start_timestamp": "01:39:51.142.142491", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1239}], "id": "kKpMzu8PEgD6e8v1", "pretty_name": "BatchNorm2d", "trace_file": "/results/RNN/RNN.28.pt.trace.json", "trace_disk_size": "153.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 14384000, "runtime_str": "14.4 ms", "start_timestamp": "01:39:51.119.119596", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1248}, {"idx": 9, "name": "Hardtanh", "type": "Hardtanh", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 185, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu2": {"time": {"ts": 1685410791147006000, "dur": 8691000, "relative_dur": 0.059457758378885006, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "8.69 ms"}}, "gpu3": {"time": {"ts": 1685410791151699000, "dur": 14156000, "relative_dur": 0.09684547550471707, "relative_gap_to_previous": 0.01568710619753576, "parent_is_longest": true, "runtime_str": "14.2 ms"}}}, "ops": [{"name": "aten::empty", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791147006000, "dur": 14000, "relative_dur": 0.0009889799378355467, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "14 us"}, "res_name": "aten::empty"}}, "id": "4rxa9JHpHOntzNtO", "pretty_name": "aten::empty", "trace_file": "/results/RNN/RNN.34.pt.trace.json", "trace_disk_size": "103 Bytes", "runtime": 14000, "runtime_str": "14 us", "start_timestamp": "01:39:51.147.147006", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::fill_", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791147023000, "dur": 4460000, "relative_dur": 0.3150607516247528, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4.46 ms"}, "res_name": "aten::fill_"}}, "id": "2ANbZabIyWscRABo", "pretty_name": "aten::fill_", "trace_file": "/results/RNN/RNN.35.pt.trace.json", "trace_disk_size": "105 Bytes", "runtime": 4460000, "runtime_str": "4.46 ms", "start_timestamp": "01:39:51.147.147023", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::to", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791151512000, "dur": 80000, "relative_dur": 0.005651313930488839, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "80 us"}, "res_name": "aten::copy_(99%) and 1 other\u2026"}, "gpu3": {"time": {"ts": 1685410791151699000, "dur": 7053000, "relative_dur": 0.49823396439672224, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "7.05 ms"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "wPlnAwpFxgxjCqMC", "pretty_name": "aten::to", "trace_file": "/results/RNN/RNN.36.pt.trace.json", "trace_disk_size": "776 Bytes", "runtime": 7053000, "runtime_str": "7.05 ms", "start_timestamp": "01:39:51.151.151512", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 7}, {"name": "aten::item(37%) and 9 others\u2026", "type": "generated", "generated_depth": 1, "instances": 388, "resources": {"cpu2": {"time": {"ts": 1685410791159164000, "dur": 3713000, "relative_dur": 0.2622916077988132, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3.71 ms"}, "res_name": "aten::item(37%) and 9 others\u2026"}, "gpu3": {"time": {"ts": 1685410791159373000, "dur": 6482000, "relative_dur": 0.45789771121785816, "relative_gap_to_previous": 0.04386832438541961, "parent_is_longest": true, "runtime_str": "6.48 ms"}, "res_name": "Memcpy DtoD Device -> Device(45%) and 4 others\u2026"}}, "id": "99KfXG4Cps81V6Mo", "pretty_name": "aten::item(37%) and 9 others\u2026", "trace_file": "/results/RNN/RNN.37.pt.trace.json", "trace_disk_size": "151.6 kB", "runtime": 6482000, "runtime_str": "6.48 ms", "start_timestamp": "01:39:51.159.159164", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1232}], "id": "y8BCzyDmzKyBT6kB", "pretty_name": "Hardtanh", "trace_file": "/results/RNN/RNN.33.pt.trace.json", "trace_disk_size": "152.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 14156000, "runtime_str": "14.2 ms", "start_timestamp": "01:39:51.147.147006", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1241}], "resources": {"cpu2": {"time": {"ts": 1685410791018448000, "dur": 76496000, "relative_dur": 0.19211363676318055, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "76.5 ms"}}, "gpu3": {"time": {"ts": 1685410791019684000, "dur": 146171000, "relative_dur": 0.3670968730301044, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "146 ms"}}, "gpu7": {"time": {"ts": 1685410791115832000, "dur": 18517000, "relative_dur": 0.0465039768346556, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "18.5 ms"}}, "gpu8": {"time": {"ts": 1685410791115832000, "dur": 18526000, "relative_dur": 0.0465265796208257, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "18.5 ms"}}}, "id": "dCPb9Rs6VoAwjzPn", "pretty_name": "MaskConv", "trace_file": "/results/RNN/RNN.7.pt.trace.json", "trace_disk_size": "1.2 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 146171000, "runtime_str": "146 ms", "start_timestamp": "01:39:51.018.18448", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 9251}, {"idx": 10, "name": "Layer0", "type": "Layer0", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 193, in forward\n    with hotline.annotate(f'Layer{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 193, "ops": [{"idx": 11, "name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 102, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 102, "resources": {"cpu2": {"time": {"ts": 1685410791163529000, "dur": 44697000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "44.7 ms"}}, "gpu10": {"time": {"ts": 1685410791208622000, "dur": 29252000, "relative_dur": 0.6544510817280802, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "29.2 ms"}}, "gpu3": {"time": {"ts": 1685410791168430000, "dur": 23166000, "relative_dur": 0.5182898181085979, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "23.2 ms"}}, "gpu7": {"time": {"ts": 1685410791192090000, "dur": 8382000, "relative_dur": 0.1875293643868716, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "8.38 ms"}}, "gpu8": {"time": {"ts": 1685410791200304000, "dur": 8455000, "relative_dur": 0.18916258361858737, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "8.46 ms"}}, "gpu9": {"time": {"ts": 1685410791208581000, "dur": 29020000, "relative_dur": 0.6492605767724903, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "29 ms"}}}, "ops": [{"name": "aten::empty", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791163529000, "dur": 19000, "relative_dur": 0.0004250844575698593, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "19 us"}, "res_name": "aten::empty"}}, "id": "EookhpEqzDWFjXaT", "pretty_name": "aten::empty", "trace_file": "/results/RNN/RNN.40.pt.trace.json", "trace_disk_size": "103 Bytes", "runtime": 19000, "runtime_str": "19 us", "start_timestamp": "01:39:51.163.163529", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::fill_", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791163552000, "dur": 4663000, "relative_dur": 0.10432467503411862, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4.66 ms"}, "res_name": "aten::fill_"}}, "id": "fKW6KOeHqe7SeaF0", "pretty_name": "aten::fill_", "trace_file": "/results/RNN/RNN.41.pt.trace.json", "trace_disk_size": "105 Bytes", "runtime": 4663000, "runtime_str": "4.66 ms", "start_timestamp": "01:39:51.163.163552", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1}, {"name": "aten::to", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791168246000, "dur": 79000, "relative_dur": 0.001767456428843099, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "79 us"}, "res_name": "aten::copy_(99%) and 1 other\u2026"}, "gpu3": {"time": {"ts": 1685410791168430000, "dur": 7041000, "relative_dur": 0.1575273508289147, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "7.04 ms"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "fSGbk7lL7ng0qSNo", "pretty_name": "aten::to", "trace_file": "/results/RNN/RNN.42.pt.trace.json", "trace_disk_size": "776 Bytes", "runtime": 7041000, "runtime_str": "7.04 ms", "start_timestamp": "01:39:51.168.168246", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 7}, {"name": "aten::item(33%) and 13 others\u2026", "type": "generated", "generated_depth": 1, "instances": 394, "resources": {"cpu2": {"time": {"ts": 1685410791175877000, "dur": 4357000, "relative_dur": 0.09747857798062509, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4.36 ms"}, "res_name": "aten::item(33%) and 13 others\u2026"}, "gpu3": {"time": {"ts": 1685410791176079000, "dur": 13569000, "relative_dur": 0.3035774213034432, "relative_gap_to_previous": 0.013602702642235497, "parent_is_longest": false, "runtime_str": "13.6 ms"}, "res_name": "elementwise_kernel<128 2 gpu_kernel_impl<direct_copy_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda#1}>TensorIteratorBase& direct_copy_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda#1} const&::{lambda#1}> gpu_kernel_impl<direct_copy_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda#1}>TensorIteratorBase& direct_copy_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda#1} const&::{lambda#1}(82%) and 5 others\u2026"}}, "id": "ISbqxdHlMAM3u6o0", "pretty_name": "aten::item(33%) and 13 others\u2026", "trace_file": "/results/RNN/RNN.43.pt.trace.json", "trace_disk_size": "163.0 kB", "runtime": 13569000, "runtime_str": "13.6 ms", "start_timestamp": "01:39:51.175.175877", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1338}, {"name": "aten::to(86%) and 5 others\u2026", "type": "generated", "generated_depth": 1, "instances": 13, "resources": {"cpu2": {"time": {"ts": 1685410791180909000, "dur": 1610000, "relative_dur": 0.0360203145624986, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.61 ms"}, "res_name": "aten::to(86%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410791189654000, "dur": 1942000, "relative_dur": 0.0434481061368772, "relative_gap_to_previous": 0.00013423719712732398, "parent_is_longest": false, "runtime_str": "1.94 ms"}, "res_name": "CatArrayBatchedCopy  2 128 1> CatArrInputTensorMetadata  128 1> TensorSizeStride 4u>(49%) and 3 others\u2026"}}, "id": "DSR1YIPGNolfj3xx", "pretty_name": "aten::to(86%) and 5 others\u2026", "trace_file": "/results/RNN/RNN.44.pt.trace.json", "trace_disk_size": "108.6 kB", "runtime": 1942000, "runtime_str": "1.94 ms", "start_timestamp": "01:39:51.180.180909", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 678}, {"name": "aten::lstm", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791191268000, "dur": 33522000, "relative_dur": 0.7499832203503591, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "33.5 ms"}, "res_name": "aten::_cudnn_rnn(99%) and 6 others\u2026"}, "gpu10": {"time": {"ts": 1685410791208622000, "dur": 29252000, "relative_dur": 0.6544510817280802, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "29.2 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4>cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4::Params(24%) and 4 others\u2026"}, "gpu7": {"time": {"ts": 1685410791192090000, "dur": 8382000, "relative_dur": 0.1875293643868716, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "8.38 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4>cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4::Params"}, "gpu8": {"time": {"ts": 1685410791200304000, "dur": 8455000, "relative_dur": 0.18916258361858737, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "8.46 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4>cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4::Params"}, "gpu9": {"time": {"ts": 1685410791208581000, "dur": 29020000, "relative_dur": 0.6492605767724903, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "29 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_32x6_tn_align4>cutlass_80_tensorop_s1688gemm_64x64_32x6_tn_align4::Params(66%) and 2 others\u2026"}}, "id": "3bHGh6Rl1VNg8fty", "pretty_name": "aten::lstm", "trace_file": "/results/RNN/RNN.45.pt.trace.json", "trace_disk_size": "2.1 MB", "runtime": 33522000, "runtime_str": "33.5 ms", "start_timestamp": "01:39:51.191.191268", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 11831}], "id": "h41A63Zg9hEjbHjY", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.39.pt.trace.json", "trace_disk_size": "2.4 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 44697000, "runtime_str": "44.7 ms", "start_timestamp": "01:39:51.163.163529", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 13856}], "resources": {"cpu2": {"time": {"ts": 1685410791163529000, "dur": 44697000, "relative_dur": 0.11225297038281586, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "44.7 ms"}}, "gpu10": {"time": {"ts": 1685410791208622000, "dur": 29252000, "relative_dur": 0.07346407789422399, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "29.2 ms"}}, "gpu3": {"time": {"ts": 1685410791168430000, "dur": 23166000, "relative_dur": 0.05817957160185946, "relative_gap_to_previous": 0.0064669082653366185, "parent_is_longest": true, "runtime_str": "23.2 ms"}}, "gpu7": {"time": {"ts": 1685410791192090000, "dur": 8382000, "relative_dur": 0.02105072818642778, "relative_gap_to_previous": 0.14501194180535987, "parent_is_longest": false, "runtime_str": "8.38 ms"}}, "gpu8": {"time": {"ts": 1685410791200304000, "dur": 8455000, "relative_dur": 0.021234061896474216, "relative_gap_to_previous": 0.16561814853044218, "parent_is_longest": false, "runtime_str": "8.46 ms"}}, "gpu9": {"time": {"ts": 1685410791208581000, "dur": 29020000, "relative_dur": 0.0728814282951723, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "29 ms"}}}, "id": "aeKiKOai09UBIsdK", "pretty_name": "Layer0", "trace_file": "/results/RNN/RNN.38.pt.trace.json", "trace_disk_size": "2.4 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 44697000, "runtime_str": "44.7 ms", "start_timestamp": "01:39:51.163.163529", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 13856}, {"idx": 12, "name": "Layer1", "type": "Layer1", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 193, in forward\n    with hotline.annotate(f'Layer{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 193, "ops": [{"idx": 13, "name": "BatchNorm", "type": "BatchNorm", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('BatchNorm'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 98, "ops": [{"idx": 14, "name": "BatchNorm1d", "type": "BatchNorm1d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 99, in forward\n    x = self.batch_norm(x)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 33, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 33, "resources": {"cpu2": {"time": {"ts": 1685410791225072000, "dur": 3076000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3.08 ms"}}, "gpu3": {"time": {"ts": 1685410791237875000, "dur": 2547000, "relative_dur": 0.8280234070221066, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.55 ms"}}}, "ops": [{"name": "aten::_pad_packed_sequence", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791225072000, "dur": 2040000, "relative_dur": 0.6631989596879063, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.04 ms"}, "res_name": "aten::copy_(52%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410791237875000, "dur": 1180000, "relative_dur": 0.3836150845253576, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.18 ms"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>(33%) and 2 others\u2026"}}, "id": "UIQt4obaKQ6JzIDK", "pretty_name": "aten::_pad_packed_sequence", "trace_file": "/results/RNN/RNN.49.pt.trace.json", "trace_disk_size": "101.1 kB", "runtime": 2040000, "runtime_str": "2.04 ms", "start_timestamp": "01:39:51.225.225072", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 609}, {"name": "aten::sum(75%) and 5 others\u2026", "type": "generated", "generated_depth": 1, "instances": 7, "resources": {"cpu2": {"time": {"ts": 1685410791227205000, "dur": 303000, "relative_dur": 0.09850455136540963, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "303 us"}, "res_name": "aten::sum(75%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410791239056000, "dur": 583000, "relative_dur": 0.18953185955786736, "relative_gap_to_previous": 0.00032509752925877764, "parent_is_longest": true, "runtime_str": "583 us"}, "res_name": "reduce_kernel<128 4 ReduceOpfunc_wrapper_tsum_functor::operatorTensorIterator&::{lambda #1}>    4>ReduceOpfunc_wrapper_tsum_functor::operatorTensorIterator&::{lambda #1}>    4>"}}, "id": "8oasJuWcnKJ0CtZI", "pretty_name": "aten::sum(75%) and 5 others\u2026", "trace_file": "/results/RNN/RNN.50.pt.trace.json", "trace_disk_size": "1.8 kB", "runtime": 583000, "runtime_str": "583 us", "start_timestamp": "01:39:51.227.227205", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 13}, {"name": "aten::_cudnn_rnn_flatten_weight", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791227524000, "dur": 231000, "relative_dur": 0.07509752925877763, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "231 us"}, "res_name": "aten::copy_(43%) and 8 others\u2026"}, "gpu3": {"time": {"ts": 1685410791239640000, "dur": 163000, "relative_dur": 0.052990897269180756, "relative_gap_to_previous": 0.00032509752925877764, "parent_is_longest": true, "runtime_str": "163 us"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>(29%) and 1 other\u2026"}}, "id": "c7Exsn1EO7khBSet", "pretty_name": "aten::_cudnn_rnn_flatten_weight", "trace_file": "/results/RNN/RNN.51.pt.trace.json", "trace_disk_size": "10.4 kB", "runtime": 231000, "runtime_str": "231 us", "start_timestamp": "01:39:51.227.227524", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 98}, {"name": "aten::batch_norm(72%) and 5 others\u2026", "type": "generated", "generated_depth": 1, "instances": 9, "resources": {"cpu2": {"time": {"ts": 1685410791227914000, "dur": 359000, "relative_dur": 0.11671001300390117, "relative_gap_to_previous": 0.011053315994798439, "parent_is_longest": true, "runtime_str": "359 us"}, "res_name": "aten::batch_norm(72%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410791239804000, "dur": 618000, "relative_dur": 0.20091027308192458, "relative_gap_to_previous": 0.00032509752925877764, "parent_is_longest": true, "runtime_str": "618 us"}, "res_name": "batch_norm_transform_input_channels_last_kernel  4> const  const  const  const  const  const    bool(64%) and 4 others\u2026"}}, "id": "vGk9jYK13Qh2yVAx", "pretty_name": "aten::batch_norm(72%) and 5 others\u2026", "trace_file": "/results/RNN/RNN.52.pt.trace.json", "trace_disk_size": "5.0 kB", "runtime": 618000, "runtime_str": "618 us", "start_timestamp": "01:39:51.227.227914", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 33}], "id": "hhrfrPf6qegNKcnz", "pretty_name": "BatchNorm1d", "trace_file": "/results/RNN/RNN.48.pt.trace.json", "trace_disk_size": "118.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 3076000, "runtime_str": "3.08 ms", "start_timestamp": "01:39:51.225.225072", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 753}], "resources": {"cpu2": {"time": {"ts": 1685410791225072000, "dur": 3076000, "relative_dur": 0.08208576841992901, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3.08 ms"}}, "gpu3": {"time": {"ts": 1685410791237875000, "dur": 2547000, "relative_dur": 0.06796893763509727, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "2.55 ms"}}}, "id": "wBjEwUpszokfqRnJ", "pretty_name": "BatchNorm", "trace_file": "/results/RNN/RNN.47.pt.trace.json", "trace_disk_size": "118.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 3076000, "runtime_str": "3.08 ms", "start_timestamp": "01:39:51.225.225072", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 753}, {"idx": 15, "name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 102, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 102, "resources": {"cpu2": {"time": {"ts": 1685410791228279000, "dur": 34391000, "relative_dur": 0.9177541162970673, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "34.4 ms"}}, "gpu10": {"time": {"ts": 1685410791253133000, "dur": 28847000, "relative_dur": 0.7698075948015904, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "28.9 ms"}}, "gpu3": {"time": {"ts": 1685410791240426000, "dur": 1620000, "relative_dur": 0.04323112641101593, "relative_gap_to_previous": 0.00010674352200250847, "parent_is_longest": false, "runtime_str": "1.62 ms"}}, "gpu7": {"time": {"ts": 1685410791242617000, "dur": 5364000, "relative_dur": 0.14314306300536386, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5.36 ms"}}, "gpu8": {"time": {"ts": 1685410791247873000, "dur": 5334000, "relative_dur": 0.14234248659034504, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5.33 ms"}}, "gpu9": {"time": {"ts": 1685410791253097000, "dur": 28862000, "relative_dur": 0.7702078830090999, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "28.9 ms"}}}, "ops": [{"name": "aten::transpose(40%) and 3 others\u2026", "type": "generated", "generated_depth": 1, "instances": 4, "resources": {"cpu2": {"time": {"ts": 1685410791228279000, "dur": 144000, "relative_dur": 0.004187141984821611, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "144 us"}, "res_name": "aten::transpose(40%) and 3 others\u2026"}}, "id": "cOYiGGK4uhSHQKTu", "pretty_name": "aten::transpose(40%) and 3 others\u2026", "trace_file": "/results/RNN/RNN.54.pt.trace.json", "trace_disk_size": "716 Bytes", "runtime": 144000, "runtime_str": "144 us", "start_timestamp": "01:39:51.228.228279", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 7}, {"name": "aten::to(90%) and 5 others\u2026", "type": "generated", "generated_depth": 1, "instances": 13, "resources": {"cpu2": {"time": {"ts": 1685410791228427000, "dur": 1459000, "relative_dur": 0.0424238899712134, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.46 ms"}, "res_name": "aten::to(90%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410791240426000, "dur": 1620000, "relative_dur": 0.04710534732924312, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "1.62 ms"}, "res_name": "CatArrayBatchedCopy  2 128 1> CatArrInputTensorMetadata  128 1> TensorSizeStride 4u>(45%) and 3 others\u2026"}}, "id": "Amk0YvPgvbnokOaq", "pretty_name": "aten::to(90%) and 5 others\u2026", "trace_file": "/results/RNN/RNN.55.pt.trace.json", "trace_disk_size": "108.6 kB", "runtime": 1620000, "runtime_str": "1.62 ms", "start_timestamp": "01:39:51.228.228427", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 678}, {"name": "aten::lstm", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791241887000, "dur": 32775000, "relative_dur": 0.9530109621703352, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "32.8 ms"}, "res_name": "aten::_cudnn_rnn(99%) and 6 others\u2026"}, "gpu10": {"time": {"ts": 1685410791253133000, "dur": 28847000, "relative_dur": 0.838795033584368, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "28.9 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_32x6_tn_align4>cutlass_80_tensorop_s1688gemm_64x64_32x6_tn_align4::Params(67%) and 3 others\u2026"}, "gpu7": {"time": {"ts": 1685410791242617000, "dur": 5364000, "relative_dur": 0.15597103893460498, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5.36 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4>cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4::Params"}, "gpu8": {"time": {"ts": 1685410791247873000, "dur": 5334000, "relative_dur": 0.15509871768776715, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5.33 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4>cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4::Params"}, "gpu9": {"time": {"ts": 1685410791253097000, "dur": 28862000, "relative_dur": 0.8392311942077869, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "28.9 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4>cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4::Params(17%) and 4 others\u2026"}}, "id": "D0azYJKplfTq4q5b", "pretty_name": "aten::lstm", "trace_file": "/results/RNN/RNN.56.pt.trace.json", "trace_disk_size": "2.1 MB", "runtime": 32775000, "runtime_str": "32.8 ms", "start_timestamp": "01:39:51.241.241887", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 11831}], "id": "MnRUVJU2CkXEIcPG", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.53.pt.trace.json", "trace_disk_size": "2.2 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 34391000, "runtime_str": "34.4 ms", "start_timestamp": "01:39:51.228.228279", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 12516}], "resources": {"cpu2": {"time": {"ts": 1685410791225072000, "dur": 37473000, "relative_dur": 0.09411046735027538, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "37.5 ms"}}, "gpu10": {"time": {"ts": 1685410791253133000, "dur": 28847000, "relative_dur": 0.0724469525165691, "relative_gap_to_previous": 0.0383217682410763, "parent_is_longest": false, "runtime_str": "28.9 ms"}}, "gpu3": {"time": {"ts": 1685410791237875000, "dur": 4171000, "relative_dur": 0.010475135679502538, "relative_gap_to_previous": 0.11622603790738383, "parent_is_longest": true, "runtime_str": "4.17 ms"}}, "gpu7": {"time": {"ts": 1685410791242617000, "dur": 5364000, "relative_dur": 0.013471260557384707, "relative_gap_to_previous": 0.10584382479324729, "parent_is_longest": false, "runtime_str": "5.36 ms"}}, "gpu8": {"time": {"ts": 1685410791247873000, "dur": 5334000, "relative_dur": 0.01339591793681768, "relative_gap_to_previous": 0.09823170869529184, "parent_is_longest": false, "runtime_str": "5.33 ms"}}, "gpu9": {"time": {"ts": 1685410791253097000, "dur": 28862000, "relative_dur": 0.07248462382685261, "relative_gap_to_previous": 0.03891697494355582, "parent_is_longest": false, "runtime_str": "28.9 ms"}}}, "id": "0mR0tvIybOfCHTB9", "pretty_name": "Layer1", "trace_file": "/results/RNN/RNN.46.pt.trace.json", "trace_disk_size": "2.3 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 37473000, "runtime_str": "37.5 ms", "start_timestamp": "01:39:51.225.225072", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 13269}, {"idx": 16, "name": "Layer2", "type": "Layer2", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 193, in forward\n    with hotline.annotate(f'Layer{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 193, "ops": [{"idx": 17, "name": "BatchNorm", "type": "BatchNorm", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('BatchNorm'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 98, "ops": [{"idx": 18, "name": "BatchNorm1d", "type": "BatchNorm1d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 99, in forward\n    x = self.batch_norm(x)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 33, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 33, "resources": {"cpu2": {"time": {"ts": 1685410791274927000, "dur": 2997000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 ms"}}, "gpu3": {"time": {"ts": 1685410791281981000, "dur": 2547000, "relative_dur": 0.8498498498498499, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.55 ms"}}}, "ops": [{"name": "aten::_pad_packed_sequence", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791274927000, "dur": 2042000, "relative_dur": 0.681348014681348, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.04 ms"}, "res_name": "aten::copy_(55%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410791281981000, "dur": 1176000, "relative_dur": 0.3923923923923924, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.18 ms"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>(33%) and 2 others\u2026"}}, "id": "iWNsyXEZgab5Pa6Q", "pretty_name": "aten::_pad_packed_sequence", "trace_file": "/results/RNN/RNN.60.pt.trace.json", "trace_disk_size": "101.1 kB", "runtime": 2042000, "runtime_str": "2.04 ms", "start_timestamp": "01:39:51.274.274927", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 609}, {"name": "aten::sum(68%) and 5 others\u2026", "type": "generated", "generated_depth": 1, "instances": 7, "resources": {"cpu2": {"time": {"ts": 1685410791277065000, "dur": 285000, "relative_dur": 0.09509509509509509, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "285 us"}, "res_name": "aten::sum(68%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410791283158000, "dur": 585000, "relative_dur": 0.19519519519519518, "relative_gap_to_previous": 0.000333667000333667, "parent_is_longest": true, "runtime_str": "585 us"}, "res_name": "reduce_kernel<128 4 ReduceOpfunc_wrapper_tsum_functor::operatorTensorIterator&::{lambda #1}>    4>ReduceOpfunc_wrapper_tsum_functor::operatorTensorIterator&::{lambda #1}>    4>"}}, "id": "pahPZ4TF0PvqdXPV", "pretty_name": "aten::sum(68%) and 5 others\u2026", "trace_file": "/results/RNN/RNN.61.pt.trace.json", "trace_disk_size": "1.8 kB", "runtime": 585000, "runtime_str": "585 us", "start_timestamp": "01:39:51.277.277065", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 13}, {"name": "aten::_cudnn_rnn_flatten_weight", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791277367000, "dur": 227000, "relative_dur": 0.07574240907574241, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "227 us"}, "res_name": "aten::copy_(46%) and 8 others\u2026"}, "gpu3": {"time": {"ts": 1685410791283744000, "dur": 163000, "relative_dur": 0.054387721054387723, "relative_gap_to_previous": 0.000333667000333667, "parent_is_longest": true, "runtime_str": "163 us"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>(29%) and 1 other\u2026"}}, "id": "HiedJY663sbrrCgj", "pretty_name": "aten::_cudnn_rnn_flatten_weight", "trace_file": "/results/RNN/RNN.62.pt.trace.json", "trace_disk_size": "10.4 kB", "runtime": 227000, "runtime_str": "227 us", "start_timestamp": "01:39:51.277.277367", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 98}, {"name": "aten::batch_norm(71%) and 5 others\u2026", "type": "generated", "generated_depth": 1, "instances": 8, "resources": {"cpu2": {"time": {"ts": 1685410791277756000, "dur": 297000, "relative_dur": 0.0990990990990991, "relative_gap_to_previous": 0.011011011011011011, "parent_is_longest": true, "runtime_str": "297 us"}, "res_name": "aten::batch_norm(71%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410791283908000, "dur": 620000, "relative_dur": 0.20687354020687354, "relative_gap_to_previous": 0.000333667000333667, "parent_is_longest": true, "runtime_str": "620 us"}, "res_name": "batch_norm_transform_input_channels_last_kernel  4> const  const  const  const  const  const    bool(63%) and 4 others\u2026"}}, "id": "fZph3DmLcQZ1UEEX", "pretty_name": "aten::batch_norm(71%) and 5 others\u2026", "trace_file": "/results/RNN/RNN.63.pt.trace.json", "trace_disk_size": "4.9 kB", "runtime": 620000, "runtime_str": "620 us", "start_timestamp": "01:39:51.277.277756", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 33}], "id": "2sfYtA6tCECVA9es", "pretty_name": "BatchNorm1d", "trace_file": "/results/RNN/RNN.59.pt.trace.json", "trace_disk_size": "118.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 2997000, "runtime_str": "3 ms", "start_timestamp": "01:39:51.274.274927", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 753}], "resources": {"cpu2": {"time": {"ts": 1685410791274927000, "dur": 2997000, "relative_dur": 0.08188300866096555, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3 ms"}}, "gpu3": {"time": {"ts": 1685410791281981000, "dur": 2547000, "relative_dur": 0.06958826261577553, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "2.55 ms"}}}, "id": "mxJyvX1CnAlOsu2x", "pretty_name": "BatchNorm", "trace_file": "/results/RNN/RNN.58.pt.trace.json", "trace_disk_size": "118.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 2997000, "runtime_str": "3 ms", "start_timestamp": "01:39:51.274.274927", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 753}, {"idx": 19, "name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 102, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 102, "resources": {"cpu2": {"time": {"ts": 1685410791278059000, "dur": 33598000, "relative_dur": 0.9179530613917652, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "33.6 ms"}}, "gpu10": {"time": {"ts": 1685410791297335000, "dur": 28795000, "relative_dur": 0.7867271386027704, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "28.8 ms"}}, "gpu3": {"time": {"ts": 1685410791284535000, "dur": 1627000, "relative_dur": 0.04445233736783148, "relative_gap_to_previous": 0.00019125160514740035, "parent_is_longest": false, "runtime_str": "1.63 ms"}}, "gpu7": {"time": {"ts": 1685410791286727000, "dur": 5416000, "relative_dur": 0.14797409906833148, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5.42 ms"}}, "gpu8": {"time": {"ts": 1685410791292029000, "dur": 5376000, "relative_dur": 0.14688123275320347, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5.38 ms"}}, "gpu9": {"time": {"ts": 1685410791297293000, "dur": 28731000, "relative_dur": 0.7849785524985656, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "28.7 ms"}}}, "ops": [{"name": "aten::transpose(38%) and 3 others\u2026", "type": "generated", "generated_depth": 1, "instances": 4, "resources": {"cpu2": {"time": {"ts": 1685410791278059000, "dur": 142000, "relative_dur": 0.004226442050122031, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "142 us"}, "res_name": "aten::transpose(38%) and 3 others\u2026"}}, "id": "EwN3GAnHoT3WsZaF", "pretty_name": "aten::transpose(38%) and 3 others\u2026", "trace_file": "/results/RNN/RNN.65.pt.trace.json", "trace_disk_size": "716 Bytes", "runtime": 142000, "runtime_str": "142 us", "start_timestamp": "01:39:51.278.278059", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 7}, {"name": "aten::to(82%) and 5 others\u2026", "type": "generated", "generated_depth": 1, "instances": 13, "resources": {"cpu2": {"time": {"ts": 1685410791278204000, "dur": 1467000, "relative_dur": 0.043663313292457887, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.47 ms"}, "res_name": "aten::to(82%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410791284535000, "dur": 1627000, "relative_dur": 0.0484255015179475, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "1.63 ms"}, "res_name": "CatArrayBatchedCopy  2 128 1> CatArrInputTensorMetadata  128 1> TensorSizeStride 4u>(45%) and 3 others\u2026"}}, "id": "F0R9owjtc4O6PPW0", "pretty_name": "aten::to(82%) and 5 others\u2026", "trace_file": "/results/RNN/RNN.66.pt.trace.json", "trace_disk_size": "108.6 kB", "runtime": 1627000, "runtime_str": "1.63 ms", "start_timestamp": "01:39:51.278.278204", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 678}, {"name": "aten::lstm", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791286003000, "dur": 31977000, "relative_dur": 0.9517530805405083, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "32 ms"}, "res_name": "aten::_cudnn_rnn(99%) and 6 others\u2026"}, "gpu10": {"time": {"ts": 1685410791297335000, "dur": 28795000, "relative_dur": 0.8570450622060837, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "28.8 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4>cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4::Params(17%) and 4 others\u2026"}, "gpu7": {"time": {"ts": 1685410791286727000, "dur": 5416000, "relative_dur": 0.1612000714328234, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5.42 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4>cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4::Params"}, "gpu8": {"time": {"ts": 1685410791292029000, "dur": 5376000, "relative_dur": 0.16000952437645097, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5.38 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4>cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4::Params"}, "gpu9": {"time": {"ts": 1685410791297293000, "dur": 28731000, "relative_dur": 0.8551401869158879, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "28.7 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_32x6_tn_align4>cutlass_80_tensorop_s1688gemm_64x64_32x6_tn_align4::Params(68%) and 2 others\u2026"}}, "id": "eXEUGGtKek2CtEez", "pretty_name": "aten::lstm", "trace_file": "/results/RNN/RNN.67.pt.trace.json", "trace_disk_size": "2.1 MB", "runtime": 31977000, "runtime_str": "32 ms", "start_timestamp": "01:39:51.286.286003", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 11831}], "id": "GZa741kc2vhRoSmJ", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.64.pt.trace.json", "trace_disk_size": "2.2 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 33598000, "runtime_str": "33.6 ms", "start_timestamp": "01:39:51.278.278059", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 12516}], "resources": {"cpu2": {"time": {"ts": 1685410791274927000, "dur": 36601000, "relative_dur": 0.09192050851246042, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "36.6 ms"}}, "gpu10": {"time": {"ts": 1685410791297335000, "dur": 28795000, "relative_dur": 0.07231635864091958, "relative_gap_to_previous": 0.038562864626890785, "parent_is_longest": false, "runtime_str": "28.8 ms"}}, "gpu3": {"time": {"ts": 1685410791281981000, "dur": 4181000, "relative_dur": 0.010500249886358214, "relative_gap_to_previous": 0.10029358507814286, "parent_is_longest": true, "runtime_str": "4.18 ms"}}, "gpu7": {"time": {"ts": 1685410791286727000, "dur": 5416000, "relative_dur": 0.013601854433034223, "relative_gap_to_previous": 0.09730750588300295, "parent_is_longest": false, "runtime_str": "5.42 ms"}}, "gpu8": {"time": {"ts": 1685410791292029000, "dur": 5376000, "relative_dur": 0.013501397605611518, "relative_gap_to_previous": 0.0974983738551061, "parent_is_longest": false, "runtime_str": "5.38 ms"}}, "gpu9": {"time": {"ts": 1685410791297293000, "dur": 28731000, "relative_dur": 0.07215562771704326, "relative_gap_to_previous": 0.03851012479249387, "parent_is_longest": false, "runtime_str": "28.7 ms"}}}, "id": "FPryvO6tepHy3itu", "pretty_name": "Layer2", "trace_file": "/results/RNN/RNN.57.pt.trace.json", "trace_disk_size": "2.3 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 36601000, "runtime_str": "36.6 ms", "start_timestamp": "01:39:51.274.274927", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 13269}, {"idx": 20, "name": "Layer3", "type": "Layer3", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 193, in forward\n    with hotline.annotate(f'Layer{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 193, "ops": [{"idx": 21, "name": "BatchNorm", "type": "BatchNorm", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('BatchNorm'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 98, "ops": [{"idx": 22, "name": "BatchNorm1d", "type": "BatchNorm1d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 99, in forward\n    x = self.batch_norm(x)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 33, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 33, "resources": {"cpu2": {"time": {"ts": 1685410791318241000, "dur": 2775000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.77 ms"}}, "gpu3": {"time": {"ts": 1685410791326132000, "dur": 2548000, "relative_dur": 0.9181981981981981, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.55 ms"}}}, "ops": [{"name": "aten::_pad_packed_sequence", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791318241000, "dur": 1825000, "relative_dur": 0.6576576576576577, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.82 ms"}, "res_name": "aten::copy_(54%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410791326132000, "dur": 1174000, "relative_dur": 0.42306306306306307, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.17 ms"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>(33%) and 2 others\u2026"}}, "id": "tNQQaR976WmLghbu", "pretty_name": "aten::_pad_packed_sequence", "trace_file": "/results/RNN/RNN.71.pt.trace.json", "trace_disk_size": "101.1 kB", "runtime": 1825000, "runtime_str": "1.82 ms", "start_timestamp": "01:39:51.318.318241", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 609}, {"name": "aten::sum(66%) and 6 others\u2026", "type": "generated", "generated_depth": 1, "instances": 8, "resources": {"cpu2": {"time": {"ts": 1685410791320160000, "dur": 275000, "relative_dur": 0.0990990990990991, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "275 us"}, "res_name": "aten::sum(66%) and 6 others\u2026"}, "gpu3": {"time": {"ts": 1685410791327307000, "dur": 582000, "relative_dur": 0.20972972972972972, "relative_gap_to_previous": 0.00036036036036036037, "parent_is_longest": true, "runtime_str": "582 us"}, "res_name": "reduce_kernel<128 4 ReduceOpfunc_wrapper_tsum_functor::operatorTensorIterator&::{lambda #1}>    4>ReduceOpfunc_wrapper_tsum_functor::operatorTensorIterator&::{lambda #1}>    4>"}}, "id": "a6eyzxv3SMfnnXgK", "pretty_name": "aten::sum(66%) and 6 others\u2026", "trace_file": "/results/RNN/RNN.72.pt.trace.json", "trace_disk_size": "1.8 kB", "runtime": 582000, "runtime_str": "582 us", "start_timestamp": "01:39:51.320.320160", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 13}, {"name": "aten::_cudnn_rnn_flatten_weight", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791320449000, "dur": 239000, "relative_dur": 0.08612612612612612, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "239 us"}, "res_name": "aten::copy_(45%) and 8 others\u2026"}, "gpu3": {"time": {"ts": 1685410791327891000, "dur": 164000, "relative_dur": 0.0590990990990991, "relative_gap_to_previous": 0.0007207207207207207, "parent_is_longest": true, "runtime_str": "164 us"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>(28%) and 1 other\u2026"}}, "id": "hD9fdKsv9hJ1e58I", "pretty_name": "aten::_cudnn_rnn_flatten_weight", "trace_file": "/results/RNN/RNN.73.pt.trace.json", "trace_disk_size": "10.4 kB", "runtime": 239000, "runtime_str": "239 us", "start_timestamp": "01:39:51.320.320449", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 98}, {"name": "aten::batch_norm(70%) and 4 others\u2026", "type": "generated", "generated_depth": 1, "instances": 7, "resources": {"cpu2": {"time": {"ts": 1685410791320847000, "dur": 298000, "relative_dur": 0.10738738738738739, "relative_gap_to_previous": 0.010810810810810811, "parent_is_longest": true, "runtime_str": "298 us"}, "res_name": "aten::batch_norm(70%) and 4 others\u2026"}, "gpu3": {"time": {"ts": 1685410791328056000, "dur": 624000, "relative_dur": 0.22486486486486487, "relative_gap_to_previous": 0.00036036036036036037, "parent_is_longest": true, "runtime_str": "624 us"}, "res_name": "batch_norm_transform_input_channels_last_kernel  4> const  const  const  const  const  const    bool(63%) and 4 others\u2026"}}, "id": "UsMlfQJpyW5Q1j3R", "pretty_name": "aten::batch_norm(70%) and 4 others\u2026", "trace_file": "/results/RNN/RNN.74.pt.trace.json", "trace_disk_size": "4.9 kB", "runtime": 624000, "runtime_str": "624 us", "start_timestamp": "01:39:51.320.320847", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 33}], "id": "TdYSxVrjIRxkuoeq", "pretty_name": "BatchNorm1d", "trace_file": "/results/RNN/RNN.70.pt.trace.json", "trace_disk_size": "118.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 2775000, "runtime_str": "2.77 ms", "start_timestamp": "01:39:51.318.318241", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 753}], "resources": {"cpu2": {"time": {"ts": 1685410791318241000, "dur": 2775000, "relative_dur": 0.07410077705679724, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.77 ms"}}, "gpu3": {"time": {"ts": 1685410791326132000, "dur": 2548000, "relative_dur": 0.06803919997863761, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "2.55 ms"}}}, "id": "FhI5YbESrAiwulhI", "pretty_name": "BatchNorm", "trace_file": "/results/RNN/RNN.69.pt.trace.json", "trace_disk_size": "118.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 2775000, "runtime_str": "2.77 ms", "start_timestamp": "01:39:51.318.318241", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 753}, {"idx": 23, "name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 102, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 102, "resources": {"cpu2": {"time": {"ts": 1685410791321151000, "dur": 34668000, "relative_dur": 0.9257390050468637, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "34.7 ms"}}, "gpu10": {"time": {"ts": 1685410791342453000, "dur": 28801000, "relative_dur": 0.7690726054100243, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "28.8 ms"}}, "gpu3": {"time": {"ts": 1685410791328690000, "dur": 1621000, "relative_dur": 0.043285534994258856, "relative_gap_to_previous": 0.00026702982723170177, "parent_is_longest": false, "runtime_str": "1.62 ms"}}, "gpu7": {"time": {"ts": 1685410791331857000, "dur": 5401000, "relative_dur": 0.14422280968784212, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5.40 ms"}}, "gpu8": {"time": {"ts": 1685410791337143000, "dur": 5372000, "relative_dur": 0.1434484231888702, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5.37 ms"}}, "gpu9": {"time": {"ts": 1685410791342401000, "dur": 28748000, "relative_dur": 0.7676573473256962, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "28.8 ms"}}}, "ops": [{"name": "aten::transpose(41%) and 3 others\u2026", "type": "generated", "generated_depth": 1, "instances": 4, "resources": {"cpu2": {"time": {"ts": 1685410791321151000, "dur": 143000, "relative_dur": 0.004124841352255683, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "143 us"}, "res_name": "aten::transpose(41%) and 3 others\u2026"}}, "id": "lz4xH99aq9o9ubHC", "pretty_name": "aten::transpose(41%) and 3 others\u2026", "trace_file": "/results/RNN/RNN.76.pt.trace.json", "trace_disk_size": "716 Bytes", "runtime": 143000, "runtime_str": "143 us", "start_timestamp": "01:39:51.321.321151", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 7}, {"name": "aten::to(84%) and 5 others\u2026", "type": "generated", "generated_depth": 1, "instances": 12, "resources": {"cpu2": {"time": {"ts": 1685410791321297000, "dur": 1462000, "relative_dur": 0.042171454944040614, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.46 ms"}, "res_name": "aten::to(84%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410791328690000, "dur": 1621000, "relative_dur": 0.04675781700703819, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "1.62 ms"}, "res_name": "CatArrayBatchedCopy  2 128 1> CatArrInputTensorMetadata  128 1> TensorSizeStride 4u>(45%) and 3 others\u2026"}}, "id": "7etc6qWxJKduaHaC", "pretty_name": "aten::to(84%) and 5 others\u2026", "trace_file": "/results/RNN/RNN.77.pt.trace.json", "trace_disk_size": "108.6 kB", "runtime": 1621000, "runtime_str": "1.62 ms", "start_timestamp": "01:39:51.321.321297", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 678}, {"name": "aten::lstm", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791330153000, "dur": 33052000, "relative_dur": 0.9533864082150687, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "33 ms"}, "res_name": "aten::_cudnn_rnn(99%) and 6 others\u2026"}, "gpu10": {"time": {"ts": 1685410791342453000, "dur": 28801000, "relative_dur": 0.8307661243798315, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "28.8 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4>cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4::Params(17%) and 4 others\u2026"}, "gpu7": {"time": {"ts": 1685410791331857000, "dur": 5401000, "relative_dur": 0.15579208491981078, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5.40 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4>cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4::Params"}, "gpu8": {"time": {"ts": 1685410791337143000, "dur": 5372000, "relative_dur": 0.1549555786315911, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5.37 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4>cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4::Params"}, "gpu9": {"time": {"ts": 1685410791342401000, "dur": 28748000, "relative_dur": 0.8292373370254991, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "28.8 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_32x6_tn_align4>cutlass_80_tensorop_s1688gemm_64x64_32x6_tn_align4::Params(68%) and 2 others\u2026"}}, "id": "rE20wmEJbxJQpbbk", "pretty_name": "aten::lstm", "trace_file": "/results/RNN/RNN.78.pt.trace.json", "trace_disk_size": "2.1 MB", "runtime": 33052000, "runtime_str": "33 ms", "start_timestamp": "01:39:51.330.330153", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 11831}], "id": "4vHHoOrlvd7zamIA", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.75.pt.trace.json", "trace_disk_size": "2.2 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 34668000, "runtime_str": "34.7 ms", "start_timestamp": "01:39:51.321.321151", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 12516}], "resources": {"cpu2": {"time": {"ts": 1685410791318241000, "dur": 37449000, "relative_dur": 0.09405019325382176, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "37.5 ms"}}, "gpu10": {"time": {"ts": 1685410791342453000, "dur": 28801000, "relative_dur": 0.07233142716503299, "relative_gap_to_previous": 0.04099391985052024, "parent_is_longest": false, "runtime_str": "28.8 ms"}}, "gpu3": {"time": {"ts": 1685410791326132000, "dur": 4179000, "relative_dur": 0.01049522704498708, "relative_gap_to_previous": 0.10038148480213772, "parent_is_longest": true, "runtime_str": "4.18 ms"}}, "gpu7": {"time": {"ts": 1685410791331857000, "dur": 5401000, "relative_dur": 0.01356418312275071, "relative_gap_to_previous": 0.09973856110663241, "parent_is_longest": false, "runtime_str": "5.40 ms"}}, "gpu8": {"time": {"ts": 1685410791337143000, "dur": 5372000, "relative_dur": 0.013491351922869248, "relative_gap_to_previous": 0.09979883520308604, "parent_is_longest": false, "runtime_str": "5.37 ms"}}, "gpu9": {"time": {"ts": 1685410791342401000, "dur": 28748000, "relative_dur": 0.0721983218686979, "relative_gap_to_previous": 0.04112953656754089, "parent_is_longest": false, "runtime_str": "28.8 ms"}}}, "id": "LR2GGT6fMPmm8VuU", "pretty_name": "Layer3", "trace_file": "/results/RNN/RNN.68.pt.trace.json", "trace_disk_size": "2.3 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 37449000, "runtime_str": "37.5 ms", "start_timestamp": "01:39:51.318.318241", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 13269}, {"idx": 24, "name": "Layer4", "type": "Layer4", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 193, in forward\n    with hotline.annotate(f'Layer{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 193, "ops": [{"idx": 25, "name": "BatchNorm", "type": "BatchNorm", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('BatchNorm'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 98, "ops": [{"idx": 26, "name": "BatchNorm1d", "type": "BatchNorm1d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 99, in forward\n    x = self.batch_norm(x)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 33, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 33, "resources": {"cpu2": {"time": {"ts": 1685410791363474000, "dur": 2836000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.84 ms"}}, "gpu3": {"time": {"ts": 1685410791371256000, "dur": 2549000, "relative_dur": 0.8988011283497884, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.55 ms"}}}, "ops": [{"name": "aten::_pad_packed_sequence", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791363474000, "dur": 1875000, "relative_dur": 0.6611424541607899, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.88 ms"}, "res_name": "aten::copy_(56%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410791371256000, "dur": 1178000, "relative_dur": 0.4153737658674189, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.18 ms"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>(33%) and 2 others\u2026"}}, "id": "UBWFTZbY0130ETJh", "pretty_name": "aten::_pad_packed_sequence", "trace_file": "/results/RNN/RNN.82.pt.trace.json", "trace_disk_size": "101.1 kB", "runtime": 1875000, "runtime_str": "1.88 ms", "start_timestamp": "01:39:51.363.363474", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 609}, {"name": "aten::sum(64%) and 6 others\u2026", "type": "generated", "generated_depth": 1, "instances": 8, "resources": {"cpu2": {"time": {"ts": 1685410791365444000, "dur": 297000, "relative_dur": 0.10472496473906912, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "297 us"}, "res_name": "aten::sum(64%) and 6 others\u2026"}, "gpu3": {"time": {"ts": 1685410791372435000, "dur": 584000, "relative_dur": 0.2059238363892807, "relative_gap_to_previous": 0.0003526093088857546, "parent_is_longest": true, "runtime_str": "584 us"}, "res_name": "reduce_kernel<128 4 ReduceOpfunc_wrapper_tsum_functor::operatorTensorIterator&::{lambda #1}>    4>ReduceOpfunc_wrapper_tsum_functor::operatorTensorIterator&::{lambda #1}>    4>"}}, "id": "56XfEokEDReVm0pM", "pretty_name": "aten::sum(64%) and 6 others\u2026", "trace_file": "/results/RNN/RNN.83.pt.trace.json", "trace_disk_size": "1.8 kB", "runtime": 584000, "runtime_str": "584 us", "start_timestamp": "01:39:51.365.365444", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 13}, {"name": "aten::_cudnn_rnn_flatten_weight", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791365759000, "dur": 225000, "relative_dur": 0.07933709449929478, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "225 us"}, "res_name": "aten::copy_(45%) and 8 others\u2026"}, "gpu3": {"time": {"ts": 1685410791373020000, "dur": 164000, "relative_dur": 0.05782792665726375, "relative_gap_to_previous": 0.0003526093088857546, "parent_is_longest": true, "runtime_str": "164 us"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>(29%) and 1 other\u2026"}}, "id": "rRLunymRSBEVyjzG", "pretty_name": "aten::_cudnn_rnn_flatten_weight", "trace_file": "/results/RNN/RNN.84.pt.trace.json", "trace_disk_size": "10.4 kB", "runtime": 225000, "runtime_str": "225 us", "start_timestamp": "01:39:51.365.365759", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 98}, {"name": "aten::batch_norm(71%) and 5 others\u2026", "type": "generated", "generated_depth": 1, "instances": 8, "resources": {"cpu2": {"time": {"ts": 1685410791366147000, "dur": 295000, "relative_dur": 0.10401974612129761, "relative_gap_to_previous": 0.010930888575458392, "parent_is_longest": true, "runtime_str": "295 us"}, "res_name": "aten::batch_norm(71%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410791373185000, "dur": 620000, "relative_dur": 0.21861777150916784, "relative_gap_to_previous": 0.0003526093088857546, "parent_is_longest": true, "runtime_str": "620 us"}, "res_name": "batch_norm_transform_input_channels_last_kernel  4> const  const  const  const  const  const    bool(63%) and 4 others\u2026"}}, "id": "Sea2dXAeMTGfUGXp", "pretty_name": "aten::batch_norm(71%) and 5 others\u2026", "trace_file": "/results/RNN/RNN.85.pt.trace.json", "trace_disk_size": "4.9 kB", "runtime": 620000, "runtime_str": "620 us", "start_timestamp": "01:39:51.366.366147", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 33}], "id": "Z6fGXKoiAcRGmJTT", "pretty_name": "BatchNorm1d", "trace_file": "/results/RNN/RNN.81.pt.trace.json", "trace_disk_size": "118.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 2836000, "runtime_str": "2.84 ms", "start_timestamp": "01:39:51.363.363474", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 753}], "resources": {"cpu2": {"time": {"ts": 1685410791363474000, "dur": 2836000, "relative_dur": 0.07594665524074769, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.84 ms"}}, "gpu3": {"time": {"ts": 1685410791371256000, "dur": 2549000, "relative_dur": 0.06826093942477639, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "2.55 ms"}}}, "id": "SdUYcrg2sdNmJFvY", "pretty_name": "BatchNorm", "trace_file": "/results/RNN/RNN.80.pt.trace.json", "trace_disk_size": "118.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 2836000, "runtime_str": "2.84 ms", "start_timestamp": "01:39:51.363.363474", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 753}, {"idx": 27, "name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 102, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 102, "resources": {"cpu2": {"time": {"ts": 1685410791366448000, "dur": 34500000, "relative_dur": 0.9238926677735526, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "34.5 ms"}}, "gpu10": {"time": {"ts": 1685410791386635000, "dur": 28603000, "relative_dur": 0.7659739703283166, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "28.6 ms"}}, "gpu3": {"time": {"ts": 1685410791373810000, "dur": 1613000, "relative_dur": 0.043195329655615664, "relative_gap_to_previous": 0.00013389748808312357, "parent_is_longest": false, "runtime_str": "1.61 ms"}}, "gpu7": {"time": {"ts": 1685410791376045000, "dur": 5391000, "relative_dur": 0.14436827165122382, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5.39 ms"}}, "gpu8": {"time": {"ts": 1685410791381323000, "dur": 5382000, "relative_dur": 0.1441272561726742, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5.38 ms"}}, "gpu9": {"time": {"ts": 1685410791386600000, "dur": 28504000, "relative_dur": 0.7633228000642708, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "28.5 ms"}}}, "ops": [{"name": "aten::transpose(38%) and 3 others\u2026", "type": "generated", "generated_depth": 1, "instances": 4, "resources": {"cpu2": {"time": {"ts": 1685410791366448000, "dur": 144000, "relative_dur": 0.0041739130434782605, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "144 us"}, "res_name": "aten::transpose(38%) and 3 others\u2026"}}, "id": "lN1hWhm7FlZrbeNH", "pretty_name": "aten::transpose(38%) and 3 others\u2026", "trace_file": "/results/RNN/RNN.87.pt.trace.json", "trace_disk_size": "716 Bytes", "runtime": 144000, "runtime_str": "144 us", "start_timestamp": "01:39:51.366.366448", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 7}, {"name": "aten::to(84%) and 5 others\u2026", "type": "generated", "generated_depth": 1, "instances": 13, "resources": {"cpu2": {"time": {"ts": 1685410791366595000, "dur": 1461000, "relative_dur": 0.04234782608695652, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.46 ms"}, "res_name": "aten::to(84%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410791373810000, "dur": 1613000, "relative_dur": 0.0467536231884058, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "1.61 ms"}, "res_name": "CatArrayBatchedCopy  2 128 1> CatArrInputTensorMetadata  128 1> TensorSizeStride 4u>(45%) and 3 others\u2026"}}, "id": "hmI7rTixkeqEglUr", "pretty_name": "aten::to(84%) and 5 others\u2026", "trace_file": "/results/RNN/RNN.88.pt.trace.json", "trace_disk_size": "108.6 kB", "runtime": 1613000, "runtime_str": "1.61 ms", "start_timestamp": "01:39:51.366.366595", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 678}, {"name": "aten::lstm", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791375272000, "dur": 32883000, "relative_dur": 0.9531304347826087, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "32.9 ms"}, "res_name": "aten::_cudnn_rnn(99%) and 6 others\u2026"}, "gpu10": {"time": {"ts": 1685410791386635000, "dur": 28603000, "relative_dur": 0.8290724637681159, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "28.6 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4>cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4::Params(17%) and 4 others\u2026"}, "gpu7": {"time": {"ts": 1685410791376045000, "dur": 5391000, "relative_dur": 0.1562608695652174, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5.39 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4>cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4::Params"}, "gpu8": {"time": {"ts": 1685410791381323000, "dur": 5382000, "relative_dur": 0.156, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "5.38 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4>cutlass_80_tensorop_s1688gemm_256x128_16x3_tn_align4::Params"}, "gpu9": {"time": {"ts": 1685410791386600000, "dur": 28504000, "relative_dur": 0.8262028985507246, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "28.5 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_32x6_tn_align4>cutlass_80_tensorop_s1688gemm_64x64_32x6_tn_align4::Params(69%) and 2 others\u2026"}}, "id": "zKl4UyBNfrbgPW2p", "pretty_name": "aten::lstm", "trace_file": "/results/RNN/RNN.89.pt.trace.json", "trace_disk_size": "2.1 MB", "runtime": 32883000, "runtime_str": "32.9 ms", "start_timestamp": "01:39:51.375.375272", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 11831}], "id": "03aekSZKhss9I2dt", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.86.pt.trace.json", "trace_disk_size": "2.2 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 34500000, "runtime_str": "34.5 ms", "start_timestamp": "01:39:51.366.366448", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 12516}], "resources": {"cpu2": {"time": {"ts": 1685410791363474000, "dur": 37342000, "relative_dur": 0.09378147124046601, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "37.3 ms"}}, "gpu10": {"time": {"ts": 1685410791386635000, "dur": 28603000, "relative_dur": 0.0718341658692906, "relative_gap_to_previous": 0.038628161564715546, "parent_is_longest": false, "runtime_str": "28.6 ms"}}, "gpu3": {"time": {"ts": 1685410791371256000, "dur": 4167000, "relative_dur": 0.010465089996760267, "relative_gap_to_previous": 0.10283011997056615, "parent_is_longest": true, "runtime_str": "4.17 ms"}}, "gpu7": {"time": {"ts": 1685410791376045000, "dur": 5391000, "relative_dur": 0.013539068915895033, "relative_gap_to_previous": 0.09741047413111123, "parent_is_longest": false, "runtime_str": "5.39 ms"}}, "gpu8": {"time": {"ts": 1685410791381323000, "dur": 5382000, "relative_dur": 0.013516466129724925, "relative_gap_to_previous": 0.09746321396550815, "parent_is_longest": false, "runtime_str": "5.38 ms"}}, "gpu9": {"time": {"ts": 1685410791386600000, "dur": 28504000, "relative_dur": 0.0715855352214194, "relative_gap_to_previous": 0.03880396101270528, "parent_is_longest": false, "runtime_str": "28.5 ms"}}}, "id": "mrq6nfYz810iHOYU", "pretty_name": "Layer4", "trace_file": "/results/RNN/RNN.79.pt.trace.json", "trace_disk_size": "2.3 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 37342000, "runtime_str": "37.3 ms", "start_timestamp": "01:39:51.363.363474", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 13269}, {"idx": 28, "name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 196, in forward\n    with hotline.annotate('Linear'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 196, "resources": {"cpu2": {"time": {"ts": 1685410791408438000, "dur": 2296000, "relative_dur": 0.0057662218940632524, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.30 ms"}}, "gpu3": {"time": {"ts": 1685410791415240000, "dur": 2609000, "relative_dur": 0.006552296568645918, "relative_gap_to_previous": 0.09999723743724588, "parent_is_longest": true, "runtime_str": "2.61 ms"}}}, "ops": [{"name": "aten::_pad_packed_sequence", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791408438000, "dur": 1820000, "relative_dur": 0.697585281717133, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.82 ms"}, "res_name": "aten::copy_(55%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410791415240000, "dur": 1178000, "relative_dur": 0.451513990034496, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.18 ms"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>(33%) and 2 others\u2026"}}, "id": "bvPwAtDQt8iulqe4", "pretty_name": "aten::_pad_packed_sequence", "trace_file": "/results/RNN/RNN.91.pt.trace.json", "trace_disk_size": "101.1 kB", "runtime": 1820000, "runtime_str": "1.82 ms", "start_timestamp": "01:39:51.408.408438", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 609}, {"name": "aten::batch_norm(39%) and 7 others\u2026", "type": "generated", "generated_depth": 1, "instances": 10, "resources": {"cpu2": {"time": {"ts": 1685410791410350000, "dur": 467000, "relative_dur": 0.17899578382522038, "relative_gap_to_previous": 0.0034495975469528554, "parent_is_longest": true, "runtime_str": "467 us"}, "res_name": "aten::batch_norm(39%) and 7 others\u2026"}, "gpu3": {"time": {"ts": 1685410791416419000, "dur": 1430000, "relative_dur": 0.5481027213491759, "relative_gap_to_previous": 0.0003832886163280951, "parent_is_longest": true, "runtime_str": "1.43 ms"}, "res_name": "reduce_kernel<128 4 ReduceOpfunc_wrapper_tsum_functor::operatorTensorIterator&::{lambda #1}>    4>ReduceOpfunc_wrapper_tsum_functor::operatorTensorIterator&::{lambda #1}>    4>(41%) and 6 others\u2026"}}, "id": "dsPBtVl8gts1GthF", "pretty_name": "aten::batch_norm(39%) and 7 others\u2026", "trace_file": "/results/RNN/RNN.92.pt.trace.json", "trace_disk_size": "6.8 kB", "runtime": 1430000, "runtime_str": "1.43 ms", "start_timestamp": "01:39:51.410.410350", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 46}], "id": "AZltJOjdKTpxN1hw", "pretty_name": "Linear", "trace_file": "/results/RNN/RNN.90.pt.trace.json", "trace_disk_size": "107.9 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 2609000, "runtime_str": "2.61 ms", "start_timestamp": "01:39:51.408.408438", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 655}, {"idx": 29, "name": "SoftMax", "type": "SoftMax", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 200, in forward\n    with hotline.annotate('SoftMax'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 200, "resources": {"cpu2": {"time": {"ts": 1685410791410823000, "dur": 185000, "relative_dur": 0.00046461282683000945, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "185 us"}}, "gpu3": {"time": {"ts": 1685410791417850000, "dur": 15000, "relative_dur": 3.767131028351428e-05, "relative_gap_to_previous": 2.5114206855676186e-06, "parent_is_longest": true, "runtime_str": "15 us"}}}, "ops": [{"name": "aten::zeros(50%) and 2 others\u2026", "type": "generated", "generated_depth": 1, "instances": 3, "resources": {"cpu2": {"time": {"ts": 1685410791410823000, "dur": 135000, "relative_dur": 0.7297297297297297, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "135 us"}, "res_name": "aten::zeros(50%) and 2 others\u2026"}}, "id": "c870hNT24kwIU8Lt", "pretty_name": "aten::zeros(50%) and 2 others\u2026", "trace_file": "/results/RNN/RNN.94.pt.trace.json", "trace_disk_size": "505 Bytes", "runtime": 135000, "runtime_str": "135 us", "start_timestamp": "01:39:51.410.410823", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 5}, {"name": "aten::log_softmax", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791410967000, "dur": 41000, "relative_dur": 0.22162162162162163, "relative_gap_to_previous": 0.04864864864864865, "parent_is_longest": true, "runtime_str": "41 us"}, "res_name": "cudaLaunchKernel"}, "gpu3": {"time": {"ts": 1685410791417850000, "dur": 15000, "relative_dur": 0.08108108108108109, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "15 us"}, "res_name": "softmax_warp_forward  5 true false>  const    bool const  bool"}}, "id": "dOjf1Oqw6Er3QP9j", "pretty_name": "aten::log_softmax", "trace_file": "/results/RNN/RNN.95.pt.trace.json", "trace_disk_size": "560 Bytes", "runtime": 41000, "runtime_str": "41 us", "start_timestamp": "01:39:51.410.410967", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 4}], "id": "xKlJijXtKMj4SkuZ", "pretty_name": "SoftMax", "trace_file": "/results/RNN/RNN.93.pt.trace.json", "trace_disk_size": "1.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 185000, "runtime_str": "185 us", "start_timestamp": "01:39:51.410.410823", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 9}], "idx": 2, "id": "Qr38UwC8QcBgCWRR", "pretty_name": "Forward", "trace_file": "/results/RNN/RNN.6.pt.trace.json", "trace_disk_size": "13.2 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "runtime": 398181000, "runtime_str": "398 ms", "start_timestamp": "01:39:51.018.18446", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 77628}, {"name": "Calc Loss", "type": "training loop", "instances": 8, "resources": {"cpu2": {"time": {"ts": 1685410791412869000, "dur": 392000, "relative_dur": 0.00023445410770175763, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "392 us"}}, "gpu3": {"time": {"ts": 1685410791417870000, "dur": 721000, "relative_dur": 0.0004312280909514471, "relative_gap_to_previous": 2.9904860676244598e-06, "parent_is_longest": true, "runtime_str": "721 us"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 80, in update_params\n    with hotline.annotate('Calc Loss'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "source_file_num": 80, "ops": [{"name": "aten::ctc_loss", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791412869000, "dur": 173000, "relative_dur": 0.23994452149791956, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "173 us"}, "res_name": "aten::to(98%) and 2 others\u2026"}, "gpu3": {"time": {"ts": 1685410791417870000, "dur": 642000, "relative_dur": 0.8904299583911235, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "642 us"}, "res_name": "ctc_loss_log_alpha_gpu_kernellong>  const long const long long const long const long  long long long long long long long const long long long(98%) and 3 others\u2026"}}, "id": "FPv6hSstHVNsP1vu", "pretty_name": "aten::ctc_loss", "trace_file": "/results/RNN/RNN.97.pt.trace.json", "trace_disk_size": "6.2 kB", "runtime": 642000, "runtime_str": "642 us", "start_timestamp": "01:39:51.412.412869", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 56}, {"name": "aten::to", "type": "generated", "generated_depth": 1, "instances": 2, "resources": {"cpu2": {"time": {"ts": 1685410791418057000, "dur": 24000, "relative_dur": 0.033287101248266296, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "24 us"}, "res_name": "aten::to"}, "gpu3": {"time": {"ts": 1685410791418513000, "dur": 0, "relative_dur": 0.0, "relative_gap_to_previous": 0.0013869625520110957, "parent_is_longest": true, "runtime_str": "0 us"}, "res_name": "Memcpy HtoD Pageable -> Device"}}, "id": "mulzQpD3FHBFH3jd", "pretty_name": "aten::to", "trace_file": "/results/RNN/RNN.98.pt.trace.json", "trace_disk_size": "1.2 kB", "runtime": 24000, "runtime_str": "24 us", "start_timestamp": "01:39:51.418.418057", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 11}, {"name": "aten::mean(46%) and 3 others\u2026", "type": "generated", "generated_depth": 1, "instances": 5, "resources": {"cpu2": {"time": {"ts": 1685410791418525000, "dur": 181000, "relative_dur": 0.2510402219140083, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "181 us"}, "res_name": "aten::mean(46%) and 3 others\u2026"}, "gpu3": {"time": {"ts": 1685410791418551000, "dur": 40000, "relative_dur": 0.05547850208044383, "relative_gap_to_previous": 0.052704576976421634, "parent_is_longest": true, "runtime_str": "40 us"}, "res_name": "reduce_kernel<512 1 ReduceOpMeanOps>    4>ReduceOpMeanOps>    4>(67%) and 1 other\u2026"}}, "id": "W8U7j6gAwvSc1Gh8", "pretty_name": "aten::mean(46%) and 3 others\u2026", "trace_file": "/results/RNN/RNN.99.pt.trace.json", "trace_disk_size": "2.0 kB", "runtime": 181000, "runtime_str": "181 us", "start_timestamp": "01:39:51.418.418525", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 15}], "idx": 30, "id": "K15cvveiciJVbS1E", "pretty_name": "Calc Loss", "trace_file": "/results/RNN/RNN.96.pt.trace.json", "trace_disk_size": "9.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "runtime": 721000, "runtime_str": "721 us", "start_timestamp": "01:39:51.412.412869", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 82}, {"name": "Zero Grad", "type": "training loop", "instances": 4, "resources": {"cpu2": {"time": {"ts": 1685410791418709000, "dur": 1024000, "relative_dur": 0.0006124515466494893, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.02 ms"}}, "gpu3": {"time": {"ts": 1685410791418746000, "dur": 987000, "relative_dur": 0.0005903219497490683, "relative_gap_to_previous": 9.270506809635825e-05, "parent_is_longest": true, "runtime_str": "987 us"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 83, in update_params\n    with hotline.annotate('Zero Grad'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "source_file_num": 83, "ops": [{"name": "Optimizer.zero_grad#Adam.zero_grad", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410791418709000, "dur": 883000, "relative_dur": 0.8623046875, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "883 us"}, "res_name": "aten::zero_"}, "gpu3": {"time": {"ts": 1685410791418746000, "dur": 841000, "relative_dur": 0.8212890625, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "841 us"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>"}}, "id": "CMNxKumNm3PaYCvs", "pretty_name": "Optimizer.zero_grad#Adam.zero_grad", "trace_file": "/results/RNN/RNN.101.pt.trace.json", "trace_disk_size": "34.1 kB", "runtime": 883000, "runtime_str": "883 us", "start_timestamp": "01:39:51.418.418709", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 238}, {"name": "aten::ones_like(82%) and 2 others\u2026", "type": "generated", "generated_depth": 1, "instances": 3, "resources": {"cpu2": {"time": {"ts": 1685410791419668000, "dur": 65000, "relative_dur": 0.0634765625, "relative_gap_to_previous": 0.07421875, "parent_is_longest": true, "runtime_str": "65 us"}, "res_name": "aten::ones_like(82%) and 2 others\u2026"}, "gpu3": {"time": {"ts": 1685410791419732000, "dur": 1000, "relative_dur": 0.0009765625, "relative_gap_to_previous": 0.1416015625, "parent_is_longest": true, "runtime_str": "1 us"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>"}}, "id": "j6araNAfZU55I7bf", "pretty_name": "aten::ones_like(82%) and 2 others\u2026", "trace_file": "/results/RNN/RNN.102.pt.trace.json", "trace_disk_size": "1.2 kB", "runtime": 65000, "runtime_str": "65 us", "start_timestamp": "01:39:51.419.419668", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 10}], "idx": 31, "id": "zK0ZBReL666xCu8G", "pretty_name": "Zero Grad", "trace_file": "/results/RNN/RNN.100.pt.trace.json", "trace_disk_size": "35.3 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "runtime": 1024000, "runtime_str": "1.02 ms", "start_timestamp": "01:39:51.418.418709", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 248}, {"name": "Backward", "type": "training loop", "instances": 1041, "resources": {"cpu11": {"time": {"ts": 1685410791420744000, "dur": 852391000, "relative_dur": 0.5098126819336961, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "852 ms"}}, "cpu2": {"time": {"ts": 1685410792371087000, "dur": 57000, "relative_dur": 0.5098126819336961, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "57 us"}}, "gpu12": {"time": {"ts": 1685410791544330000, "dur": 842639000, "relative_dur": 0.5039800379074014, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "843 ms"}}, "gpu13": {"time": {"ts": 1685410791544332000, "dur": 825889000, "relative_dur": 0.49396190958085945, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "826 ms"}}, "gpu14": {"time": {"ts": 1685410791593676000, "dur": 807460000, "relative_dur": 0.48293957603280924, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "807 ms"}}, "gpu15": {"time": {"ts": 1685410791593804000, "dur": 808133000, "relative_dur": 0.4833420954575115, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "808 ms"}}, "gpu3": {"time": {"ts": 1685410791420990000, "dur": 1121724000, "relative_dur": 0.6708999987439959, "relative_gap_to_previous": 0.0007518081974007892, "parent_is_longest": true, "runtime_str": "1.12 s"}}, "gpu4": {"time": {"ts": 1685410791579645000, "dur": 854335000, "relative_dur": 0.5109753829167886, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "854 ms"}}, "gpu5": {"time": {"ts": 1685410791584691000, "dur": 849361000, "relative_dur": 0.5080004473767157, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "849 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 86, in update_params\n    with hotline.annotate('Backward'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "source_file_num": 86, "is_model_pass": "Backward", "ops": [{"name": "SoftMax", "type": "SoftMax", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 200, in forward\n    with hotline.annotate('SoftMax'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 200, "resources": {"cpu11": {"time": {"ts": 1685410791420744000, "dur": 1036000, "relative_dur": 0.0009235783490412972, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.04 ms"}}, "gpu3": {"time": {"ts": 1685410791420990000, "dur": 2395000, "relative_dur": 0.0021351063184883268, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.40 ms"}}}, "is_backward_op": true, "ops": [{"name": "Mean0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410791420744000, "dur": 273000, "relative_dur": 0.1139874739039666, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "273 us"}, "res_name": "aten::div(84%) and 1 other\u2026"}, "gpu3": {"time": {"ts": 1685410791420990000, "dur": 2000, "relative_dur": 0.0008350730688935282, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "elementwise_kernel<128 2 gpu_kernel_impl<BUnaryFunctor  binary_ernal::MulFunctorTensorIteratorBase& BUnaryFunctor  binary_ernal::MulFunctor const&::{lambda#1}> gpu_kernel_impl<BUnaryFunctor  binary_ernal::MulFunctorTensorIteratorBase& BUnaryFunctor  binary_ernal::MulFunctor const&::{lambda#1}"}}, "id": "a3uYPYzNYVcizQdH", "pretty_name": "Mean0", "trace_file": "/results/RNN/RNN.105.pt.trace.json", "trace_disk_size": "1.4 kB", "runtime": 273000, "runtime_str": "273 us", "start_timestamp": "01:39:51.420.420744", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 8}, {"name": "Div0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410791421030000, "dur": 75000, "relative_dur": 0.031315240083507306, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "75 us"}, "res_name": "cudaLaunchKernel"}, "gpu3": {"time": {"ts": 1685410791421075000, "dur": 2000, "relative_dur": 0.0008350730688935282, "relative_gap_to_previous": 0.03465553235908142, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "vectorized_elementwise_kernel<4 BinaryFunctor  binary_ernal::DivFunctor Array<char 3> BinaryFunctor  binary_ernal::DivFunctor Array<char 3>"}}, "id": "A9lAY7QPvjlbNr63", "pretty_name": "Div0", "trace_file": "/results/RNN/RNN.106.pt.trace.json", "trace_disk_size": "846 Bytes", "runtime": 75000, "runtime_str": "75 us", "start_timestamp": "01:39:51.421.421030", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 5}, {"name": "CtcLoss0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410791421114000, "dur": 590000, "relative_dur": 0.24634655532359082, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "590 us"}, "res_name": "aten::logsumexp(41%) and 16 others\u2026"}, "gpu3": {"time": {"ts": 1685410791421219000, "dur": 2141000, "relative_dur": 0.8939457202505219, "relative_gap_to_previous": 0.0592901878914405, "parent_is_longest": true, "runtime_str": "2.14 ms"}, "res_name": "ctc_loss_backward_log_beta_gpu_kernellong>  const long const long long const long const long long long long long long long long const long long long(28%) and 14 others\u2026"}}, "id": "tDoG0t8z1HP5g5DJ", "pretty_name": "CtcLoss0", "trace_file": "/results/RNN/RNN.107.pt.trace.json", "trace_disk_size": "18.2 kB", "runtime": 2141000, "runtime_str": "2.14 ms", "start_timestamp": "01:39:51.421.421114", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 111}, {"name": "LogSoftmax0(62%) and 1 other\u2026", "type": "generated", "generated_depth": 1, "instances": 3, "resources": {"cpu11": {"time": {"ts": 1685410791421768000, "dur": 67000, "relative_dur": 0.027974947807933193, "relative_gap_to_previous": 0.0037578288100208767, "parent_is_longest": true, "runtime_str": "67 us"}, "res_name": "LogSoftmax0(62%) and 1 other\u2026"}, "gpu3": {"time": {"ts": 1685410791423362000, "dur": 23000, "relative_dur": 0.009603340292275574, "relative_gap_to_previous": 0.0008350730688935282, "parent_is_longest": true, "runtime_str": "23 us"}, "res_name": "softmax_warp_backward  5 true false>  const  const    bool const"}}, "id": "azERVYAoAe85Yz9z", "pretty_name": "LogSoftmax0(62%) and 1 other\u2026", "trace_file": "/results/RNN/RNN.108.pt.trace.json", "trace_disk_size": "1.7 kB", "runtime": 67000, "runtime_str": "67 us", "start_timestamp": "01:39:51.421.421768", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 13}], "id": "FZgXrVMoJEzC7L5U", "pretty_name": "SoftMax", "trace_file": "/results/RNN/RNN.104.pt.trace.json", "trace_disk_size": "22.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 2395000, "runtime_str": "2.40 ms", "start_timestamp": "01:39:51.420.420744", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 137}, {"name": "Linear", "type": "Linear", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 196, in forward\n    with hotline.annotate('Linear'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 196, "resources": {"cpu11": {"time": {"ts": 1685410791421840000, "dur": 191000, "relative_dur": 0.00017027361454332796, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "191 us"}}, "gpu3": {"time": {"ts": 1685410791423386000, "dur": 456000, "relative_dur": 0.0004065171111610343, "relative_gap_to_previous": 8.914848928970049e-07, "parent_is_longest": true, "runtime_str": "456 us"}}}, "is_backward_op": true, "ops": [{"name": "View0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410791421840000, "dur": 18000, "relative_dur": 0.039473684210526314, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "18 us"}, "res_name": "aten::_reshape_alias"}}, "id": "OueLZFwYmc12cQWn", "pretty_name": "View0", "trace_file": "/results/RNN/RNN.110.pt.trace.json", "trace_disk_size": "460 Bytes", "runtime": 18000, "runtime_str": "18 us", "start_timestamp": "01:39:51.421.421840", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 4}, {"name": "Mm0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410791421862000, "dur": 169000, "relative_dur": 0.3706140350877193, "relative_gap_to_previous": 0.008771929824561403, "parent_is_longest": true, "runtime_str": "169 us"}, "res_name": "aten::mm(92%) and 1 other\u2026"}, "gpu3": {"time": {"ts": 1685410791423386000, "dur": 456000, "relative_dur": 1.0, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "456 us"}, "res_name": "ampere_sgemm_32x128_nn(53%) and 2 others\u2026"}}, "id": "Z8sNOTkSzZk1C9Px", "pretty_name": "Mm0", "trace_file": "/results/RNN/RNN.111.pt.trace.json", "trace_disk_size": "3.3 kB", "runtime": 456000, "runtime_str": "456 us", "start_timestamp": "01:39:51.421.421862", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 27}], "id": "MyKjc4WjhXIy7KqV", "pretty_name": "Linear", "trace_file": "/results/RNN/RNN.109.pt.trace.json", "trace_disk_size": "3.7 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 456000, "runtime_str": "456 us", "start_timestamp": "01:39:51.421.421840", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 31}, {"name": "Layer4", "type": "Layer4", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 193, in forward\n    with hotline.annotate(f'Layer{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 193, "ops": [{"name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 102, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 102, "resources": {"cpu11": {"time": {"ts": 1685410791422037000, "dur": 151763000, "relative_dur": 0.7830584908775695, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "152 ms"}}, "gpu12": {"time": {"ts": 1685410791544330000, "dur": 49769000, "relative_dur": 0.2567953851234211, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "49.8 ms"}}, "gpu13": {"time": {"ts": 1685410791544332000, "dur": 55565000, "relative_dur": 0.2867012713613473, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "55.6 ms"}}, "gpu14": {"time": {"ts": 1685410791593676000, "dur": 19064000, "relative_dur": 0.09836539255345497, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "19.1 ms"}}, "gpu15": {"time": {"ts": 1685410791593804000, "dur": 19742000, "relative_dur": 0.10186370015685627, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "19.7 ms"}}, "gpu3": {"time": {"ts": 1685410791423843000, "dur": 166409000, "relative_dur": 0.858628126805911, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "166 ms"}}, "gpu4": {"time": {"ts": 1685410791579645000, "dur": 21617000, "relative_dur": 0.11153822339635103, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "21.6 ms"}}, "gpu5": {"time": {"ts": 1685410791584691000, "dur": 11057000, "relative_dur": 0.05705130851151655, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "11.1 ms"}}}, "is_backward_op": true, "ops": [{"name": "CopySlices(54%) and 7 others\u2026", "type": "generated", "generated_depth": 1, "instances": 191, "resources": {"cpu11": {"time": {"ts": 1685410791422037000, "dur": 9726000, "relative_dur": 0.058446358069575564, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9.73 ms"}, "res_name": "CopySlices(54%) and 7 others\u2026"}, "gpu3": {"time": {"ts": 1685410791423843000, "dur": 120476000, "relative_dur": 0.7239752657608663, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "120 ms"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>(43%) and 6 others\u2026"}}, "id": "VFJQ1yklbjymFINE", "pretty_name": "CopySlices(54%) and 7 others\u2026", "trace_file": "/results/RNN/RNN.114.pt.trace.json", "trace_disk_size": "419.3 kB", "runtime": 120476000, "runtime_str": "120 ms", "start_timestamp": "01:39:51.422.422037", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 2879}, {"name": "CudnnRnn0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410791432714000, "dur": 142032000, "relative_dur": 0.8535115288235612, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "142 ms"}, "res_name": "cudaLaunchKernel(98%) and 13 others\u2026"}, "gpu12": {"time": {"ts": 1685410791544330000, "dur": 49769000, "relative_dur": 0.2990763720712221, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "49.8 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4>cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4::Params(70%) and 5 others\u2026"}, "gpu13": {"time": {"ts": 1685410791544332000, "dur": 55565000, "relative_dur": 0.33390621901459655, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "55.6 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4>cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4::Params(69%) and 5 others\u2026"}, "gpu14": {"time": {"ts": 1685410791593676000, "dur": 19064000, "relative_dur": 0.11456111147834552, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "19.1 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x128_16x6_nt_align4>cutlass_80_tensorop_s1688gemm_128x128_16x6_nt_align4::Params(20%) and 4 others\u2026"}, "gpu15": {"time": {"ts": 1685410791593804000, "dur": 19742000, "relative_dur": 0.11863541034439243, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "19.7 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x128_16x5_nt_align4>cutlass_80_tensorop_s1688gemm_128x128_16x5_nt_align4::Params(54%) and 4 others\u2026"}, "gpu3": {"time": {"ts": 1685410791544321000, "dur": 45931000, "relative_dur": 0.2760127156584079, "relative_gap_to_previous": 1.201858072580209e-05, "parent_is_longest": true, "runtime_str": "45.9 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x256_16x4_nt_align4>cutlass_80_tensorop_s1688gemm_64x256_16x4_nt_align4::Params(12%) and 14 others\u2026"}, "gpu4": {"time": {"ts": 1685410791579645000, "dur": 21617000, "relative_dur": 0.1299028297748319, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "21.6 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x256_16x4_nt_align4>cutlass_80_tensorop_s1688gemm_64x256_16x4_nt_align4::Params(57%) and 2 others\u2026"}, "gpu5": {"time": {"ts": 1685410791584691000, "dur": 11057000, "relative_dur": 0.06644472354259685, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "11.1 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x256_16x4_nt_align4>cutlass_80_tensorop_s1688gemm_64x256_16x4_nt_align4::Params(52%) and 1 other\u2026"}}, "id": "UmnFFJuwy5dbNnmu", "pretty_name": "CudnnRnn0", "trace_file": "/results/RNN/RNN.115.pt.trace.json", "trace_disk_size": "2.8 MB", "runtime": 142032000, "runtime_str": "142 ms", "start_timestamp": "01:39:51.432.432714", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 16261}], "id": "xb18BX9WSv8LDWAq", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.113.pt.trace.json", "trace_disk_size": "3.2 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 166409000, "runtime_str": "166 ms", "start_timestamp": "01:39:51.422.422037", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 19140}, {"name": "BatchNorm", "type": "BatchNorm", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('BatchNorm'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 98, "ops": [{"name": "BatchNorm1d", "type": "BatchNorm1d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 99, in forward\n    x = self.batch_norm(x)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 33, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 33, "resources": {"cpu11": {"time": {"ts": 1685410791576043000, "dur": 12410000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12.4 ms"}}, "gpu3": {"time": {"ts": 1685410791613549000, "dur": 4102000, "relative_dur": 0.3305398871877518, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4.10 ms"}}}, "is_backward_op": true, "ops": [{"name": "AccumulateGrad", "type": "generated", "generated_depth": 1, "instances": 8, "resources": {"cpu11": {"time": {"ts": 1685410791576043000, "dur": 161000, "relative_dur": 0.01297340854149879, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "161 us"}, "res_name": "AccumulateGrad"}, "gpu3": {"time": {"ts": 1685410791613549000, "dur": 159000, "relative_dur": 0.01281224818694601, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "159 us"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>"}}, "id": "m2R2qNJ0jN2PBXhF", "pretty_name": "AccumulateGrad", "trace_file": "/results/RNN/RNN.118.pt.trace.json", "trace_disk_size": "6.1 kB", "runtime": 161000, "runtime_str": "161 us", "start_timestamp": "01:39:51.576.576043", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 40}, {"name": "PackPaddedSequence0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410791576209000, "dur": 12109000, "relative_dur": 0.9757453666398066, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12.1 ms"}, "res_name": "aten::copy_(61%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410791613709000, "dur": 2971000, "relative_dur": 0.23940370668815472, "relative_gap_to_previous": 8.058017727639001e-05, "parent_is_longest": true, "runtime_str": "2.97 ms"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>(10%) and 1 other\u2026"}}, "id": "eCO4uPR8Lx94JZ3k", "pretty_name": "PackPaddedSequence0", "trace_file": "/results/RNN/RNN.119.pt.trace.json", "trace_disk_size": "793.9 kB", "runtime": 12109000, "runtime_str": "12.1 ms", "start_timestamp": "01:39:51.576.576209", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7517}, {"name": "NativeBatchNorm0(82%) and 2 others\u2026", "type": "generated", "generated_depth": 1, "instances": 3, "resources": {"cpu11": {"time": {"ts": 1685410791591731000, "dur": 128000, "relative_dur": 0.010314262691377921, "relative_gap_to_previous": 0.0005640612409347301, "parent_is_longest": true, "runtime_str": "128 us"}, "res_name": "NativeBatchNorm0(82%) and 2 others\u2026"}, "gpu3": {"time": {"ts": 1685410791616681000, "dur": 970000, "relative_dur": 0.0781627719580983, "relative_gap_to_previous": 8.058017727639001e-05, "parent_is_longest": true, "runtime_str": "970 us"}, "res_name": "batch_norm_backward_elemt_channels_last_kernel<4   const  const  const  const  const  const  const(60%) and 2 others\u2026"}}, "id": "6CemDx38kGrUoVlR", "pretty_name": "NativeBatchNorm0(82%) and 2 others\u2026", "trace_file": "/results/RNN/RNN.120.pt.trace.json", "trace_disk_size": "3.6 kB", "runtime": 970000, "runtime_str": "970 us", "start_timestamp": "01:39:51.591.591731", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 28}], "id": "SaNwMZwzl8GYBRva", "pretty_name": "BatchNorm1d", "trace_file": "/results/RNN/RNN.117.pt.trace.json", "trace_disk_size": "803.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 12410000, "runtime_str": "12.4 ms", "start_timestamp": "01:39:51.576.576043", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7585}], "resources": {"cpu11": {"time": {"ts": 1685410791576043000, "dur": 12410000, "relative_dur": 0.06403244448113597, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12.4 ms"}}, "gpu3": {"time": {"ts": 1685410791613549000, "dur": 4102000, "relative_dur": 0.021165276975150665, "relative_gap_to_previous": 0.12020659621893832, "parent_is_longest": true, "runtime_str": "4.10 ms"}}}, "is_backward_op": true, "id": "CCUFWbwtQccxsu1a", "pretty_name": "BatchNorm", "trace_file": "/results/RNN/RNN.116.pt.trace.json", "trace_disk_size": "803.6 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 12410000, "runtime_str": "12.4 ms", "start_timestamp": "01:39:51.576.576043", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7585}], "resources": {"cpu11": {"time": {"ts": 1685410791422037000, "dur": 164191000, "relative_dur": 0.14637379604965214, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "164 ms"}}, "gpu12": {"time": {"ts": 1685410791544330000, "dur": 49769000, "relative_dur": 0.04436831163459104, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "49.8 ms"}}, "gpu13": {"time": {"ts": 1685410791544332000, "dur": 55565000, "relative_dur": 0.04953535807382208, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "55.6 ms"}}, "gpu14": {"time": {"ts": 1685410791593676000, "dur": 19064000, "relative_dur": 0.016995267998188502, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "19.1 ms"}}, "gpu15": {"time": {"ts": 1685410791593804000, "dur": 19742000, "relative_dur": 0.017599694755572673, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "19.7 ms"}}, "gpu3": {"time": {"ts": 1685410791423843000, "dur": 193808000, "relative_dur": 0.17277690412258273, "relative_gap_to_previous": 8.914848928970049e-07, "parent_is_longest": true, "runtime_str": "194 ms"}}, "gpu4": {"time": {"ts": 1685410791579645000, "dur": 21617000, "relative_dur": 0.019271228929754556, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "21.6 ms"}}, "gpu5": {"time": {"ts": 1685410791584691000, "dur": 11057000, "relative_dur": 0.009857148460762183, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "11.1 ms"}}}, "is_backward_op": true, "id": "HaFWNQgc2wSgQHwC", "pretty_name": "Layer4", "trace_file": "/results/RNN/RNN.112.pt.trace.json", "trace_disk_size": "4.0 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 193808000, "runtime_str": "194 ms", "start_timestamp": "01:39:51.422.422037", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 26725}, {"name": "Layer3", "type": "Layer3", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 193, in forward\n    with hotline.annotate(f'Layer{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 193, "ops": [{"name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 102, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 102, "resources": {"cpu11": {"time": {"ts": 1685410791591866000, "dur": 157249000, "relative_dur": 0.8158014879068658, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "157 ms"}}, "gpu12": {"time": {"ts": 1685410791736738000, "dur": 55681000, "relative_dur": 0.2888707886736462, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "55.7 ms"}}, "gpu13": {"time": {"ts": 1685410791736739000, "dur": 57025000, "relative_dur": 0.2958434066219119, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "57 ms"}}, "gpu14": {"time": {"ts": 1685410791790755000, "dur": 14730000, "relative_dur": 0.07641864760264379, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "14.7 ms"}}, "gpu15": {"time": {"ts": 1685410791790709000, "dur": 15580000, "relative_dur": 0.08082841341813918, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "15.6 ms"}}, "gpu3": {"time": {"ts": 1685410791617652000, "dur": 164795000, "relative_dur": 0.854949832428899, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "165 ms"}}, "gpu4": {"time": {"ts": 1685410791771854000, "dur": 22378000, "relative_dur": 0.1160961640225365, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "22.4 ms"}}, "gpu5": {"time": {"ts": 1685410791776837000, "dur": 11135000, "relative_dur": 0.057767932182989715, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "11.1 ms"}}}, "is_backward_op": true, "ops": [{"name": "CopySlices(55%) and 5 others\u2026", "type": "generated", "generated_depth": 1, "instances": 82, "resources": {"cpu11": {"time": {"ts": 1685410791591866000, "dur": 3907000, "relative_dur": 0.023708243575351194, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3.91 ms"}, "res_name": "CopySlices(55%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410791617652000, "dur": 47558000, "relative_dur": 0.2885888528171364, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "47.6 ms"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>(42%) and 3 others\u2026"}}, "id": "19sbrcwkLhNR5YIj", "pretty_name": "CopySlices(55%) and 5 others\u2026", "trace_file": "/results/RNN/RNN.123.pt.trace.json", "trace_disk_size": "169.9 kB", "runtime": 47558000, "runtime_str": "47.6 ms", "start_timestamp": "01:39:51.591.591866", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1197}, {"name": "Slice0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410791596162000, "dur": 71000, "relative_dur": 0.0004308383142692436, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "71 us"}, "res_name": "Slice0(99%) and 1 other\u2026"}, "gpu3": {"time": {"ts": 1685410791665212000, "dur": 1169000, "relative_dur": 0.007093661822264025, "relative_gap_to_previous": 1.2136290542795594e-05, "parent_is_longest": true, "runtime_str": "1.17 ms"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>(75%) and 2 others\u2026"}}, "id": "YV8DXuc4KHZiHRMW", "pretty_name": "Slice0", "trace_file": "/results/RNN/RNN.124.pt.trace.json", "trace_disk_size": "2.2 kB", "runtime": 1169000, "runtime_str": "1.17 ms", "start_timestamp": "01:39:51.596.596162", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 17}, {"name": "CopySlices(54%) and 2 others\u2026", "type": "generated", "generated_depth": 1, "instances": 105, "resources": {"cpu11": {"time": {"ts": 1685410791613638000, "dur": 5522000, "relative_dur": 0.033508298188658636, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5.52 ms"}, "res_name": "CopySlices(54%) and 2 others\u2026"}, "gpu3": {"time": {"ts": 1685410791666383000, "dur": 70346000, "relative_dur": 0.4268697472617494, "relative_gap_to_previous": 1.2136290542795594e-05, "parent_is_longest": true, "runtime_str": "70.3 ms"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>(43%) and 3 others\u2026"}}, "id": "XhGdXx2CQNqp5EEI", "pretty_name": "CopySlices(54%) and 2 others\u2026", "trace_file": "/results/RNN/RNN.125.pt.trace.json", "trace_disk_size": "243.2 kB", "runtime": 70346000, "runtime_str": "70.3 ms", "start_timestamp": "01:39:51.613.613638", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1635}, {"name": "CudnnRnn0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410791619665000, "dur": 147733000, "relative_dur": 0.8964653053794108, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "148 ms"}, "res_name": "cudaLaunchKernel(98%) and 13 others\u2026"}, "gpu12": {"time": {"ts": 1685410791736738000, "dur": 55681000, "relative_dur": 0.33788039685670074, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "55.7 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4>cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4::Params(69%) and 5 others\u2026"}, "gpu13": {"time": {"ts": 1685410791736739000, "dur": 57025000, "relative_dur": 0.3460359841014594, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "57 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4>cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4::Params(67%) and 5 others\u2026"}, "gpu14": {"time": {"ts": 1685410791790755000, "dur": 14730000, "relative_dur": 0.08938377984768955, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "14.7 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x128_16x6_nt_align4>cutlass_80_tensorop_s1688gemm_128x128_16x6_nt_align4::Params(21%) and 4 others\u2026"}, "gpu15": {"time": {"ts": 1685410791790709000, "dur": 15580000, "relative_dur": 0.09454170332837768, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "15.6 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x128_16x5_nt_align4>cutlass_80_tensorop_s1688gemm_128x128_16x5_nt_align4::Params(49%) and 4 others\u2026"}, "gpu3": {"time": {"ts": 1685410791736731000, "dur": 45716000, "relative_dur": 0.2774113292272217, "relative_gap_to_previous": 1.2136290542795594e-05, "parent_is_longest": true, "runtime_str": "45.7 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x256_16x4_nt_align4>cutlass_80_tensorop_s1688gemm_64x256_16x4_nt_align4::Params(13%) and 14 others\u2026"}, "gpu4": {"time": {"ts": 1685410791771854000, "dur": 22378000, "relative_dur": 0.1357929548833399, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "22.4 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x256_16x4_nt_align4>cutlass_80_tensorop_s1688gemm_64x256_16x4_nt_align4::Params(62%) and 2 others\u2026"}, "gpu5": {"time": {"ts": 1685410791776837000, "dur": 11135000, "relative_dur": 0.06756879759701448, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "11.1 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x256_16x4_nt_align4>cutlass_80_tensorop_s1688gemm_64x256_16x4_nt_align4::Params(52%) and 1 other\u2026"}}, "id": "lIPk3vu7INP969BC", "pretty_name": "CudnnRnn0", "trace_file": "/results/RNN/RNN.126.pt.trace.json", "trace_disk_size": "2.8 MB", "runtime": 147733000, "runtime_str": "148 ms", "start_timestamp": "01:39:51.619.619665", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 16261}], "id": "XHEi9Su0mY6FLwdh", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.122.pt.trace.json", "trace_disk_size": "3.2 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 164795000, "runtime_str": "165 ms", "start_timestamp": "01:39:51.591.591866", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 19110}, {"name": "BatchNorm", "type": "BatchNorm", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('BatchNorm'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 98, "ops": [{"name": "BatchNorm1d", "type": "BatchNorm1d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 99, in forward\n    x = self.batch_norm(x)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 33, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 33, "resources": {"cpu11": {"time": {"ts": 1685410791768662000, "dur": 12142000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12.1 ms"}}, "gpu3": {"time": {"ts": 1685410791806292000, "dur": 4114000, "relative_dur": 0.33882391698237524, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4.11 ms"}}}, "is_backward_op": true, "ops": [{"name": "AccumulateGrad", "type": "generated", "generated_depth": 1, "instances": 8, "resources": {"cpu11": {"time": {"ts": 1685410791768662000, "dur": 156000, "relative_dur": 0.01284796573875803, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "156 us"}, "res_name": "AccumulateGrad"}, "gpu3": {"time": {"ts": 1685410791806292000, "dur": 160000, "relative_dur": 0.013177400757700544, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "160 us"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>"}}, "id": "2JooEg1F9jyGWnsi", "pretty_name": "AccumulateGrad", "trace_file": "/results/RNN/RNN.129.pt.trace.json", "trace_disk_size": "6.1 kB", "runtime": 160000, "runtime_str": "160 us", "start_timestamp": "01:39:51.768.768662", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 40}, {"name": "PackPaddedSequence0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410791768822000, "dur": 11852000, "relative_dur": 0.9761159611266678, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "11.8 ms"}, "res_name": "aten::copy_(61%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410791806453000, "dur": 2980000, "relative_dur": 0.24542908911217262, "relative_gap_to_previous": 8.235875473562839e-05, "parent_is_longest": true, "runtime_str": "2.98 ms"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>(10%) and 1 other\u2026"}}, "id": "gio9ajJRgruFUYRS", "pretty_name": "PackPaddedSequence0", "trace_file": "/results/RNN/RNN.130.pt.trace.json", "trace_disk_size": "793.8 kB", "runtime": 11852000, "runtime_str": "11.8 ms", "start_timestamp": "01:39:51.768.768822", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7517}, {"name": "NativeBatchNorm0(84%) and 2 others\u2026", "type": "generated", "generated_depth": 1, "instances": 3, "resources": {"cpu11": {"time": {"ts": 1685410791784052000, "dur": 122000, "relative_dur": 0.010047768077746665, "relative_gap_to_previous": 0.0006588700378850271, "parent_is_longest": true, "runtime_str": "122 us"}, "res_name": "NativeBatchNorm0(84%) and 2 others\u2026"}, "gpu3": {"time": {"ts": 1685410791809434000, "dur": 972000, "relative_dur": 0.0800527096030308, "relative_gap_to_previous": 8.235875473562839e-05, "parent_is_longest": true, "runtime_str": "972 us"}, "res_name": "batch_norm_backward_elemt_channels_last_kernel<4   const  const  const  const  const  const  const(60%) and 2 others\u2026"}}, "id": "enAKIaAnZCCK67AR", "pretty_name": "NativeBatchNorm0(84%) and 2 others\u2026", "trace_file": "/results/RNN/RNN.131.pt.trace.json", "trace_disk_size": "3.6 kB", "runtime": 972000, "runtime_str": "972 us", "start_timestamp": "01:39:51.784.784052", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 28}], "id": "2tf0I2HyybaQQNKk", "pretty_name": "BatchNorm1d", "trace_file": "/results/RNN/RNN.128.pt.trace.json", "trace_disk_size": "803.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 12142000, "runtime_str": "12.1 ms", "start_timestamp": "01:39:51.768.768662", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7585}], "resources": {"cpu11": {"time": {"ts": 1685410791768662000, "dur": 12142000, "relative_dur": 0.06299220768440603, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12.1 ms"}}, "gpu3": {"time": {"ts": 1685410791806292000, "dur": 4114000, "relative_dur": 0.021343266546997728, "relative_gap_to_previous": 0.12370690102410326, "parent_is_longest": true, "runtime_str": "4.11 ms"}}}, "is_backward_op": true, "id": "rpnHKQxp1lih4SJE", "pretty_name": "BatchNorm", "trace_file": "/results/RNN/RNN.127.pt.trace.json", "trace_disk_size": "803.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 12142000, "runtime_str": "12.1 ms", "start_timestamp": "01:39:51.768.768662", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7585}], "resources": {"cpu11": {"time": {"ts": 1685410791591866000, "dur": 169406000, "relative_dur": 0.15102288976611003, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "169 ms"}}, "gpu12": {"time": {"ts": 1685410791736738000, "dur": 55681000, "relative_dur": 0.049638770321398136, "relative_gap_to_previous": 0.1271605136379359, "parent_is_longest": false, "runtime_str": "55.7 ms"}}, "gpu13": {"time": {"ts": 1685410791736739000, "dur": 57025000, "relative_dur": 0.05083692601745171, "relative_gap_to_previous": 0.12199257571381196, "parent_is_longest": false, "runtime_str": "57 ms"}}, "gpu14": {"time": {"ts": 1685410791790755000, "dur": 14730000, "relative_dur": 0.013131572472372883, "relative_gap_to_previous": 0.15869768320906033, "parent_is_longest": false, "runtime_str": "14.7 ms"}}, "gpu15": {"time": {"ts": 1685410791790709000, "dur": 15580000, "relative_dur": 0.013889334631335338, "relative_gap_to_previous": 0.1579381380803121, "parent_is_longest": false, "runtime_str": "15.6 ms"}}, "gpu3": {"time": {"ts": 1685410791617652000, "dur": 192754000, "relative_dur": 0.1718372790454693, "relative_gap_to_previous": 8.914848928970049e-07, "parent_is_longest": true, "runtime_str": "193 ms"}}, "gpu4": {"time": {"ts": 1685410791771854000, "dur": 22378000, "relative_dur": 0.019949648933249176, "relative_gap_to_previous": 0.15208019084908586, "parent_is_longest": false, "runtime_str": "22.4 ms"}}, "gpu5": {"time": {"ts": 1685410791776837000, "dur": 11135000, "relative_dur": 0.00992668428240815, "relative_gap_to_previous": 0.16143810776982573, "parent_is_longest": false, "runtime_str": "11.1 ms"}}}, "is_backward_op": true, "id": "mL6rIiMpQtyztBlz", "pretty_name": "Layer3", "trace_file": "/results/RNN/RNN.121.pt.trace.json", "trace_disk_size": "4.0 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 192754000, "runtime_str": "193 ms", "start_timestamp": "01:39:51.591.591866", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 26695}, {"name": "Layer2", "type": "Layer2", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 193, in forward\n    with hotline.annotate(f'Layer{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 193, "ops": [{"name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 102, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 102, "resources": {"cpu11": {"time": {"ts": 1685410791784181000, "dur": 157644000, "relative_dur": 0.8217815588640061, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "158 ms"}}, "gpu12": {"time": {"ts": 1685410791929805000, "dur": 49280000, "relative_dur": 0.25689144668251385, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "49.3 ms"}}, "gpu13": {"time": {"ts": 1685410791929806000, "dur": 49736000, "relative_dur": 0.2592685266274657, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "49.7 ms"}}, "gpu14": {"time": {"ts": 1685410791974948000, "dur": 22453000, "relative_dur": 0.11704512281579715, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "22.4 ms"}}, "gpu15": {"time": {"ts": 1685410791974976000, "dur": 23221000, "relative_dur": 0.12104862588097919, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "23.2 ms"}}, "gpu3": {"time": {"ts": 1685410791810406000, "dur": 164540000, "relative_dur": 0.8577296801367864, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "165 ms"}}, "gpu4": {"time": {"ts": 1685410791964550000, "dur": 16009000, "relative_dur": 0.08345322990950416, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "16 ms"}}, "gpu5": {"time": {"ts": 1685410791969310000, "dur": 16808000, "relative_dur": 0.08761833270778598, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "16.8 ms"}}}, "is_backward_op": true, "ops": [{"name": "CopySlices(55%) and 5 others\u2026", "type": "generated", "generated_depth": 1, "instances": 82, "resources": {"cpu11": {"time": {"ts": 1685410791784181000, "dur": 3893000, "relative_dur": 0.023659900328187676, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3.89 ms"}, "res_name": "CopySlices(55%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410791810406000, "dur": 47736000, "relative_dur": 0.29011790446092134, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "47.7 ms"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>(42%) and 3 others\u2026"}}, "id": "1gj8Mih8uQsFHA5i", "pretty_name": "CopySlices(55%) and 5 others\u2026", "trace_file": "/results/RNN/RNN.134.pt.trace.json", "trace_disk_size": "169.9 kB", "runtime": 47736000, "runtime_str": "47.7 ms", "start_timestamp": "01:39:51.784.784181", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1197}, {"name": "Slice0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410791788465000, "dur": 70000, "relative_dur": 0.00042542846724200804, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "70 us"}, "res_name": "Slice0(99%) and 1 other\u2026"}, "gpu3": {"time": {"ts": 1685410791858144000, "dur": 1169000, "relative_dur": 0.007104655402941534, "relative_gap_to_previous": 1.2155099064057372e-05, "parent_is_longest": true, "runtime_str": "1.17 ms"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>(75%) and 2 others\u2026"}}, "id": "X3Zt3LQZ68cb7Dj9", "pretty_name": "Slice0", "trace_file": "/results/RNN/RNN.135.pt.trace.json", "trace_disk_size": "2.2 kB", "runtime": 1169000, "runtime_str": "1.17 ms", "start_timestamp": "01:39:51.788.788465", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 17}, {"name": "CopySlices(55%) and 2 others\u2026", "type": "generated", "generated_depth": 1, "instances": 105, "resources": {"cpu11": {"time": {"ts": 1685410791806381000, "dur": 5481000, "relative_dur": 0.033311048985049226, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5.48 ms"}, "res_name": "CopySlices(55%) and 2 others\u2026"}, "gpu3": {"time": {"ts": 1685410791859315000, "dur": 70480000, "relative_dur": 0.4283456910173818, "relative_gap_to_previous": 1.2155099064057372e-05, "parent_is_longest": true, "runtime_str": "70.5 ms"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>(43%) and 3 others\u2026"}}, "id": "pDhnzvTYDh1EZefx", "pretty_name": "CopySlices(55%) and 2 others\u2026", "trace_file": "/results/RNN/RNN.136.pt.trace.json", "trace_disk_size": "243.2 kB", "runtime": 70480000, "runtime_str": "70.5 ms", "start_timestamp": "01:39:51.806.806381", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1635}, {"name": "CudnnRnn0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410791812370000, "dur": 148184000, "relative_dur": 0.9005955998541388, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "148 ms"}, "res_name": "cudaLaunchKernel(99%) and 13 others\u2026"}, "gpu12": {"time": {"ts": 1685410791929805000, "dur": 49280000, "relative_dur": 0.29950164093837367, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "49.3 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4>cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4::Params(69%) and 5 others\u2026"}, "gpu13": {"time": {"ts": 1685410791929806000, "dur": 49736000, "relative_dur": 0.3022730035249787, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "49.7 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4>cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4::Params(69%) and 5 others\u2026"}, "gpu14": {"time": {"ts": 1685410791974948000, "dur": 22453000, "relative_dur": 0.1364592196426401, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "22.4 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x128_16x6_nt_align4>cutlass_80_tensorop_s1688gemm_128x128_16x6_nt_align4::Params(26%) and 4 others\u2026"}, "gpu15": {"time": {"ts": 1685410791974976000, "dur": 23221000, "relative_dur": 0.1411267776832381, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "23.2 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x128_16x5_nt_align4>cutlass_80_tensorop_s1688gemm_128x128_16x5_nt_align4::Params(55%) and 4 others\u2026"}, "gpu3": {"time": {"ts": 1685410791929797000, "dur": 45149000, "relative_dur": 0.27439528382156314, "relative_gap_to_previous": 1.2155099064057372e-05, "parent_is_longest": true, "runtime_str": "45.1 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x256_16x4_nt_align4>cutlass_80_tensorop_s1688gemm_64x256_16x4_nt_align4::Params(12%) and 14 others\u2026"}, "gpu4": {"time": {"ts": 1685410791964550000, "dur": 16009000, "relative_dur": 0.09729549045824723, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "16 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x256_16x4_nt_align4>cutlass_80_tensorop_s1688gemm_64x256_16x4_nt_align4::Params(50%) and 2 others\u2026"}, "gpu5": {"time": {"ts": 1685410791969310000, "dur": 16808000, "relative_dur": 0.10215145253433816, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "16.8 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x256_16x4_nt_align4>cutlass_80_tensorop_s1688gemm_64x256_16x4_nt_align4::Params(58%) and 1 other\u2026"}}, "id": "KpufURqIh6JUwqBq", "pretty_name": "CudnnRnn0", "trace_file": "/results/RNN/RNN.137.pt.trace.json", "trace_disk_size": "2.8 MB", "runtime": 148184000, "runtime_str": "148 ms", "start_timestamp": "01:39:51.812.812370", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 16261}], "id": "9p5MSxHic6b6vOZh", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.133.pt.trace.json", "trace_disk_size": "3.2 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 164540000, "runtime_str": "165 ms", "start_timestamp": "01:39:51.784.784181", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 19110}, {"name": "BatchNorm", "type": "BatchNorm", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('BatchNorm'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 98, "ops": [{"name": "BatchNorm1d", "type": "BatchNorm1d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 99, in forward\n    x = self.batch_norm(x)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 33, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 33, "resources": {"cpu11": {"time": {"ts": 1685410791961818000, "dur": 12508000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12.5 ms"}}, "gpu3": {"time": {"ts": 1685410791998200000, "dur": 4038000, "relative_dur": 0.3228333866325552, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4.04 ms"}}}, "is_backward_op": true, "ops": [{"name": "AccumulateGrad", "type": "generated", "generated_depth": 1, "instances": 8, "resources": {"cpu11": {"time": {"ts": 1685410791961818000, "dur": 176000, "relative_dur": 0.014070994563479372, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "176 us"}, "res_name": "AccumulateGrad"}, "gpu3": {"time": {"ts": 1685410791998200000, "dur": 159000, "relative_dur": 0.012711864406779662, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "159 us"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>"}}, "id": "AO6EcIP93pt7JnHt", "pretty_name": "AccumulateGrad", "trace_file": "/results/RNN/RNN.140.pt.trace.json", "trace_disk_size": "6.1 kB", "runtime": 176000, "runtime_str": "176 us", "start_timestamp": "01:39:51.961.961818", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 40}, {"name": "PackPaddedSequence0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410791961998000, "dur": 12194000, "relative_dur": 0.9748960665174289, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12.2 ms"}, "res_name": "aten::copy_(61%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410791998360000, "dur": 2909000, "relative_dur": 0.23257115446114487, "relative_gap_to_previous": 7.99488327470419e-05, "parent_is_longest": true, "runtime_str": "2.91 ms"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>(10%) and 1 other\u2026"}}, "id": "eYtpF8X6wmKwqRMX", "pretty_name": "PackPaddedSequence0", "trace_file": "/results/RNN/RNN.141.pt.trace.json", "trace_disk_size": "793.8 kB", "runtime": 12194000, "runtime_str": "12.2 ms", "start_timestamp": "01:39:51.961.961998", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7517}, {"name": "NativeBatchNorm0(83%) and 2 others\u2026", "type": "generated", "generated_depth": 1, "instances": 3, "resources": {"cpu11": {"time": {"ts": 1685410791977658000, "dur": 127000, "relative_dur": 0.01015350175887432, "relative_gap_to_previous": 0.0005596418292292932, "parent_is_longest": true, "runtime_str": "127 us"}, "res_name": "NativeBatchNorm0(83%) and 2 others\u2026"}, "gpu3": {"time": {"ts": 1685410792001270000, "dur": 968000, "relative_dur": 0.07739047009913655, "relative_gap_to_previous": 7.99488327470419e-05, "parent_is_longest": true, "runtime_str": "968 us"}, "res_name": "batch_norm_backward_elemt_channels_last_kernel<4   const  const  const  const  const  const  const(60%) and 2 others\u2026"}}, "id": "6ifHmI3KWHgGECJT", "pretty_name": "NativeBatchNorm0(83%) and 2 others\u2026", "trace_file": "/results/RNN/RNN.142.pt.trace.json", "trace_disk_size": "3.6 kB", "runtime": 968000, "runtime_str": "968 us", "start_timestamp": "01:39:51.977.977658", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 28}], "id": "SgufPzLoAy8upZhC", "pretty_name": "BatchNorm1d", "trace_file": "/results/RNN/RNN.139.pt.trace.json", "trace_disk_size": "803.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 12508000, "runtime_str": "12.5 ms", "start_timestamp": "01:39:51.961.961818", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7585}], "resources": {"cpu11": {"time": {"ts": 1685410791961818000, "dur": 12508000, "relative_dur": 0.06520288585845949, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12.5 ms"}}, "gpu3": {"time": {"ts": 1685410791998200000, "dur": 4038000, "relative_dur": 0.021049668459902415, "relative_gap_to_previous": 0.12122065140331123, "parent_is_longest": true, "runtime_str": "4.04 ms"}}}, "is_backward_op": true, "id": "ymOlBwdkhgC98OIE", "pretty_name": "BatchNorm", "trace_file": "/results/RNN/RNN.138.pt.trace.json", "trace_disk_size": "803.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 12508000, "runtime_str": "12.5 ms", "start_timestamp": "01:39:51.961.961818", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7585}], "resources": {"cpu11": {"time": {"ts": 1685410791784181000, "dur": 170172000, "relative_dur": 0.15170576719406914, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "170 ms"}}, "gpu12": {"time": {"ts": 1685410791929805000, "dur": 49280000, "relative_dur": 0.043932375521964405, "relative_gap_to_previous": 0.12247754349554793, "parent_is_longest": false, "runtime_str": "49.3 ms"}}, "gpu13": {"time": {"ts": 1685410791929806000, "dur": 49736000, "relative_dur": 0.04433889263312544, "relative_gap_to_previous": 0.12127938779949435, "parent_is_longest": false, "runtime_str": "49.7 ms"}}, "gpu14": {"time": {"ts": 1685410791974948000, "dur": 22453000, "relative_dur": 0.020016510300216454, "relative_gap_to_previous": 0.15107370440500514, "parent_is_longest": false, "runtime_str": "22.4 ms"}}, "gpu15": {"time": {"ts": 1685410791974976000, "dur": 23221000, "relative_dur": 0.020701170697961353, "relative_gap_to_previous": 0.15038191212811708, "parent_is_longest": false, "runtime_str": "23.2 ms"}}, "gpu3": {"time": {"ts": 1685410791810406000, "dur": 191832000, "relative_dur": 0.17101532997421826, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "192 ms"}}, "gpu4": {"time": {"ts": 1685410791964550000, "dur": 16009000, "relative_dur": 0.014271781650388152, "relative_gap_to_previous": 0.1518359239884321, "parent_is_longest": false, "runtime_str": "16 ms"}}, "gpu5": {"time": {"ts": 1685410791969310000, "dur": 16808000, "relative_dur": 0.014984078079812859, "relative_gap_to_previous": 0.16166008750815708, "parent_is_longest": false, "runtime_str": "16.8 ms"}}}, "is_backward_op": true, "id": "gngAmwuUrHBBm25d", "pretty_name": "Layer2", "trace_file": "/results/RNN/RNN.132.pt.trace.json", "trace_disk_size": "4.0 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 191832000, "runtime_str": "192 ms", "start_timestamp": "01:39:51.784.784181", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 26695}, {"name": "Layer1", "type": "Layer1", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 193, in forward\n    with hotline.annotate(f'Layer{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 193, "ops": [{"name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 102, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 102, "resources": {"cpu11": {"time": {"ts": 1685410791977792000, "dur": 158011000, "relative_dur": 0.8161683049157804, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "158 ms"}}, "gpu12": {"time": {"ts": 1685410792121918000, "dur": 47218000, "relative_dur": 0.24389336831937852, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "47.2 ms"}}, "gpu13": {"time": {"ts": 1685410792121919000, "dur": 47251000, "relative_dur": 0.24406382198439058, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "47.2 ms"}}, "gpu14": {"time": {"ts": 1685410792167650000, "dur": 23222000, "relative_dur": 0.11994772754272963, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "23.2 ms"}}, "gpu15": {"time": {"ts": 1685410792167630000, "dur": 24062000, "relative_dur": 0.124286548106673, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "24.1 ms"}}, "gpu3": {"time": {"ts": 1685410792002239000, "dur": 165389000, "relative_dur": 0.8542776122024163, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "165 ms"}}, "gpu4": {"time": {"ts": 1685410792157191000, "dur": 17542000, "relative_dur": 0.09060903611035066, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "17.5 ms"}}, "gpu5": {"time": {"ts": 1685410792162022000, "dur": 18348000, "relative_dur": 0.09477223774670586, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "18.4 ms"}}}, "is_backward_op": true, "ops": [{"name": "CopySlices(55%) and 5 others\u2026", "type": "generated", "generated_depth": 1, "instances": 82, "resources": {"cpu11": {"time": {"ts": 1685410791977792000, "dur": 3869000, "relative_dur": 0.023393333293024326, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3.87 ms"}, "res_name": "CopySlices(55%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410792002239000, "dur": 47788000, "relative_dur": 0.28894303732412674, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "47.8 ms"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>(42%) and 3 others\u2026"}}, "id": "XR6rOmD9kUBuIylf", "pretty_name": "CopySlices(55%) and 5 others\u2026", "trace_file": "/results/RNN/RNN.145.pt.trace.json", "trace_disk_size": "169.9 kB", "runtime": 47788000, "runtime_str": "47.8 ms", "start_timestamp": "01:39:51.977.977792", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1197}, {"name": "Slice0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410791982047000, "dur": 71000, "relative_dur": 0.00042929094437961415, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "71 us"}, "res_name": "Slice0(99%) and 1 other\u2026"}, "gpu3": {"time": {"ts": 1685410792050029000, "dur": 1177000, "relative_dur": 0.00711655551457473, "relative_gap_to_previous": 1.2092702658580679e-05, "parent_is_longest": true, "runtime_str": "1.18 ms"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>(74%) and 2 others\u2026"}}, "id": "0GLJGc9HQyydwpgt", "pretty_name": "Slice0", "trace_file": "/results/RNN/RNN.146.pt.trace.json", "trace_disk_size": "2.2 kB", "runtime": 1177000, "runtime_str": "1.18 ms", "start_timestamp": "01:39:51.982.982047", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 17}, {"name": "CopySlices(54%) and 2 others\u2026", "type": "generated", "generated_depth": 1, "instances": 105, "resources": {"cpu11": {"time": {"ts": 1685410791998288000, "dur": 5448000, "relative_dur": 0.03294052204197377, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5.45 ms"}, "res_name": "CopySlices(54%) and 2 others\u2026"}, "gpu3": {"time": {"ts": 1685410792051207000, "dur": 70702000, "relative_dur": 0.4274891316834856, "relative_gap_to_previous": 6.046351329290339e-06, "parent_is_longest": true, "runtime_str": "70.7 ms"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>(43%) and 3 others\u2026"}}, "id": "zrm3YXFIPQg9i77L", "pretty_name": "CopySlices(54%) and 2 others\u2026", "trace_file": "/results/RNN/RNN.147.pt.trace.json", "trace_disk_size": "243.3 kB", "runtime": 70702000, "runtime_str": "70.7 ms", "start_timestamp": "01:39:51.998.998288", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1635}, {"name": "CudnnRnn0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410792004236000, "dur": 148606000, "relative_dur": 0.8985240856405202, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "149 ms"}, "res_name": "cudaLaunchKernel(99%) and 13 others\u2026"}, "gpu12": {"time": {"ts": 1685410792121918000, "dur": 47218000, "relative_dur": 0.28549661706643126, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "47.2 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4>cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4::Params(69%) and 5 others\u2026"}, "gpu13": {"time": {"ts": 1685410792121919000, "dur": 47251000, "relative_dur": 0.28569614666029786, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "47.2 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4>cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4::Params(69%) and 5 others\u2026"}, "gpu14": {"time": {"ts": 1685410792167650000, "dur": 23222000, "relative_dur": 0.14040837056878028, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "23.2 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x128_16x6_nt_align4>cutlass_80_tensorop_s1688gemm_128x128_16x6_nt_align4::Params(20%) and 4 others\u2026"}, "gpu15": {"time": {"ts": 1685410792167630000, "dur": 24062000, "relative_dur": 0.14548730568538415, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "24.1 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x128_16x5_nt_align4>cutlass_80_tensorop_s1688gemm_128x128_16x5_nt_align4::Params(55%) and 4 others\u2026"}, "gpu3": {"time": {"ts": 1685410792121911000, "dur": 45717000, "relative_dur": 0.27642104372116644, "relative_gap_to_previous": 1.2092702658580679e-05, "parent_is_longest": true, "runtime_str": "45.7 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x256_16x4_nt_align4>cutlass_80_tensorop_s1688gemm_64x256_16x4_nt_align4::Params(14%) and 14 others\u2026"}, "gpu4": {"time": {"ts": 1685410792157191000, "dur": 17542000, "relative_dur": 0.10606509501841115, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "17.5 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x256_16x4_nt_align4>cutlass_80_tensorop_s1688gemm_64x256_16x4_nt_align4::Params(56%) and 2 others\u2026"}, "gpu5": {"time": {"ts": 1685410792162022000, "dur": 18348000, "relative_dur": 0.11093845418981915, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "18.4 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x256_16x4_nt_align4>cutlass_80_tensorop_s1688gemm_64x256_16x4_nt_align4::Params(62%) and 1 other\u2026"}}, "id": "0vG1yWYFtgyBSitZ", "pretty_name": "CudnnRnn0", "trace_file": "/results/RNN/RNN.148.pt.trace.json", "trace_disk_size": "2.8 MB", "runtime": 148606000, "runtime_str": "149 ms", "start_timestamp": "01:39:52.004.4236", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 16261}], "id": "iZPQkEQ0umGIunoB", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.144.pt.trace.json", "trace_disk_size": "3.2 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 165389000, "runtime_str": "165 ms", "start_timestamp": "01:39:51.977.977792", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 19110}, {"name": "BatchNorm", "type": "BatchNorm", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 98, in forward\n    with hotline.annotate('BatchNorm'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 98, "ops": [{"name": "BatchNorm1d", "type": "BatchNorm1d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 99, in forward\n    x = self.batch_norm(x)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 33, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 33, "resources": {"cpu11": {"time": {"ts": 1685410792154141000, "dur": 11983000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12 ms"}}, "gpu3": {"time": {"ts": 1685410792191695000, "dur": 4145000, "relative_dur": 0.3459067011599766, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "4.14 ms"}}}, "is_backward_op": true, "ops": [{"name": "AccumulateGrad", "type": "generated", "generated_depth": 1, "instances": 8, "resources": {"cpu11": {"time": {"ts": 1685410792154141000, "dur": 168000, "relative_dur": 0.014019861470416423, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "168 us"}, "res_name": "AccumulateGrad"}, "gpu3": {"time": {"ts": 1685410792191695000, "dur": 159000, "relative_dur": 0.013268797463072687, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "159 us"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>"}}, "id": "WbuMQOXilcz9zqVJ", "pretty_name": "AccumulateGrad", "trace_file": "/results/RNN/RNN.151.pt.trace.json", "trace_disk_size": "6.1 kB", "runtime": 168000, "runtime_str": "168 us", "start_timestamp": "01:39:52.154.154141", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 40}, {"name": "PackPaddedSequence0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410792154313000, "dur": 11681000, "relative_dur": 0.974797629975799, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "11.7 ms"}, "res_name": "aten::copy_(61%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410792191855000, "dur": 3012000, "relative_dur": 0.2513560877910373, "relative_gap_to_previous": 8.345155637152634e-05, "parent_is_longest": true, "runtime_str": "3.01 ms"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>(10%) and 1 other\u2026"}}, "id": "SXkSeFmKhMl1rXuh", "pretty_name": "PackPaddedSequence0", "trace_file": "/results/RNN/RNN.152.pt.trace.json", "trace_disk_size": "793.8 kB", "runtime": 11681000, "runtime_str": "11.7 ms", "start_timestamp": "01:39:52.154.154313", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7517}, {"name": "NativeBatchNorm0(84%) and 2 others\u2026", "type": "generated", "generated_depth": 1, "instances": 3, "resources": {"cpu11": {"time": {"ts": 1685410792169360000, "dur": 123000, "relative_dur": 0.010264541433697738, "relative_gap_to_previous": 0.0005841608946006843, "parent_is_longest": true, "runtime_str": "123 us"}, "res_name": "NativeBatchNorm0(84%) and 2 others\u2026"}, "gpu3": {"time": {"ts": 1685410792194868000, "dur": 972000, "relative_dur": 0.08111491279312359, "relative_gap_to_previous": 8.345155637152634e-05, "parent_is_longest": true, "runtime_str": "972 us"}, "res_name": "batch_norm_backward_elemt_channels_last_kernel<4   const  const  const  const  const  const  const(60%) and 2 others\u2026"}}, "id": "MRU7dZG3pmG0Cwxn", "pretty_name": "NativeBatchNorm0(84%) and 2 others\u2026", "trace_file": "/results/RNN/RNN.153.pt.trace.json", "trace_disk_size": "3.6 kB", "runtime": 972000, "runtime_str": "972 us", "start_timestamp": "01:39:52.169.169360", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 28}], "id": "xtLiHkch7BrhgZG2", "pretty_name": "BatchNorm1d", "trace_file": "/results/RNN/RNN.150.pt.trace.json", "trace_disk_size": "803.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 11983000, "runtime_str": "12 ms", "start_timestamp": "01:39:52.154.154141", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7585}], "resources": {"cpu11": {"time": {"ts": 1685410792154141000, "dur": 11983000, "relative_dur": 0.061895341449682596, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12 ms"}}, "gpu3": {"time": {"ts": 1685410792191695000, "dur": 4145000, "relative_dur": 0.02141001337803007, "relative_gap_to_previous": 0.12431237441955362, "parent_is_longest": true, "runtime_str": "4.14 ms"}}}, "is_backward_op": true, "id": "Zip0Zv3sSbU0JP7G", "pretty_name": "BatchNorm", "trace_file": "/results/RNN/RNN.149.pt.trace.json", "trace_disk_size": "803.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 11983000, "runtime_str": "12 ms", "start_timestamp": "01:39:52.154.154141", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7585}], "resources": {"cpu11": {"time": {"ts": 1685410791977792000, "dur": 170008000, "relative_dur": 0.151559563671634, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "170 ms"}}, "gpu12": {"time": {"ts": 1685410792121918000, "dur": 47218000, "relative_dur": 0.04209413367281078, "relative_gap_to_previous": 0.1273334617071579, "parent_is_longest": false, "runtime_str": "47.2 ms"}}, "gpu13": {"time": {"ts": 1685410792121919000, "dur": 47251000, "relative_dur": 0.04212355267427638, "relative_gap_to_previous": 0.12692694459599688, "parent_is_longest": false, "runtime_str": "47.2 ms"}}, "gpu14": {"time": {"ts": 1685410792167650000, "dur": 23222000, "relative_dur": 0.02070206218285425, "relative_gap_to_previous": 0.1517744115308222, "parent_is_longest": false, "runtime_str": "23.2 ms"}}, "gpu15": {"time": {"ts": 1685410792167630000, "dur": 24062000, "relative_dur": 0.021450909492887735, "relative_gap_to_previous": 0.15104695985821825, "parent_is_longest": false, "runtime_str": "24.1 ms"}}, "gpu3": {"time": {"ts": 1685410792002239000, "dur": 193601000, "relative_dur": 0.17259236674975306, "relative_gap_to_previous": 8.914848928970049e-07, "parent_is_longest": true, "runtime_str": "194 ms"}}, "gpu4": {"time": {"ts": 1685410792157191000, "dur": 17542000, "relative_dur": 0.01563842799119926, "relative_gap_to_previous": 0.15746475960218378, "parent_is_longest": false, "runtime_str": "17.5 ms"}}, "gpu5": {"time": {"ts": 1685410792162022000, "dur": 18348000, "relative_dur": 0.016356964814874246, "relative_gap_to_previous": 0.15681575860015476, "parent_is_longest": false, "runtime_str": "18.4 ms"}}}, "is_backward_op": true, "id": "22pidGWlscDdXPGS", "pretty_name": "Layer1", "trace_file": "/results/RNN/RNN.143.pt.trace.json", "trace_disk_size": "4.0 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 193601000, "runtime_str": "194 ms", "start_timestamp": "01:39:51.977.977792", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 26695}, {"name": "Layer0", "type": "Layer0", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 193, in forward\n    with hotline.annotate(f'Layer{idx}'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 193, "ops": [{"name": "LSTM", "type": "LSTM", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 194, in forward\n    x = rnn(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 102, in forward\n    with hotline.annotate('LSTM'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 102, "resources": {"cpu11": {"time": {"ts": 1685410792169490000, "dur": 157287000, "relative_dur": 0.9055512055822951, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "157 ms"}}, "gpu12": {"time": {"ts": 1685410792315672000, "dur": 71297000, "relative_dur": 0.4104794694056145, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "71.3 ms"}}, "gpu13": {"time": {"ts": 1685410792315671000, "dur": 54550000, "relative_dur": 0.3140616723856021, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "54.5 ms"}}, "gpu14": {"time": {"ts": 1685410792369552000, "dur": 31584000, "relative_dur": 0.18183911751836584, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "31.6 ms"}}, "gpu15": {"time": {"ts": 1685410792369536000, "dur": 32401000, "relative_dur": 0.18654284595721163, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "32.4 ms"}}, "gpu3": {"time": {"ts": 1685410792195842000, "dur": 173692000, "relative_dur": 1.0, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "174 ms"}}, "gpu4": {"time": {"ts": 1685410792350311000, "dur": 30860000, "relative_dur": 0.1776708196117265, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "30.9 ms"}}, "gpu5": {"time": {"ts": 1685410792359687000, "dur": 31870000, "relative_dur": 0.1834857103378394, "relative_gap_to_previous": 0, "parent_is_longest": false, "runtime_str": "31.9 ms"}}}, "is_backward_op": true, "ops": [{"name": "CopySlices(55%) and 5 others\u2026", "type": "generated", "generated_depth": 1, "instances": 82, "resources": {"cpu11": {"time": {"ts": 1685410792169490000, "dur": 3883000, "relative_dur": 0.022355664049006286, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3.88 ms"}, "res_name": "CopySlices(55%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410792195842000, "dur": 47865000, "relative_dur": 0.2755740045597955, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "47.9 ms"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>(42%) and 3 others\u2026"}}, "id": "wAE6SzxdZlkxqsVr", "pretty_name": "CopySlices(55%) and 5 others\u2026", "trace_file": "/results/RNN/RNN.156.pt.trace.json", "trace_disk_size": "169.9 kB", "runtime": 47865000, "runtime_str": "47.9 ms", "start_timestamp": "01:39:52.169.169490", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1197}, {"name": "Slice0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410792173756000, "dur": 71000, "relative_dur": 0.0004087695460930843, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "71 us"}, "res_name": "Slice0(99%) and 1 other\u2026"}, "gpu3": {"time": {"ts": 1685410792243710000, "dur": 1178000, "relative_dur": 0.006782120074614835, "relative_gap_to_previous": 1.7271952651820464e-05, "parent_is_longest": true, "runtime_str": "1.18 ms"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>(74%) and 2 others\u2026"}}, "id": "tyGQaCcR6HOBCQrh", "pretty_name": "Slice0", "trace_file": "/results/RNN/RNN.157.pt.trace.json", "trace_disk_size": "2.2 kB", "runtime": 1178000, "runtime_str": "1.18 ms", "start_timestamp": "01:39:52.173.173756", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 17}, {"name": "CopySlices(54%) and 2 others\u2026", "type": "generated", "generated_depth": 1, "instances": 105, "resources": {"cpu11": {"time": {"ts": 1685410792191784000, "dur": 5479000, "relative_dur": 0.031544342859774775, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "5.48 ms"}, "res_name": "CopySlices(54%) and 2 others\u2026"}, "gpu3": {"time": {"ts": 1685410792244890000, "dur": 70772000, "relative_dur": 0.407456877691546, "relative_gap_to_previous": 1.1514635101213643e-05, "parent_is_longest": true, "runtime_str": "70.8 ms"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>(43%) and 3 others\u2026"}}, "id": "47xEvDkj8qxbBW6M", "pretty_name": "CopySlices(54%) and 2 others\u2026", "trace_file": "/results/RNN/RNN.158.pt.trace.json", "trace_disk_size": "243.3 kB", "runtime": 70772000, "runtime_str": "70.8 ms", "start_timestamp": "01:39:52.191.191784", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 1635}, {"name": "CudnnRnn0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410792197751000, "dur": 147838000, "relative_dur": 0.8511503120466113, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "148 ms"}, "res_name": "cudaLaunchKernel(99%) and 13 others\u2026"}, "gpu12": {"time": {"ts": 1685410792315672000, "dur": 71297000, "relative_dur": 0.4104794694056145, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "71.3 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4>cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4::Params(70%) and 5 others\u2026"}, "gpu13": {"time": {"ts": 1685410792315671000, "dur": 54550000, "relative_dur": 0.3140616723856021, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "54.5 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4>cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4::Params(70%) and 5 others\u2026"}, "gpu14": {"time": {"ts": 1685410792369552000, "dur": 31584000, "relative_dur": 0.18183911751836584, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "31.6 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x128_16x5_nt_align4>cutlass_80_tensorop_s1688gemm_128x128_16x5_nt_align4::Params(63%) and 4 others\u2026"}, "gpu15": {"time": {"ts": 1685410792369536000, "dur": 32401000, "relative_dur": 0.18654284595721163, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "32.4 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x128_16x5_nt_align4>cutlass_80_tensorop_s1688gemm_128x128_16x5_nt_align4::Params(50%) and 4 others\u2026"}, "gpu3": {"time": {"ts": 1685410792315664000, "dur": 53870000, "relative_dur": 0.3101466964511895, "relative_gap_to_previous": 1.1514635101213643e-05, "parent_is_longest": true, "runtime_str": "53.9 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x128_16x3_nt_align4>cutlass_80_tensorop_s1688gemm_256x128_16x3_nt_align4::Params(23%) and 13 others\u2026"}, "gpu4": {"time": {"ts": 1685410792350311000, "dur": 30860000, "relative_dur": 0.1776708196117265, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "30.9 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x128_16x3_nt_align4>cutlass_80_tensorop_s1688gemm_256x128_16x3_nt_align4::Params(54%) and 2 others\u2026"}, "gpu5": {"time": {"ts": 1685410792359687000, "dur": 31870000, "relative_dur": 0.1834857103378394, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "31.9 ms"}, "res_name": "cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x128_16x3_nt_align4>cutlass_80_tensorop_s1688gemm_256x128_16x3_nt_align4::Params(64%) and 1 other\u2026"}}, "id": "ZcNWIVTw4XLKF9ts", "pretty_name": "CudnnRnn0", "trace_file": "/results/RNN/RNN.159.pt.trace.json", "trace_disk_size": "2.8 MB", "runtime": 147838000, "runtime_str": "148 ms", "start_timestamp": "01:39:52.197.197751", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 16261}], "id": "jL0WRTqn4GEBeUdu", "pretty_name": "LSTM", "trace_file": "/results/RNN/RNN.155.pt.trace.json", "trace_disk_size": "3.2 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 173692000, "runtime_str": "174 ms", "start_timestamp": "01:39:52.169.169490", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 19110}], "resources": {"cpu11": {"time": {"ts": 1685410792169490000, "dur": 157287000, "relative_dur": 0.14021898434909122, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "157 ms"}}, "gpu12": {"time": {"ts": 1685410792315672000, "dur": 71297000, "relative_dur": 0.06356019840887776, "relative_gap_to_previous": 0.13063463026555552, "parent_is_longest": false, "runtime_str": "71.3 ms"}}, "gpu13": {"time": {"ts": 1685410792315671000, "dur": 54550000, "relative_dur": 0.04863050090753162, "relative_gap_to_previous": 0.13060342829430413, "parent_is_longest": false, "runtime_str": "54.5 ms"}}, "gpu14": {"time": {"ts": 1685410792369552000, "dur": 31584000, "relative_dur": 0.028156658857259004, "relative_gap_to_previous": 0.15929052066283686, "parent_is_longest": false, "runtime_str": "31.6 ms"}}, "gpu15": {"time": {"ts": 1685410792369536000, "dur": 32401000, "relative_dur": 0.02888500201475586, "relative_gap_to_previous": 0.15854523929237496, "parent_is_longest": false, "runtime_str": "32.4 ms"}}, "gpu3": {"time": {"ts": 1685410792195842000, "dur": 173692000, "relative_dur": 0.15484379401706658, "relative_gap_to_previous": 1.7829697857940098e-06, "parent_is_longest": true, "runtime_str": "174 ms"}}, "gpu4": {"time": {"ts": 1685410792350311000, "dur": 30860000, "relative_dur": 0.027511223794801573, "relative_gap_to_previous": 0.15652513452507033, "parent_is_longest": false, "runtime_str": "30.9 ms"}}, "gpu5": {"time": {"ts": 1685410792359687000, "dur": 31870000, "relative_dur": 0.02841162353662755, "relative_gap_to_previous": 0.15985839653961223, "parent_is_longest": false, "runtime_str": "31.9 ms"}}}, "is_backward_op": true, "id": "IJpoPXdWUKWbElAU", "pretty_name": "Layer0", "trace_file": "/results/RNN/RNN.154.pt.trace.json", "trace_disk_size": "3.2 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 173692000, "runtime_str": "174 ms", "start_timestamp": "01:39:52.169.169490", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 19110}, {"name": "MaskConv", "type": "MaskConv", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 182, in forward\n    with hotline.annotate('MaskConv'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 182, "ops": [{"name": "Hardtanh", "type": "Hardtanh", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 185, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu11": {"time": {"ts": 1685410792346918000, "dur": 13218000, "relative_dur": 0.09390118282243455, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "13.2 ms"}}, "gpu3": {"time": {"ts": 1685410792401940000, "dur": 8652000, "relative_dur": 0.061464142364934464, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "8.65 ms"}}}, "is_backward_op": true, "ops": [{"name": "AccumulateGrad", "type": "generated", "generated_depth": 1, "instances": 8, "resources": {"cpu11": {"time": {"ts": 1685410792346918000, "dur": 157000, "relative_dur": 0.01187774247238614, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "157 us"}, "res_name": "AccumulateGrad"}, "gpu3": {"time": {"ts": 1685410792401940000, "dur": 211000, "relative_dur": 0.015963080647601754, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "211 us"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>"}}, "id": "76Rk6ewcB57JP45t", "pretty_name": "AccumulateGrad", "trace_file": "/results/RNN/RNN.162.pt.trace.json", "trace_disk_size": "6.1 kB", "runtime": 211000, "runtime_str": "211 us", "start_timestamp": "01:39:52.346.346918", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 40}, {"name": "PackPaddedSequence0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410792347080000, "dur": 12877000, "relative_dur": 0.9742018459676199, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "12.9 ms"}, "res_name": "aten::copy_(62%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410792402153000, "dur": 3949000, "relative_dur": 0.29875926766530486, "relative_gap_to_previous": 0.00015130882130428205, "parent_is_longest": true, "runtime_str": "3.95 ms"}, "res_name": "vectorized_elementwise_kernel<4 FillFunctor Array<char 1> FillFunctor Array<char 1>(15%) and 1 other\u2026"}}, "id": "cPXePC1fpBZ8Ndtw", "pretty_name": "PackPaddedSequence0", "trace_file": "/results/RNN/RNN.163.pt.trace.json", "trace_disk_size": "793.8 kB", "runtime": 12877000, "runtime_str": "12.9 ms", "start_timestamp": "01:39:52.347.347080", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7517}, {"name": "MaskedFill0(46%) and 4 others\u2026", "type": "generated", "generated_depth": 1, "instances": 7, "resources": {"cpu11": {"time": {"ts": 1685410792363474000, "dur": 171000, "relative_dur": 0.012936904221516114, "relative_gap_to_previous": 0.0006052352852171282, "parent_is_longest": true, "runtime_str": "171 us"}, "res_name": "MaskedFill0(46%) and 4 others\u2026"}, "gpu3": {"time": {"ts": 1685410792406104000, "dur": 4488000, "relative_dur": 0.3395369950068089, "relative_gap_to_previous": 0.00015130882130428205, "parent_is_longest": true, "runtime_str": "4.49 ms"}, "res_name": "elementwise_kernel<128 2 gpu_kernel_impl<direct_copy_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda#1}>TensorIteratorBase& direct_copy_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda#1} const&::{lambda#1}> gpu_kernel_impl<direct_copy_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda#1}>TensorIteratorBase& direct_copy_kernel_cudaTensorIteratorBase&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda#1} const&::{lambda#1}(61%) and 2 others\u2026"}}, "id": "fvTIACkpV0s7XE8R", "pretty_name": "MaskedFill0(46%) and 4 others\u2026", "trace_file": "/results/RNN/RNN.164.pt.trace.json", "trace_disk_size": "5.9 kB", "runtime": 4488000, "runtime_str": "4.49 ms", "start_timestamp": "01:39:52.363.363474", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 36}], "id": "cWfYSP4TtQEeQb5N", "pretty_name": "Hardtanh", "trace_file": "/results/RNN/RNN.161.pt.trace.json", "trace_disk_size": "805.8 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 13218000, "runtime_str": "13.2 ms", "start_timestamp": "01:39:52.346.346918", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 7593}, {"name": "BatchNorm2d", "type": "BatchNorm2d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 185, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu11": {"time": {"ts": 1685410792363649000, "dur": 135000, "relative_dur": 0.0009590452172059816, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "135 us"}}, "gpu3": {"time": {"ts": 1685410792410595000, "dur": 4214000, "relative_dur": 0.029936418854118567, "relative_gap_to_previous": 2.1312115937910702e-05, "parent_is_longest": true, "runtime_str": "4.21 ms"}}}, "is_backward_op": true, "ops": [{"name": "MaskedFill0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410792363649000, "dur": 35000, "relative_dur": 0.008305647840531562, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "35 us"}, "res_name": "aten::clone(68%) and 1 other\u2026"}, "gpu3": {"time": {"ts": 1685410792410595000, "dur": 1431000, "relative_dur": 0.3395823445657333, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.43 ms"}, "res_name": "vectorized_elementwise_kernel<4 masked_fill_kernel<bool>TensorIterator& c10::Scalar const&::{lambda#1}::operator const::{lambda#14}::operator const::{lambda bool#1} Array<char 3> masked_fill_kernel<bool>TensorIterator& c10::Scalar const&::{lambda#1}::operator const::{lambda#14}::operator const::{lambda bool#1} Array<char 3>(53%) and 1 other\u2026"}}, "id": "5sc7HGFR7IAtCMTF", "pretty_name": "MaskedFill0", "trace_file": "/results/RNN/RNN.166.pt.trace.json", "trace_disk_size": "1.8 kB", "runtime": 1431000, "runtime_str": "1.43 ms", "start_timestamp": "01:39:52.363.363649", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 12}, {"name": "CudnnBatchNorm0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410792363697000, "dur": 95000, "relative_dur": 0.022543901281442808, "relative_gap_to_previous": 0.0011865211200759373, "parent_is_longest": true, "runtime_str": "95 us"}, "res_name": "cudaLaunchKernel(43%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410792412027000, "dur": 2782000, "relative_dur": 0.6601803512102515, "relative_gap_to_previous": 0.00023730422401518748, "parent_is_longest": true, "runtime_str": "2.78 ms"}, "res_name": "cudnn::bn_bw_1C11_kernel_new 2 512 true 1>    cudnnTensorStruct  const cudnnTensorStruct  const cudnnTensorStruct   const    const  const"}}, "id": "NKRET5FAqQCzFT38", "pretty_name": "CudnnBatchNorm0", "trace_file": "/results/RNN/RNN.167.pt.trace.json", "trace_disk_size": "1.7 kB", "runtime": 2782000, "runtime_str": "2.78 ms", "start_timestamp": "01:39:52.363.363697", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 13}], "id": "plFS5an6fx9dDYts", "pretty_name": "BatchNorm2d", "trace_file": "/results/RNN/RNN.165.pt.trace.json", "trace_disk_size": "3.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 4214000, "runtime_str": "4.21 ms", "start_timestamp": "01:39:52.363.363649", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 25}, {"name": "Conv2d", "type": "Conv2d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 185, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu11": {"time": {"ts": 1685410792363799000, "dur": 6146000, "relative_dur": 0.043661421518133056, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "6.15 ms"}}, "gpu3": {"time": {"ts": 1685410792414811000, "dur": 98950000, "relative_dur": 0.7029446240187547, "relative_gap_to_previous": 1.4208077291940469e-05, "parent_is_longest": true, "runtime_str": "99 ms"}}, "gpu4": {"time": {"ts": 1685410792416248000, "dur": 17732000, "relative_dur": 0.1259688132703442, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "17.7 ms"}}, "gpu5": {"time": {"ts": 1685410792416249000, "dur": 17803000, "relative_dur": 0.1264732000142081, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "17.8 ms"}}}, "is_backward_op": true, "ops": [{"name": "MaskedFill0(56%) and 1 other\u2026", "type": "generated", "generated_depth": 1, "instances": 3, "resources": {"cpu11": {"time": {"ts": 1685410792363799000, "dur": 82000, "relative_dur": 0.0008287013643254169, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "82 us"}, "res_name": "MaskedFill0(56%) and 1 other\u2026"}, "gpu3": {"time": {"ts": 1685410792414811000, "dur": 1435000, "relative_dur": 0.014502273875694796, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.44 ms"}, "res_name": "vectorized_elementwise_kernel<4 masked_fill_kernel<bool>TensorIterator& c10::Scalar const&::{lambda#1}::operator const::{lambda#14}::operator const::{lambda bool#1} Array<char 3> masked_fill_kernel<bool>TensorIterator& c10::Scalar const&::{lambda#1}::operator const::{lambda#14}::operator const::{lambda bool#1} Array<char 3>(53%) and 2 others\u2026"}}, "id": "RojTaOEFYtCugWZQ", "pretty_name": "MaskedFill0(56%) and 1 other\u2026", "trace_file": "/results/RNN/RNN.169.pt.trace.json", "trace_disk_size": "3.3 kB", "runtime": 1435000, "runtime_str": "1.44 ms", "start_timestamp": "01:39:52.363.363799", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 22}, {"name": "Convolution0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410792363895000, "dur": 6059000, "relative_dur": 0.061232945932289035, "relative_gap_to_previous": 5.053057099545225e-05, "parent_is_longest": true, "runtime_str": "6.06 ms"}, "res_name": "cudaLaunchKernel(96%) and 8 others\u2026"}, "gpu3": {"time": {"ts": 1685410792416269000, "dur": 97492000, "relative_dur": 0.9852652854977261, "relative_gap_to_previous": 0.00023244062657908033, "parent_is_longest": true, "runtime_str": "97.5 ms"}, "res_name": "wgrad_alg0_engine512 6 5 3 3 3 false 512>    const    const kernel_grad_params  long long(73%) and 6 others\u2026"}, "gpu4": {"time": {"ts": 1685410792416248000, "dur": 17732000, "relative_dur": 0.17920161697827186, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "17.7 ms"}, "res_name": "ampere_gcgemm_64x64_nt(47%) and 2 others\u2026"}, "gpu5": {"time": {"ts": 1685410792416249000, "dur": 17803000, "relative_dur": 0.17991915108640727, "relative_gap_to_previous": 0.0, "parent_is_longest": false, "runtime_str": "17.8 ms"}, "res_name": "ampere_gcgemm_64x64_nt(43%) and 2 others\u2026"}}, "id": "jCvocNEdKd66mz9t", "pretty_name": "Convolution0", "trace_file": "/results/RNN/RNN.170.pt.trace.json", "trace_disk_size": "453.7 kB", "runtime": 97492000, "runtime_str": "97.5 ms", "start_timestamp": "01:39:52.363.363895", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 2966}], "id": "G56PPXEbAI8tg3vg", "pretty_name": "Conv2d", "trace_file": "/results/RNN/RNN.168.pt.trace.json", "trace_disk_size": "457.1 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 98950000, "runtime_str": "99 ms", "start_timestamp": "01:39:52.363.363799", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 2988}, {"name": "Hardtanh", "type": "Hardtanh", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 185, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu11": {"time": {"ts": 1685410792369964000, "dur": 123000, "relative_dur": 0.0008737967534543388, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "123 us"}}, "gpu3": {"time": {"ts": 1685410792513762000, "dur": 4748000, "relative_dur": 0.03372997549106667, "relative_gap_to_previous": 7.104038645970234e-06, "parent_is_longest": true, "runtime_str": "4.75 ms"}}}, "is_backward_op": true, "ops": [{"name": "AccumulateGrad", "type": "generated", "generated_depth": 1, "instances": 2, "resources": {"cpu11": {"time": {"ts": 1685410792369964000, "dur": 46000, "relative_dur": 0.009688289806234204, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "46 us"}, "res_name": "AccumulateGrad"}, "gpu3": {"time": {"ts": 1685410792513762000, "dur": 9000, "relative_dur": 0.0018955349620893007, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "9 us"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>"}}, "id": "8MIEvgj0JxMGVprS", "pretty_name": "AccumulateGrad", "trace_file": "/results/RNN/RNN.172.pt.trace.json", "trace_disk_size": "1.5 kB", "runtime": 46000, "runtime_str": "46 us", "start_timestamp": "01:39:52.369.369964", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 10}, {"name": "MaskedFill0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410792370014000, "dur": 41000, "relative_dur": 0.008635214827295703, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "41 us"}, "res_name": "aten::clone(68%) and 1 other\u2026"}, "gpu3": {"time": {"ts": 1685410792513772000, "dur": 2786000, "relative_dur": 0.5867733782645325, "relative_gap_to_previous": 0.00021061499578770007, "parent_is_longest": true, "runtime_str": "2.79 ms"}, "res_name": "vectorized_elementwise_kernel<4 masked_fill_kernel<bool>TensorIterator& c10::Scalar const&::{lambda#1}::operator const::{lambda#14}::operator const::{lambda bool#1} Array<char 3> masked_fill_kernel<bool>TensorIterator& c10::Scalar const&::{lambda#1}::operator const::{lambda#14}::operator const::{lambda bool#1} Array<char 3>(53%) and 1 other\u2026"}}, "id": "DyUEAb0YP6043F22", "pretty_name": "MaskedFill0", "trace_file": "/results/RNN/RNN.173.pt.trace.json", "trace_disk_size": "1.8 kB", "runtime": 2786000, "runtime_str": "2.79 ms", "start_timestamp": "01:39:52.370.370014", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 12}, {"name": "Hardtanh0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410792370068000, "dur": 27000, "relative_dur": 0.0056866048862679024, "relative_gap_to_previous": 0.0010530749789385003, "parent_is_longest": true, "runtime_str": "27 us"}, "res_name": "aten::empty(50%) and 1 other\u2026"}, "gpu3": {"time": {"ts": 1685410792516560000, "dur": 1950000, "relative_dur": 0.4106992417860152, "relative_gap_to_previous": 0.00042122999157540015, "parent_is_longest": true, "runtime_str": "1.95 ms"}, "res_name": "vectorized_elementwise_kernel<4 hardtanh_backward_kernelTensorIterator& c10::Scalar const& c10::Scalar const&::{lambda#1}::operator const::{lambda#4}::operator const::{lambda #1} Array<char 3> hardtanh_backward_kernelTensorIterator& c10::Scalar const& c10::Scalar const&::{lambda#1}::operator const::{lambda#4}::operator const::{lambda #1} Array<char 3>"}}, "id": "dFf69fA0qzLG5Yp2", "pretty_name": "Hardtanh0", "trace_file": "/results/RNN/RNN.174.pt.trace.json", "trace_disk_size": "1.2 kB", "runtime": 1950000, "runtime_str": "1.95 ms", "start_timestamp": "01:39:52.370.370068", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 6}], "id": "HvAO7DHCgHlysRPI", "pretty_name": "Hardtanh", "trace_file": "/results/RNN/RNN.171.pt.trace.json", "trace_disk_size": "4.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 4748000, "runtime_str": "4.75 ms", "start_timestamp": "01:39:52.369.369964", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 28}, {"name": "BatchNorm2d", "type": "BatchNorm2d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 185, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu11": {"time": {"ts": 1685410792370099000, "dur": 99000, "relative_dur": 0.0007032998259510532, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "99 us"}}, "gpu3": {"time": {"ts": 1685410792518510000, "dur": 8739000, "relative_dur": 0.062082193727133875, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "8.74 ms"}}}, "is_backward_op": true, "ops": [{"name": "MaskedFill0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410792370099000, "dur": 33000, "relative_dur": 0.0037761757638173706, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "33 us"}, "res_name": "aten::clone(68%) and 1 other\u2026"}, "gpu3": {"time": {"ts": 1685410792518510000, "dur": 2795000, "relative_dur": 0.31983064423847124, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "2.79 ms"}, "res_name": "vectorized_elementwise_kernel<4 masked_fill_kernel<bool>TensorIterator& c10::Scalar const&::{lambda#1}::operator const::{lambda#14}::operator const::{lambda bool#1} Array<char 3> masked_fill_kernel<bool>TensorIterator& c10::Scalar const&::{lambda#1}::operator const::{lambda#14}::operator const::{lambda bool#1} Array<char 3>(53%) and 1 other\u2026"}}, "id": "5lBwr63HdI4FKWSm", "pretty_name": "MaskedFill0", "trace_file": "/results/RNN/RNN.176.pt.trace.json", "trace_disk_size": "1.8 kB", "runtime": 2795000, "runtime_str": "2.79 ms", "start_timestamp": "01:39:52.370.370099", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 12}, {"name": "CudnnBatchNorm0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410792370143000, "dur": 62000, "relative_dur": 0.007094633253232636, "relative_gap_to_previous": 0.0004577182744021055, "parent_is_longest": true, "runtime_str": "62 us"}, "res_name": "aten::empty(65%) and 5 others\u2026"}, "gpu3": {"time": {"ts": 1685410792521307000, "dur": 5942000, "relative_dur": 0.6799404966243278, "relative_gap_to_previous": 0.00022885913720105275, "parent_is_longest": true, "runtime_str": "5.94 ms"}, "res_name": "cudnn::bn_bw_1C11_kernel_new 2 512 true 1>    cudnnTensorStruct  const cudnnTensorStruct  const cudnnTensorStruct   const    const  const"}}, "id": "IdjxapdPWyF5JyHI", "pretty_name": "CudnnBatchNorm0", "trace_file": "/results/RNN/RNN.177.pt.trace.json", "trace_disk_size": "1.7 kB", "runtime": 5942000, "runtime_str": "5.94 ms", "start_timestamp": "01:39:52.370.370143", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 13}], "id": "TRJvazaArN12deRi", "pretty_name": "BatchNorm2d", "trace_file": "/results/RNN/RNN.175.pt.trace.json", "trace_disk_size": "3.5 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 8739000, "runtime_str": "8.74 ms", "start_timestamp": "01:39:52.370.370099", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 25}, {"name": "Conv2d", "type": "Conv2d", "is_model_op": true, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 76, in update_params\n    (log_y, output_lengths), _ = workload.model_fn(\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/workload.py\", line 192, in model_fn\n    log_y, output_lengths = params(features, input_lengths, transcripts)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n    return self.module(*inputs[0], **kwargs[0])\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 185, in forward\n    x, _ = self.conv(x, output_lengths)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py\", line 66, in forward\n    with hotline.annotate(module_name):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "source_file_num": 66, "resources": {"cpu11": {"time": {"ts": 1685410792370211000, "dur": 244000, "relative_dur": 0.0017333854296167372, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "244 us"}}, "gpu3": {"time": {"ts": 1685410792527250000, "dur": 15455000, "relative_dur": 0.10979291727346997, "relative_gap_to_previous": 7.104038645970234e-06, "parent_is_longest": true, "runtime_str": "15.5 ms"}}}, "is_backward_op": true, "ops": [{"name": "AccumulateGrad", "type": "generated", "generated_depth": 1, "instances": 2, "resources": {"cpu11": {"time": {"ts": 1685410792370211000, "dur": 43000, "relative_dur": 0.002782271109673245, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "43 us"}, "res_name": "AccumulateGrad"}, "gpu3": {"time": {"ts": 1685410792527250000, "dur": 7000, "relative_dur": 0.00045292785506308636, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "7 us"}, "res_name": "vectorized_elementwise_kernel<4 CUDAFunctor_add Array<char 3> CUDAFunctor_add Array<char 3>"}}, "id": "dbD5LRjaT1JAI1IP", "pretty_name": "AccumulateGrad", "trace_file": "/results/RNN/RNN.179.pt.trace.json", "trace_disk_size": "1.5 kB", "runtime": 43000, "runtime_str": "43 us", "start_timestamp": "01:39:52.370.370211", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu11", "trace_event_count": 10}, {"name": "MaskedFill0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410792370258000, "dur": 36000, "relative_dur": 0.0023293432546101587, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "36 us"}, "res_name": "aten::clone(68%) and 1 other\u2026"}, "gpu3": {"time": {"ts": 1685410792527257000, "dur": 2786000, "relative_dur": 0.18026528631510838, "relative_gap_to_previous": 0.0, "parent_is_longest": true, "runtime_str": "2.79 ms"}, "res_name": "vectorized_elementwise_kernel<4 masked_fill_kernel<bool>TensorIterator& c10::Scalar const&::{lambda#1}::operator const::{lambda#14}::operator const::{lambda bool#1} Array<char 3> masked_fill_kernel<bool>TensorIterator& c10::Scalar const&::{lambda#1}::operator const::{lambda#14}::operator const::{lambda bool#1} Array<char 3>(53%) and 1 other\u2026"}}, "id": "JcmXSwDHGXAzqfOP", "pretty_name": "MaskedFill0", "trace_file": "/results/RNN/RNN.180.pt.trace.json", "trace_disk_size": "1.8 kB", "runtime": 2786000, "runtime_str": "2.79 ms", "start_timestamp": "01:39:52.370.370258", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 12}, {"name": "Convolution0", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu11": {"time": {"ts": 1685410792370306000, "dur": 156000, "relative_dur": 0.010093820769977354, "relative_gap_to_previous": 0.00032351989647363315, "parent_is_longest": true, "runtime_str": "156 us"}, "res_name": "aten::sum(42%) and 7 others\u2026"}, "gpu3": {"time": {"ts": 1685410792530044000, "dur": 12661000, "relative_dur": 0.8192170818505338, "relative_gap_to_previous": 6.470397929472663e-05, "parent_is_longest": true, "runtime_str": "12.7 ms"}, "res_name": "wgrad_alg0_engine512 6 5 3 3 3 false 512>    const    const kernel_grad_params  long long(92%) and 3 others\u2026"}}, "id": "s7d1GMBUWgXd4E4b", "pretty_name": "Convolution0", "trace_file": "/results/RNN/RNN.181.pt.trace.json", "trace_disk_size": "4.1 kB", "runtime": 12661000, "runtime_str": "12.7 ms", "start_timestamp": "01:39:52.370.370306", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 25}], "id": "TjqsXfsRcQxbWFab", "pretty_name": "Conv2d", "trace_file": "/results/RNN/RNN.178.pt.trace.json", "trace_disk_size": "7.4 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 15455000, "runtime_str": "15.5 ms", "start_timestamp": "01:39:52.370.370211", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 47}], "resources": {"cpu11": {"time": {"ts": 1685410792346918000, "dur": 19996000, "relative_dur": 0.01782613191836851, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "20 ms"}}, "gpu3": {"time": {"ts": 1685410792401940000, "dur": 140765000, "relative_dur": 0.12548987094864691, "relative_gap_to_previous": 0.028889459439220343, "parent_is_longest": true, "runtime_str": "141 ms"}}, "gpu4": {"time": {"ts": 1685410792416248000, "dur": 17732000, "relative_dur": 0.015807810120849693, "relative_gap_to_previous": 0.03127061558814824, "parent_is_longest": false, "runtime_str": "17.7 ms"}}, "gpu5": {"time": {"ts": 1685410792416249000, "dur": 17803000, "relative_dur": 0.01587110554824538, "relative_gap_to_previous": 0.022012544975412846, "parent_is_longest": false, "runtime_str": "17.8 ms"}}}, "is_backward_op": true, "id": "9uRPimLoJxP86K2z", "pretty_name": "MaskConv", "trace_file": "/results/RNN/RNN.160.pt.trace.json", "trace_disk_size": "1.3 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/algorithmic_efficiency/workloads/librispeech/librispeech_pytorch/models.py", "runtime": 140765000, "runtime_str": "141 ms", "start_timestamp": "01:39:52.346.346918", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 10706}], "idx": 32, "id": "O2na5iNfYCQAEhLg", "pretty_name": "Backward", "trace_file": "/results/RNN/RNN.103.pt.trace.json", "trace_disk_size": "20.5 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "runtime": 1121724000, "runtime_str": "1.12 s", "start_timestamp": "01:39:51.420.420744", "recommendations": "None", "bound_by": "GPU-Bound", "longest_res": "gpu3", "trace_event_count": 136811}, {"name": "Optimizer", "type": "training loop", "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410792371149000, "dur": 36980000, "relative_dur": 0.022117634956150503, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "37 ms"}}, "gpu3": {"time": {"ts": 1685410792542715000, "dur": 6454000, "relative_dur": 0.0038601194160896523, "relative_gap_to_previous": 5.980972135248919e-07, "parent_is_longest": true, "runtime_str": "6.45 ms"}}}, "source_stack_trace": "  File \"submission_runner.py\", line 434, in <module>\n    app.run(main)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"submission_runner.py\", line 419, in main\n    score = score_submission_on_workload(workload,\n  File \"submission_runner.py\", line 365, in score_submission_on_workload\n    timing, metrics = train_once(workload, global_batch_size, data_dir,\n  File \"submission_runner.py\", line 265, in train_once\n    optimizer_state, model_params, model_state = update_params(\n  File \"/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py\", line 89, in update_params\n    with hotline.annotate('Optimizer'):\n", "source_file_name": "/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "source_file_num": 89, "ops": [{"name": "aten::sqrt(13%) and 9 others\u2026", "type": "generated", "generated_depth": 1, "instances": 188, "resources": {"cpu2": {"time": {"ts": 1685410792371149000, "dur": 3176000, "relative_dur": 0.0858842617631152, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "3.18 ms"}, "res_name": "aten::sqrt(13%) and 9 others\u2026"}, "gpu3": {"time": {"ts": 1685410792542715000, "dur": 1727000, "relative_dur": 0.04670091941590049, "relative_gap_to_previous": 0, "parent_is_longest": true, "runtime_str": "1.73 ms"}, "res_name": "vectorized_elementwise_kernel<4 addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4> addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4>(18%) and 6 others\u2026"}}, "id": "ziGmzCKOtiQztpux", "pretty_name": "aten::sqrt(13%) and 9 others\u2026", "trace_file": "/results/RNN/RNN.183.pt.trace.json", "trace_disk_size": "102.8 kB", "runtime": 3176000, "runtime_str": "3.18 ms", "start_timestamp": "01:39:52.371.371149", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 557}, {"name": "aten::addcdiv_", "type": "generated", "generated_depth": 1, "instances": 1, "resources": {"cpu2": {"time": {"ts": 1685410792374330000, "dur": 27617000, "relative_dur": 0.7468090859924283, "relative_gap_to_previous": 0.00013520822065981613, "parent_is_longest": true, "runtime_str": "27.6 ms"}, "res_name": "cudaLaunchKernel"}, "gpu3": {"time": {"ts": 1685410792544444000, "dur": 2000, "relative_dur": 5.4083288263926445e-05, "relative_gap_to_previous": 5.4083288263926445e-05, "parent_is_longest": true, "runtime_str": "2 us"}, "res_name": "vectorized_elementwise_kernel<4 addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4> addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4>"}}, "id": "0zfTEKC6JbRwObul", "pretty_name": "aten::addcdiv_", "trace_file": "/results/RNN/RNN.184.pt.trace.json", "trace_disk_size": "780 Bytes", "runtime": 27617000, "runtime_str": "27.6 ms", "start_timestamp": "01:39:52.374.374330", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 3}, {"name": "aten::mul_(27%) and 7 others\u2026", "type": "generated", "generated_depth": 1, "instances": 418, "resources": {"cpu2": {"time": {"ts": 1685410792401953000, "dur": 6161000, "relative_dur": 0.16660356949702543, "relative_gap_to_previous": 0.00016224986479177934, "parent_is_longest": true, "runtime_str": "6.16 ms"}, "res_name": "aten::mul_(27%) and 7 others\u2026"}, "gpu3": {"time": {"ts": 1685410792544447000, "dur": 4722000, "relative_dur": 0.12769064359113033, "relative_gap_to_previous": 2.7041644131963223e-05, "parent_is_longest": true, "runtime_str": "4.72 ms"}, "res_name": "vectorized_elementwise_kernel<4 addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4> addcdiv_cuda_kernelTensorIteratorBase& c10::Scalar const&::{lambda#2}::operator const::{lambda#14}::operator const::{lambda  #1} Array<char 4>(19%) and 6 others\u2026"}}, "id": "Or48Xug0DNIl1VTW", "pretty_name": "aten::mul_(27%) and 7 others\u2026", "trace_file": "/results/RNN/RNN.185.pt.trace.json", "trace_disk_size": "235.5 kB", "runtime": 6161000, "runtime_str": "6.16 ms", "start_timestamp": "01:39:52.401.401953", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1271}], "idx": 33, "id": "DOhNNHt48B3xLDht", "pretty_name": "Optimizer", "trace_file": "/results/RNN/RNN.182.pt.trace.json", "trace_disk_size": "339.2 kB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/reference_submissions/librispeech/librispeech_pytorch/submission.py", "runtime": 36980000, "runtime_str": "37 ms", "start_timestamp": "01:39:52.371.371149", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2", "trace_event_count": 1832}], "resources": {"cpu11": {"time": {"ts": 1685410791420744000, "dur": 852391000, "parent_is_longest": false, "runtime_str": "852 ms"}}, "cpu2": {"time": {"ts": 1685410790604527000, "dur": 1671969000, "parent_is_longest": true, "runtime_str": "1.67 s"}}, "cpu6": {"time": {"ts": 1685410790770475000, "dur": 120671000, "parent_is_longest": false, "runtime_str": "121 ms"}}, "gpu10": {"time": {"ts": 1685410791208622000, "dur": 206616000, "parent_is_longest": false, "runtime_str": "207 ms"}}, "gpu12": {"time": {"ts": 1685410791544330000, "dur": 842639000, "parent_is_longest": false, "runtime_str": "843 ms"}}, "gpu13": {"time": {"ts": 1685410791544332000, "dur": 825889000, "parent_is_longest": false, "runtime_str": "826 ms"}}, "gpu14": {"time": {"ts": 1685410791593676000, "dur": 807460000, "parent_is_longest": false, "runtime_str": "807 ms"}}, "gpu15": {"time": {"ts": 1685410791593804000, "dur": 808133000, "parent_is_longest": false, "runtime_str": "808 ms"}}, "gpu3": {"time": {"ts": 1685410791011158000, "dur": 1538011000, "parent_is_longest": true, "runtime_str": "1.54 s"}}, "gpu4": {"time": {"ts": 1685410791579645000, "dur": 854335000, "parent_is_longest": false, "runtime_str": "854 ms"}}, "gpu5": {"time": {"ts": 1685410791584691000, "dur": 849361000, "parent_is_longest": false, "runtime_str": "849 ms"}}, "gpu7": {"time": {"ts": 1685410791115832000, "dur": 265604000, "parent_is_longest": false, "runtime_str": "266 ms"}}, "gpu8": {"time": {"ts": 1685410791115832000, "dur": 270873000, "parent_is_longest": false, "runtime_str": "271 ms"}}, "gpu9": {"time": {"ts": 1685410791208581000, "dur": 206523000, "parent_is_longest": false, "runtime_str": "207 ms"}}}, "source_file_name": "/home/ubuntu/algorithmic-efficiency/submission_runner.py", "source_file_num": 236, "id": "rjdkRLSrsmjNo9BT", "pretty_name": "RNN-T Training Iteration", "total_accuracy_str": "96.95%", "trace_file": "/results/RNN/RNN.1.pt.trace.json", "trace_disk_size": "81.1 MB", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN/home/ubuntu/algorithmic-efficiency/submission_runner.py", "config": {"trace_filepath": "/home/ubuntu/cpath/results/RNN.worker0.pt.trace.json", "output_dir": "/home/ubuntu/cpath/results", "ui_traces_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/RNN", "ui_model_path": "/home/ubuntu/cpath/results/ui/src/results/RNN.js", "results_summary_csv_filepath": "/home/ubuntu/cpath/results/results_summary.csv", "ui_source_code_path": "/home/ubuntu/cpath/results/ui/dist/traces/results/code/RNN", "run_name": "RNN", "model_name": "RNN-T", "backend": "torch", "test": false, "is_test_accuracy": true, "view_manual_annotations": false, "source_file_name": "/home/ubuntu/algorithmic-efficiency/submission_runner.py", "source_file_num": 236, "num_gpus": 1, "slice_idx": 0, "drop_flow_view": "", "last_found_was_fused": false, "count_sum_greater_than_1": 0, "count_sum_less_than_1": 0, "tiny_op_threshold": 0.05, "max_generated_depth": 1, "remove_slice_args": true, "write_model_ops_to_file": true, "op_idx": 1}, "metadata": {}, "metadata.model": "RNN-T", "metadata.dataset": "LibriSpeech", "metadata.batch_size": 64, "metadata.optimizer": "Adam", "trace_event_count": 216681, "pytorch_version": "1.13.1+cu117", "gpu_model": "NVIDIA GeForce RTX 3090", "gpu_cuda_version": "11.7", "hotline_traces_trace_disk_size": "193.6 MB", "hotline_annotation_count": "185", "processed_datetime": "30/05/2023 01:40:41", "runtime_without_profiling": "1.69 s \u00b10.4%", "runtime_with_profiling": "1.77 s \u00b10.3%", "runtime_profiling_overhead_factor": "0.05\u00d7 slower", "hotline_analysis_time": "21.3 s", "runtime": 1671969000, "runtime_str": "1.67 s", "start_timestamp": "01:39:50.604.604527", "recommendations": "None", "bound_by": "CPU-Bound", "longest_res": "cpu2"}]
