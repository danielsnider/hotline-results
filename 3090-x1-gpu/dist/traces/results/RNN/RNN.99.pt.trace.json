[{"ph":"X","cat":"cpu_op","name":"autograd::engine::evaluate_function: torch::autograd::AccumulateGrad","pid":7,"tid":193,"ts":1677891894792239,"dur":24},{"ph":"X","cat":"cpu_op","name":"torch::autograd::AccumulateGrad","pid":7,"tid":193,"ts":1677891894792242,"dur":19},{"ph":"X","cat":"cpu_op","name":"aten::add_","pid":7,"tid":193,"ts":1677891894792244,"dur":16},{"ph":"X","cat":"cuda_runtime","name":"cudaLaunchKernel","pid":7,"tid":193,"ts":1677891894792252,"dur":6},{"ph":"X","cat":"cpu_op","name":"autograd::engine::evaluate_function: torch::autograd::AccumulateGrad","pid":7,"tid":193,"ts":1677891894792268,"dur":18},{"ph":"X","cat":"cpu_op","name":"torch::autograd::AccumulateGrad","pid":7,"tid":193,"ts":1677891894792270,"dur":15},{"ph":"X","cat":"cpu_op","name":"aten::add_","pid":7,"tid":193,"ts":1677891894792271,"dur":13},{"ph":"X","cat":"cuda_runtime","name":"cudaLaunchKernel","pid":7,"tid":193,"ts":1677891894792277,"dur":5},{"ph":"X","cat":"cpu_op","name":"autograd::engine::evaluate_function: MaskedFillBackward0","pid":7,"tid":193,"ts":1677891894792291,"dur":48},{"ph":"X","cat":"cpu_op","name":"MaskedFillBackward0","pid":7,"tid":193,"ts":1677891894792292,"dur":41},{"ph":"X","cat":"cpu_op","name":"aten::masked_fill","pid":7,"tid":193,"ts":1677891894792294,"dur":38},{"ph":"X","cat":"cpu_op","name":"aten::clone","pid":7,"tid":193,"ts":1677891894792296,"dur":23},{"ph":"X","cat":"cpu_op","name":"aten::empty_like","pid":7,"tid":193,"ts":1677891894792297,"dur":6},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":7,"tid":193,"ts":1677891894792298,"dur":5},{"ph":"X","cat":"cpu_op","name":"aten::copy_","pid":7,"tid":193,"ts":1677891894792304,"dur":15},{"ph":"X","cat":"cuda_runtime","name":"cudaMemcpyAsync","pid":7,"tid":193,"ts":1677891894792307,"dur":9},{"ph":"X","cat":"cpu_op","name":"aten::masked_fill_","pid":7,"tid":193,"ts":1677891894792320,"dur":12},{"ph":"X","cat":"cuda_runtime","name":"cudaLaunchKernel","pid":7,"tid":193,"ts":1677891894792325,"dur":5},{"ph":"X","cat":"cpu_op","name":"autograd::engine::evaluate_function: HardtanhBackward0","pid":7,"tid":193,"ts":1677891894792344,"dur":27},{"ph":"X","cat":"cpu_op","name":"HardtanhBackward0","pid":7,"tid":193,"ts":1677891894792345,"dur":21},{"ph":"X","cat":"cpu_op","name":"aten::hardtanh_backward","pid":7,"tid":193,"ts":1677891894792348,"dur":18},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":7,"tid":193,"ts":1677891894792351,"dur":4},{"ph":"X","cat":"cuda_runtime","name":"cudaLaunchKernel","pid":7,"tid":193,"ts":1677891894792358,"dur":5},{"ph":"X","cat":"kernel","name":"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)","pid":0,"tid":7,"ts":1677891894933759,"dur":5},{"ph":"X","cat":"kernel","name":"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)","pid":0,"tid":7,"ts":1677891894933765,"dur":2},{"ph":"X","cat":"gpu_memcpy","name":"Memcpy DtoD (Device -> Device)","pid":0,"tid":7,"ts":1677891894933769,"dur":1310},{"ph":"X","cat":"kernel","name":"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#14}::operator()() const::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_fill_kernel<bool>(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#14}::operator()() const::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)","pid":0,"tid":7,"ts":1677891894935080,"dur":1471},{"ph":"X","cat":"kernel","name":"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)","pid":0,"tid":7,"ts":1677891894936553,"dur":1952}]