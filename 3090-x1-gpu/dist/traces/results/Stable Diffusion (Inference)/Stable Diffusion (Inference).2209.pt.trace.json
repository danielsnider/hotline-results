[{"ph":"X","cat":"cpu_op","name":"aten::add","pid":18,"tid":18,"ts":1677894811200959,"dur":17},{"ph":"X","cat":"cuda_runtime","name":"cudaLaunchKernel","pid":18,"tid":18,"ts":1677894811200968,"dur":5},{"ph":"X","cat":"cpu_op","name":"aten::zeros","pid":18,"tid":18,"ts":1677894811201070,"dur":6},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894811201072,"dur":2},{"ph":"X","cat":"cpu_op","name":"aten::zero_","pid":18,"tid":18,"ts":1677894811201075,"dur":1},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894811201084,"dur":1},{"ph":"X","cat":"cpu_op","name":"aten::zeros","pid":18,"tid":18,"ts":1677894811201177,"dur":3},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894811201177,"dur":2},{"ph":"X","cat":"cpu_op","name":"aten::zero_","pid":18,"tid":18,"ts":1677894811201180,"dur":0},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894811201186,"dur":1},{"ph":"X","cat":"cpu_op","name":"aten::group_norm","pid":18,"tid":18,"ts":1677894811201209,"dur":83},{"ph":"X","cat":"cpu_op","name":"aten::native_group_norm","pid":18,"tid":18,"ts":1677894811201210,"dur":80},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894811201216,"dur":7},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894811201225,"dur":4},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894811201230,"dur":4},{"ph":"X","cat":"cuda_runtime","name":"cudaLaunchKernel","pid":18,"tid":18,"ts":1677894811201237,"dur":12},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894811201251,"dur":5},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894811201257,"dur":5},{"ph":"X","cat":"cuda_runtime","name":"cudaLaunchKernel","pid":18,"tid":18,"ts":1677894811201263,"dur":5},{"ph":"X","cat":"cpu_op","name":"aten::view","pid":18,"tid":18,"ts":1677894811201270,"dur":1},{"ph":"X","cat":"cpu_op","name":"aten::view","pid":18,"tid":18,"ts":1677894811201272,"dur":0},{"ph":"X","cat":"cpu_op","name":"aten::view","pid":18,"tid":18,"ts":1677894811201273,"dur":0},{"ph":"X","cat":"cpu_op","name":"aten::view","pid":18,"tid":18,"ts":1677894811201274,"dur":0},{"ph":"X","cat":"cuda_runtime","name":"cudaLaunchKernel","pid":18,"tid":18,"ts":1677894811201280,"dur":5},{"ph":"X","cat":"kernel","name":"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)","pid":0,"tid":7,"ts":1677894811200975,"dur":2},{"ph":"X","cat":"kernel","name":"void at::native::(anonymous namespace)::RowwiseMomentsCUDAKernel<float>(long, float, float const*, float*, float*)","pid":0,"tid":7,"ts":1677894811201250,"dur":4},{"ph":"X","cat":"kernel","name":"void at::native::(anonymous namespace)::ComputeFusedParamsCUDAKernel<float>(long, long, long, float const*, float const*, float const*, float const*, at::AccumulateType<float, true>::type*, at::AccumulateType<float, true>::type*)","pid":0,"tid":7,"ts":1677894811201269,"dur":2},{"ph":"X","cat":"kernel","name":"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::GroupNormKernelImplInternal<float>(at::Tensor const&, at::Tensor const&, at::Tensor const&, long, long, long, long, float, at::Tensor&, at::Tensor&, at::Tensor&)::{lambda(float, float, float)#2}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::GroupNormKernelImplInternal<float>(at::Tensor const&, at::Tensor const&, at::Tensor const&, long, long, long, long, float, at::Tensor&, at::Tensor&, at::Tensor&)::{lambda(float, float, float)#2} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::GroupNormKernelImplInternal<float>(at::Tensor const&, at::Tensor const&, at::Tensor const&, long, long, long, long, float, at::Tensor&, at::Tensor&, at::Tensor&)::{lambda(float, float, float)#2}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::GroupNormKernelImplInternal<float>(at::Tensor const&, at::Tensor const&, at::Tensor const&, long, long, long, long, float, at::Tensor&, at::Tensor&, at::Tensor&)::{lambda(float, float, float)#2} const&)::{lambda(int)#1})","pid":0,"tid":7,"ts":1677894811201287,"dur":3}]