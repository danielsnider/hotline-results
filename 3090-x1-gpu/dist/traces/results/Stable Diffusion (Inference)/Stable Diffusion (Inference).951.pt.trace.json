[{"ph":"X","cat":"cpu_op","name":"aten::add","pid":18,"tid":18,"ts":1677894810961460,"dur":17},{"ph":"X","cat":"cuda_runtime","name":"cudaLaunchKernel","pid":18,"tid":18,"ts":1677894810961469,"dur":6},{"ph":"X","cat":"cpu_op","name":"aten::zeros","pid":18,"tid":18,"ts":1677894810961569,"dur":5},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810961570,"dur":2},{"ph":"X","cat":"cpu_op","name":"aten::zero_","pid":18,"tid":18,"ts":1677894810961573,"dur":0},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810961580,"dur":1},{"ph":"X","cat":"cpu_op","name":"aten::zeros","pid":18,"tid":18,"ts":1677894810961657,"dur":3},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810961658,"dur":1},{"ph":"X","cat":"cpu_op","name":"aten::zero_","pid":18,"tid":18,"ts":1677894810961660,"dur":0},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810961665,"dur":1},{"ph":"X","cat":"cpu_op","name":"aten::group_norm","pid":18,"tid":18,"ts":1677894810961682,"dur":74},{"ph":"X","cat":"cpu_op","name":"aten::native_group_norm","pid":18,"tid":18,"ts":1677894810961684,"dur":71},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810961689,"dur":6},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810961696,"dur":4},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810961700,"dur":4},{"ph":"X","cat":"cuda_runtime","name":"cudaLaunchKernel","pid":18,"tid":18,"ts":1677894810961706,"dur":10},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810961718,"dur":4},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810961723,"dur":4},{"ph":"X","cat":"cuda_runtime","name":"cudaLaunchKernel","pid":18,"tid":18,"ts":1677894810961727,"dur":5},{"ph":"X","cat":"cpu_op","name":"aten::view","pid":18,"tid":18,"ts":1677894810961734,"dur":1},{"ph":"X","cat":"cpu_op","name":"aten::view","pid":18,"tid":18,"ts":1677894810961736,"dur":1},{"ph":"X","cat":"cpu_op","name":"aten::view","pid":18,"tid":18,"ts":1677894810961737,"dur":1},{"ph":"X","cat":"cpu_op","name":"aten::view","pid":18,"tid":18,"ts":1677894810961738,"dur":1},{"ph":"X","cat":"cuda_runtime","name":"cudaLaunchKernel","pid":18,"tid":18,"ts":1677894810961744,"dur":5},{"ph":"X","cat":"kernel","name":"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)","pid":0,"tid":7,"ts":1677894810961476,"dur":2},{"ph":"X","cat":"kernel","name":"void at::native::(anonymous namespace)::RowwiseMomentsCUDAKernel<float>(long, float, float const*, float*, float*)","pid":0,"tid":7,"ts":1677894810961717,"dur":4},{"ph":"X","cat":"kernel","name":"void at::native::(anonymous namespace)::ComputeFusedParamsCUDAKernel<float>(long, long, long, float const*, float const*, float const*, float const*, at::AccumulateType<float, true>::type*, at::AccumulateType<float, true>::type*)","pid":0,"tid":7,"ts":1677894810961734,"dur":2},{"ph":"X","cat":"kernel","name":"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::GroupNormKernelImplInternal<float>(at::Tensor const&, at::Tensor const&, at::Tensor const&, long, long, long, long, float, at::Tensor&, at::Tensor&, at::Tensor&)::{lambda(float, float, float)#2}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::GroupNormKernelImplInternal<float>(at::Tensor const&, at::Tensor const&, at::Tensor const&, long, long, long, long, float, at::Tensor&, at::Tensor&, at::Tensor&)::{lambda(float, float, float)#2} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::GroupNormKernelImplInternal<float>(at::Tensor const&, at::Tensor const&, at::Tensor const&, long, long, long, long, float, at::Tensor&, at::Tensor&, at::Tensor&)::{lambda(float, float, float)#2}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::GroupNormKernelImplInternal<float>(at::Tensor const&, at::Tensor const&, at::Tensor const&, long, long, long, long, float, at::Tensor&, at::Tensor&, at::Tensor&)::{lambda(float, float, float)#2} const&)::{lambda(int)#1})","pid":0,"tid":7,"ts":1677894810961751,"dur":3}]