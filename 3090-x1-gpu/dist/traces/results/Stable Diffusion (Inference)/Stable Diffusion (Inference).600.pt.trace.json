[{"ph":"X","cat":"cpu_op","name":"aten::add","pid":18,"tid":18,"ts":1677894810890966,"dur":18},{"ph":"X","cat":"cuda_runtime","name":"cudaLaunchKernel","pid":18,"tid":18,"ts":1677894810890976,"dur":6},{"ph":"X","cat":"cpu_op","name":"aten::zeros","pid":18,"tid":18,"ts":1677894810891081,"dur":6},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810891082,"dur":3},{"ph":"X","cat":"cpu_op","name":"aten::zero_","pid":18,"tid":18,"ts":1677894810891086,"dur":0},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810891095,"dur":1},{"ph":"X","cat":"cpu_op","name":"aten::zeros","pid":18,"tid":18,"ts":1677894810891185,"dur":3},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810891186,"dur":1},{"ph":"X","cat":"cpu_op","name":"aten::zero_","pid":18,"tid":18,"ts":1677894810891188,"dur":0},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810891195,"dur":0},{"ph":"X","cat":"cpu_op","name":"aten::group_norm","pid":18,"tid":18,"ts":1677894810891218,"dur":82},{"ph":"X","cat":"cpu_op","name":"aten::native_group_norm","pid":18,"tid":18,"ts":1677894810891219,"dur":79},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810891225,"dur":7},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810891234,"dur":4},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810891239,"dur":4},{"ph":"X","cat":"cuda_runtime","name":"cudaLaunchKernel","pid":18,"tid":18,"ts":1677894810891247,"dur":12},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810891261,"dur":4},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810891266,"dur":4},{"ph":"X","cat":"cuda_runtime","name":"cudaLaunchKernel","pid":18,"tid":18,"ts":1677894810891271,"dur":5},{"ph":"X","cat":"cpu_op","name":"aten::view","pid":18,"tid":18,"ts":1677894810891277,"dur":2},{"ph":"X","cat":"cpu_op","name":"aten::view","pid":18,"tid":18,"ts":1677894810891280,"dur":0},{"ph":"X","cat":"cpu_op","name":"aten::view","pid":18,"tid":18,"ts":1677894810891281,"dur":0},{"ph":"X","cat":"cpu_op","name":"aten::view","pid":18,"tid":18,"ts":1677894810891282,"dur":1},{"ph":"X","cat":"cuda_runtime","name":"cudaLaunchKernel","pid":18,"tid":18,"ts":1677894810891288,"dur":5},{"ph":"X","cat":"kernel","name":"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)","pid":0,"tid":7,"ts":1677894810891208,"dur":2},{"ph":"X","cat":"kernel","name":"void at::native::(anonymous namespace)::RowwiseMomentsCUDAKernel<float>(long, float, float const*, float*, float*)","pid":0,"tid":7,"ts":1677894810891260,"dur":3},{"ph":"X","cat":"kernel","name":"void at::native::(anonymous namespace)::ComputeFusedParamsCUDAKernel<float>(long, long, long, float const*, float const*, float const*, float const*, at::AccumulateType<float, true>::type*, at::AccumulateType<float, true>::type*)","pid":0,"tid":7,"ts":1677894810891277,"dur":2},{"ph":"X","cat":"kernel","name":"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::GroupNormKernelImplInternal<float>(at::Tensor const&, at::Tensor const&, at::Tensor const&, long, long, long, long, float, at::Tensor&, at::Tensor&, at::Tensor&)::{lambda(float, float, float)#2}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::GroupNormKernelImplInternal<float>(at::Tensor const&, at::Tensor const&, at::Tensor const&, long, long, long, long, float, at::Tensor&, at::Tensor&, at::Tensor&)::{lambda(float, float, float)#2} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::GroupNormKernelImplInternal<float>(at::Tensor const&, at::Tensor const&, at::Tensor const&, long, long, long, long, float, at::Tensor&, at::Tensor&, at::Tensor&)::{lambda(float, float, float)#2}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::GroupNormKernelImplInternal<float>(at::Tensor const&, at::Tensor const&, at::Tensor const&, long, long, long, long, float, at::Tensor&, at::Tensor&, at::Tensor&)::{lambda(float, float, float)#2} const&)::{lambda(int)#1})","pid":0,"tid":7,"ts":1677894810891295,"dur":2}]