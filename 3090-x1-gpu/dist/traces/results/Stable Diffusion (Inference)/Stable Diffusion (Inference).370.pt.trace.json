[{"ph":"X","cat":"cpu_op","name":"aten::add","pid":18,"tid":18,"ts":1677894810844909,"dur":19},{"ph":"X","cat":"cuda_runtime","name":"cudaLaunchKernel","pid":18,"tid":18,"ts":1677894810844919,"dur":7},{"ph":"X","cat":"cpu_op","name":"aten::zeros","pid":18,"tid":18,"ts":1677894810845017,"dur":5},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810845018,"dur":2},{"ph":"X","cat":"cpu_op","name":"aten::zero_","pid":18,"tid":18,"ts":1677894810845021,"dur":1},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810845029,"dur":2},{"ph":"X","cat":"cpu_op","name":"aten::zeros","pid":18,"tid":18,"ts":1677894810845126,"dur":4},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810845127,"dur":1},{"ph":"X","cat":"cpu_op","name":"aten::zero_","pid":18,"tid":18,"ts":1677894810845129,"dur":0},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810845136,"dur":1},{"ph":"X","cat":"cpu_op","name":"aten::group_norm","pid":18,"tid":18,"ts":1677894810845159,"dur":89},{"ph":"X","cat":"cpu_op","name":"aten::native_group_norm","pid":18,"tid":18,"ts":1677894810845160,"dur":87},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810845166,"dur":7},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810845175,"dur":4},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810845180,"dur":5},{"ph":"X","cat":"cuda_runtime","name":"cudaLaunchKernel","pid":18,"tid":18,"ts":1677894810845188,"dur":12},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810845202,"dur":5},{"ph":"X","cat":"cpu_op","name":"aten::empty","pid":18,"tid":18,"ts":1677894810845208,"dur":5},{"ph":"X","cat":"cuda_runtime","name":"cudaLaunchKernel","pid":18,"tid":18,"ts":1677894810845213,"dur":6},{"ph":"X","cat":"cpu_op","name":"aten::view","pid":18,"tid":18,"ts":1677894810845221,"dur":2},{"ph":"X","cat":"cpu_op","name":"aten::view","pid":18,"tid":18,"ts":1677894810845224,"dur":1},{"ph":"X","cat":"cpu_op","name":"aten::view","pid":18,"tid":18,"ts":1677894810845226,"dur":0},{"ph":"X","cat":"cpu_op","name":"aten::view","pid":18,"tid":18,"ts":1677894810845227,"dur":1},{"ph":"X","cat":"cuda_runtime","name":"cudaLaunchKernel","pid":18,"tid":18,"ts":1677894810845234,"dur":6},{"ph":"X","cat":"kernel","name":"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)","pid":0,"tid":7,"ts":1677894810844927,"dur":3},{"ph":"X","cat":"kernel","name":"void at::native::(anonymous namespace)::RowwiseMomentsCUDAKernel<float>(long, float, float const*, float*, float*)","pid":0,"tid":7,"ts":1677894810845200,"dur":4},{"ph":"X","cat":"kernel","name":"void at::native::(anonymous namespace)::ComputeFusedParamsCUDAKernel<float>(long, long, long, float const*, float const*, float const*, float const*, at::AccumulateType<float, true>::type*, at::AccumulateType<float, true>::type*)","pid":0,"tid":7,"ts":1677894810845221,"dur":2},{"ph":"X","cat":"kernel","name":"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::GroupNormKernelImplInternal<float>(at::Tensor const&, at::Tensor const&, at::Tensor const&, long, long, long, long, float, at::Tensor&, at::Tensor&, at::Tensor&)::{lambda(float, float, float)#2}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::GroupNormKernelImplInternal<float>(at::Tensor const&, at::Tensor const&, at::Tensor const&, long, long, long, long, float, at::Tensor&, at::Tensor&, at::Tensor&)::{lambda(float, float, float)#2} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl<at::native::(anonymous namespace)::GroupNormKernelImplInternal<float>(at::Tensor const&, at::Tensor const&, at::Tensor const&, long, long, long, long, float, at::Tensor&, at::Tensor&, at::Tensor&)::{lambda(float, float, float)#2}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::GroupNormKernelImplInternal<float>(at::Tensor const&, at::Tensor const&, at::Tensor const&, long, long, long, long, float, at::Tensor&, at::Tensor&, at::Tensor&)::{lambda(float, float, float)#2} const&)::{lambda(int)#1})","pid":0,"tid":7,"ts":1677894810845242,"dur":3}]